Running script with Seed: 1
Running script with ent coef: .001
Running script with Seed: 1
Running script with ent coef: .002
Running script with Seed: 2
Running script with ent coef: .001
Running script with Seed: 2
Running script with ent coef: .002
Running script with Seed: 3
Running script with ent coef: .001
Running script with Seed: 3
Running script with ent coef: .002
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240225_154732-4ts77xgw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-valley-23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/4ts77xgw
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240225_154734-mtgakx2v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-monkey-24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/mtgakx2v
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240225_234734-pe6a45mq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-pine-24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/pe6a45mq
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240225_234734-uhktx3ql
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-night-26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/uhktx3ql
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240225_154734-7xavsi5z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-haze-27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/7xavsi5z
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240225_234734-p13vkfbg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-lion-28
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/p13vkfbg
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
Using cpu device
------------------------------------
| avg_speed          | 0.319       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.319       |
| reward             | -0.39735815 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.12e+03   |
| time/              |             |
|    fps             | 86          |
|    iterations      | 1           |
|    time_elapsed    | 23          |
|    total_timesteps | 2048        |
------------------------------------
Using cpu device
------------------------------------
| avg_speed          | 1.96        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 1.96        |
| reward             | -0.41150528 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.56e+03   |
| time/              |             |
|    fps             | 89          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 2048        |
------------------------------------
Using cpu device
------------------------------------
| avg_speed          | 0.319       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.319       |
| reward             | -0.39735815 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.12e+03   |
| time/              |             |
|    fps             | 89          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 2048        |
------------------------------------
Using cpu device
------------------------------------
| avg_speed          | 1.96        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 1.96        |
| reward             | -0.41150528 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.56e+03   |
| time/              |             |
|    fps             | 86          |
|    iterations      | 1           |
|    time_elapsed    | 23          |
|    total_timesteps | 2048        |
------------------------------------
Using cpu device
-----------------------------------
| avg_speed          | 0.995      |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.995      |
| reward             | -0.5212695 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -1.2e+03   |
| time/              |            |
|    fps             | 85         |
|    iterations      | 1          |
|    time_elapsed    | 23         |
|    total_timesteps | 2048       |
-----------------------------------
Using cpu device
-----------------------------------
| avg_speed          | 0.995      |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.995      |
| reward             | -0.5212695 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -1.2e+03   |
| time/              |            |
|    fps             | 75         |
|    iterations      | 1          |
|    time_elapsed    | 27         |
|    total_timesteps | 2048       |
-----------------------------------
-------------------------------------------
| avg_speed                | 1.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.94         |
| reward                   | -0.5134541   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 81           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0040029883 |
|    clip_fraction         | 0.0276       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.183        |
|    cost_value_loss       | 2.52         |
|    cost_values           | 0.069        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.00201      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 159          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 0.997        |
|    value_loss            | 342          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.95        |
| reward                   | -0.5154107  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 84          |
|    iterations            | 2           |
|    time_elapsed          | 48          |
|    total_timesteps       | 4096        |
| train/                   |             |
|    approx_kl             | 0.004074916 |
|    clip_fraction         | 0.028       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.183       |
|    cost_value_loss       | 2.52        |
|    cost_values           | 0.069       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.00201     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 159         |
|    n_updates             | 10          |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.998       |
|    value_loss            | 342         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.51         |
| reward                   | -0.8889363   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.5e+03     |
| time/                    |              |
|    fps                   | 84           |
|    iterations            | 2            |
|    time_elapsed          | 48           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0040971683 |
|    clip_fraction         | 0.0385       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.184        |
|    cost_value_loss       | 0.873        |
|    cost_values           | 0.0611       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0055       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 314          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 1.01         |
|    value_loss            | 694          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.543       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.543       |
| reward                   | -0.31484848 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 81          |
|    iterations            | 2           |
|    time_elapsed          | 50          |
|    total_timesteps       | 4096        |
| train/                   |             |
|    approx_kl             | 0.002224312 |
|    clip_fraction         | 0.0193      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.535       |
|    cost_value_loss       | 2.42        |
|    cost_values           | 0.115       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0161      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 175         |
|    n_updates             | 10          |
|    policy_gradient_loss  | -0.00234    |
|    std                   | 1           |
|    value_loss            | 408         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.74         |
| reward                   | -2.5156183   |
| rollout/                 |              |
|    ep_len_mean           | 880          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 50           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0040932326 |
|    clip_fraction         | 0.0391       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.184        |
|    cost_value_loss       | 0.873        |
|    cost_values           | 0.0611       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0055       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 314          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00361     |
|    std                   | 1.01         |
|    value_loss            | 694          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.544        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.544        |
| reward                   | -0.3145315   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 2            |
|    time_elapsed          | 55           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0022206455 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.535        |
|    cost_value_loss       | 2.42         |
|    cost_values           | 0.115        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0161       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 175          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00234     |
|    std                   | 1            |
|    value_loss            | 408          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.13         |
| reward                   | -0.64236957  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.57e+03    |
| time/                    |              |
|    fps                   | 81           |
|    iterations            | 3            |
|    time_elapsed          | 75           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0038844354 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.729        |
|    cost_value_loss       | 3.07         |
|    cost_values           | 0.353        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0576       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 317          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 1            |
|    value_loss            | 638          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.708        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.708        |
| reward                   | -0.61965317  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 81           |
|    iterations            | 3            |
|    time_elapsed          | 75           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0053043077 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.664        |
|    cost_value_loss       | 4.07         |
|    cost_values           | 0.243        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0782       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 127          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.996        |
|    value_loss            | 286          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.756        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.756        |
| reward                   | -0.6099979   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 78           |
|    iterations            | 3            |
|    time_elapsed          | 78           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0055072512 |
|    clip_fraction         | 0.0397       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.649        |
|    cost_value_loss       | 4.16         |
|    cost_values           | 0.241        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0749       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 120          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 0.995        |
|    value_loss            | 271          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.64         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.64         |
| reward                   | -0.49148872  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 78           |
|    iterations            | 3            |
|    time_elapsed          | 77           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0047857477 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.743        |
|    cost_value_loss       | 4.36         |
|    cost_values           | 0.4          |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0875       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 170          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 1.01         |
|    value_loss            | 354          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.03         |
| reward                   | -1.4435618   |
| rollout/                 |              |
|    ep_len_mean           | 920          |
|    ep_rew_mean           | -1.52e+03    |
| time/                    |              |
|    fps                   | 78           |
|    iterations            | 3            |
|    time_elapsed          | 78           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0038432628 |
|    clip_fraction         | 0.00986      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.645        |
|    cost_value_loss       | 2.41         |
|    cost_values           | 0.342        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0521       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 350          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 1            |
|    value_loss            | 702          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.631        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.631        |
| reward                   | -0.49402416  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 3            |
|    time_elapsed          | 86           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0045377007 |
|    clip_fraction         | 0.0342       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.743        |
|    cost_value_loss       | 4.36         |
|    cost_values           | 0.4          |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0873       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 170          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 1.01         |
|    value_loss            | 354          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.35        |
| reward                   | -1.0283196  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.51e+03   |
| time/                    |             |
|    fps                   | 79          |
|    iterations            | 4           |
|    time_elapsed          | 102         |
|    total_timesteps       | 8192        |
| train/                   |             |
|    approx_kl             | 0.004866104 |
|    clip_fraction         | 0.0306      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.626       |
|    cost_value_loss       | 1.29        |
|    cost_values           | 0.543       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0433      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 376         |
|    n_updates             | 30          |
|    policy_gradient_loss  | -0.003      |
|    std                   | 0.997       |
|    value_loss            | 802         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.25         |
| reward                   | -0.8286822   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 79           |
|    iterations            | 4            |
|    time_elapsed          | 102          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0024659035 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.539        |
|    cost_value_loss       | 0.554        |
|    cost_values           | 0.466        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.128        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 111          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 0.993        |
|    value_loss            | 232          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.84         |
| reward                   | -0.75644135  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 76           |
|    iterations            | 4            |
|    time_elapsed          | 106          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0048419456 |
|    clip_fraction         | 0.0376       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.563        |
|    cost_value_loss       | 0.657        |
|    cost_values           | 0.463        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0904       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 235          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00348     |
|    std                   | 0.997        |
|    value_loss            | 472          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.51         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.51         |
| reward                   | -0.41781145  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 77           |
|    iterations            | 4            |
|    time_elapsed          | 106          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0052506262 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 8.14         |
|    cost_values           | 0.807        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.149        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 141          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 1.01         |
|    value_loss            | 296          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.69        |
| reward                   | -2.7868998  |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -1.57e+03   |
| time/                    |             |
|    fps                   | 76          |
|    iterations            | 4           |
|    time_elapsed          | 106         |
|    total_timesteps       | 8192        |
| train/                   |             |
|    approx_kl             | 0.004732402 |
|    clip_fraction         | 0.0257      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.651       |
|    cost_value_loss       | 1.52        |
|    cost_values           | 0.533       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0331      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 467         |
|    n_updates             | 30          |
|    policy_gradient_loss  | -0.00143    |
|    std                   | 0.999       |
|    value_loss            | 962         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0259       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0259       |
| reward                   | -0.4376974   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 4            |
|    time_elapsed          | 117          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0035461462 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 8.07         |
|    cost_values           | 0.797        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.116        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 181          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 1.01         |
|    value_loss            | 357          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.97         |
| reward                   | -0.5445647   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 78           |
|    iterations            | 5            |
|    time_elapsed          | 130          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0035545998 |
|    clip_fraction         | 0.00825      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.725        |
|    cost_value_loss       | 1.9          |
|    cost_values           | 0.561        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0576       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 203          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.000983    |
|    std                   | 0.988        |
|    value_loss            | 443          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.05         |
| reward                   | -0.33170626  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.48e+03    |
| time/                    |              |
|    fps                   | 78           |
|    iterations            | 5            |
|    time_elapsed          | 130          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0028571356 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.676        |
|    cost_value_loss       | 1.28         |
|    cost_values           | 0.603        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0257       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 270          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.997        |
|    value_loss            | 547          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -1.1710106   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 5            |
|    time_elapsed          | 135          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0031450125 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 4.97         |
|    cost_values           | 0.696        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0677       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 185          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.994        |
|    value_loss            | 408          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.09         |
| reward                   | -0.9955411   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 5            |
|    time_elapsed          | 135          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0035695317 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 0.939        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.109        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 288          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00245     |
|    std                   | 1            |
|    value_loss            | 579          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -2.1036634   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -1.56e+03    |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 5            |
|    time_elapsed          | 135          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0028603594 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.708        |
|    cost_value_loss       | 1.47         |
|    cost_values           | 0.601        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0378       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 533          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 1            |
|    value_loss            | 1.08e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.66         |
| reward                   | -0.91133416  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 5            |
|    time_elapsed          | 150          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0020926818 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 0.929        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.102        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 260          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 1            |
|    value_loss            | 526          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.526        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.526        |
| reward                   | -0.6811168   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 77           |
|    iterations            | 6            |
|    time_elapsed          | 159          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0050826194 |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.728        |
|    cost_value_loss       | 1.14         |
|    cost_values           | 0.664        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0508       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 114          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.987        |
|    value_loss            | 233          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.08        |
| reward                   | -0.49191353 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.42e+03   |
| time/                    |             |
|    fps                   | 76          |
|    iterations            | 6           |
|    time_elapsed          | 159         |
|    total_timesteps       | 12288       |
| train/                   |             |
|    approx_kl             | 0.004810377 |
|    clip_fraction         | 0.0381      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.937       |
|    cost_value_loss       | 3.09        |
|    cost_values           | 0.764       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0576      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 251         |
|    n_updates             | 50          |
|    policy_gradient_loss  | -0.00408    |
|    std                   | 1           |
|    value_loss            | 510         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.989        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.989        |
| reward                   | -0.2093453   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 74           |
|    iterations            | 6            |
|    time_elapsed          | 164          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0055861236 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 8.93         |
|    cost_values           | 0.903        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0698       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 241          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00185     |
|    std                   | 0.995        |
|    value_loss            | 467          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0646747   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 74           |
|    iterations            | 6            |
|    time_elapsed          | 164          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0021985362 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 16.5         |
|    cost_values           | 0.956        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.169        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 114          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00283     |
|    std                   | 1            |
|    value_loss            | 222          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.21        |
| reward                   | -2.606396   |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -1.56e+03   |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 6           |
|    time_elapsed          | 165         |
|    total_timesteps       | 12288       |
| train/                   |             |
|    approx_kl             | 0.003939522 |
|    clip_fraction         | 0.0289      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 3.07        |
|    cost_values           | 0.73        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0378      |
|    lagrangian_multiplier | 0.000397    |
|    learning_rate         | 0.0003      |
|    loss                  | 247         |
|    n_updates             | 50          |
|    policy_gradient_loss  | -0.0034     |
|    std                   | 1           |
|    value_loss            | 574         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.3787982   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 6            |
|    time_elapsed          | 183          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0028416435 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 2.36         |
|    cost_values           | 0.976        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0772       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 158          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 1.01         |
|    value_loss            | 319          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.96         |
| reward                   | -0.63947713  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 7            |
|    time_elapsed          | 188          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0021827202 |
|    clip_fraction         | 0.00806      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.823        |
|    cost_value_loss       | 1.2          |
|    cost_values           | 0.757        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0402       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 200          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.983        |
|    value_loss            | 403          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.216451    |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 7            |
|    time_elapsed          | 191          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0018518143 |
|    clip_fraction         | 0.00864      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.923        |
|    cost_value_loss       | 1.06         |
|    cost_values           | 0.864        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0449       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 179          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00185     |
|    std                   | 1            |
|    value_loss            | 377          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.62         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.62         |
| reward                   | -0.44971618  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 7            |
|    time_elapsed          | 195          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0019310432 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.61         |
|    cost_values           | 0.939        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0921       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 138          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 0.988        |
|    value_loss            | 275          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -1.5824392   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 7            |
|    time_elapsed          | 194          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0022493983 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 8.87         |
|    cost_values           | 0.965        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.152        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 192          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.998        |
|    value_loss            | 382          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -2.5072975   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -1.58e+03    |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 7            |
|    time_elapsed          | 196          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0045696627 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 4.51         |
|    cost_values           | 0.878        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0658       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 364          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 1            |
|    value_loss            | 760          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.8703262   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 7            |
|    time_elapsed          | 218          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0031028646 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 4.89         |
|    cost_values           | 0.971        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0707       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 339          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 1            |
|    value_loss            | 664          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.52        |
| reward                   | -0.7903343  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 8           |
|    time_elapsed          | 219         |
|    total_timesteps       | 16384       |
| train/                   |             |
|    approx_kl             | 0.004159013 |
|    clip_fraction         | 0.0272      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.84        |
|    cost_value_loss       | 14.8        |
|    cost_values           | 0.906       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.13        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 180         |
|    n_updates             | 70          |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.977       |
|    value_loss            | 346         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3236374   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 8            |
|    time_elapsed          | 224          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0032491973 |
|    clip_fraction         | 0.00601      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 9.31         |
|    cost_values           | 0.877        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0679       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 245          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 1            |
|    value_loss            | 478          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.9         |
| reward                   | -1.0968822  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 8           |
|    time_elapsed          | 226         |
|    total_timesteps       | 16384       |
| train/                   |             |
|    approx_kl             | 0.003724829 |
|    clip_fraction         | 0.0335      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 5.14        |
|    cost_values           | 0.946       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.0863      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 151         |
|    n_updates             | 70          |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.986       |
|    value_loss            | 307         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.2          |
| reward                   | -1.3645293   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 8            |
|    time_elapsed          | 226          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0016922383 |
|    clip_fraction         | 0.00645      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 3.86         |
|    cost_values           | 0.988        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0802       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 134          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.996        |
|    value_loss            | 272          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -1.5056558  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -1.57e+03   |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 8           |
|    time_elapsed          | 228         |
|    total_timesteps       | 16384       |
| train/                   |             |
|    approx_kl             | 0.003407918 |
|    clip_fraction         | 0.0177      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.35        |
|    cost_value_loss       | 4.57        |
|    cost_values           | 0.885       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0453      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 379         |
|    n_updates             | 70          |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 1.01        |
|    value_loss            | 812         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.74         |
| reward                   | -1.0960442   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 9            |
|    time_elapsed          | 251          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0017619604 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 3.72         |
|    cost_values           | 0.96         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.0523       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 207          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.976        |
|    value_loss            | 437          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.11         |
| reward                   | -1.2601384   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 8            |
|    time_elapsed          | 255          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0049082693 |
|    clip_fraction         | 0.0357       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 2.73         |
|    cost_values           | 0.989        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0668       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 232          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 1            |
|    value_loss            | 467          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.0839716   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 9            |
|    time_elapsed          | 256          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0061312877 |
|    clip_fraction         | 0.0301       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 1.57         |
|    cost_values           | 0.961        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0302       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 214          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.0024      |
|    std                   | 0.999        |
|    value_loss            | 432          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -0.8540133   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 9            |
|    time_elapsed          | 259          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0043574832 |
|    clip_fraction         | 0.0347       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.993        |
|    cost_value_loss       | 0.982        |
|    cost_values           | 0.938        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.045        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 162          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.991        |
|    value_loss            | 336          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.08         |
| reward                   | -0.818458    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 9            |
|    time_elapsed          | 258          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0049107196 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 1.16         |
|    cost_values           | 0.993        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0258       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 268          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 0.994        |
|    value_loss            | 561          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -1.5881703   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -1.45e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 9            |
|    time_elapsed          | 264          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0055799456 |
|    clip_fraction         | 0.0401       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 5.18         |
|    cost_values           | 0.918        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0765       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 246          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00322     |
|    std                   | 1.01         |
|    value_loss            | 513          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.34        |
| reward                   | -1.0650924  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 10          |
|    time_elapsed          | 283         |
|    total_timesteps       | 20480       |
| train/                   |             |
|    approx_kl             | 0.004229892 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 5.66        |
|    cost_values           | 0.955       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.0768      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 114         |
|    n_updates             | 90          |
|    policy_gradient_loss  | -0.00417    |
|    std                   | 0.975       |
|    value_loss            | 242         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.8223861   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 10           |
|    time_elapsed          | 289          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0034337197 |
|    clip_fraction         | 0.0507       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.99         |
|    cost_value_loss       | 1.06         |
|    cost_values           | 0.922        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0548       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 190          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.0056      |
|    std                   | 1            |
|    value_loss            | 408          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7663193   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 10           |
|    time_elapsed          | 291          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0053451257 |
|    clip_fraction         | 0.0426       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 2.33         |
|    cost_values           | 0.949        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0784       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 135          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00481     |
|    std                   | 0.99         |
|    value_loss            | 285          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.63577086  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 10           |
|    time_elapsed          | 290          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0059290933 |
|    clip_fraction         | 0.0582       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 5.62         |
|    cost_values           | 0.994        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0512       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 211          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00393     |
|    std                   | 0.996        |
|    value_loss            | 414          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -1.3484126   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 9            |
|    time_elapsed          | 290          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0026157806 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.935        |
|    cost_value_loss       | 0.537        |
|    cost_values           | 0.977        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0246       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 361          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 1            |
|    value_loss            | 742          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.7449124  |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 10          |
|    time_elapsed          | 305         |
|    total_timesteps       | 20480       |
| train/                   |             |
|    approx_kl             | 0.004263106 |
|    clip_fraction         | 0.026       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 0.947       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0826      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 164         |
|    n_updates             | 90          |
|    policy_gradient_loss  | -0.00341    |
|    std                   | 1.01        |
|    value_loss            | 332         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -1.2720581   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 11           |
|    time_elapsed          | 316          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0042122584 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 3.2          |
|    cost_values           | 0.961        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.0331       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 158          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.976        |
|    value_loss            | 335          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1820159   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 322          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0048974706 |
|    clip_fraction         | 0.0456       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 4.2          |
|    cost_values           | 0.948        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0299       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 296          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00395     |
|    std                   | 1            |
|    value_loss            | 614          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.22         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.22         |
| reward                   | -0.6515779   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 325          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0053866417 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 4.93         |
|    cost_values           | 0.973        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0704       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 0.986        |
|    value_loss            | 217          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0228215   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 11           |
|    time_elapsed          | 324          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0032627224 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 2.71         |
|    cost_values           | 0.982        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0329       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 181          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.993        |
|    value_loss            | 385          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.098996   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 10          |
|    time_elapsed          | 328         |
|    total_timesteps       | 20480       |
| train/                   |             |
|    approx_kl             | 0.005331997 |
|    clip_fraction         | 0.0516      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.41        |
|    cost_value_loss       | 16.8        |
|    cost_values           | 0.981       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.116       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 187         |
|    n_updates             | 90          |
|    policy_gradient_loss  | -0.00394    |
|    std                   | 1           |
|    value_loss            | 359         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2666017  |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -1.39e+03   |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 11          |
|    time_elapsed          | 348         |
|    total_timesteps       | 22528       |
| train/                   |             |
|    approx_kl             | 0.003469246 |
|    clip_fraction         | 0.0251      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.41        |
|    cost_value_loss       | 12.7        |
|    cost_values           | 0.967       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0887      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 225         |
|    n_updates             | 100         |
|    policy_gradient_loss  | -0.00324    |
|    std                   | 1.01        |
|    value_loss            | 435         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.2          |
| reward                   | -1.7675824   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 12           |
|    time_elapsed          | 349          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0031399257 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 2.01         |
|    cost_values           | 0.979        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.0477       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 112          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.979        |
|    value_loss            | 238          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -2.6584432   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 12           |
|    time_elapsed          | 357          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0049858955 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 6.68         |
|    cost_values           | 0.951        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0324       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 215          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.0039      |
|    std                   | 1            |
|    value_loss            | 453          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0677       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0677       |
| reward                   | -0.48668048  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 12           |
|    time_elapsed          | 360          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0028445704 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 5.3          |
|    cost_values           | 0.954        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0508       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 291          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 0.988        |
|    value_loss            | 558          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.66         |
| reward                   | -1.1143446   |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 12           |
|    time_elapsed          | 360          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0011328636 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 7.74         |
|    cost_values           | 0.985        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0463       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 202          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.992        |
|    value_loss            | 384          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1747742  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 368         |
|    total_timesteps       | 22528       |
| train/                   |             |
|    approx_kl             | 0.006955551 |
|    clip_fraction         | 0.0604      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 3.38        |
|    cost_values           | 0.987       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0307      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 252         |
|    n_updates             | 100         |
|    policy_gradient_loss  | -0.0045     |
|    std                   | 1           |
|    value_loss            | 518         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.65         |
| reward                   | -1.2679499   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 13           |
|    time_elapsed          | 384          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0050316527 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 3.69         |
|    cost_values           | 0.979        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.0236       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 192          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 0.981        |
|    value_loss            | 407          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.07         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.07         |
| reward                   | -0.56727254  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 12           |
|    time_elapsed          | 391          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0073416517 |
|    clip_fraction         | 0.0576       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 8.2          |
|    cost_values           | 0.992        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0358       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 330          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 1.01         |
|    value_loss            | 693          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.747        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.747        |
| reward                   | -0.8919894   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 13           |
|    time_elapsed          | 395          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0042542135 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 5.97         |
|    cost_values           | 0.969        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0314       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 249          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 0.988        |
|    value_loss            | 495          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.0672572   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 13           |
|    time_elapsed          | 393          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0056826416 |
|    clip_fraction         | 0.0395       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.2          |
|    cost_values           | 0.963        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0222       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 207          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00398     |
|    std                   | 1            |
|    value_loss            | 456          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.33         |
| reward                   | -1.6616479   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 13           |
|    time_elapsed          | 396          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0033720424 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 7.98         |
|    cost_values           | 0.987        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0637       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 95.5         |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00494     |
|    std                   | 0.985        |
|    value_loss            | 187          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.6096551   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 12           |
|    time_elapsed          | 409          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0023934343 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 2.96         |
|    cost_values           | 0.978        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.049        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 236          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 1            |
|    value_loss            | 454          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.57         |
| reward                   | -0.8717618   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 14           |
|    time_elapsed          | 420          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0043718684 |
|    clip_fraction         | 0.0357       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 20.7         |
|    cost_values           | 0.979        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.087        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 134          |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 0.977        |
|    value_loss            | 265          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -2.1495967   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 14           |
|    time_elapsed          | 431          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0029903972 |
|    clip_fraction         | 0.00781      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 12           |
|    cost_values           | 0.976        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.106        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 92.1         |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.989        |
|    value_loss            | 181          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.905649    |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 14           |
|    time_elapsed          | 430          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0045178393 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.56         |
|    cost_values           | 0.97         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0186       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 294          |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.999        |
|    value_loss            | 614          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -1.4620266  |
| rollout/                 |             |
|    ep_len_mean           | 925         |
|    ep_rew_mean           | -1.37e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 13          |
|    time_elapsed          | 430         |
|    total_timesteps       | 26624       |
| train/                   |             |
|    approx_kl             | 0.004071764 |
|    clip_fraction         | 0.0285      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.55        |
|    cost_value_loss       | 3.98        |
|    cost_values           | 0.989       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.035       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 243         |
|    n_updates             | 120         |
|    policy_gradient_loss  | -0.0034     |
|    std                   | 1           |
|    value_loss            | 502         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.64        |
| reward                   | -0.42034277 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 14          |
|    time_elapsed          | 433         |
|    total_timesteps       | 28672       |
| train/                   |             |
|    approx_kl             | 0.00553384  |
|    clip_fraction         | 0.0367      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.61        |
|    cost_value_loss       | 4.72        |
|    cost_values           | 0.995       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.0363      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 139         |
|    n_updates             | 130         |
|    policy_gradient_loss  | -0.003      |
|    std                   | 0.984       |
|    value_loss            | 283         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -1.5156175   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 13           |
|    time_elapsed          | 451          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0051211636 |
|    clip_fraction         | 0.0445       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 4.26         |
|    cost_values           | 0.972        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0495       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 294          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00332     |
|    std                   | 0.998        |
|    value_loss            | 598          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.7          |
| reward                   | -1.0951433   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 15           |
|    time_elapsed          | 456          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0040236614 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 1.32         |
|    cost_values           | 0.964        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.0221       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 110          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.974        |
|    value_loss            | 227          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -1.4693347  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 15          |
|    time_elapsed          | 468         |
|    total_timesteps       | 30720       |
| train/                   |             |
|    approx_kl             | 0.004605353 |
|    clip_fraction         | 0.0309      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 6.86        |
|    cost_values           | 0.984       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.0523      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 104         |
|    n_updates             | 140         |
|    policy_gradient_loss  | -0.00301    |
|    std                   | 0.986       |
|    value_loss            | 221         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.29         |
| reward                   | -1.1195571   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 15           |
|    time_elapsed          | 467          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0027843053 |
|    clip_fraction         | 0.00474      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.52         |
|    cost_values           | 0.957        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0588       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 172          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.997        |
|    value_loss            | 370          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.5895253   |
| rollout/                 |              |
|    ep_len_mean           | 902          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 14           |
|    time_elapsed          | 468          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0037430367 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 5.08         |
|    cost_values           | 0.992        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0685       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 155          |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00392     |
|    std                   | 0.999        |
|    value_loss            | 318          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.93       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.93       |
| reward                   | -2.2635553 |
| rollout/                 |            |
|    ep_len_mean           | 940        |
|    ep_rew_mean           | -1.08e+03  |
| time/                    |            |
|    fps                   | 65         |
|    iterations            | 15         |
|    time_elapsed          | 471        |
|    total_timesteps       | 30720      |
| train/                   |            |
|    approx_kl             | 0.00235138 |
|    clip_fraction         | 0.0105     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.33       |
|    cost_value_loss       | 14.6       |
|    cost_values           | 0.997      |
|    entropy               | -2.8       |
|    entropy_loss          | -2.81      |
|    explained_variance    | 0.0279     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 247        |
|    n_updates             | 140        |
|    policy_gradient_loss  | -0.00167   |
|    std                   | 0.984      |
|    value_loss            | 480        |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.3691916  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 16          |
|    time_elapsed          | 493         |
|    total_timesteps       | 32768       |
| train/                   |             |
|    approx_kl             | 0.004896408 |
|    clip_fraction         | 0.0492      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.21        |
|    cost_value_loss       | 1.38        |
|    cost_values           | 0.966       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.0284      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 89.7        |
|    n_updates             | 150         |
|    policy_gradient_loss  | -0.00458    |
|    std                   | 0.974       |
|    value_loss            | 187         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.5805918  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 57          |
|    iterations            | 14          |
|    time_elapsed          | 494         |
|    total_timesteps       | 28672       |
| train/                   |             |
|    approx_kl             | 0.003515435 |
|    clip_fraction         | 0.055       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.44        |
|    cost_value_loss       | 5.22        |
|    cost_values           | 0.974       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.074       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 277         |
|    n_updates             | 130         |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 1           |
|    value_loss            | 549         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -1.1181152   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 16           |
|    time_elapsed          | 504          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0076742535 |
|    clip_fraction         | 0.0864       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 3.51         |
|    cost_values           | 0.965        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.106        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 95.5         |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.00809     |
|    std                   | 0.998        |
|    value_loss            | 198          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -1.1815993  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 16          |
|    time_elapsed          | 508         |
|    total_timesteps       | 32768       |
| train/                   |             |
|    approx_kl             | 0.005367591 |
|    clip_fraction         | 0.0407      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 4.72        |
|    cost_values           | 0.987       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.0312      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 179         |
|    n_updates             | 150         |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.984       |
|    value_loss            | 381         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.42        |
| reward                   | -1.2147477  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 507         |
|    total_timesteps       | 30720       |
| train/                   |             |
|    approx_kl             | 0.002987422 |
|    clip_fraction         | 0.0123      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.28        |
|    cost_value_loss       | 2.91        |
|    cost_values           | 0.995       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0339      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 267         |
|    n_updates             | 140         |
|    policy_gradient_loss  | -0.00306    |
|    std                   | 0.998       |
|    value_loss            | 558         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9399445   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 16           |
|    time_elapsed          | 511          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0034762756 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 2.44         |
|    cost_values           | 0.985        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.0375       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 169          |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.984        |
|    value_loss            | 353          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.34         |
| reward                   | -1.9763358   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 17           |
|    time_elapsed          | 532          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0032249289 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 2.12         |
|    cost_values           | 0.973        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.0489       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 112          |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.0037      |
|    std                   | 0.973        |
|    value_loss            | 224          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.57977     |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 56           |
|    iterations            | 15           |
|    time_elapsed          | 539          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0032627918 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.623        |
|    cost_values           | 0.987        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0315       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 186          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 1            |
|    value_loss            | 376          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.57        |
| reward                   | -2.0478404  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 17          |
|    time_elapsed          | 544         |
|    total_timesteps       | 34816       |
| train/                   |             |
|    approx_kl             | 0.004472716 |
|    clip_fraction         | 0.0391      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.49        |
|    cost_value_loss       | 5.14        |
|    cost_values           | 0.973       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0319      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 121         |
|    n_updates             | 160         |
|    policy_gradient_loss  | -0.00453    |
|    std                   | 0.992       |
|    value_loss            | 240         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0308      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0308      |
| reward                   | -0.42609498 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 17          |
|    time_elapsed          | 547         |
|    total_timesteps       | 34816       |
| train/                   |             |
|    approx_kl             | 0.00582514  |
|    clip_fraction         | 0.0366      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 1.04        |
|    cost_values           | 0.97        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.0131      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 273         |
|    n_updates             | 160         |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.982       |
|    value_loss            | 558         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.61        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.61        |
| reward                   | -1.5354953  |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 16          |
|    time_elapsed          | 548         |
|    total_timesteps       | 32768       |
| train/                   |             |
|    approx_kl             | 0.005335883 |
|    clip_fraction         | 0.0635      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 1.8         |
|    cost_values           | 0.984       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0349      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 151         |
|    n_updates             | 150         |
|    policy_gradient_loss  | -0.0046     |
|    std                   | 0.998       |
|    value_loss            | 315         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.5144985  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 17          |
|    time_elapsed          | 551         |
|    total_timesteps       | 34816       |
| train/                   |             |
|    approx_kl             | 0.002607542 |
|    clip_fraction         | 0.0139      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 1.68        |
|    cost_values           | 0.989       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.00835     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 235         |
|    n_updates             | 160         |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.986       |
|    value_loss            | 511         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -2.5895572   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 18           |
|    time_elapsed          | 571          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0065573007 |
|    clip_fraction         | 0.0457       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.994        |
|    cost_value_loss       | 1.29         |
|    cost_values           | 0.953        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.012        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 263          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00278     |
|    std                   | 0.972        |
|    value_loss            | 566          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.82009107  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 18           |
|    time_elapsed          | 583          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0032133255 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 3.43         |
|    cost_values           | 0.969        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.031        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 161          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00283     |
|    std                   | 0.992        |
|    value_loss            | 323          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.44         |
| reward                   | -0.52637976  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 18           |
|    time_elapsed          | 587          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0057425173 |
|    clip_fraction         | 0.0463       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.912        |
|    cost_value_loss       | 0.218        |
|    cost_values           | 0.968        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.0165       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 218          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 0.981        |
|    value_loss            | 454          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.7333539  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 55          |
|    iterations            | 16          |
|    time_elapsed          | 586         |
|    total_timesteps       | 32768       |
| train/                   |             |
|    approx_kl             | 0.005569691 |
|    clip_fraction         | 0.0331      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 0.994       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0466      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 203         |
|    n_updates             | 150         |
|    policy_gradient_loss  | -0.00443    |
|    std                   | 1.01        |
|    value_loss            | 377         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.87         |
| reward                   | -1.3812792   |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 17           |
|    time_elapsed          | 589          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0034934347 |
|    clip_fraction         | 0.0472       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 1.91         |
|    cost_values           | 0.989        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0392       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 131          |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.00435     |
|    std                   | 0.996        |
|    value_loss            | 274          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.1          |
| reward                   | -0.6443601   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 18           |
|    time_elapsed          | 591          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0041681835 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 5.8          |
|    cost_values           | 0.992        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0364       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 108          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 0.989        |
|    value_loss            | 214          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -2.6463938   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 19           |
|    time_elapsed          | 610          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0049347864 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 4.2          |
|    cost_values           | 0.967        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.0328       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 261          |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00426     |
|    std                   | 0.966        |
|    value_loss            | 509          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9294446   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 19           |
|    time_elapsed          | 622          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0052229883 |
|    clip_fraction         | 0.0421       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.37         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 0.987        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.07         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 131          |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00463     |
|    std                   | 0.992        |
|    value_loss            | 274          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1892213  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 19          |
|    time_elapsed          | 628         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.005692876 |
|    clip_fraction         | 0.0439      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.33        |
|    cost_value_loss       | 3.71        |
|    cost_values           | 0.985       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.0176      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 133         |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.00409    |
|    std                   | 0.983       |
|    value_loss            | 277         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.7746105  |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 18          |
|    time_elapsed          | 630         |
|    total_timesteps       | 36864       |
| train/                   |             |
|    approx_kl             | 0.004291258 |
|    clip_fraction         | 0.0383      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.16        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 0.983       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0895      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 129         |
|    n_updates             | 170         |
|    policy_gradient_loss  | -0.0044     |
|    std                   | 0.998       |
|    value_loss            | 252         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -2.011436   |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 55          |
|    iterations            | 17          |
|    time_elapsed          | 631         |
|    total_timesteps       | 34816       |
| train/                   |             |
|    approx_kl             | 0.003977389 |
|    clip_fraction         | 0.0222      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 1.88        |
|    cost_values           | 0.961       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.016       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 310         |
|    n_updates             | 160         |
|    policy_gradient_loss  | -0.00423    |
|    std                   | 1.02        |
|    value_loss            | 650         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.6667482   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 19           |
|    time_elapsed          | 633          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0027772544 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 9.79         |
|    cost_values           | 0.992        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0618       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 123          |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00323     |
|    std                   | 0.994        |
|    value_loss            | 233          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.3710958  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 20          |
|    time_elapsed          | 650         |
|    total_timesteps       | 40960       |
| train/                   |             |
|    approx_kl             | 0.004129415 |
|    clip_fraction         | 0.0188      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 3.38        |
|    cost_values           | 0.975       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.0169      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 331         |
|    n_updates             | 190         |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.962       |
|    value_loss            | 679         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -1.3518662  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 20          |
|    time_elapsed          | 663         |
|    total_timesteps       | 40960       |
| train/                   |             |
|    approx_kl             | 0.004570366 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.32        |
|    cost_value_loss       | 3.07        |
|    cost_values           | 0.991       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.0172      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 251         |
|    n_updates             | 190         |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 0.991       |
|    value_loss            | 521         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.58        |
| reward                   | -0.65575176 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 20          |
|    time_elapsed          | 670         |
|    total_timesteps       | 40960       |
| train/                   |             |
|    approx_kl             | 0.003813529 |
|    clip_fraction         | 0.0299      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.14        |
|    cost_value_loss       | 1.55        |
|    cost_values           | 0.989       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.012       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 217         |
|    n_updates             | 190         |
|    policy_gradient_loss  | -0.00343    |
|    std                   | 0.986       |
|    value_loss            | 442         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.2177603  |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 57          |
|    iterations            | 19          |
|    time_elapsed          | 674         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.005007366 |
|    clip_fraction         | 0.0665      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 0.922       |
|    cost_values           | 0.985       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0214      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 113         |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.0079     |
|    std                   | 0.996       |
|    value_loss            | 233         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -2.657911   |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 20          |
|    time_elapsed          | 676         |
|    total_timesteps       | 40960       |
| train/                   |             |
|    approx_kl             | 0.001715618 |
|    clip_fraction         | 0.00977     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 2.39        |
|    cost_values           | 0.991       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0134      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 73.5        |
|    n_updates             | 190         |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.999       |
|    value_loss            | 140         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -1.5874151  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -1.3e+03    |
| time/                    |             |
|    fps                   | 54          |
|    iterations            | 18          |
|    time_elapsed          | 680         |
|    total_timesteps       | 36864       |
| train/                   |             |
|    approx_kl             | 0.006185968 |
|    clip_fraction         | 0.0507      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.22        |
|    cost_value_loss       | 2.2         |
|    cost_values           | 0.98        |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.0349      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 269         |
|    n_updates             | 170         |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 1.02        |
|    value_loss            | 565         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.3489652   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 21           |
|    time_elapsed          | 693          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0017049608 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 1.72         |
|    cost_values           | 0.992        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.0128       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 336          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.957        |
|    value_loss            | 654          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.4022579   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 705          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0035239547 |
|    clip_fraction         | 0.043        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 3.25         |
|    cost_values           | 0.985        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0169       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 183          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 0.991        |
|    value_loss            | 360          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.33         |
| reward                   | -0.8863946   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 21           |
|    time_elapsed          | 712          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0024466198 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 1.06         |
|    cost_values           | 0.986        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0149       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 156          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.984        |
|    value_loss            | 337          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -1.4804566  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 56          |
|    iterations            | 20          |
|    time_elapsed          | 718         |
|    total_timesteps       | 40960       |
| train/                   |             |
|    approx_kl             | 0.004910414 |
|    clip_fraction         | 0.0309      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.38        |
|    cost_value_loss       | 3.65        |
|    cost_values           | 0.995       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.054       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 127         |
|    n_updates             | 190         |
|    policy_gradient_loss  | -0.00298    |
|    std                   | 0.998       |
|    value_loss            | 262         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -1.4057933   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 21           |
|    time_elapsed          | 720          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0036776767 |
|    clip_fraction         | 0.0316       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 7.96         |
|    cost_values           | 0.998        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.027        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 212          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00278     |
|    std                   | 1            |
|    value_loss            | 451          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.128346    |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 53           |
|    iterations            | 19           |
|    time_elapsed          | 727          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0049244585 |
|    clip_fraction         | 0.0334       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 2.84         |
|    cost_values           | 0.988        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0199       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 252          |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 1.02         |
|    value_loss            | 491          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -2.2824135   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 22           |
|    time_elapsed          | 737          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0038630834 |
|    clip_fraction         | 0.0477       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.997        |
|    cost_value_loss       | 0.905        |
|    cost_values           | 0.994        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.0117       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 201          |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.00482     |
|    std                   | 0.958        |
|    value_loss            | 431          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0533273  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 22          |
|    time_elapsed          | 750         |
|    total_timesteps       | 45056       |
| train/                   |             |
|    approx_kl             | 0.005137886 |
|    clip_fraction         | 0.055       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 2.35        |
|    cost_values           | 0.977       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.028       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 156         |
|    n_updates             | 210         |
|    policy_gradient_loss  | -0.00466    |
|    std                   | 0.991       |
|    value_loss            | 324         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -1.714451    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 22           |
|    time_elapsed          | 756          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0038897626 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.74         |
|    cost_values           | 0.986        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.0416       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 108          |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.978        |
|    value_loss            | 222          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.51         |
| reward                   | -0.5254848   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 56           |
|    iterations            | 21           |
|    time_elapsed          | 764          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0029553932 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.97         |
|    cost_values           | 0.991        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0373       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 95           |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 1            |
|    value_loss            | 196          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.99         |
| reward                   | -1.8072746   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 22           |
|    time_elapsed          | 764          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0044294177 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 7.52         |
|    cost_values           | 0.995        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0222       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 160          |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 1.01         |
|    value_loss            | 324          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -1.1800452 |
| rollout/                 |            |
|    ep_len_mean           | 977        |
|    ep_rew_mean           | -1.27e+03  |
| time/                    |            |
|    fps                   | 52         |
|    iterations            | 20         |
|    time_elapsed          | 779        |
|    total_timesteps       | 40960      |
| train/                   |            |
|    approx_kl             | 0.00527327 |
|    clip_fraction         | 0.0521     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.66       |
|    cost_value_loss       | 8.83       |
|    cost_values           | 0.993      |
|    entropy               | -2.89      |
|    entropy_loss          | -2.88      |
|    explained_variance    | 0.0324     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 126        |
|    n_updates             | 190        |
|    policy_gradient_loss  | -0.00511   |
|    std                   | 1.03       |
|    value_loss            | 248        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.199982    |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 23           |
|    time_elapsed          | 781          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0035662795 |
|    clip_fraction         | 0.0275       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 4.8          |
|    cost_values           | 0.99         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.0127       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 278          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00321     |
|    std                   | 0.959        |
|    value_loss            | 551          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.2409465   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 23           |
|    time_elapsed          | 798          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0029849957 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 0.987        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0223       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 149          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 0.993        |
|    value_loss            | 300          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.76426685  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 23           |
|    time_elapsed          | 800          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0041104504 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 1.06         |
|    cost_values           | 0.979        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.0203       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 246          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 0.979        |
|    value_loss            | 508          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0559       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0559       |
| reward                   | -0.3207968   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 23           |
|    time_elapsed          | 810          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0022361847 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 5.44         |
|    cost_values           | 0.993        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0172       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 162          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 1.01         |
|    value_loss            | 323          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.21        |
| reward                   | -0.49753693 |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 55          |
|    iterations            | 22          |
|    time_elapsed          | 810         |
|    total_timesteps       | 45056       |
| train/                   |             |
|    approx_kl             | 0.004309765 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 2.96        |
|    cost_values           | 0.984       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0219      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 92          |
|    n_updates             | 210         |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 0.999       |
|    value_loss            | 193         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0210491   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 59           |
|    iterations            | 24           |
|    time_elapsed          | 828          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0038453522 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 1.86         |
|    cost_values           | 0.971        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.0123       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 156          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 0.956        |
|    value_loss            | 341          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.9075776  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 51          |
|    iterations            | 21          |
|    time_elapsed          | 830         |
|    total_timesteps       | 43008       |
| train/                   |             |
|    approx_kl             | 0.005760351 |
|    clip_fraction         | 0.0373      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.46        |
|    cost_value_loss       | 21.2        |
|    cost_values           | 1.02        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.0256      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 47.6        |
|    n_updates             | 200         |
|    policy_gradient_loss  | -0.00651    |
|    std                   | 1.03        |
|    value_loss            | 79.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.159264    |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 24           |
|    time_elapsed          | 846          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0031616949 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.93         |
|    cost_values           | 0.994        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.0163       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 272          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 0.979        |
|    value_loss            | 532          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.08         |
| reward                   | -0.95863765  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 57           |
|    iterations            | 24           |
|    time_elapsed          | 847          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0049425825 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 6.13         |
|    cost_values           | 0.989        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0288       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 219          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00535     |
|    std                   | 1            |
|    value_loss            | 435          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.887929   |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 54          |
|    iterations            | 23          |
|    time_elapsed          | 857         |
|    total_timesteps       | 47104       |
| train/                   |             |
|    approx_kl             | 0.006107715 |
|    clip_fraction         | 0.0579      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 4.13        |
|    cost_values           | 0.984       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0208      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 111         |
|    n_updates             | 220         |
|    policy_gradient_loss  | -0.00534    |
|    std                   | 0.995       |
|    value_loss            | 229         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.289        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.289        |
| reward                   | -0.22491965  |
| rollout/                 |              |
|    ep_len_mean           | 945          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 57           |
|    iterations            | 24           |
|    time_elapsed          | 857          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0025789207 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 0.999        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0291       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 134          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 1.01         |
|    value_loss            | 270          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8742916   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 25           |
|    time_elapsed          | 874          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0037727277 |
|    clip_fraction         | 0.0192       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 1.28         |
|    cost_values           | 0.981        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.0153       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 150          |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.955        |
|    value_loss            | 313          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.62        |
| reward                   | -1.8303323  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 50          |
|    iterations            | 22          |
|    time_elapsed          | 883         |
|    total_timesteps       | 45056       |
| train/                   |             |
|    approx_kl             | 0.003133493 |
|    clip_fraction         | 0.0184      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 5.51        |
|    cost_values           | 0.98        |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.0185      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 170         |
|    n_updates             | 210         |
|    policy_gradient_loss  | -0.00226    |
|    std                   | 1.04        |
|    value_loss            | 340         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.2922024   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 57           |
|    iterations            | 25           |
|    time_elapsed          | 893          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0031269016 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 2.89         |
|    cost_values           | 0.979        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.0101       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 139          |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.003       |
|    std                   | 0.977        |
|    value_loss            | 281          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.57         |
| reward                   | -1.7262809   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 56           |
|    iterations            | 25           |
|    time_elapsed          | 898          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0059518823 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.55         |
|    cost_value_loss       | 21.4         |
|    cost_values           | 0.999        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.038        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 151          |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 0.999        |
|    value_loss            | 290          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.294       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.294       |
| reward                   | -0.5743777  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 56          |
|    iterations            | 25          |
|    time_elapsed          | 905         |
|    total_timesteps       | 51200       |
| train/                   |             |
|    approx_kl             | 0.004716776 |
|    clip_fraction         | 0.0369      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 7.82        |
|    cost_values           | 0.997       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0163      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 88.2        |
|    n_updates             | 240         |
|    policy_gradient_loss  | -0.00475    |
|    std                   | 1.01        |
|    value_loss            | 178         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.27         |
| reward                   | -1.4520125   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 54           |
|    iterations            | 24           |
|    time_elapsed          | 905          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0025671187 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 1.49         |
|    cost_values           | 0.97         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0201       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 145          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 0.995        |
|    value_loss            | 306          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -1.878412   |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 57          |
|    iterations            | 26          |
|    time_elapsed          | 921         |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.004260932 |
|    clip_fraction         | 0.0457      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 1.41        |
|    cost_values           | 0.979       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.00527     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 224         |
|    n_updates             | 250         |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 0.954       |
|    value_loss            | 492         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.264        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.264        |
| reward                   | -0.51034653  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 50           |
|    iterations            | 23           |
|    time_elapsed          | 937          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0046732635 |
|    clip_fraction         | 0.0384       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 3.93         |
|    cost_values           | 0.997        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0333       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 219          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00401     |
|    std                   | 1.04         |
|    value_loss            | 429          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.8483588   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 56           |
|    iterations            | 26           |
|    time_elapsed          | 940          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0024840285 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.889        |
|    cost_value_loss       | 0.427        |
|    cost_values           | 0.968        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.00449      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 160          |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.975        |
|    value_loss            | 323          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8394342  |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 55          |
|    iterations            | 26          |
|    time_elapsed          | 951         |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.004882647 |
|    clip_fraction         | 0.0427      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 1.77        |
|    cost_values           | 0.982       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0105      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 183         |
|    n_updates             | 250         |
|    policy_gradient_loss  | -0.00312    |
|    std                   | 1           |
|    value_loss            | 374         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.82        |
| reward                   | -0.2801492  |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 53          |
|    iterations            | 25          |
|    time_elapsed          | 955         |
|    total_timesteps       | 51200       |
| train/                   |             |
|    approx_kl             | 0.002268028 |
|    clip_fraction         | 0.00737     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.44        |
|    cost_value_loss       | 3.75        |
|    cost_values           | 0.985       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0127      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 135         |
|    n_updates             | 240         |
|    policy_gradient_loss  | -0.00234    |
|    std                   | 0.993       |
|    value_loss            | 269         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.837       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.837       |
| reward                   | -0.62484586 |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 55          |
|    iterations            | 26          |
|    time_elapsed          | 956         |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.002899433 |
|    clip_fraction         | 0.0295      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.61        |
|    cost_value_loss       | 6.07        |
|    cost_values           | 0.997       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.00984     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 162         |
|    n_updates             | 250         |
|    policy_gradient_loss  | -0.00358    |
|    std                   | 1.01        |
|    value_loss            | 344         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.739        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.739        |
| reward                   | -0.7111421   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 56           |
|    iterations            | 27           |
|    time_elapsed          | 970          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0045242775 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.74         |
|    cost_values           | 0.988        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.0166       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 150          |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00442     |
|    std                   | 0.949        |
|    value_loss            | 328          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3496912   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 55           |
|    iterations            | 27           |
|    time_elapsed          | 987          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0031377333 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.916        |
|    cost_value_loss       | 0.792        |
|    cost_values           | 0.943        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.00563      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 291          |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.971        |
|    value_loss            | 593          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.3276354  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 49          |
|    iterations            | 24          |
|    time_elapsed          | 993         |
|    total_timesteps       | 49152       |
| train/                   |             |
|    approx_kl             | 0.002602915 |
|    clip_fraction         | 0.0149      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 1.46        |
|    cost_values           | 0.999       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.0134      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 205         |
|    n_updates             | 230         |
|    policy_gradient_loss  | -0.00228    |
|    std                   | 1.04        |
|    value_loss            | 432         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.61        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.61        |
| reward                   | -1.3952988  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 54          |
|    iterations            | 27          |
|    time_elapsed          | 1005        |
|    total_timesteps       | 55296       |
| train/                   |             |
|    approx_kl             | 0.002735186 |
|    clip_fraction         | 0.00649     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 4.87        |
|    cost_values           | 0.993       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.012       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 237         |
|    n_updates             | 260         |
|    policy_gradient_loss  | -0.0023     |
|    std                   | 0.998       |
|    value_loss            | 480         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.9306737  |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 52          |
|    iterations            | 26          |
|    time_elapsed          | 1006        |
|    total_timesteps       | 53248       |
| train/                   |             |
|    approx_kl             | 0.002088266 |
|    clip_fraction         | 0.0117      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 5.89        |
|    cost_values           | 0.991       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.0253      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 152         |
|    n_updates             | 250         |
|    policy_gradient_loss  | -0.00362    |
|    std                   | 0.987       |
|    value_loss            | 308         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.27         |
| reward                   | -0.93894887  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 54           |
|    iterations            | 27           |
|    time_elapsed          | 1009         |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0036450194 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 12.2         |
|    cost_values           | 1            |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0167       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 164          |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 1.01         |
|    value_loss            | 325          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.42        |
| reward                   | -0.83888304 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 56          |
|    iterations            | 28          |
|    time_elapsed          | 1020        |
|    total_timesteps       | 57344       |
| train/                   |             |
|    approx_kl             | 0.0051313   |
|    clip_fraction         | 0.0376      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 1.67        |
|    cost_values           | 0.998       |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.00601     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 299         |
|    n_updates             | 270         |
|    policy_gradient_loss  | -0.00327    |
|    std                   | 0.946       |
|    value_loss            | 609         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.7708802   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 55           |
|    iterations            | 28           |
|    time_elapsed          | 1037         |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0034193164 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.955        |
|    cost_value_loss       | 0.798        |
|    cost_values           | 0.937        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.0137       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 164          |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 0.976        |
|    value_loss            | 327          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0242093   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 48           |
|    iterations            | 25           |
|    time_elapsed          | 1049         |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0045645367 |
|    clip_fraction         | 0.0645       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 6.02         |
|    cost_values           | 0.999        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.0232       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 186          |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.00495     |
|    std                   | 1.04         |
|    value_loss            | 377          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -1.377717    |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 52           |
|    iterations            | 27           |
|    time_elapsed          | 1056         |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0059116604 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 3.85         |
|    cost_values           | 0.989        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.0281       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 108          |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00404     |
|    std                   | 0.98         |
|    value_loss            | 224          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.6046597   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 53           |
|    iterations            | 28           |
|    time_elapsed          | 1062         |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0021767055 |
|    clip_fraction         | 0.00986      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 2.32         |
|    cost_values           | 0.989        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0164       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 134          |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 1            |
|    value_loss            | 274          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0425      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0425      |
| reward                   | -0.7011951  |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 53          |
|    iterations            | 28          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 57344       |
| train/                   |             |
|    approx_kl             | 0.002564182 |
|    clip_fraction         | 0.00894     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 1.66        |
|    cost_values           | 0.98        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.00578     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 103         |
|    n_updates             | 270         |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 1.01        |
|    value_loss            | 213         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.7106695  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 55          |
|    iterations            | 29          |
|    time_elapsed          | 1072        |
|    total_timesteps       | 59392       |
| train/                   |             |
|    approx_kl             | 0.003041604 |
|    clip_fraction         | 0.0171      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 1.98        |
|    cost_values           | 0.997       |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.0171      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 271         |
|    n_updates             | 280         |
|    policy_gradient_loss  | -0.00203    |
|    std                   | 0.947       |
|    value_loss            | 564         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.077957    |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 54           |
|    iterations            | 29           |
|    time_elapsed          | 1087         |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0037512027 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.972        |
|    cost_value_loss       | 0.8          |
|    cost_values           | 0.946        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.0116       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 135          |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00475     |
|    std                   | 0.977        |
|    value_loss            | 277          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -1.330472   |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 51          |
|    iterations            | 28          |
|    time_elapsed          | 1108        |
|    total_timesteps       | 57344       |
| train/                   |             |
|    approx_kl             | 0.002723873 |
|    clip_fraction         | 0.0164      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.13        |
|    cost_value_loss       | 1.35        |
|    cost_values           | 0.997       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.0155      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 91.8        |
|    n_updates             | 270         |
|    policy_gradient_loss  | -0.00292    |
|    std                   | 0.977       |
|    value_loss            | 201         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.4281204   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 48           |
|    iterations            | 26           |
|    time_elapsed          | 1109         |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0029314952 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 1.02         |
|    cost_values           | 0.999        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00849      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 226          |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 1.04         |
|    value_loss            | 453          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.14         |
| reward                   | -0.64189655  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 53           |
|    iterations            | 29           |
|    time_elapsed          | 1116         |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0016298224 |
|    clip_fraction         | 0.00776      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 18.5         |
|    cost_values           | 1            |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0259       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 115          |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 1.01         |
|    value_loss            | 213          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.2674721   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 53           |
|    iterations            | 29           |
|    time_elapsed          | 1119         |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0025384454 |
|    clip_fraction         | 0.00791      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.33         |
|    cost_values           | 0.992        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.012        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 149          |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.0034      |
|    std                   | 0.995        |
|    value_loss            | 304          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.96       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.96       |
| reward                   | -1.5320557 |
| rollout/                 |            |
|    ep_len_mean           | 972        |
|    ep_rew_mean           | -1.22e+03  |
| time/                    |            |
|    fps                   | 54         |
|    iterations            | 30         |
|    time_elapsed          | 1125       |
|    total_timesteps       | 61440      |
| train/                   |            |
|    approx_kl             | 0.00476743 |
|    clip_fraction         | 0.0508     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.09       |
|    cost_value_loss       | 2.29       |
|    cost_values           | 0.993      |
|    entropy               | -2.73      |
|    entropy_loss          | -2.73      |
|    explained_variance    | 0.0253     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 161        |
|    n_updates             | 290        |
|    policy_gradient_loss  | -0.00485   |
|    std                   | 0.946      |
|    value_loss            | 330        |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -1.3542665  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 53          |
|    iterations            | 30          |
|    time_elapsed          | 1139        |
|    total_timesteps       | 61440       |
| train/                   |             |
|    approx_kl             | 0.004675382 |
|    clip_fraction         | 0.0559      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 2.3         |
|    cost_values           | 0.971       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.019       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 139         |
|    n_updates             | 290         |
|    policy_gradient_loss  | -0.00528    |
|    std                   | 0.975       |
|    value_loss            | 288         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.8594573  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 51          |
|    iterations            | 29          |
|    time_elapsed          | 1162        |
|    total_timesteps       | 59392       |
| train/                   |             |
|    approx_kl             | 0.004773324 |
|    clip_fraction         | 0.0391      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 1.67        |
|    cost_values           | 0.986       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.00651     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 193         |
|    n_updates             | 280         |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 0.977       |
|    value_loss            | 367         |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.64         |
| reward                   | -1.2937797   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 52           |
|    iterations            | 30           |
|    time_elapsed          | 1168         |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0028995234 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 26.8         |
|    cost_values           | 1.01         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0274       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 85.1         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 1.01         |
|    value_loss            | 143          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -2.7296002  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 47          |
|    iterations            | 27          |
|    time_elapsed          | 1168        |
|    total_timesteps       | 55296       |
| train/                   |             |
|    approx_kl             | 0.004639579 |
|    clip_fraction         | 0.0387      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.51        |
|    cost_value_loss       | 21.9        |
|    cost_values           | 1           |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.0355      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 83.4        |
|    n_updates             | 260         |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 1.05        |
|    value_loss            | 157         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.8200872   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 53           |
|    iterations            | 31           |
|    time_elapsed          | 1178         |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0057962765 |
|    clip_fraction         | 0.0613       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.913        |
|    cost_value_loss       | 0.451        |
|    cost_values           | 0.971        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.00559      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 346          |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00453     |
|    std                   | 0.945        |
|    value_loss            | 693          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.4862566   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 51           |
|    iterations            | 30           |
|    time_elapsed          | 1181         |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0028756699 |
|    clip_fraction         | 0.00952      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 1.11         |
|    cost_values           | 0.981        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.00762      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.993        |
|    value_loss            | 234          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.5564233   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 53           |
|    iterations            | 31           |
|    time_elapsed          | 1191         |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0038979142 |
|    clip_fraction         | 0.0389       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.969        |
|    cost_value_loss       | 1.06         |
|    cost_values           | 0.93         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.0157       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 113          |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00441     |
|    std                   | 0.973        |
|    value_loss            | 227          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.07         |
| reward                   | -0.9223122   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 50           |
|    iterations            | 30           |
|    time_elapsed          | 1216         |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0034280894 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 1.36         |
|    cost_values           | 0.976        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.0136       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 280          |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00397     |
|    std                   | 0.978        |
|    value_loss            | 588          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.929        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.929        |
| reward                   | -0.46775994  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 46           |
|    iterations            | 28           |
|    time_elapsed          | 1229         |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0045618033 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 4.83         |
|    cost_values           | 0.992        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.0211       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 142          |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00374     |
|    std                   | 1.05         |
|    value_loss            | 284          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.7523856   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 53           |
|    iterations            | 32           |
|    time_elapsed          | 1232         |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0027900585 |
|    clip_fraction         | 0.00679      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.921        |
|    cost_value_loss       | 0.622        |
|    cost_values           | 0.946        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.0136       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 190          |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 0.944        |
|    value_loss            | 386          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.5          |
| reward                   | -0.45133376  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 51           |
|    iterations            | 31           |
|    time_elapsed          | 1234         |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0037683037 |
|    clip_fraction         | 0.0466       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 8.65         |
|    cost_values           | 1            |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.024        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 71.5         |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00414     |
|    std                   | 1.01         |
|    value_loss            | 143          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.6376348   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 52           |
|    iterations            | 32           |
|    time_elapsed          | 1243         |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0032817582 |
|    clip_fraction         | 0.0426       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 1.34         |
|    cost_values           | 0.957        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.00754      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 82.6         |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00398     |
|    std                   | 0.968        |
|    value_loss            | 177          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.418614    |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 50           |
|    iterations            | 31           |
|    time_elapsed          | 1246         |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0044620135 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 1.73         |
|    cost_values           | 0.994        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.00773      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 169          |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.0025      |
|    std                   | 0.993        |
|    value_loss            | 346          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -1.6045454  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 49          |
|    iterations            | 31          |
|    time_elapsed          | 1273        |
|    total_timesteps       | 63488       |
| train/                   |             |
|    approx_kl             | 0.005771327 |
|    clip_fraction         | 0.0447      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.46        |
|    cost_value_loss       | 2.93        |
|    cost_values           | 0.988       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.0175      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 247         |
|    n_updates             | 300         |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 0.979       |
|    value_loss            | 493         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.6587476   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 52           |
|    iterations            | 33           |
|    time_elapsed          | 1286         |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0036053106 |
|    clip_fraction         | 0.0436       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.93         |
|    cost_value_loss       | 0.917        |
|    cost_values           | 0.935        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.00745      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 376          |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.0042      |
|    std                   | 0.946        |
|    value_loss            | 736          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.58        |
| reward                   | -0.37277743 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 46          |
|    iterations            | 29          |
|    time_elapsed          | 1290        |
|    total_timesteps       | 59392       |
| train/                   |             |
|    approx_kl             | 0.004236373 |
|    clip_fraction         | 0.0267      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 0.88        |
|    cost_values           | 0.997       |
|    entropy               | -2.95       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.00579     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 82          |
|    n_updates             | 280         |
|    policy_gradient_loss  | -0.00517    |
|    std                   | 1.06        |
|    value_loss            | 165         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.2714126  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 52          |
|    iterations            | 33          |
|    time_elapsed          | 1296        |
|    total_timesteps       | 67584       |
| train/                   |             |
|    approx_kl             | 0.004957457 |
|    clip_fraction         | 0.0587      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.929       |
|    cost_value_loss       | 0.752       |
|    cost_values           | 0.976       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.00707     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 158         |
|    n_updates             | 320         |
|    policy_gradient_loss  | -0.00421    |
|    std                   | 0.969       |
|    value_loss            | 330         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.06        |
| reward                   | -1.1668935  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.09e+03   |
| time/                    |             |
|    fps                   | 50          |
|    iterations            | 32          |
|    time_elapsed          | 1302        |
|    total_timesteps       | 65536       |
| train/                   |             |
|    approx_kl             | 0.004457318 |
|    clip_fraction         | 0.0224      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.58        |
|    cost_value_loss       | 8.04        |
|    cost_values           | 1           |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.00517     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 282         |
|    n_updates             | 310         |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 1.01        |
|    value_loss            | 550         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.051023    |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 50           |
|    iterations            | 32           |
|    time_elapsed          | 1309         |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0044905622 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 16.9         |
|    cost_values           | 0.999        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0248       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 132          |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00381     |
|    std                   | 0.993        |
|    value_loss            | 262          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -1.2153155 |
| rollout/                 |            |
|    ep_len_mean           | 956        |
|    ep_rew_mean           | -1.23e+03  |
| time/                    |            |
|    fps                   | 49         |
|    iterations            | 32         |
|    time_elapsed          | 1328       |
|    total_timesteps       | 65536      |
| train/                   |            |
|    approx_kl             | 0.00589657 |
|    clip_fraction         | 0.0398     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.67       |
|    cost_value_loss       | 6.73       |
|    cost_values           | 0.993      |
|    entropy               | -2.81      |
|    entropy_loss          | -2.8       |
|    explained_variance    | 0.0258     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 72.7       |
|    n_updates             | 310        |
|    policy_gradient_loss  | -0.00407   |
|    std                   | 0.985      |
|    value_loss            | 154        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.7680153   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 51           |
|    iterations            | 34           |
|    time_elapsed          | 1344         |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0026175575 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.95         |
|    cost_value_loss       | 1.35         |
|    cost_values           | 0.935        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.00509      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 228          |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.947        |
|    value_loss            | 485          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.7919852   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 51           |
|    iterations            | 34           |
|    time_elapsed          | 1352         |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0041373773 |
|    clip_fraction         | 0.0471       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.97         |
|    cost_value_loss       | 0.795        |
|    cost_values           | 0.962        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.00773      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00306     |
|    std                   | 0.971        |
|    value_loss            | 223          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.28        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.28        |
| reward                   | -0.78381723 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 45          |
|    iterations            | 30          |
|    time_elapsed          | 1354        |
|    total_timesteps       | 61440       |
| train/                   |             |
|    approx_kl             | 0.002530972 |
|    clip_fraction         | 0.0167      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 5.27        |
|    cost_values           | 1           |
|    entropy               | -2.96       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.00958     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 258         |
|    n_updates             | 290         |
|    policy_gradient_loss  | -0.00273    |
|    std                   | 1.06        |
|    value_loss            | 516         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.43         |
| reward                   | -1.2662603   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 49           |
|    iterations            | 33           |
|    time_elapsed          | 1358         |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0021332137 |
|    clip_fraction         | 0.00703      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 1            |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0135       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 242          |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 1.01         |
|    value_loss            | 518          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0983135   |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 49           |
|    iterations            | 33           |
|    time_elapsed          | 1373         |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0035753152 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 1.78         |
|    cost_values           | 0.989        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0135       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 92           |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 0.993        |
|    value_loss            | 200          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0670416   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 48           |
|    iterations            | 33           |
|    time_elapsed          | 1386         |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0039821905 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 1.65         |
|    cost_values           | 0.986        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.00744      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 89.9         |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00412     |
|    std                   | 0.992        |
|    value_loss            | 190          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.9921868  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 51          |
|    iterations            | 35          |
|    time_elapsed          | 1401        |
|    total_timesteps       | 71680       |
| train/                   |             |
|    approx_kl             | 0.003971186 |
|    clip_fraction         | 0.0234      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.836       |
|    cost_values           | 0.955       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.0108      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 131         |
|    n_updates             | 340         |
|    policy_gradient_loss  | -0.00328    |
|    std                   | 0.938       |
|    value_loss            | 281         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.5682817   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 50           |
|    iterations            | 35           |
|    time_elapsed          | 1407         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0046876306 |
|    clip_fraction         | 0.0267       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.909        |
|    cost_value_loss       | 0.595        |
|    cost_values           | 0.955        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.00332      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 178          |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00327     |
|    std                   | 0.972        |
|    value_loss            | 370          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.286       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.286       |
| reward                   | -1.443899   |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 49          |
|    iterations            | 34          |
|    time_elapsed          | 1410        |
|    total_timesteps       | 69632       |
| train/                   |             |
|    approx_kl             | 0.004597716 |
|    clip_fraction         | 0.0331      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 2.04        |
|    cost_values           | 0.996       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -0.000749   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 94.5        |
|    n_updates             | 330         |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 1.01        |
|    value_loss            | 193         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.13        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.13        |
| reward                   | -0.43187994 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 44          |
|    iterations            | 31          |
|    time_elapsed          | 1418        |
|    total_timesteps       | 63488       |
| train/                   |             |
|    approx_kl             | 0.004559286 |
|    clip_fraction         | 0.0345      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 3.55        |
|    cost_values           | 0.998       |
|    entropy               | -2.97       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.00348     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.7        |
|    n_updates             | 300         |
|    policy_gradient_loss  | -0.0045     |
|    std                   | 1.07        |
|    value_loss            | 72          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.7212127   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 48           |
|    iterations            | 34           |
|    time_elapsed          | 1434         |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0039217686 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 9.02         |
|    cost_values           | 0.995        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0315       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 71.5         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00329     |
|    std                   | 0.99         |
|    value_loss            | 141          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1143969  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 48          |
|    iterations            | 34          |
|    time_elapsed          | 1444        |
|    total_timesteps       | 69632       |
| train/                   |             |
|    approx_kl             | 0.003508687 |
|    clip_fraction         | 0.0213      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.32        |
|    cost_value_loss       | 2.08        |
|    cost_values           | 0.984       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.0187      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 184         |
|    n_updates             | 330         |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 0.993       |
|    value_loss            | 381         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.000826    |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 50           |
|    iterations            | 36           |
|    time_elapsed          | 1454         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0036636197 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.938        |
|    cost_value_loss       | 0.413        |
|    cost_values           | 0.974        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.00544      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 219          |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00309     |
|    std                   | 0.933        |
|    value_loss            | 448          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.35         |
| reward                   | -1.4636161   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 49           |
|    iterations            | 35           |
|    time_elapsed          | 1461         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0048117996 |
|    clip_fraction         | 0.0488       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 4.23         |
|    cost_values           | 0.994        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.000969     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.9         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00433     |
|    std                   | 1.01         |
|    value_loss            | 107          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4511552   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 50           |
|    iterations            | 36           |
|    time_elapsed          | 1464         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0060485187 |
|    clip_fraction         | 0.0697       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.961        |
|    cost_value_loss       | 0.64         |
|    cost_values           | 0.942        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.0148       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 167          |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.0064      |
|    std                   | 0.971        |
|    value_loss            | 352          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.08         |
| reward                   | -0.5161125   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 44           |
|    iterations            | 32           |
|    time_elapsed          | 1483         |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0030818777 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 7.87         |
|    cost_values           | 1            |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.01         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 342          |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 1.07         |
|    value_loss            | 670          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.476023    |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 48           |
|    iterations            | 35           |
|    time_elapsed          | 1489         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0044443076 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 3.06         |
|    cost_values           | 0.987        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0112       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 170          |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.99         |
|    value_loss            | 362          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.63531965  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 47           |
|    iterations            | 35           |
|    time_elapsed          | 1505         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0030468497 |
|    clip_fraction         | 0.0201       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 1.51         |
|    cost_values           | 0.98         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.00984      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 167          |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.0034      |
|    std                   | 0.996        |
|    value_loss            | 377          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3773133   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 50           |
|    iterations            | 37           |
|    time_elapsed          | 1508         |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0042614657 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.932        |
|    cost_value_loss       | 0.637        |
|    cost_values           | 0.955        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.0154       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 226          |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00388     |
|    std                   | 0.932        |
|    value_loss            | 469          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -1.7133819   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 48           |
|    iterations            | 36           |
|    time_elapsed          | 1512         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0018499052 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 2.28         |
|    cost_values           | 0.998        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.00589      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 181          |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 1.01         |
|    value_loss            | 380          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.16         |
| reward                   | -0.40351003  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 49           |
|    iterations            | 37           |
|    time_elapsed          | 1522         |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0035696346 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.994        |
|    cost_value_loss       | 1.77         |
|    cost_values           | 0.954        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.0166       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 202          |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 0.972        |
|    value_loss            | 418          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.74       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.74       |
| reward                   | -2.0874496 |
| rollout/                 |            |
|    ep_len_mean           | 960        |
|    ep_rew_mean           | -1.21e+03  |
| time/                    |            |
|    fps                   | 47         |
|    iterations            | 36         |
|    time_elapsed          | 1543       |
|    total_timesteps       | 73728      |
| train/                   |            |
|    approx_kl             | 0.00693978 |
|    clip_fraction         | 0.0625     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.05       |
|    cost_value_loss       | 1.75       |
|    cost_values           | 0.995      |
|    entropy               | -2.83      |
|    entropy_loss          | -2.82      |
|    explained_variance    | 0.00349    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 152        |
|    n_updates             | 350        |
|    policy_gradient_loss  | -0.0044    |
|    std                   | 0.997      |
|    value_loss            | 304        |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.872       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.872       |
| reward                   | -0.52554363 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 43          |
|    iterations            | 33          |
|    time_elapsed          | 1550        |
|    total_timesteps       | 67584       |
| train/                   |             |
|    approx_kl             | 0.004049898 |
|    clip_fraction         | 0.0271      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 1.19        |
|    cost_values           | 0.998       |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.00517     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 260         |
|    n_updates             | 320         |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 1.06        |
|    value_loss            | 521         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -1.9638532  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 49          |
|    iterations            | 38          |
|    time_elapsed          | 1563        |
|    total_timesteps       | 77824       |
| train/                   |             |
|    approx_kl             | 0.005263225 |
|    clip_fraction         | 0.0366      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 1.71        |
|    cost_values           | 0.955       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.0146      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 185         |
|    n_updates             | 370         |
|    policy_gradient_loss  | -0.00606    |
|    std                   | 0.935       |
|    value_loss            | 365         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -1.3008083  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 48          |
|    iterations            | 37          |
|    time_elapsed          | 1564        |
|    total_timesteps       | 75776       |
| train/                   |             |
|    approx_kl             | 0.004273718 |
|    clip_fraction         | 0.0569      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 4.61        |
|    cost_values           | 0.999       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.0209      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 123         |
|    n_updates             | 360         |
|    policy_gradient_loss  | -0.00509    |
|    std                   | 1.01        |
|    value_loss            | 263         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.4010183   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 46           |
|    iterations            | 36           |
|    time_elapsed          | 1568         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0047636987 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 4.79         |
|    cost_values           | 0.997        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0146       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.5         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.0035      |
|    std                   | 1            |
|    value_loss            | 110          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -1.1452171  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 49          |
|    iterations            | 38          |
|    time_elapsed          | 1581        |
|    total_timesteps       | 77824       |
| train/                   |             |
|    approx_kl             | 0.004212862 |
|    clip_fraction         | 0.0316      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.988       |
|    cost_value_loss       | 0.98        |
|    cost_values           | 0.97        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.00802     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 202         |
|    n_updates             | 370         |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.97        |
|    value_loss            | 421         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1987548  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 47          |
|    iterations            | 37          |
|    time_elapsed          | 1598        |
|    total_timesteps       | 75776       |
| train/                   |             |
|    approx_kl             | 0.003361734 |
|    clip_fraction         | 0.0174      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.74        |
|    cost_value_loss       | 6.19        |
|    cost_values           | 0.996       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0335      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 93.2        |
|    n_updates             | 360         |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.995       |
|    value_loss            | 196         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.38        |
| reward                   | -0.8704668  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 43          |
|    iterations            | 34          |
|    time_elapsed          | 1617        |
|    total_timesteps       | 69632       |
| train/                   |             |
|    approx_kl             | 0.005953165 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.91        |
|    cost_value_loss       | 7.55        |
|    cost_values           | 0.999       |
|    entropy               | -2.97       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.035       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 75.1        |
|    n_updates             | 330         |
|    policy_gradient_loss  | -0.00515    |
|    std                   | 1.07        |
|    value_loss            | 153         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.1475282  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 49          |
|    iterations            | 39          |
|    time_elapsed          | 1618        |
|    total_timesteps       | 79872       |
| train/                   |             |
|    approx_kl             | 0.004878264 |
|    clip_fraction         | 0.0405      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.909       |
|    cost_value_loss       | 0.62        |
|    cost_values           | 0.902       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.0223      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 124         |
|    n_updates             | 380         |
|    policy_gradient_loss  | -0.00587    |
|    std                   | 0.932       |
|    value_loss            | 269         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.6741596   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 48           |
|    iterations            | 38           |
|    time_elapsed          | 1618         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0042225667 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 3.72         |
|    cost_values           | 0.995        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.00654      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 189          |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.0035      |
|    std                   | 1.01         |
|    value_loss            | 352          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2059113  |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 46          |
|    iterations            | 37          |
|    time_elapsed          | 1631        |
|    total_timesteps       | 75776       |
| train/                   |             |
|    approx_kl             | 0.004885213 |
|    clip_fraction         | 0.0332      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.936       |
|    cost_value_loss       | 0.578       |
|    cost_values           | 0.971       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0016      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 136         |
|    n_updates             | 360         |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 1           |
|    value_loss            | 281         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.99507314  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 48           |
|    iterations            | 39           |
|    time_elapsed          | 1640         |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0053137355 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.979        |
|    cost_value_loss       | 1.07         |
|    cost_values           | 0.976        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.0148       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 117          |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.0047      |
|    std                   | 0.97         |
|    value_loss            | 251          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.9653853  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 47          |
|    iterations            | 38          |
|    time_elapsed          | 1654        |
|    total_timesteps       | 77824       |
| train/                   |             |
|    approx_kl             | 0.002806495 |
|    clip_fraction         | 0.0144      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.16        |
|    cost_value_loss       | 1.41        |
|    cost_values           | 0.998       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.00494     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 180         |
|    n_updates             | 370         |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.989       |
|    value_loss            | 379         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.5273373   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 47           |
|    iterations            | 39           |
|    time_elapsed          | 1672         |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0038393983 |
|    clip_fraction         | 0.0426       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.06         |
|    cost_values           | 0.995        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.00963      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 150          |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00513     |
|    std                   | 1.01         |
|    value_loss            | 316          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.6161504  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 48          |
|    iterations            | 40          |
|    time_elapsed          | 1674        |
|    total_timesteps       | 81920       |
| train/                   |             |
|    approx_kl             | 0.004412559 |
|    clip_fraction         | 0.0205      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.972       |
|    cost_value_loss       | 1.01        |
|    cost_values           | 0.915       |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.00864     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 280         |
|    n_updates             | 390         |
|    policy_gradient_loss  | -0.00273    |
|    std                   | 0.928       |
|    value_loss            | 571         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.85         |
| reward                   | -0.65131205  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 42           |
|    iterations            | 35           |
|    time_elapsed          | 1687         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0034897355 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 1.93         |
|    cost_values           | 0.995        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00928      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00338     |
|    std                   | 1.07         |
|    value_loss            | 212          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.175367   |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 45          |
|    iterations            | 38          |
|    time_elapsed          | 1695        |
|    total_timesteps       | 77824       |
| train/                   |             |
|    approx_kl             | 0.003358579 |
|    clip_fraction         | 0.022       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 1.29        |
|    cost_values           | 0.968       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.00411     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 110         |
|    n_updates             | 370         |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 1           |
|    value_loss            | 227         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.7616944   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 48           |
|    iterations            | 40           |
|    time_elapsed          | 1701         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0045882496 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.905        |
|    cost_value_loss       | 0.509        |
|    cost_values           | 0.959        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.00607      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 91.6         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00425     |
|    std                   | 0.963        |
|    value_loss            | 201          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.4884019   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 46           |
|    iterations            | 39           |
|    time_elapsed          | 1710         |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0054076174 |
|    clip_fraction         | 0.051        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 3.54         |
|    cost_values           | 0.988        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0202       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 86.1         |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00548     |
|    std                   | 0.979        |
|    value_loss            | 178          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.79       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.79       |
| reward                   | -1.3622241 |
| rollout/                 |            |
|    ep_len_mean           | 966        |
|    ep_rew_mean           | -1.11e+03  |
| time/                    |            |
|    fps                   | 47         |
|    iterations            | 40         |
|    time_elapsed          | 1727       |
|    total_timesteps       | 81920      |
| train/                   |            |
|    approx_kl             | 0.00128553 |
|    clip_fraction         | 0.00605    |
|    clip_range            | 0.2        |
|    cost_returns          | 1.47       |
|    cost_value_loss       | 5.23       |
|    cost_values           | 0.999      |
|    entropy               | -2.85      |
|    entropy_loss          | -2.86      |
|    explained_variance    | 0.0231     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 198        |
|    n_updates             | 390        |
|    policy_gradient_loss  | -0.0012    |
|    std                   | 1.01       |
|    value_loss            | 394        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.1650426   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 48           |
|    iterations            | 41           |
|    time_elapsed          | 1732         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0036499125 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 2.26         |
|    cost_values           | 0.966        |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.0205       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 273          |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00406     |
|    std                   | 0.925        |
|    value_loss            | 578          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.65         |
| reward                   | -0.6653727   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 41           |
|    iterations            | 36           |
|    time_elapsed          | 1756         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0050015594 |
|    clip_fraction         | 0.0321       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 8.27         |
|    cost_values           | 0.997        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0307       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 93.9         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00406     |
|    std                   | 1.06         |
|    value_loss            | 185          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.3830353   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 45           |
|    iterations            | 39           |
|    time_elapsed          | 1759         |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0040686885 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 3.65         |
|    cost_values           | 0.993        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.012        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 119          |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.998        |
|    value_loss            | 243          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1070063   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 47           |
|    iterations            | 41           |
|    time_elapsed          | 1763         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0043931645 |
|    clip_fraction         | 0.0301       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.854        |
|    cost_value_loss       | 0.434        |
|    cost_values           | 0.918        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.00129      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 251          |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.0037      |
|    std                   | 0.961        |
|    value_loss            | 503          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.0968671   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 46           |
|    iterations            | 40           |
|    time_elapsed          | 1768         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0048607923 |
|    clip_fraction         | 0.043        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 14.7         |
|    cost_values           | 1            |
|    entropy               | -2.8         |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.0202       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 114          |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00497     |
|    std                   | 0.98         |
|    value_loss            | 215          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.34        |
| reward                   | -1.4262439  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 47          |
|    iterations            | 41          |
|    time_elapsed          | 1784        |
|    total_timesteps       | 83968       |
| train/                   |             |
|    approx_kl             | 0.004415977 |
|    clip_fraction         | 0.0307      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 6.89        |
|    cost_values           | 0.998       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.0118      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 107         |
|    n_updates             | 400         |
|    policy_gradient_loss  | -0.00309    |
|    std                   | 1.01        |
|    value_loss            | 217         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -2.4075723  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 48          |
|    iterations            | 42          |
|    time_elapsed          | 1788        |
|    total_timesteps       | 86016       |
| train/                   |             |
|    approx_kl             | 0.003783698 |
|    clip_fraction         | 0.0193      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 0.895       |
|    cost_values           | 0.975       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.0154      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 109         |
|    n_updates             | 410         |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.924       |
|    value_loss            | 231         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.453273    |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 47           |
|    iterations            | 42           |
|    time_elapsed          | 1826         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0050642113 |
|    clip_fraction         | 0.0539       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.868        |
|    cost_value_loss       | 0.713        |
|    cost_values           | 0.885        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.00838      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 81           |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00496     |
|    std                   | 0.964        |
|    value_loss            | 168          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.583        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.583        |
| reward                   | -0.28757963  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 46           |
|    iterations            | 41           |
|    time_elapsed          | 1824         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0047492418 |
|    clip_fraction         | 0.0391       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 1.9          |
|    cost_values           | 0.985        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.00999      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.1         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00551     |
|    std                   | 0.98         |
|    value_loss            | 131          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.1689801  |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 44          |
|    iterations            | 40          |
|    time_elapsed          | 1826        |
|    total_timesteps       | 81920       |
| train/                   |             |
|    approx_kl             | 0.003895504 |
|    clip_fraction         | 0.0329      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.5         |
|    cost_value_loss       | 3.36        |
|    cost_values           | 0.991       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0203      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 68.8        |
|    n_updates             | 390         |
|    policy_gradient_loss  | -0.00293    |
|    std                   | 0.996       |
|    value_loss            | 144         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.479774    |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 41           |
|    iterations            | 37           |
|    time_elapsed          | 1826         |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0077983798 |
|    clip_fraction         | 0.0729       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 7.43         |
|    cost_values           | 0.999        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0335       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.4         |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00776     |
|    std                   | 1.07         |
|    value_loss            | 106          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.515587    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 46           |
|    iterations            | 42           |
|    time_elapsed          | 1841         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0031234156 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 2.33         |
|    cost_values           | 0.992        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.00994      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 97.2         |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 1.01         |
|    value_loss            | 213          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.9533875   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 47           |
|    iterations            | 43           |
|    time_elapsed          | 1846         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0037013649 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.936        |
|    cost_value_loss       | 0.823        |
|    cost_values           | 0.971        |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.00639      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 261          |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.925        |
|    value_loss            | 523          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.172        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.172        |
| reward                   | -0.53182334  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 45           |
|    iterations            | 42           |
|    time_elapsed          | 1888         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0052785566 |
|    clip_fraction         | 0.0578       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 1            |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.0228       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51.4         |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00539     |
|    std                   | 0.981        |
|    value_loss            | 98           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.86167353  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 46           |
|    iterations            | 43           |
|    time_elapsed          | 1891         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0046905763 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.9          |
|    cost_value_loss       | 0.631        |
|    cost_values           | 0.88         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.00651      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 90.6         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00466     |
|    std                   | 0.966        |
|    value_loss            | 194          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.6293756   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 44           |
|    iterations            | 41           |
|    time_elapsed          | 1892         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0042985277 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.943        |
|    cost_value_loss       | 0.571        |
|    cost_values           | 0.975        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.00147      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 198          |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.995        |
|    value_loss            | 425          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -2.5469704  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 46          |
|    iterations            | 43          |
|    time_elapsed          | 1899        |
|    total_timesteps       | 88064       |
| train/                   |             |
|    approx_kl             | 0.004930214 |
|    clip_fraction         | 0.0325      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 2.72        |
|    cost_values           | 0.992       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.00689     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 63.1        |
|    n_updates             | 420         |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 1.02        |
|    value_loss            | 131         |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.07         |
| reward                   | -0.5835534   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 40           |
|    iterations            | 38           |
|    time_elapsed          | 1900         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0042229686 |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 3.83         |
|    cost_values           | 0.987        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.00618      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 197          |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.0042      |
|    std                   | 1.07         |
|    value_loss            | 418          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.137644   |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 47          |
|    iterations            | 44          |
|    time_elapsed          | 1905        |
|    total_timesteps       | 90112       |
| train/                   |             |
|    approx_kl             | 0.007850711 |
|    clip_fraction         | 0.0654      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.864       |
|    cost_value_loss       | 0.23        |
|    cost_values           | 0.944       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.00248     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 351         |
|    n_updates             | 430         |
|    policy_gradient_loss  | -0.00528    |
|    std                   | 0.925       |
|    value_loss            | 713         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.53        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.53        |
| reward                   | -0.8080114  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 45          |
|    iterations            | 43          |
|    time_elapsed          | 1950        |
|    total_timesteps       | 88064       |
| train/                   |             |
|    approx_kl             | 0.002952814 |
|    clip_fraction         | 0.0162      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 7.65        |
|    cost_values           | 1           |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.00536     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 241         |
|    n_updates             | 420         |
|    policy_gradient_loss  | -0.00387    |
|    std                   | 0.979       |
|    value_loss            | 491         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.105495    |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 46           |
|    iterations            | 44           |
|    time_elapsed          | 1956         |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0069345543 |
|    clip_fraction         | 0.0763       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.968        |
|    cost_value_loss       | 1.74         |
|    cost_values           | 0.916        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.0107       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.6         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00697     |
|    std                   | 0.968        |
|    value_loss            | 130          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.13        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.13        |
| reward                   | -0.63639295 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 46          |
|    iterations            | 44          |
|    time_elapsed          | 1958        |
|    total_timesteps       | 90112       |
| train/                   |             |
|    approx_kl             | 0.004822361 |
|    clip_fraction         | 0.0318      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 3.07        |
|    cost_values           | 0.996       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.0127      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 202         |
|    n_updates             | 430         |
|    policy_gradient_loss  | -0.00351    |
|    std                   | 1.02        |
|    value_loss            | 418         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.0309741  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 43          |
|    iterations            | 42          |
|    time_elapsed          | 1960        |
|    total_timesteps       | 86016       |
| train/                   |             |
|    approx_kl             | 0.003484829 |
|    clip_fraction         | 0.0277      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.99        |
|    cost_value_loss       | 0.875       |
|    cost_values           | 0.97        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.00584     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 155         |
|    n_updates             | 410         |
|    policy_gradient_loss  | -0.00209    |
|    std                   | 0.999       |
|    value_loss            | 323         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.4470384  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 46          |
|    iterations            | 45          |
|    time_elapsed          | 1967        |
|    total_timesteps       | 92160       |
| train/                   |             |
|    approx_kl             | 0.003043409 |
|    clip_fraction         | 0.0206      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.878       |
|    cost_value_loss       | 0.447       |
|    cost_values           | 0.909       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.0062      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 258         |
|    n_updates             | 440         |
|    policy_gradient_loss  | -0.00294    |
|    std                   | 0.922       |
|    value_loss            | 534         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.78         |
| reward                   | -0.88386166  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 40           |
|    iterations            | 39           |
|    time_elapsed          | 1975         |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0056699794 |
|    clip_fraction         | 0.0469       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 4.62         |
|    cost_values           | 1            |
|    entropy               | -2.97        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.00739      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 134          |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00549     |
|    std                   | 1.07         |
|    value_loss            | 276          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -2.0248678  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 45          |
|    iterations            | 45          |
|    time_elapsed          | 2018        |
|    total_timesteps       | 92160       |
| train/                   |             |
|    approx_kl             | 0.006641576 |
|    clip_fraction         | 0.0465      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 2.33        |
|    cost_values           | 0.992       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.00286     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 75          |
|    n_updates             | 440         |
|    policy_gradient_loss  | -0.00483    |
|    std                   | 1.02        |
|    value_loss            | 137         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.63917875  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 45           |
|    iterations            | 45           |
|    time_elapsed          | 2022         |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0031421878 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.982        |
|    cost_value_loss       | 0.804        |
|    cost_values           | 0.962        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.0192       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 71.4         |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.974        |
|    value_loss            | 149          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.60635674 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 44          |
|    iterations            | 44          |
|    time_elapsed          | 2022        |
|    total_timesteps       | 90112       |
| train/                   |             |
|    approx_kl             | 0.003305974 |
|    clip_fraction         | 0.0242      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.09        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 1           |
|    entropy               | -2.78       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.0252      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 117         |
|    n_updates             | 430         |
|    policy_gradient_loss  | -0.00324    |
|    std                   | 0.972       |
|    value_loss            | 217         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.4316648  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 46          |
|    iterations            | 46          |
|    time_elapsed          | 2029        |
|    total_timesteps       | 94208       |
| train/                   |             |
|    approx_kl             | 0.004904549 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.948       |
|    cost_value_loss       | 0.706       |
|    cost_values           | 0.905       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.0157      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 245         |
|    n_updates             | 450         |
|    policy_gradient_loss  | -0.0052     |
|    std                   | 0.926       |
|    value_loss            | 485         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.409401    |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 43           |
|    iterations            | 43           |
|    time_elapsed          | 2031         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0054843896 |
|    clip_fraction         | 0.0484       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.918        |
|    cost_value_loss       | 0.429        |
|    cost_values           | 0.966        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0025       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00492     |
|    std                   | 1            |
|    value_loss            | 210          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -2.435359    |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 39           |
|    iterations            | 40           |
|    time_elapsed          | 2050         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0027830063 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.04         |
|    cost_value_loss       | 20.9         |
|    cost_values           | 1            |
|    entropy               | -2.99        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.0193       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 80.3         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 1.08         |
|    value_loss            | 167          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.69         |
| reward                   | -0.42395946  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 45           |
|    iterations            | 46           |
|    time_elapsed          | 2079         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0044386247 |
|    clip_fraction         | 0.0322       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 3.55         |
|    cost_values           | 0.997        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.00862      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 109          |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 1.02         |
|    value_loss            | 214          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -1.2288532 |
| rollout/                 |            |
|    ep_len_mean           | 977        |
|    ep_rew_mean           | -1.19e+03  |
| time/                    |            |
|    fps                   | 45         |
|    iterations            | 46         |
|    time_elapsed          | 2089       |
|    total_timesteps       | 94208      |
| train/                   |            |
|    approx_kl             | 0.00541938 |
|    clip_fraction         | 0.0615     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.18       |
|    cost_value_loss       | 1.21       |
|    cost_values           | 0.938      |
|    entropy               | -2.78      |
|    entropy_loss          | -2.78      |
|    explained_variance    | 0.014      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 60.3       |
|    n_updates             | 450        |
|    policy_gradient_loss  | -0.00684   |
|    std                   | 0.972      |
|    value_loss            | 116        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9340435   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 46           |
|    iterations            | 47           |
|    time_elapsed          | 2092         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0027542321 |
|    clip_fraction         | 0.0251       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.833        |
|    cost_value_loss       | 0.209        |
|    cost_values           | 0.9          |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.00515      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 144          |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00435     |
|    std                   | 0.924        |
|    value_loss            | 306          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.01         |
| reward                   | -0.72338784  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 43           |
|    iterations            | 45           |
|    time_elapsed          | 2095         |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0052621854 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 4.2          |
|    cost_values           | 0.997        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.00845      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 118          |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00484     |
|    std                   | 0.971        |
|    value_loss            | 242          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -2.0488563  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 42          |
|    iterations            | 44          |
|    time_elapsed          | 2101        |
|    total_timesteps       | 90112       |
| train/                   |             |
|    approx_kl             | 0.005401255 |
|    clip_fraction         | 0.045       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.99        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 0.993       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0188      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 73.2        |
|    n_updates             | 430         |
|    policy_gradient_loss  | -0.00374    |
|    std                   | 1.01        |
|    value_loss            | 142         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.145       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.145       |
| reward                   | -0.57877606 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 39          |
|    iterations            | 41          |
|    time_elapsed          | 2127        |
|    total_timesteps       | 83968       |
| train/                   |             |
|    approx_kl             | 0.002929533 |
|    clip_fraction         | 0.0162      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.67        |
|    cost_value_loss       | 6.43        |
|    cost_values           | 1           |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.00916     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 122         |
|    n_updates             | 400         |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 1.08        |
|    value_loss            | 269         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.26         |
| reward                   | -0.43089557  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 44           |
|    iterations            | 47           |
|    time_elapsed          | 2142         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0022845212 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 1.88         |
|    cost_values           | 0.988        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.00649      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 112          |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 1.01         |
|    value_loss            | 230          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.3994325  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 44          |
|    iterations            | 47          |
|    time_elapsed          | 2157        |
|    total_timesteps       | 96256       |
| train/                   |             |
|    approx_kl             | 0.004097622 |
|    clip_fraction         | 0.038       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.49        |
|    cost_value_loss       | 8.7         |
|    cost_values           | 0.975       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.0111      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 173         |
|    n_updates             | 460         |
|    policy_gradient_loss  | -0.00438    |
|    std                   | 0.971       |
|    value_loss            | 338         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.903       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.903       |
| reward                   | -0.46108437 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 45          |
|    iterations            | 48          |
|    time_elapsed          | 2157        |
|    total_timesteps       | 98304       |
| train/                   |             |
|    approx_kl             | 0.004913487 |
|    clip_fraction         | 0.0307      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 1.13        |
|    cost_values           | 0.918       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.0115      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 97.6        |
|    n_updates             | 470         |
|    policy_gradient_loss  | -0.00469    |
|    std                   | 0.923       |
|    value_loss            | 187         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.08         |
| reward                   | -1.3671246   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 43           |
|    iterations            | 46           |
|    time_elapsed          | 2172         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0050481353 |
|    clip_fraction         | 0.0444       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 9.81         |
|    cost_values           | 1            |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.0053       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 313          |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00389     |
|    std                   | 0.971        |
|    value_loss            | 591          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.8343774  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 42          |
|    iterations            | 45          |
|    time_elapsed          | 2174        |
|    total_timesteps       | 92160       |
| train/                   |             |
|    approx_kl             | 0.002685516 |
|    clip_fraction         | 0.0154      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.2         |
|    cost_value_loss       | 2.59        |
|    cost_values           | 0.988       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.00801     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 124         |
|    n_updates             | 440         |
|    policy_gradient_loss  | -0.00417    |
|    std                   | 1.01        |
|    value_loss            | 261         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.428        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.428        |
| reward                   | -0.39441192  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 44           |
|    iterations            | 48           |
|    time_elapsed          | 2205         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0060181315 |
|    clip_fraction         | 0.0441       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 5            |
|    cost_values           | 0.999        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0111       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 64.7         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.0046      |
|    std                   | 1.01         |
|    value_loss            | 126          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.411509    |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 38           |
|    iterations            | 42           |
|    time_elapsed          | 2206         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0030810907 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 5.28         |
|    cost_values           | 1            |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.00564      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 395          |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00426     |
|    std                   | 1.08         |
|    value_loss            | 790          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.49         |
| reward                   | -0.47902235  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 45           |
|    iterations            | 49           |
|    time_elapsed          | 2223         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0044635767 |
|    clip_fraction         | 0.0419       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 1.11         |
|    cost_values           | 0.968        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.00887      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 123          |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00474     |
|    std                   | 0.92         |
|    value_loss            | 264          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.304474   |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 44          |
|    iterations            | 48          |
|    time_elapsed          | 2227        |
|    total_timesteps       | 98304       |
| train/                   |             |
|    approx_kl             | 0.004629558 |
|    clip_fraction         | 0.0161      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.95        |
|    cost_value_loss       | 0.42        |
|    cost_values           | 0.904       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.00849     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 125         |
|    n_updates             | 470         |
|    policy_gradient_loss  | -0.00463    |
|    std                   | 0.971       |
|    value_loss            | 261         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.49         |
| reward                   | -1.3727659   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 41           |
|    iterations            | 46           |
|    time_elapsed          | 2247         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0026543369 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 1.21         |
|    cost_values           | 0.985        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.00437      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 94.3         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 1.01         |
|    value_loss            | 207          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.16         |
| reward                   | -1.0721854   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 42           |
|    iterations            | 47           |
|    time_elapsed          | 2249         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0066819247 |
|    clip_fraction         | 0.076        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 2.93         |
|    cost_values           | 1            |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.00491      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 481          |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00507     |
|    std                   | 0.973        |
|    value_loss            | 963          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.61         |
| reward                   | -0.49559897  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 44           |
|    iterations            | 49           |
|    time_elapsed          | 2269         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0073662885 |
|    clip_fraction         | 0.0667       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 9.74         |
|    cost_values           | 1            |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0242       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 77.6         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00569     |
|    std                   | 1.02         |
|    value_loss            | 158          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.02        |
| reward                   | -0.35267514 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 38          |
|    iterations            | 43          |
|    time_elapsed          | 2283        |
|    total_timesteps       | 88064       |
| train/                   |             |
|    approx_kl             | 0.004454349 |
|    clip_fraction         | 0.031       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.79        |
|    cost_value_loss       | 5.88        |
|    cost_values           | 1           |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.00952     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 238         |
|    n_updates             | 420         |
|    policy_gradient_loss  | -0.00354    |
|    std                   | 1.08        |
|    value_loss            | 506         |
------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/pe6a45mq
-----------------------------------
| avg_speed          | 7.98       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.98       |
| reward             | -1.3226376 |
| rollout/           |            |
|    ep_len_mean     | 983        |
|    ep_rew_mean     | -1.34e+03  |
| time/              |            |
|    fps             | 32         |
|    iterations      | 1          |
|    time_elapsed    | 62         |
|    total_timesteps | 102400     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.42232493  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 43           |
|    iterations            | 49           |
|    time_elapsed          | 2298         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0050656674 |
|    clip_fraction         | 0.0449       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 1.08         |
|    cost_values           | 0.95         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.0179       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.4         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00725     |
|    std                   | 0.962        |
|    value_loss            | 120          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.55        |
| reward                   | -1.7497197  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 41          |
|    iterations            | 47          |
|    time_elapsed          | 2323        |
|    total_timesteps       | 96256       |
| train/                   |             |
|    approx_kl             | 0.005225144 |
|    clip_fraction         | 0.0469      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 0.627       |
|    cost_values           | 0.979       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.00513     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 67.3        |
|    n_updates             | 460         |
|    policy_gradient_loss  | -0.00487    |
|    std                   | 1           |
|    value_loss            | 139         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.85         |
| reward                   | -0.993324    |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 42           |
|    iterations            | 48           |
|    time_elapsed          | 2325         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0068701827 |
|    clip_fraction         | 0.0595       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 1            |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.00484      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 337          |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00433     |
|    std                   | 0.975        |
|    value_loss            | 663          |
-------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/7xavsi5z
-----------------------------------
| avg_speed          | 2.38       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 2.38       |
| reward             | -1.3726672 |
| rollout/           |            |
|    ep_len_mean     | 972        |
|    ep_rew_mean     | -1.11e+03  |
| time/              |            |
|    fps             | 32         |
|    iterations      | 1          |
|    time_elapsed    | 62         |
|    total_timesteps | 102400     |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.65         |
| reward                   | -0.6846995   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 31           |
|    iterations            | 2            |
|    time_elapsed          | 131          |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0025842031 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.919        |
|    cost_value_loss       | 0.456        |
|    cost_values           | 0.965        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00339      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 216          |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 0.918        |
|    value_loss            | 438          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.6398292  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 38          |
|    iterations            | 44          |
|    time_elapsed          | 2364        |
|    total_timesteps       | 90112       |
| train/                   |             |
|    approx_kl             | 0.004126204 |
|    clip_fraction         | 0.0309      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.28        |
|    cost_value_loss       | 9.63        |
|    cost_values           | 1           |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.00846     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 295         |
|    n_updates             | 430         |
|    policy_gradient_loss  | -0.00396    |
|    std                   | 1.07        |
|    value_loss            | 590         |
------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/4ts77xgw
-----------------------------------
| avg_speed          | 8.03       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.03       |
| reward             | -1.2053207 |
| rollout/           |            |
|    ep_len_mean     | 978        |
|    ep_rew_mean     | -1.2e+03   |
| time/              |            |
|    fps             | 29         |
|    iterations      | 1          |
|    time_elapsed    | 68         |
|    total_timesteps | 102400     |
-----------------------------------
-------------------------------------------
| avg_speed                | 1.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.64         |
| reward                   | -1.2098522   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 41           |
|    iterations            | 49           |
|    time_elapsed          | 2394         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0028480096 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 1            |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.00648      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 382          |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.000826    |
|    std                   | 0.977        |
|    value_loss            | 796          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.26         |
| reward                   | -1.0421714   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 31           |
|    iterations            | 2            |
|    time_elapsed          | 128          |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0068142186 |
|    clip_fraction         | 0.066        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.8          |
|    cost_values           | 0.971        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.00385      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 230          |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00434     |
|    std                   | 1.02         |
|    value_loss            | 465          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.816        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.816        |
| reward                   | -0.36767313  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 40           |
|    iterations            | 48           |
|    time_elapsed          | 2400         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0053104684 |
|    clip_fraction         | 0.0409       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 3.1          |
|    cost_values           | 0.989        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.00477      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 194          |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.999        |
|    value_loss            | 394          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -1.3016485   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 30           |
|    iterations            | 3            |
|    time_elapsed          | 198          |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0042538443 |
|    clip_fraction         | 0.0531       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.934        |
|    cost_value_loss       | 0.536        |
|    cost_values           | 0.941        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00578      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 342          |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00569     |
|    std                   | 0.918        |
|    value_loss            | 667          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -1.4199106   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 29           |
|    iterations            | 2            |
|    time_elapsed          | 140          |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0067081302 |
|    clip_fraction         | 0.0415       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.966        |
|    cost_value_loss       | 0.773        |
|    cost_values           | 0.955        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.0146       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.3         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.0068      |
|    std                   | 0.959        |
|    value_loss            | 109          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.86         |
| reward                   | -1.0976553   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 37           |
|    iterations            | 45           |
|    time_elapsed          | 2445         |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0059634536 |
|    clip_fraction         | 0.046        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 10.3         |
|    cost_values           | 1            |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.0118       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 154          |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00551     |
|    std                   | 1.07         |
|    value_loss            | 323          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.41         |
| reward                   | -2.234194    |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 31           |
|    iterations            | 3            |
|    time_elapsed          | 196          |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0040958407 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 1.62         |
|    cost_values           | 0.993        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.00724      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.9         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 1.03         |
|    value_loss            | 94.9         |
-------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/uhktx3ql
----------------------------------
| avg_speed          | 7.93      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 7.93      |
| reward             | -1.798304 |
| rollout/           |           |
|    ep_len_mean     | 970       |
|    ep_rew_mean     | -1.23e+03 |
| time/              |           |
|    fps             | 26        |
|    iterations      | 1         |
|    time_elapsed    | 78        |
|    total_timesteps | 102400    |
----------------------------------
-------------------------------------------
| avg_speed                | 4.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.88         |
| reward                   | -0.801967    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 40           |
|    iterations            | 49           |
|    time_elapsed          | 2477         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0050727013 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.63         |
|    cost_values           | 0.987        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.00981      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 86           |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 0.998        |
|    value_loss            | 175          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.733695    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 30           |
|    iterations            | 4            |
|    time_elapsed          | 267          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0023322373 |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.8          |
|    cost_value_loss       | 0.0847       |
|    cost_values           | 0.912        |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.00156      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 379          |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 0.916        |
|    value_loss            | 783          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.9674733   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 3            |
|    time_elapsed          | 215          |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0063450383 |
|    clip_fraction         | 0.0595       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 1.71         |
|    cost_values           | 0.951        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.0111       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 70.9         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00573     |
|    std                   | 0.961        |
|    value_loss            | 151          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.18        |
| reward                   | -1.1656717  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 37          |
|    iterations            | 46          |
|    time_elapsed          | 2527        |
|    total_timesteps       | 94208       |
| train/                   |             |
|    approx_kl             | 0.005378286 |
|    clip_fraction         | 0.069       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 13.7        |
|    cost_values           | 1.01        |
|    entropy               | -3          |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.0129      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 110         |
|    n_updates             | 450         |
|    policy_gradient_loss  | -0.00794    |
|    std                   | 1.09        |
|    value_loss            | 222         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -1.2876581  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 30          |
|    iterations            | 4           |
|    time_elapsed          | 266         |
|    total_timesteps       | 108544      |
| train/                   |             |
|    approx_kl             | 0.004068584 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.13        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 1           |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.0168      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 69.7        |
|    n_updates             | 520         |
|    policy_gradient_loss  | -0.00373    |
|    std                   | 1.03        |
|    value_loss            | 136         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.7          |
| reward                   | -1.324404    |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 2            |
|    time_elapsed          | 156          |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0033310417 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 4.87         |
|    cost_values           | 0.999        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.00784      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 213          |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 0.988        |
|    value_loss            | 430          |
-------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/mtgakx2v
-----------------------------------
| avg_speed          | 0.874      |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.874      |
| reward             | -0.6176806 |
| rollout/           |            |
|    ep_len_mean     | 968        |
|    ep_rew_mean     | -1.18e+03  |
| time/              |            |
|    fps             | 26         |
|    iterations      | 1          |
|    time_elapsed    | 76         |
|    total_timesteps | 102400     |
-----------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4006928  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 30          |
|    iterations            | 5           |
|    time_elapsed          | 337         |
|    total_timesteps       | 110592      |
| train/                   |             |
|    approx_kl             | 0.006669554 |
|    clip_fraction         | 0.0637      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 1.6         |
|    cost_values           | 0.937       |
|    entropy               | -2.67       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.0126      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 84          |
|    n_updates             | 530         |
|    policy_gradient_loss  | -0.00745    |
|    std                   | 0.918       |
|    value_loss            | 158         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1174691  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 28          |
|    iterations            | 4           |
|    time_elapsed          | 289         |
|    total_timesteps       | 108544      |
| train/                   |             |
|    approx_kl             | 0.003999997 |
|    clip_fraction         | 0.0326      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.851       |
|    cost_value_loss       | 0.501       |
|    cost_values           | 0.955       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.00373     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 200         |
|    n_updates             | 520         |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 0.961       |
|    value_loss            | 426         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00523      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00523      |
| reward                   | -0.7385868   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 30           |
|    iterations            | 5            |
|    time_elapsed          | 335          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0047232043 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.987        |
|    cost_value_loss       | 0.725        |
|    cost_values           | 0.95         |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0013       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 169          |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 1.03         |
|    value_loss            | 337          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.47         |
| reward                   | -1.3508677   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 36           |
|    iterations            | 47           |
|    time_elapsed          | 2610         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0047037452 |
|    clip_fraction         | 0.0385       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 7.39         |
|    cost_values           | 1            |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.0253       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.7         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00666     |
|    std                   | 1.09         |
|    value_loss            | 45.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3551763  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 30          |
|    iterations            | 6           |
|    time_elapsed          | 408         |
|    total_timesteps       | 112640      |
| train/                   |             |
|    approx_kl             | 0.005131088 |
|    clip_fraction         | 0.0549      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 0.956       |
|    cost_values           | 0.977       |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.00505     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 174         |
|    n_updates             | 540         |
|    policy_gradient_loss  | -0.00542    |
|    std                   | 0.919       |
|    value_loss            | 356         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.6011921  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 2           |
|    time_elapsed          | 156         |
|    total_timesteps       | 104448      |
| train/                   |             |
|    approx_kl             | 0.001801346 |
|    clip_fraction         | 0.0189      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.57        |
|    cost_value_loss       | 9.01        |
|    cost_values           | 0.987       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.0166      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 121         |
|    n_updates             | 500         |
|    policy_gradient_loss  | -0.00243    |
|    std                   | 0.994       |
|    value_loss            | 250         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.7209979   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 3            |
|    time_elapsed          | 243          |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0059002875 |
|    clip_fraction         | 0.0504       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 44.6         |
|    cost_values           | 1.02         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.00902      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 223          |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00565     |
|    std                   | 0.991        |
|    value_loss            | 432          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.9763951   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 5            |
|    time_elapsed          | 363          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0024999245 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 0.865        |
|    cost_values           | 0.965        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.00991      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 100          |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.957        |
|    value_loss            | 213          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.22         |
| reward                   | -1.2804937   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 30           |
|    iterations            | 6            |
|    time_elapsed          | 406          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0042406446 |
|    clip_fraction         | 0.0429       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 2            |
|    cost_values           | 0.955        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00587      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 82.5         |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00341     |
|    std                   | 1.03         |
|    value_loss            | 174          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.409       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.409       |
| reward                   | -0.47514588 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 36          |
|    iterations            | 48          |
|    time_elapsed          | 2696        |
|    total_timesteps       | 98304       |
| train/                   |             |
|    approx_kl             | 0.002089763 |
|    clip_fraction         | 0.0144      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 2.62        |
|    cost_values           | 1           |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.00442     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 247         |
|    n_updates             | 470         |
|    policy_gradient_loss  | -0.00124    |
|    std                   | 1.09        |
|    value_loss            | 512         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.82998604 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 29          |
|    iterations            | 7           |
|    time_elapsed          | 481         |
|    total_timesteps       | 114688      |
| train/                   |             |
|    approx_kl             | 0.005636041 |
|    clip_fraction         | 0.0477      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.935       |
|    cost_value_loss       | 0.5         |
|    cost_values           | 0.916       |
|    entropy               | -2.66       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.00507     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 84.1        |
|    n_updates             | 550         |
|    policy_gradient_loss  | -0.00476    |
|    std                   | 0.917       |
|    value_loss            | 169         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.1653337   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 3            |
|    time_elapsed          | 237          |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0044518905 |
|    clip_fraction         | 0.0664       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 1.81         |
|    cost_values           | 0.976        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.00426      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 146          |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00528     |
|    std                   | 0.991        |
|    value_loss            | 299          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.24         |
| reward                   | -2.0011494   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 4            |
|    time_elapsed          | 331          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0030922075 |
|    clip_fraction         | 0.0409       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 4.05         |
|    cost_values           | 0.973        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.00303      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 212          |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.994        |
|    value_loss            | 434          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -2.18513    |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 27          |
|    iterations            | 6           |
|    time_elapsed          | 439         |
|    total_timesteps       | 112640      |
| train/                   |             |
|    approx_kl             | 0.006435199 |
|    clip_fraction         | 0.0487      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.956       |
|    cost_value_loss       | 0.45        |
|    cost_values           | 0.923       |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.00427     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 125         |
|    n_updates             | 540         |
|    policy_gradient_loss  | -0.0073     |
|    std                   | 0.957       |
|    value_loss            | 260         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.99         |
| reward                   | -1.1510621   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 29           |
|    iterations            | 7            |
|    time_elapsed          | 478          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0016169038 |
|    clip_fraction         | 0.00308      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 1.64         |
|    cost_values           | 0.988        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00596      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 98           |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 1.03         |
|    value_loss            | 221          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.7877723   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 29           |
|    iterations            | 8            |
|    time_elapsed          | 555          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0042739026 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.917        |
|    cost_value_loss       | 0.259        |
|    cost_values           | 0.921        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00397      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 131          |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.00453     |
|    std                   | 0.918        |
|    value_loss            | 264          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.13         |
| reward                   | -0.575626    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 36           |
|    iterations            | 49           |
|    time_elapsed          | 2782         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0039754636 |
|    clip_fraction         | 0.0569       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.24         |
|    cost_value_loss       | 20.1         |
|    cost_values           | 1.01         |
|    entropy               | -3.03        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.00892      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 197          |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00538     |
|    std                   | 1.1          |
|    value_loss            | 375          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.47968906  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 4            |
|    time_elapsed          | 319          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0030217315 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.917        |
|    cost_value_loss       | 0.422        |
|    cost_values           | 0.996        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.00133      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 275          |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.993        |
|    value_loss            | 567          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.6937096   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 7            |
|    time_elapsed          | 516          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0038462998 |
|    clip_fraction         | 0.0384       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.932        |
|    cost_value_loss       | 0.524        |
|    cost_values           | 0.919        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.00274      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 96.7         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00589     |
|    std                   | 0.959        |
|    value_loss            | 190          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.384       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.384       |
| reward                   | -0.5990325  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 5           |
|    time_elapsed          | 421         |
|    total_timesteps       | 110592      |
| train/                   |             |
|    approx_kl             | 0.004789284 |
|    clip_fraction         | 0.0517      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 1.88        |
|    cost_values           | 0.997       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.00276     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 331         |
|    n_updates             | 530         |
|    policy_gradient_loss  | -0.00456    |
|    std                   | 0.992       |
|    value_loss            | 688         |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.54         |
| reward                   | -1.2089462   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 29           |
|    iterations            | 8            |
|    time_elapsed          | 551          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0049842615 |
|    clip_fraction         | 0.0472       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 2.46         |
|    cost_values           | 0.995        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00724      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 64.2         |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.00601     |
|    std                   | 1.03         |
|    value_loss            | 128          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -2.1132493  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.39e+03   |
| time/                    |             |
|    fps                   | 29          |
|    iterations            | 9           |
|    time_elapsed          | 628         |
|    total_timesteps       | 118784      |
| train/                   |             |
|    approx_kl             | 0.002798614 |
|    clip_fraction         | 0.0173      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 0.983       |
|    cost_values           | 0.946       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.00511     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 153         |
|    n_updates             | 570         |
|    policy_gradient_loss  | -0.0035     |
|    std                   | 0.923       |
|    value_loss            | 308         |
------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/p13vkfbg
-----------------------------------
| avg_speed          | 2.26       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 2.26       |
| reward             | -0.7003649 |
| rollout/           |            |
|    ep_len_mean     | 968        |
|    ep_rew_mean     | -1.18e+03  |
| time/              |            |
|    fps             | 24         |
|    iterations      | 1          |
|    time_elapsed    | 83         |
|    total_timesteps | 102400     |
-----------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -1.2520635  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 5           |
|    time_elapsed          | 402         |
|    total_timesteps       | 110592      |
| train/                   |             |
|    approx_kl             | 0.005384191 |
|    clip_fraction         | 0.0834      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.976       |
|    cost_value_loss       | 1.05        |
|    cost_values           | 0.984       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.00271     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 161         |
|    n_updates             | 530         |
|    policy_gradient_loss  | -0.00727    |
|    std                   | 0.996       |
|    value_loss            | 325         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -2.1056318  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 27          |
|    iterations            | 8           |
|    time_elapsed          | 593         |
|    total_timesteps       | 116736      |
| train/                   |             |
|    approx_kl             | 0.003961583 |
|    clip_fraction         | 0.0254      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.861       |
|    cost_value_loss       | 0.591       |
|    cost_values           | 0.911       |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.00411     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 86.5        |
|    n_updates             | 560         |
|    policy_gradient_loss  | -0.0046     |
|    std                   | 0.958       |
|    value_loss            | 182         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.58        |
| reward                   | -1.7182038  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 29          |
|    iterations            | 9           |
|    time_elapsed          | 625         |
|    total_timesteps       | 118784      |
| train/                   |             |
|    approx_kl             | 0.003811655 |
|    clip_fraction         | 0.0172      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.12        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 1           |
|    entropy               | -2.89       |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.0244      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.8        |
|    n_updates             | 570         |
|    policy_gradient_loss  | -0.00271    |
|    std                   | 1.03        |
|    value_loss            | 61.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.639        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.639        |
| reward                   | -0.5334753   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 6            |
|    time_elapsed          | 513          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0032213985 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.76         |
|    cost_value_loss       | 32           |
|    cost_values           | 1.01         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0088       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 192          |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.989        |
|    value_loss            | 364          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.0180316   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 10           |
|    time_elapsed          | 706          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0057795653 |
|    clip_fraction         | 0.0463       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.863        |
|    cost_value_loss       | 0.166        |
|    cost_values           | 0.952        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.0017       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 133          |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00522     |
|    std                   | 0.922        |
|    value_loss            | 284          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.97         |
| reward                   | -0.7073122   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 2            |
|    time_elapsed          | 170          |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0069649206 |
|    clip_fraction         | 0.0495       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 6.36         |
|    cost_values           | 1.09         |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.00919      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 77           |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00527     |
|    std                   | 1.11         |
|    value_loss            | 155          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -1.5670756  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 6           |
|    time_elapsed          | 488         |
|    total_timesteps       | 112640      |
| train/                   |             |
|    approx_kl             | 0.005812965 |
|    clip_fraction         | 0.0453      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.35        |
|    cost_value_loss       | 6.13        |
|    cost_values           | 0.984       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.00325     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 168         |
|    n_updates             | 540         |
|    policy_gradient_loss  | -0.00399    |
|    std                   | 0.994       |
|    value_loss            | 346         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8281188   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 9            |
|    time_elapsed          | 673          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0032497612 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.816        |
|    cost_value_loss       | 0.402        |
|    cost_values           | 0.87         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.00057      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 151          |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.955        |
|    value_loss            | 315          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.7          |
| reward                   | -1.1643445   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 29           |
|    iterations            | 10           |
|    time_elapsed          | 700          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0049152626 |
|    clip_fraction         | 0.0411       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.981        |
|    cost_value_loss       | 0.77         |
|    cost_values           | 0.987        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00205      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 271          |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 1.03         |
|    value_loss            | 562          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.7332352   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 11           |
|    time_elapsed          | 783          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0041461717 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.873        |
|    cost_value_loss       | 0.353        |
|    cost_values           | 0.889        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00262      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 151          |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 0.918        |
|    value_loss            | 310          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.08         |
| reward                   | -1.2243673   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 7            |
|    time_elapsed          | 616          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0039980006 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.46         |
|    cost_value_loss       | 33.4         |
|    cost_values           | 1.3          |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0159       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.2         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00463     |
|    std                   | 0.987        |
|    value_loss            | 41.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.09        |
| reward                   | -0.67472064 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 3           |
|    time_elapsed          | 257         |
|    total_timesteps       | 106496      |
| train/                   |             |
|    approx_kl             | 0.007567187 |
|    clip_fraction         | 0.0585      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.68        |
|    cost_value_loss       | 6.26        |
|    cost_values           | 0.999       |
|    entropy               | -3.04       |
|    entropy_loss          | -3.04       |
|    explained_variance    | 0.00674     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.1        |
|    n_updates             | 510         |
|    policy_gradient_loss  | -0.00741    |
|    std                   | 1.11        |
|    value_loss            | 37.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.7          |
| reward                   | -1.6759826   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 29           |
|    iterations            | 11           |
|    time_elapsed          | 776          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0037439198 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 1.35         |
|    cost_values           | 0.99         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00593      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 82.4         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 1.03         |
|    value_loss            | 164          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.84         |
| reward                   | -0.48499414  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 10           |
|    time_elapsed          | 752          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0055694003 |
|    clip_fraction         | 0.0351       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.802        |
|    cost_value_loss       | 0.294        |
|    cost_values           | 0.832        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.00166      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 84.4         |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00546     |
|    std                   | 0.954        |
|    value_loss            | 179          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.84980184  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 7            |
|    time_elapsed          | 575          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0023052688 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 1.02         |
|    cost_values           | 0.984        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.00396      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 108          |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.992        |
|    value_loss            | 222          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.096084    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 12           |
|    time_elapsed          | 860          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0061483765 |
|    clip_fraction         | 0.0584       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.865        |
|    cost_value_loss       | 0.487        |
|    cost_values           | 0.872        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00449      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 140          |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00598     |
|    std                   | 0.919        |
|    value_loss            | 289          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -2.5866761  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 8           |
|    time_elapsed          | 716         |
|    total_timesteps       | 116736      |
| train/                   |             |
|    approx_kl             | 0.004010589 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.71        |
|    cost_value_loss       | 16.2        |
|    cost_values           | 1.91        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.0132      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.4        |
|    n_updates             | 560         |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 0.991       |
|    value_loss            | 39.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.48        |
| reward                   | -2.23024    |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 28          |
|    iterations            | 12          |
|    time_elapsed          | 853         |
|    total_timesteps       | 124928      |
| train/                   |             |
|    approx_kl             | 0.003306627 |
|    clip_fraction         | 0.0167      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.13        |
|    cost_value_loss       | 1.04        |
|    cost_values           | 0.995       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.00891     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 66          |
|    n_updates             | 600         |
|    policy_gradient_loss  | -0.00299    |
|    std                   | 1.03        |
|    value_loss            | 129         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.47541767 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 27          |
|    iterations            | 11          |
|    time_elapsed          | 833         |
|    total_timesteps       | 122880      |
| train/                   |             |
|    approx_kl             | 0.004664194 |
|    clip_fraction         | 0.0252      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.81        |
|    cost_value_loss       | 0.469       |
|    cost_values           | 0.811       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.00416     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 46.6        |
|    n_updates             | 590         |
|    policy_gradient_loss  | -0.0048     |
|    std                   | 0.951       |
|    value_loss            | 99.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.386        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.386        |
| reward                   | -0.5794299   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 4            |
|    time_elapsed          | 348          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0049185674 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 14.6         |
|    cost_values           | 1            |
|    entropy               | -3.03        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.00883      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47           |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 1.1          |
|    value_loss            | 92.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.95769554 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 8           |
|    time_elapsed          | 662         |
|    total_timesteps       | 116736      |
| train/                   |             |
|    approx_kl             | 0.003726122 |
|    clip_fraction         | 0.0313      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.967       |
|    cost_value_loss       | 0.36        |
|    cost_values           | 0.987       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.00536     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 133         |
|    n_updates             | 560         |
|    policy_gradient_loss  | -0.0039     |
|    std                   | 0.99        |
|    value_loss            | 283         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -1.1445076   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.43e+03    |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 13           |
|    time_elapsed          | 938          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0045967586 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.815        |
|    cost_value_loss       | 0.303        |
|    cost_values           | 0.85         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00209      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 147          |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 0.922        |
|    value_loss            | 320          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.32        |
| reward                   | -1.5963793  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 28          |
|    iterations            | 13          |
|    time_elapsed          | 931         |
|    total_timesteps       | 126976      |
| train/                   |             |
|    approx_kl             | 0.008857894 |
|    clip_fraction         | 0.0926      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.938       |
|    cost_value_loss       | 0.512       |
|    cost_values           | 0.984       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.00141     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 134         |
|    n_updates             | 610         |
|    policy_gradient_loss  | -0.0071     |
|    std                   | 1.03        |
|    value_loss            | 276         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -2.5988092   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 9            |
|    time_elapsed          | 812          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0022966946 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 3.48         |
|    cost_values           | 1.87         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0064       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 203          |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.991        |
|    value_loss            | 420          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0236703   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 12           |
|    time_elapsed          | 914          |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0044690985 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.796        |
|    cost_value_loss       | 0.494        |
|    cost_values           | 0.805        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.00174      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 95.9         |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00436     |
|    std                   | 0.954        |
|    value_loss            | 207          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.09         |
| reward                   | -0.96398014  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 5            |
|    time_elapsed          | 438          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0039555402 |
|    clip_fraction         | 0.0365       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 13.3         |
|    cost_values           | 1.01         |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.0114       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.3         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 1.11         |
|    value_loss            | 44.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8311346   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 9            |
|    time_elapsed          | 751          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0047170185 |
|    clip_fraction         | 0.0301       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 4.47         |
|    cost_values           | 0.988        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.00536      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66.1         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00513     |
|    std                   | 0.993        |
|    value_loss            | 134          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -2.140259   |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.44e+03   |
| time/                    |             |
|    fps                   | 28          |
|    iterations            | 14          |
|    time_elapsed          | 1020        |
|    total_timesteps       | 129024      |
| train/                   |             |
|    approx_kl             | 0.004226047 |
|    clip_fraction         | 0.0407      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.751       |
|    cost_value_loss       | 0.178       |
|    cost_values           | 0.806       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.000972    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 215         |
|    n_updates             | 620         |
|    policy_gradient_loss  | -0.00393    |
|    std                   | 0.923       |
|    value_loss            | 432         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -2.1315284   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 14           |
|    time_elapsed          | 1009         |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0031645368 |
|    clip_fraction         | 0.0298       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.904        |
|    cost_value_loss       | 0.553        |
|    cost_values           | 0.964        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.00314      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 168          |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 1.03         |
|    value_loss            | 345          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.88131565 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 13          |
|    time_elapsed          | 996         |
|    total_timesteps       | 126976      |
| train/                   |             |
|    approx_kl             | 0.004628662 |
|    clip_fraction         | 0.0432      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.777       |
|    cost_value_loss       | 0.497       |
|    cost_values           | 0.792       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.00332     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 61.3        |
|    n_updates             | 610         |
|    policy_gradient_loss  | -0.0052     |
|    std                   | 0.953       |
|    value_loss            | 134         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -2.547891   |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 10          |
|    time_elapsed          | 902         |
|    total_timesteps       | 120832      |
| train/                   |             |
|    approx_kl             | 0.005884257 |
|    clip_fraction         | 0.0368      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.91        |
|    cost_value_loss       | 26.8        |
|    cost_values           | 1.38        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.00456     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 203         |
|    n_updates             | 580         |
|    policy_gradient_loss  | -0.00407    |
|    std                   | 0.99        |
|    value_loss            | 391         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.15         |
| reward                   | -0.6662082   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 6            |
|    time_elapsed          | 529          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0025333639 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 21.7         |
|    cost_values           | 1.08         |
|    entropy               | -3.05        |
|    entropy_loss          | -3.05        |
|    explained_variance    | 0.014        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.8         |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 1.11         |
|    value_loss            | 42.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -1.4875675   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 10           |
|    time_elapsed          | 841          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0046399185 |
|    clip_fraction         | 0.052        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.983        |
|    cost_value_loss       | 0.988        |
|    cost_values           | 0.964        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.000926     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.3         |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00519     |
|    std                   | 0.997        |
|    value_loss            | 117          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4051633   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.46e+03    |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 15           |
|    time_elapsed          | 1096         |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0027818359 |
|    clip_fraction         | 0.00815      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.798        |
|    cost_value_loss       | 0.639        |
|    cost_values           | 0.779        |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.00391      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 241          |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00367     |
|    std                   | 0.922        |
|    value_loss            | 488          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.633        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.633        |
| reward                   | -0.23948163  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 15           |
|    time_elapsed          | 1090         |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0047218828 |
|    clip_fraction         | 0.0298       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 2.55         |
|    cost_values           | 0.969        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00786      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 181          |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 1.03         |
|    value_loss            | 366          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -1.120547   |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 14          |
|    time_elapsed          | 1080        |
|    total_timesteps       | 129024      |
| train/                   |             |
|    approx_kl             | 0.004507766 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.834       |
|    cost_value_loss       | 1.32        |
|    cost_values           | 0.795       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.00155     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 114         |
|    n_updates             | 620         |
|    policy_gradient_loss  | -0.00437    |
|    std                   | 0.955       |
|    value_loss            | 236         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -2.502474    |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 11           |
|    time_elapsed          | 993          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0058141463 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.18         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 1.06         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.00383      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 179          |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00347     |
|    std                   | 0.986        |
|    value_loss            | 335          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -2.350765   |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 27          |
|    iterations            | 16          |
|    time_elapsed          | 1179        |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.006114413 |
|    clip_fraction         | 0.0579      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.729       |
|    cost_value_loss       | 0.303       |
|    cost_values           | 0.772       |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.00202     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 244         |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 0.92        |
|    value_loss            | 519         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6703509  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 7           |
|    time_elapsed          | 623         |
|    total_timesteps       | 114688      |
| train/                   |             |
|    approx_kl             | 0.004662884 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.99        |
|    cost_value_loss       | 9.23        |
|    cost_values           | 1.07        |
|    entropy               | -3.06       |
|    entropy_loss          | -3.06       |
|    explained_variance    | 0.0111      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.7        |
|    n_updates             | 550         |
|    policy_gradient_loss  | -0.00379    |
|    std                   | 1.12        |
|    value_loss            | 49.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.4615533   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 11           |
|    time_elapsed          | 933          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0042324443 |
|    clip_fraction         | 0.0407       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.94         |
|    cost_values           | 0.98         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.00469      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 77.1         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00392     |
|    std                   | 0.996        |
|    value_loss            | 168          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.42        |
| reward                   | -0.89454734 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 27          |
|    iterations            | 16          |
|    time_elapsed          | 1171        |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.004161371 |
|    clip_fraction         | 0.0412      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 1.93        |
|    cost_values           | 0.994       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.0039      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 107         |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.00387    |
|    std                   | 1.04        |
|    value_loss            | 198         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.74         |
| reward                   | -1.289535    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 15           |
|    time_elapsed          | 1164         |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0045156972 |
|    clip_fraction         | 0.0419       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.873        |
|    cost_value_loss       | 0.855        |
|    cost_values           | 0.834        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.00325      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 87           |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00436     |
|    std                   | 0.956        |
|    value_loss            | 174          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.8183697  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 27          |
|    iterations            | 17          |
|    time_elapsed          | 1260        |
|    total_timesteps       | 135168      |
| train/                   |             |
|    approx_kl             | 0.003696174 |
|    clip_fraction         | 0.0302      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.691       |
|    cost_value_loss       | 0.162       |
|    cost_values           | 0.735       |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.00128     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 317         |
|    n_updates             | 650         |
|    policy_gradient_loss  | -0.00354    |
|    std                   | 0.92        |
|    value_loss            | 629         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.86         |
| reward                   | -1.7017454   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 12           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 124928       |
| train/                   |              |
|    approx_kl             | 0.0026628012 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 9.49         |
|    cost_values           | 1            |
|    entropy               | -2.82        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.00524      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 128          |
|    n_updates             | 600          |
|    policy_gradient_loss  | -0.00242     |
|    std                   | 0.99         |
|    value_loss            | 248          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -1.1285756   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 8            |
|    time_elapsed          | 719          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0057017775 |
|    clip_fraction         | 0.0604       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 7.41         |
|    cost_values           | 1.01         |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.00567      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.00503     |
|    std                   | 1.12         |
|    value_loss            | 18.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -1.6806227  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 12          |
|    time_elapsed          | 1028        |
|    total_timesteps       | 124928      |
| train/                   |             |
|    approx_kl             | 0.004832934 |
|    clip_fraction         | 0.0274      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 1.1         |
|    cost_values           | 0.988       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.00336     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 119         |
|    n_updates             | 600         |
|    policy_gradient_loss  | -0.00387    |
|    std                   | 0.996       |
|    value_loss            | 234         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.81        |
| reward                   | -0.51266664 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 27          |
|    iterations            | 17          |
|    time_elapsed          | 1254        |
|    total_timesteps       | 135168      |
| train/                   |             |
|    approx_kl             | 0.002980966 |
|    clip_fraction         | 0.0318      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.63        |
|    cost_value_loss       | 6.97        |
|    cost_values           | 0.998       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.00815     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 86.6        |
|    n_updates             | 650         |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 1.04        |
|    value_loss            | 193         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.86300296 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 16          |
|    time_elapsed          | 1251        |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.008816931 |
|    clip_fraction         | 0.0765      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.96        |
|    cost_value_loss       | 1.01        |
|    cost_values           | 0.902       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.00532     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 44.2        |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.00822    |
|    std                   | 0.963       |
|    value_loss            | 104         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -2.1361973  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 13          |
|    time_elapsed          | 1168        |
|    total_timesteps       | 126976      |
| train/                   |             |
|    approx_kl             | 0.003200117 |
|    clip_fraction         | 0.0176      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 8.02        |
|    cost_values           | 1           |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.00458     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 134         |
|    n_updates             | 610         |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.994       |
|    value_loss            | 290         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.6915742   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.46e+03    |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 18           |
|    time_elapsed          | 1341         |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0049986243 |
|    clip_fraction         | 0.0626       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.697        |
|    cost_value_loss       | 0.313        |
|    cost_values           | 0.705        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.0022       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 107          |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.00607     |
|    std                   | 0.918        |
|    value_loss            | 212          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -1.1731263   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 9            |
|    time_elapsed          | 814          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0054792603 |
|    clip_fraction         | 0.0505       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 8.22         |
|    cost_values           | 1            |
|    entropy               | -3.04        |
|    entropy_loss          | -3.05        |
|    explained_variance    | 0.00718      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.9         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00579     |
|    std                   | 1.11         |
|    value_loss            | 39.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2057267   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 13           |
|    time_elapsed          | 1122         |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0039319484 |
|    clip_fraction         | 0.0589       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 3.04         |
|    cost_values           | 0.999        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0063       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 136          |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00533     |
|    std                   | 0.991        |
|    value_loss            | 280          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.53         |
| reward                   | -1.0678124   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 18           |
|    time_elapsed          | 1337         |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0017849848 |
|    clip_fraction         | 0.00942      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 3.45         |
|    cost_values           | 0.997        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0144       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 105          |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 1.04         |
|    value_loss            | 205          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -2.0501766   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 17           |
|    time_elapsed          | 1338         |
|    total_timesteps       | 135168       |
| train/                   |              |
|    approx_kl             | 0.0055294815 |
|    clip_fraction         | 0.0391       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 2.33         |
|    cost_values           | 0.951        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.0059       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 77.5         |
|    n_updates             | 650          |
|    policy_gradient_loss  | -0.00368     |
|    std                   | 0.96         |
|    value_loss            | 162          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.7022955  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.45e+03   |
| time/                    |             |
|    fps                   | 27          |
|    iterations            | 19          |
|    time_elapsed          | 1427        |
|    total_timesteps       | 139264      |
| train/                   |             |
|    approx_kl             | 0.003803011 |
|    clip_fraction         | 0.0303      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.647       |
|    cost_value_loss       | 0.235       |
|    cost_values           | 0.68        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.00131     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 157         |
|    n_updates             | 670         |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.921       |
|    value_loss            | 323         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.889        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.889        |
| reward                   | -0.6299661   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 14           |
|    time_elapsed          | 1258         |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0033105284 |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 3.09         |
|    cost_values           | 1            |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.00205      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 159          |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00301     |
|    std                   | 0.999        |
|    value_loss            | 317          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.91        |
| reward                   | -1.4519147  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 27          |
|    iterations            | 19          |
|    time_elapsed          | 1422        |
|    total_timesteps       | 139264      |
| train/                   |             |
|    approx_kl             | 0.006700306 |
|    clip_fraction         | 0.0631      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.23        |
|    cost_value_loss       | 2.76        |
|    cost_values           | 0.998       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.00786     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 91.5        |
|    n_updates             | 670         |
|    policy_gradient_loss  | -0.00755    |
|    std                   | 1.04        |
|    value_loss            | 188         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.1713973   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 14           |
|    time_elapsed          | 1216         |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0056427075 |
|    clip_fraction         | 0.0506       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 1.32         |
|    cost_values           | 0.986        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.00524      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 55.7         |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00597     |
|    std                   | 0.987        |
|    value_loss            | 114          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.84        |
| reward                   | -1.1793178  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -1.09e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 10          |
|    time_elapsed          | 911         |
|    total_timesteps       | 120832      |
| train/                   |             |
|    approx_kl             | 0.004507761 |
|    clip_fraction         | 0.0477      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 2.99        |
|    cost_values           | 1           |
|    entropy               | -3.05       |
|    entropy_loss          | -3.04       |
|    explained_variance    | 0.00579     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26          |
|    n_updates             | 580         |
|    policy_gradient_loss  | -0.00737    |
|    std                   | 1.11        |
|    value_loss            | 50          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1286974  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 18          |
|    time_elapsed          | 1427        |
|    total_timesteps       | 137216      |
| train/                   |             |
|    approx_kl             | 0.004817548 |
|    clip_fraction         | 0.0355      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 1.45        |
|    cost_values           | 0.965       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.00588     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 67.1        |
|    n_updates             | 660         |
|    policy_gradient_loss  | -0.00585    |
|    std                   | 0.962       |
|    value_loss            | 139         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -2.506688    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.48e+03    |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 20           |
|    time_elapsed          | 1515         |
|    total_timesteps       | 141312       |
| train/                   |              |
|    approx_kl             | 0.0053742845 |
|    clip_fraction         | 0.0479       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.629        |
|    cost_value_loss       | 0.253        |
|    cost_values           | 0.643        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.00527      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 78.5         |
|    n_updates             | 680          |
|    policy_gradient_loss  | -0.00674     |
|    std                   | 0.921        |
|    value_loss            | 173          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.42         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.42         |
| reward                   | -0.5102844   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 15           |
|    time_elapsed          | 1363         |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0024108025 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 1            |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.00629      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 153          |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 1            |
|    value_loss            | 327          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.03        |
| reward                   | -1.2655073  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 27          |
|    iterations            | 20          |
|    time_elapsed          | 1507        |
|    total_timesteps       | 141312      |
| train/                   |             |
|    approx_kl             | 0.004301174 |
|    clip_fraction         | 0.0269      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 1.46        |
|    cost_values           | 0.997       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.00429     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 180         |
|    n_updates             | 680         |
|    policy_gradient_loss  | -0.00309    |
|    std                   | 1.04        |
|    value_loss            | 393         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.72        |
| reward                   | -0.9095706  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 15          |
|    time_elapsed          | 1313        |
|    total_timesteps       | 131072      |
| train/                   |             |
|    approx_kl             | 0.004781577 |
|    clip_fraction         | 0.0368      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.23        |
|    cost_value_loss       | 1.53        |
|    cost_values           | 0.979       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.0123      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.6        |
|    n_updates             | 630         |
|    policy_gradient_loss  | -0.00469    |
|    std                   | 0.983       |
|    value_loss            | 50.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.604        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.604        |
| reward                   | -0.3692623   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 11           |
|    time_elapsed          | 1010         |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0026310636 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.92         |
|    cost_value_loss       | 60.5         |
|    cost_values           | 1.1          |
|    entropy               | -3.05        |
|    entropy_loss          | -3.05        |
|    explained_variance    | 0.0354       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.5         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00397     |
|    std                   | 1.11         |
|    value_loss            | 73.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.4969522  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 19          |
|    time_elapsed          | 1517        |
|    total_timesteps       | 139264      |
| train/                   |             |
|    approx_kl             | 0.004386325 |
|    clip_fraction         | 0.043       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.19        |
|    cost_value_loss       | 1.94        |
|    cost_values           | 0.94        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.00635     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 146         |
|    n_updates             | 670         |
|    policy_gradient_loss  | -0.00573    |
|    std                   | 0.963       |
|    value_loss            | 288         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.42         |
| reward                   | -0.29574218  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.48e+03    |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 21           |
|    time_elapsed          | 1603         |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0018930765 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.579        |
|    cost_value_loss       | 0.15         |
|    cost_values           | 0.615        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00155      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 267          |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.921        |
|    value_loss            | 556          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.03        |
| reward                   | -0.60017323 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 16          |
|    time_elapsed          | 1444        |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.004187224 |
|    clip_fraction         | 0.0382      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 5.44        |
|    cost_values           | 1           |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0074      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 208         |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.00421    |
|    std                   | 1           |
|    value_loss            | 434         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.84         |
| reward                   | -1.6942538   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 21           |
|    time_elapsed          | 1595         |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0041442914 |
|    clip_fraction         | 0.039        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 2.59         |
|    cost_values           | 0.995        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00606      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 76.6         |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.00511     |
|    std                   | 1.04         |
|    value_loss            | 158          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -1.3826358  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 16          |
|    time_elapsed          | 1412        |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.005249921 |
|    clip_fraction         | 0.0547      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.2         |
|    cost_value_loss       | 1.84        |
|    cost_values           | 0.98        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.0164      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 42.3        |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.00646    |
|    std                   | 0.99        |
|    value_loss            | 88          |
------------------------------------------
------------------------------------------
| avg_speed                | 3.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.04        |
| reward                   | -0.7188049  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 12          |
|    time_elapsed          | 1110        |
|    total_timesteps       | 124928      |
| train/                   |             |
|    approx_kl             | 0.003175706 |
|    clip_fraction         | 0.0378      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.68        |
|    cost_value_loss       | 4.79        |
|    cost_values           | 1.16        |
|    entropy               | -3.05       |
|    entropy_loss          | -3.05       |
|    explained_variance    | 0.00978     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.8        |
|    n_updates             | 600         |
|    policy_gradient_loss  | -0.00352    |
|    std                   | 1.11        |
|    value_loss            | 36.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.3024142   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 20           |
|    time_elapsed          | 1609         |
|    total_timesteps       | 141312       |
| train/                   |              |
|    approx_kl             | 0.0028243493 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 0.871        |
|    cost_values           | 0.938        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.00749      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.6         |
|    n_updates             | 680          |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.967        |
|    value_loss            | 108          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.22        |
| reward                   | -0.59377855 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.5e+03    |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 22          |
|    time_elapsed          | 1692        |
|    total_timesteps       | 145408      |
| train/                   |             |
|    approx_kl             | 0.005420373 |
|    clip_fraction         | 0.0562      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.585       |
|    cost_value_loss       | 0.4         |
|    cost_values           | 0.588       |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.00438     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 54.1        |
|    n_updates             | 700         |
|    policy_gradient_loss  | -0.00691    |
|    std                   | 0.92        |
|    value_loss            | 110         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.07        |
| reward                   | -0.86552393 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 17          |
|    time_elapsed          | 1524        |
|    total_timesteps       | 135168      |
| train/                   |             |
|    approx_kl             | 0.003833571 |
|    clip_fraction         | 0.0362      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.35        |
|    cost_value_loss       | 22.5        |
|    cost_values           | 1.27        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0129      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.2        |
|    n_updates             | 650         |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.997       |
|    value_loss            | 24.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -1.3862919  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 22          |
|    time_elapsed          | 1683        |
|    total_timesteps       | 145408      |
| train/                   |             |
|    approx_kl             | 0.004496375 |
|    clip_fraction         | 0.0368      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 1.04        |
|    cost_values           | 0.993       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.00672     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 56.2        |
|    n_updates             | 700         |
|    policy_gradient_loss  | -0.00328    |
|    std                   | 1.05        |
|    value_loss            | 115         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9089555  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 17          |
|    time_elapsed          | 1510        |
|    total_timesteps       | 135168      |
| train/                   |             |
|    approx_kl             | 0.003978524 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.14        |
|    cost_value_loss       | 1.76        |
|    cost_values           | 0.968       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.00368     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 44.1        |
|    n_updates             | 650         |
|    policy_gradient_loss  | -0.00476    |
|    std                   | 0.99        |
|    value_loss            | 88.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.02         |
| reward                   | -0.45312062  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 13           |
|    time_elapsed          | 1211         |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0077969395 |
|    clip_fraction         | 0.0853       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.54         |
|    cost_value_loss       | 27.2         |
|    cost_values           | 1.26         |
|    entropy               | -3.03        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.00426      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.1         |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.0059      |
|    std                   | 1.1          |
|    value_loss            | 31.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -2.3921561  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 21          |
|    time_elapsed          | 1703        |
|    total_timesteps       | 143360      |
| train/                   |             |
|    approx_kl             | 0.004025068 |
|    clip_fraction         | 0.0516      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 7.89        |
|    cost_values           | 0.977       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.00556     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 78.9        |
|    n_updates             | 690         |
|    policy_gradient_loss  | -0.00396    |
|    std                   | 0.968       |
|    value_loss            | 166         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8638497  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.52e+03   |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 23          |
|    time_elapsed          | 1782        |
|    total_timesteps       | 147456      |
| train/                   |             |
|    approx_kl             | 0.004091068 |
|    clip_fraction         | 0.0239      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.612       |
|    cost_value_loss       | 0.442       |
|    cost_values           | 0.591       |
|    entropy               | -2.66       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.00212     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 350         |
|    n_updates             | 710         |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.915       |
|    value_loss            | 744         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.939       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.939       |
| reward                   | -0.62555534 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 18          |
|    time_elapsed          | 1632        |
|    total_timesteps       | 137216      |
| train/                   |             |
|    approx_kl             | 0.005138344 |
|    clip_fraction         | 0.0521      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.79        |
|    cost_value_loss       | 17.7        |
|    cost_values           | 1.84        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.00952     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.9        |
|    n_updates             | 660         |
|    policy_gradient_loss  | -0.0058     |
|    std                   | 1           |
|    value_loss            | 42.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.38         |
| reward                   | -1.1063516   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 23           |
|    time_elapsed          | 1771         |
|    total_timesteps       | 147456       |
| train/                   |              |
|    approx_kl             | 0.0010316686 |
|    clip_fraction         | 0.0043       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 1.48         |
|    cost_values           | 0.999        |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00426      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 148          |
|    n_updates             | 710          |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 1.05         |
|    value_loss            | 289          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -1.228742   |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 18          |
|    time_elapsed          | 1610        |
|    total_timesteps       | 137216      |
| train/                   |             |
|    approx_kl             | 0.006406294 |
|    clip_fraction         | 0.0564      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 4.41        |
|    cost_values           | 0.984       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.00773     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.3        |
|    n_updates             | 660         |
|    policy_gradient_loss  | -0.00627    |
|    std                   | 0.992       |
|    value_loss            | 60.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2273543  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 22          |
|    time_elapsed          | 1795        |
|    total_timesteps       | 145408      |
| train/                   |             |
|    approx_kl             | 0.004038346 |
|    clip_fraction         | 0.0625      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 1.49        |
|    cost_values           | 0.937       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.0149      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 99.1        |
|    n_updates             | 700         |
|    policy_gradient_loss  | -0.00595    |
|    std                   | 0.972       |
|    value_loss            | 199         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.36924434  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 14           |
|    time_elapsed          | 1310         |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0061130105 |
|    clip_fraction         | 0.0641       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.74         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 2.01         |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.0146       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.1         |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00681     |
|    std                   | 1.09         |
|    value_loss            | 23.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.4459329  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.5e+03    |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 24          |
|    time_elapsed          | 1870        |
|    total_timesteps       | 149504      |
| train/                   |             |
|    approx_kl             | 0.005282974 |
|    clip_fraction         | 0.0423      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.607       |
|    cost_value_loss       | 0.482       |
|    cost_values           | 0.603       |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.000974    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 379         |
|    n_updates             | 720         |
|    policy_gradient_loss  | -0.00527    |
|    std                   | 0.914       |
|    value_loss            | 781         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.4840084  |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 24          |
|    time_elapsed          | 1861        |
|    total_timesteps       | 149504      |
| train/                   |             |
|    approx_kl             | 0.005044318 |
|    clip_fraction         | 0.0342      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.32        |
|    cost_value_loss       | 4.37        |
|    cost_values           | 0.998       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.00268     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 188         |
|    n_updates             | 720         |
|    policy_gradient_loss  | -0.00339    |
|    std                   | 1.05        |
|    value_loss            | 370         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.56         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.56         |
| reward                   | -1.631538    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 19           |
|    time_elapsed          | 1739         |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0046530263 |
|    clip_fraction         | 0.0501       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.46         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 1.98         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.00609      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66.9         |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 1.01         |
|    value_loss            | 142          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.87907106 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 23          |
|    time_elapsed          | 1887        |
|    total_timesteps       | 147456      |
| train/                   |             |
|    approx_kl             | 0.00565057  |
|    clip_fraction         | 0.057       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 1.65        |
|    cost_values           | 0.972       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.00342     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 151         |
|    n_updates             | 710         |
|    policy_gradient_loss  | -0.00562    |
|    std                   | 0.975       |
|    value_loss            | 299         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -1.1453813  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.51e+03   |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 25          |
|    time_elapsed          | 1965        |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.005254676 |
|    clip_fraction         | 0.0296      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.659       |
|    cost_value_loss       | 0.782       |
|    cost_values           | 0.627       |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.00466     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 147         |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00553    |
|    std                   | 0.914       |
|    value_loss            | 324         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.7423465   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 19           |
|    time_elapsed          | 1711         |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0056817327 |
|    clip_fraction         | 0.055        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 0.815        |
|    cost_values           | 0.986        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.00351      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 57.4         |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.00501     |
|    std                   | 0.99         |
|    value_loss            | 111          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.16         |
| reward                   | -0.5803226   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 15           |
|    time_elapsed          | 1412         |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0065751923 |
|    clip_fraction         | 0.0534       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.87         |
|    cost_value_loss       | 6.98         |
|    cost_values           | 2.34         |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.0182       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.82         |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00475     |
|    std                   | 1.09         |
|    value_loss            | 11.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.5         |
| reward                   | -0.8411754  |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 26          |
|    iterations            | 25          |
|    time_elapsed          | 1952        |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.002326727 |
|    clip_fraction         | 0.016       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.13        |
|    cost_value_loss       | 1.52        |
|    cost_values           | 0.983       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.00694     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.7        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00322    |
|    std                   | 1.05        |
|    value_loss            | 76.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.39        |
| reward                   | -1.4642434  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 20          |
|    time_elapsed          | 1848        |
|    total_timesteps       | 141312      |
| train/                   |             |
|    approx_kl             | 0.003581426 |
|    clip_fraction         | 0.0314      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 1.41        |
|    cost_values           | 1.65        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.00686     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 136         |
|    n_updates             | 680         |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 1.01        |
|    value_loss            | 277         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.6254181   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 24           |
|    time_elapsed          | 1980         |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0063009625 |
|    clip_fraction         | 0.0709       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 2.29         |
|    cost_values           | 0.958        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.00607      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.2         |
|    n_updates             | 720          |
|    policy_gradient_loss  | -0.00675     |
|    std                   | 0.974        |
|    value_loss            | 73.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7903545  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.51e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 26          |
|    time_elapsed          | 2060        |
|    total_timesteps       | 153600      |
| train/                   |             |
|    approx_kl             | 0.005713215 |
|    clip_fraction         | 0.0514      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.662       |
|    cost_value_loss       | 0.421       |
|    cost_values           | 0.658       |
|    entropy               | -2.65       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.00338     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 114         |
|    n_updates             | 740         |
|    policy_gradient_loss  | -0.00635    |
|    std                   | 0.912       |
|    value_loss            | 230         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.65         |
| reward                   | -1.7067691   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 20           |
|    time_elapsed          | 1814         |
|    total_timesteps       | 141312       |
| train/                   |              |
|    approx_kl             | 0.0043787984 |
|    clip_fraction         | 0.0485       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 2.23         |
|    cost_values           | 0.99         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0112       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 70.6         |
|    n_updates             | 680          |
|    policy_gradient_loss  | -0.00439     |
|    std                   | 0.986        |
|    value_loss            | 144          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.7263366  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -992        |
| time/                    |             |
|    fps                   | 21          |
|    iterations            | 16          |
|    time_elapsed          | 1515        |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.007487421 |
|    clip_fraction         | 0.0624      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.6         |
|    cost_value_loss       | 8.05        |
|    cost_values           | 2.25        |
|    entropy               | -2.99       |
|    entropy_loss          | -3          |
|    explained_variance    | 0.00992     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.3        |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 1.08        |
|    value_loss            | 24.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.42         |
| reward                   | -1.8060063   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 26           |
|    time_elapsed          | 2045         |
|    total_timesteps       | 153600       |
| train/                   |              |
|    approx_kl             | 0.0037983556 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 1.85         |
|    cost_values           | 0.976        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.0113       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38           |
|    n_updates             | 740          |
|    policy_gradient_loss  | -0.00466     |
|    std                   | 1.04         |
|    value_loss            | 80           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.73         |
| reward                   | -0.60579324  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 21           |
|    time_elapsed          | 1961         |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0044484506 |
|    clip_fraction         | 0.0536       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 1.76         |
|    cost_values           | 1.15         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.00557      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 219          |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 1.01         |
|    value_loss            | 456          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.8311726  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 25          |
|    time_elapsed          | 2075        |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.005752262 |
|    clip_fraction         | 0.0372      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.686       |
|    cost_values           | 0.938       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.014       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 42.5        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00586    |
|    std                   | 0.974       |
|    value_loss            | 85.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.7113534  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.49e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 27          |
|    time_elapsed          | 2152        |
|    total_timesteps       | 155648      |
| train/                   |             |
|    approx_kl             | 0.006143341 |
|    clip_fraction         | 0.048       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.617       |
|    cost_value_loss       | 0.221       |
|    cost_values           | 0.633       |
|    entropy               | -2.64       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.00818     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.9        |
|    n_updates             | 750         |
|    policy_gradient_loss  | -0.00563    |
|    std                   | 0.908       |
|    value_loss            | 69.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.7602916  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 21          |
|    time_elapsed          | 1918        |
|    total_timesteps       | 143360      |
| train/                   |             |
|    approx_kl             | 0.004989234 |
|    clip_fraction         | 0.0454      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 8.37        |
|    cost_values           | 0.994       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.00712     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 67.4        |
|    n_updates             | 690         |
|    policy_gradient_loss  | -0.00528    |
|    std                   | 0.99        |
|    value_loss            | 122         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.06        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.06        |
| reward                   | -0.31836858 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -982        |
| time/                    |             |
|    fps                   | 21          |
|    iterations            | 17          |
|    time_elapsed          | 1620        |
|    total_timesteps       | 135168      |
| train/                   |             |
|    approx_kl             | 0.004422038 |
|    clip_fraction         | 0.0498      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.5         |
|    cost_value_loss       | 4.38        |
|    cost_values           | 1.99        |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.00578     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 61.8        |
|    n_updates             | 650         |
|    policy_gradient_loss  | -0.00423    |
|    std                   | 1.08        |
|    value_loss            | 139         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.98         |
| reward                   | -1.7659224   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 27           |
|    time_elapsed          | 2139         |
|    total_timesteps       | 155648       |
| train/                   |              |
|    approx_kl             | 0.0026552933 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 1.77         |
|    cost_values           | 0.98         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.00465      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 78.7         |
|    n_updates             | 750          |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 1.04         |
|    value_loss            | 171          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.0557971   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 26           |
|    time_elapsed          | 2173         |
|    total_timesteps       | 153600       |
| train/                   |              |
|    approx_kl             | 0.0046475246 |
|    clip_fraction         | 0.0365       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.883        |
|    cost_value_loss       | 0.462        |
|    cost_values           | 0.915        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.00549      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 72.9         |
|    n_updates             | 740          |
|    policy_gradient_loss  | -0.00428     |
|    std                   | 0.97         |
|    value_loss            | 155          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.587        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.587        |
| reward                   | -0.5060199   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 22           |
|    time_elapsed          | 2075         |
|    total_timesteps       | 145408       |
| train/                   |              |
|    approx_kl             | 0.0053551514 |
|    clip_fraction         | 0.0318       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.37         |
|    cost_value_loss       | 12.4         |
|    cost_values           | 0.983        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.00712      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 86.5         |
|    n_updates             | 700          |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 1.01         |
|    value_loss            | 178          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1779721  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.49e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 28          |
|    time_elapsed          | 2250        |
|    total_timesteps       | 157696      |
| train/                   |             |
|    approx_kl             | 0.004825204 |
|    clip_fraction         | 0.0373      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.585       |
|    cost_value_loss       | 0.207       |
|    cost_values           | 0.595       |
|    entropy               | -2.63       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.00251     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 52.7        |
|    n_updates             | 760         |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 0.903       |
|    value_loss            | 114         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -0.7901022  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 22          |
|    time_elapsed          | 2023        |
|    total_timesteps       | 145408      |
| train/                   |             |
|    approx_kl             | 0.004519115 |
|    clip_fraction         | 0.031       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.16        |
|    cost_value_loss       | 1.23        |
|    cost_values           | 0.974       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.00457     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 75.6        |
|    n_updates             | 700         |
|    policy_gradient_loss  | -0.00408    |
|    std                   | 0.99        |
|    value_loss            | 157         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.47        |
| reward                   | -2.264983   |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 28          |
|    time_elapsed          | 2233        |
|    total_timesteps       | 157696      |
| train/                   |             |
|    approx_kl             | 0.004347016 |
|    clip_fraction         | 0.0275      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 1.47        |
|    cost_values           | 0.984       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.0058      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 103         |
|    n_updates             | 760         |
|    policy_gradient_loss  | -0.00417    |
|    std                   | 1.04        |
|    value_loss            | 209         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.83689815 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -975        |
| time/                    |             |
|    fps                   | 21          |
|    iterations            | 18          |
|    time_elapsed          | 1726        |
|    total_timesteps       | 137216      |
| train/                   |             |
|    approx_kl             | 0.004018831 |
|    clip_fraction         | 0.0353      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 26.8        |
|    cost_values           | 1.97        |
|    entropy               | -3          |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.0242      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.9        |
|    n_updates             | 660         |
|    policy_gradient_loss  | -0.00524    |
|    std                   | 1.08        |
|    value_loss            | 10.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.015888    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 27           |
|    time_elapsed          | 2273         |
|    total_timesteps       | 155648       |
| train/                   |              |
|    approx_kl             | 0.0048102494 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.919        |
|    cost_value_loss       | 0.94         |
|    cost_values           | 0.907        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.00194      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.4         |
|    n_updates             | 750          |
|    policy_gradient_loss  | -0.00306     |
|    std                   | 0.971        |
|    value_loss            | 121          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.4707279  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.48e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 29          |
|    time_elapsed          | 2348        |
|    total_timesteps       | 159744      |
| train/                   |             |
|    approx_kl             | 0.006238631 |
|    clip_fraction         | 0.0587      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.535       |
|    cost_value_loss       | 0.121       |
|    cost_values           | 0.561       |
|    entropy               | -2.64       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.00349     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 131         |
|    n_updates             | 770         |
|    policy_gradient_loss  | -0.00627    |
|    std                   | 0.904       |
|    value_loss            | 268         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.07         |
| reward                   | -0.6382411   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 23           |
|    time_elapsed          | 2191         |
|    total_timesteps       | 147456       |
| train/                   |              |
|    approx_kl             | 0.0040154546 |
|    clip_fraction         | 0.0455       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 13.2         |
|    cost_values           | 1            |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.01         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 710          |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 1.02         |
|    value_loss            | 220          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.66         |
| reward                   | -1.5789696   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 29           |
|    time_elapsed          | 2327         |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0043356987 |
|    clip_fraction         | 0.044        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.925        |
|    cost_values           | 0.992        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00307      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79.5         |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.0051      |
|    std                   | 1.04         |
|    value_loss            | 180          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.9653054  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 23          |
|    time_elapsed          | 2130        |
|    total_timesteps       | 147456      |
| train/                   |             |
|    approx_kl             | 0.002416808 |
|    clip_fraction         | 0.0131      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 1.56        |
|    cost_values           | 0.985       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.00638     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 96.9        |
|    n_updates             | 710         |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.99        |
|    value_loss            | 191         |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.33         |
| reward                   | -0.8899292   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -970         |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 19           |
|    time_elapsed          | 1833         |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0066536046 |
|    clip_fraction         | 0.0469       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.15         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 2.57         |
|    entropy               | -3.01        |
|    entropy_loss          | -3           |
|    explained_variance    | 0.0105       |
|    lagrangian_multiplier | 0.000229     |
|    learning_rate         | 0.0003       |
|    loss                  | 19.3         |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.0055      |
|    std                   | 1.09         |
|    value_loss            | 25.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1683326   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 28           |
|    time_elapsed          | 2371         |
|    total_timesteps       | 157696       |
| train/                   |              |
|    approx_kl             | 0.0042300276 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 2.93         |
|    cost_values           | 0.976        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.0157       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.4         |
|    n_updates             | 760          |
|    policy_gradient_loss  | -0.0056      |
|    std                   | 0.969        |
|    value_loss            | 68.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.2174629   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.48e+03    |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 30           |
|    time_elapsed          | 2445         |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0035471958 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.545        |
|    cost_value_loss       | 0.328        |
|    cost_values           | 0.54         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.00245      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79.4         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.00447     |
|    std                   | 0.903        |
|    value_loss            | 158          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.36         |
| reward                   | -0.55682987  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 30           |
|    time_elapsed          | 2424         |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0041573495 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 2.63         |
|    cost_values           | 0.986        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.00502      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 85.7         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 1.04         |
|    value_loss            | 166          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.3916241   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 24           |
|    time_elapsed          | 2308         |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0031521039 |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 11.1         |
|    cost_values           | 1            |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.00601      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 85.5         |
|    n_updates             | 720          |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 1.02         |
|    value_loss            | 160          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.7104423   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 24           |
|    time_elapsed          | 2238         |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0042646406 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 4.07         |
|    cost_values           | 0.996        |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.014        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66.4         |
|    n_updates             | 720          |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 0.99         |
|    value_loss            | 135          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.516        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.516        |
| reward                   | -0.56817865  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -953         |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 20           |
|    time_elapsed          | 1944         |
|    total_timesteps       | 141312       |
| train/                   |              |
|    approx_kl             | 0.0034862077 |
|    clip_fraction         | 0.0536       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.93         |
|    cost_value_loss       | 11.5         |
|    cost_values           | 2.91         |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.00291      |
|    lagrangian_multiplier | 0.000904     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.08         |
|    n_updates             | 680          |
|    policy_gradient_loss  | -0.00484     |
|    std                   | 1.09         |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -1.1494821  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 29          |
|    time_elapsed          | 2471        |
|    total_timesteps       | 159744      |
| train/                   |             |
|    approx_kl             | 0.008127278 |
|    clip_fraction         | 0.0671      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.79        |
|    cost_values           | 0.961       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.0103      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.9        |
|    n_updates             | 770         |
|    policy_gradient_loss  | -0.00823    |
|    std                   | 0.968       |
|    value_loss            | 39.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.4206828   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.48e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 31           |
|    time_elapsed          | 2548         |
|    total_timesteps       | 163840       |
| train/                   |              |
|    approx_kl             | 0.0043142387 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.581        |
|    cost_value_loss       | 0.515        |
|    cost_values           | 0.567        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.00617      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.1         |
|    n_updates             | 790          |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 0.91         |
|    value_loss            | 110          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.991        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.991        |
| reward                   | -1.0871626   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 31           |
|    time_elapsed          | 2522         |
|    total_timesteps       | 163840       |
| train/                   |              |
|    approx_kl             | 0.0044758664 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 3.87         |
|    cost_values           | 0.993        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00755      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27           |
|    n_updates             | 790          |
|    policy_gradient_loss  | -0.00414     |
|    std                   | 1.05         |
|    value_loss            | 48.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.53         |
| reward                   | -0.9786438   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 25           |
|    time_elapsed          | 2429         |
|    total_timesteps       | 151552       |
| train/                   |              |
|    approx_kl             | 0.0043515246 |
|    clip_fraction         | 0.0463       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 3.48         |
|    cost_values           | 1            |
|    entropy               | -2.88        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.013        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 77.2         |
|    n_updates             | 730          |
|    policy_gradient_loss  | -0.00464     |
|    std                   | 1.02         |
|    value_loss            | 164          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.98932993 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 21          |
|    iterations            | 25          |
|    time_elapsed          | 2348        |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.004050821 |
|    clip_fraction         | 0.0289      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 3.65        |
|    cost_values           | 1           |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.00713     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 46.4        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 0.981       |
|    value_loss            | 93          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.8106067   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -948         |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 21           |
|    time_elapsed          | 2059         |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0042179236 |
|    clip_fraction         | 0.0346       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.44         |
|    cost_value_loss       | 43.9         |
|    cost_values           | 3            |
|    entropy               | -3.02        |
|    entropy_loss          | -3.01        |
|    explained_variance    | -0.116       |
|    lagrangian_multiplier | 0.0133       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.58         |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 1.1          |
|    value_loss            | 4.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9691839   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 30           |
|    time_elapsed          | 2573         |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0059316014 |
|    clip_fraction         | 0.0428       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.992        |
|    cost_value_loss       | 0.552        |
|    cost_values           | 0.976        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.00635      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.4         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.00446     |
|    std                   | 0.968        |
|    value_loss            | 74.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -1.2165972   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.47e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 32           |
|    time_elapsed          | 2650         |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0028495016 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.622        |
|    cost_value_loss       | 0.531        |
|    cost_values           | 0.597        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.00648      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 250          |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.91         |
|    value_loss            | 531          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.16        |
| reward                   | -2.1304812  |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 25          |
|    iterations            | 32          |
|    time_elapsed          | 2620        |
|    total_timesteps       | 165888      |
| train/                   |             |
|    approx_kl             | 0.006817921 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.76        |
|    cost_values           | 0.989       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.0065      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.6        |
|    n_updates             | 800         |
|    policy_gradient_loss  | -0.00476    |
|    std                   | 1.05        |
|    value_loss            | 41.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.2958398   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 26           |
|    time_elapsed          | 2458         |
|    total_timesteps       | 153600       |
| train/                   |              |
|    approx_kl             | 0.0076632174 |
|    clip_fraction         | 0.085        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.06         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 1.02         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.00597      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29.3         |
|    n_updates             | 740          |
|    policy_gradient_loss  | -0.00704     |
|    std                   | 0.981        |
|    value_loss            | 44           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.517       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.517       |
| reward                   | -0.57968265 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 20          |
|    iterations            | 26          |
|    time_elapsed          | 2550        |
|    total_timesteps       | 153600      |
| train/                   |             |
|    approx_kl             | 0.007081123 |
|    clip_fraction         | 0.0513      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.65        |
|    cost_value_loss       | 5.84        |
|    cost_values           | 1           |
|    entropy               | -2.89       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.00384     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 166         |
|    n_updates             | 740         |
|    policy_gradient_loss  | -0.00644    |
|    std                   | 1.02        |
|    value_loss            | 330         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.149419    |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -928         |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 22           |
|    time_elapsed          | 2171         |
|    total_timesteps       | 145408       |
| train/                   |              |
|    approx_kl             | 0.0042418246 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.05         |
|    cost_value_loss       | 11.4         |
|    cost_values           | 2.93         |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.0137       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36           |
|    n_updates             | 700          |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 1.1          |
|    value_loss            | 61.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -2.2290857  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 33          |
|    time_elapsed          | 2750        |
|    total_timesteps       | 167936      |
| train/                   |             |
|    approx_kl             | 0.002667671 |
|    clip_fraction         | 0.0254      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.582       |
|    cost_value_loss       | 0.2         |
|    cost_values           | 0.598       |
|    entropy               | -2.64       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.00255     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 82.3        |
|    n_updates             | 810         |
|    policy_gradient_loss  | -0.00432    |
|    std                   | 0.906       |
|    value_loss            | 175         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -2.0801504  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 31          |
|    time_elapsed          | 2677        |
|    total_timesteps       | 163840      |
| train/                   |             |
|    approx_kl             | 0.004004935 |
|    clip_fraction         | 0.0458      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.914       |
|    cost_value_loss       | 0.486       |
|    cost_values           | 0.957       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.00184     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 64.6        |
|    n_updates             | 790         |
|    policy_gradient_loss  | -0.00355    |
|    std                   | 0.971       |
|    value_loss            | 136         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -1.1644971   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 33           |
|    time_elapsed          | 2721         |
|    total_timesteps       | 167936       |
| train/                   |              |
|    approx_kl             | 0.0034586748 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 1.35         |
|    cost_values           | 0.972        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00573      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 88.3         |
|    n_updates             | 810          |
|    policy_gradient_loss  | -0.00239     |
|    std                   | 1.04         |
|    value_loss            | 184          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.654       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.654       |
| reward                   | -0.4691601  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 21          |
|    iterations            | 27          |
|    time_elapsed          | 2569        |
|    total_timesteps       | 155648      |
| train/                   |             |
|    approx_kl             | 0.005219915 |
|    clip_fraction         | 0.0317      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.68        |
|    cost_value_loss       | 5.09        |
|    cost_values           | 1.01        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.00942     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.2        |
|    n_updates             | 750         |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.974       |
|    value_loss            | 40.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.705        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.705        |
| reward                   | -0.56024975  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 27           |
|    time_elapsed          | 2672         |
|    total_timesteps       | 155648       |
| train/                   |              |
|    approx_kl             | 0.0033984855 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.79         |
|    cost_value_loss       | 19.5         |
|    cost_values           | 1            |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.00554      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 195          |
|    n_updates             | 750          |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 1.03         |
|    value_loss            | 369          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0294       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0294       |
| reward                   | -0.5497693   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -926         |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 23           |
|    time_elapsed          | 2285         |
|    total_timesteps       | 147456       |
| train/                   |              |
|    approx_kl             | 0.0048525664 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.59         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 2.94         |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.00403      |
|    lagrangian_multiplier | 0.00568      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.45         |
|    n_updates             | 710          |
|    policy_gradient_loss  | -0.00497     |
|    std                   | 1.1          |
|    value_loss            | 12.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.4034294  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 34          |
|    time_elapsed          | 2852        |
|    total_timesteps       | 169984      |
| train/                   |             |
|    approx_kl             | 0.008448902 |
|    clip_fraction         | 0.0978      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.597       |
|    cost_value_loss       | 0.396       |
|    cost_values           | 0.591       |
|    entropy               | -2.65       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.00442     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 61.4        |
|    n_updates             | 820         |
|    policy_gradient_loss  | -0.00974    |
|    std                   | 0.909       |
|    value_loss            | 123         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.108       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.108       |
| reward                   | -0.578451   |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 32          |
|    time_elapsed          | 2782        |
|    total_timesteps       | 165888      |
| train/                   |             |
|    approx_kl             | 0.003981791 |
|    clip_fraction         | 0.0275      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 1.14        |
|    cost_values           | 0.964       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.00566     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 60.6        |
|    n_updates             | 800         |
|    policy_gradient_loss  | -0.00482    |
|    std                   | 0.968       |
|    value_loss            | 128         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.56        |
| reward                   | -1.8920691  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 34          |
|    time_elapsed          | 2822        |
|    total_timesteps       | 169984      |
| train/                   |             |
|    approx_kl             | 0.005103037 |
|    clip_fraction         | 0.0622      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.897       |
|    cost_values           | 0.994       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.007       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 91.8        |
|    n_updates             | 820         |
|    policy_gradient_loss  | -0.00636    |
|    std                   | 1.04        |
|    value_loss            | 177         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.323        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.323        |
| reward                   | -0.33964053  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 28           |
|    time_elapsed          | 2682         |
|    total_timesteps       | 157696       |
| train/                   |              |
|    approx_kl             | 0.0071359603 |
|    clip_fraction         | 0.0793       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.61         |
|    cost_value_loss       | 12.2         |
|    cost_values           | 1.45         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -0.02        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 760          |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.969        |
|    value_loss            | 9.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -2.1239572  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.48e+03   |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 35          |
|    time_elapsed          | 2956        |
|    total_timesteps       | 172032      |
| train/                   |             |
|    approx_kl             | 0.002602463 |
|    clip_fraction         | 0.00923     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.617       |
|    cost_value_loss       | 0.303       |
|    cost_values           | 0.609       |
|    entropy               | -2.66       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.00166     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 134         |
|    n_updates             | 830         |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.914       |
|    value_loss            | 265         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.554        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.554        |
| reward                   | -0.538462    |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -918         |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 24           |
|    time_elapsed          | 2399         |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0054406896 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 12.2         |
|    cost_values           | 2.89         |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.011        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.3         |
|    n_updates             | 720          |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 1.1          |
|    value_loss            | 93.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.32         |
| reward                   | -0.63577086  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 33           |
|    time_elapsed          | 2886         |
|    total_timesteps       | 167936       |
| train/                   |              |
|    approx_kl             | 0.0064937463 |
|    clip_fraction         | 0.0581       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.53         |
|    cost_value_loss       | 20.9         |
|    cost_values           | 1.24         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.00484      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.4         |
|    n_updates             | 810          |
|    policy_gradient_loss  | -0.00689     |
|    std                   | 0.96         |
|    value_loss            | 41.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -1.4264514  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 20          |
|    iterations            | 28          |
|    time_elapsed          | 2796        |
|    total_timesteps       | 157696      |
| train/                   |             |
|    approx_kl             | 0.004638925 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.83        |
|    cost_value_loss       | 17.3        |
|    cost_values           | 1.01        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.00886     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 60.6        |
|    n_updates             | 760         |
|    policy_gradient_loss  | -0.00465    |
|    std                   | 1.03        |
|    value_loss            | 105         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.6783619  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 35          |
|    time_elapsed          | 2925        |
|    total_timesteps       | 172032      |
| train/                   |             |
|    approx_kl             | 0.005166253 |
|    clip_fraction         | 0.0533      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.95        |
|    cost_value_loss       | 0.893       |
|    cost_values           | 0.982       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.00759     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 35.3        |
|    n_updates             | 830         |
|    policy_gradient_loss  | -0.00728    |
|    std                   | 1.04        |
|    value_loss            | 73.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.417       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.417       |
| reward                   | -0.26731002 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 21          |
|    iterations            | 29          |
|    time_elapsed          | 2795        |
|    total_timesteps       | 159744      |
| train/                   |             |
|    approx_kl             | 0.003634883 |
|    clip_fraction         | 0.056       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.62        |
|    cost_value_loss       | 4.95        |
|    cost_values           | 2.17        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.00875     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.2        |
|    n_updates             | 770         |
|    policy_gradient_loss  | -0.00328    |
|    std                   | 0.974       |
|    value_loss            | 43.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.51047194  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.47e+03    |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 36           |
|    time_elapsed          | 3056         |
|    total_timesteps       | 174080       |
| train/                   |              |
|    approx_kl             | 0.0033285161 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.594        |
|    cost_value_loss       | 0.3          |
|    cost_values           | 0.608        |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.00394      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 176          |
|    n_updates             | 840          |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 0.915        |
|    value_loss            | 370          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.656751   |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 34          |
|    time_elapsed          | 2995        |
|    total_timesteps       | 169984      |
| train/                   |             |
|    approx_kl             | 0.004236964 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.6         |
|    cost_value_loss       | 19.5        |
|    cost_values           | 1.23        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.0102      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 60.9        |
|    n_updates             | 820         |
|    policy_gradient_loss  | -0.00278    |
|    std                   | 0.963       |
|    value_loss            | 105         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.481       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.481       |
| reward                   | -0.43838236 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -915        |
| time/                    |             |
|    fps                   | 20          |
|    iterations            | 25          |
|    time_elapsed          | 2512        |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.005590831 |
|    clip_fraction         | 0.0559      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 2.87        |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.00835     |
|    lagrangian_multiplier | 0.00338     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.3         |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00756    |
|    std                   | 1.1         |
|    value_loss            | 6.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -2.0528526  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 36          |
|    time_elapsed          | 3027        |
|    total_timesteps       | 174080      |
| train/                   |             |
|    approx_kl             | 0.004873763 |
|    clip_fraction         | 0.0506      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.996       |
|    cost_value_loss       | 1.38        |
|    cost_values           | 0.974       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.00506     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.4        |
|    n_updates             | 840         |
|    policy_gradient_loss  | -0.00638    |
|    std                   | 1.03        |
|    value_loss            | 72.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.5057474   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 29           |
|    time_elapsed          | 2920         |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0019027092 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.93         |
|    cost_value_loss       | 20.4         |
|    cost_values           | 1.01         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0115       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 109          |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 1.03         |
|    value_loss            | 199          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.6444726   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.47e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 37           |
|    time_elapsed          | 3162         |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0024888576 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.67         |
|    cost_value_loss       | 0.379        |
|    cost_values           | 0.645        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00601      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.9         |
|    n_updates             | 850          |
|    policy_gradient_loss  | -0.00501     |
|    std                   | 0.921        |
|    value_loss            | 104          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.47       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.47       |
| reward                   | -1.4790809 |
| rollout/                 |            |
|    ep_len_mean           | 969        |
|    ep_rew_mean           | -1.1e+03   |
| time/                    |            |
|    fps                   | 21         |
|    iterations            | 30         |
|    time_elapsed          | 2910       |
|    total_timesteps       | 161792     |
| train/                   |            |
|    approx_kl             | 0.00430057 |
|    clip_fraction         | 0.0456     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.67       |
|    cost_value_loss       | 7.16       |
|    cost_values           | 1.94       |
|    entropy               | -2.79      |
|    entropy_loss          | -2.79      |
|    explained_variance    | 0.0112     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 76.1       |
|    n_updates             | 780        |
|    policy_gradient_loss  | -0.00325   |
|    std                   | 0.978      |
|    value_loss            | 155        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.83577967  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 35           |
|    time_elapsed          | 3105         |
|    total_timesteps       | 172032       |
| train/                   |              |
|    approx_kl             | 0.0074197035 |
|    clip_fraction         | 0.0994       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 1.17         |
|    cost_values           | 1.01         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.00596      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.82         |
|    n_updates             | 830          |
|    policy_gradient_loss  | -0.00808     |
|    std                   | 0.966        |
|    value_loss            | 13           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.168        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.168        |
| reward                   | -0.54236186  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 24           |
|    iterations            | 37           |
|    time_elapsed          | 3132         |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0047186157 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.72         |
|    cost_values           | 0.991        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0222       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 850          |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 1.03         |
|    value_loss            | 221          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.761        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.761        |
| reward                   | -0.404882    |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -904         |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 26           |
|    time_elapsed          | 2624         |
|    total_timesteps       | 153600       |
| train/                   |              |
|    approx_kl             | 0.0064222477 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.1          |
|    cost_value_loss       | 14.4         |
|    cost_values           | 2.99         |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.0106       |
|    lagrangian_multiplier | 0.00279      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 740          |
|    policy_gradient_loss  | -0.00656     |
|    std                   | 1.09         |
|    value_loss            | 34.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.1437875   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 30           |
|    time_elapsed          | 3044         |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0041869474 |
|    clip_fraction         | 0.0399       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.24         |
|    cost_value_loss       | 2.66         |
|    cost_values           | 0.998        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.011        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 105          |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.00403     |
|    std                   | 1.03         |
|    value_loss            | 221          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8726987  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 38          |
|    time_elapsed          | 3267        |
|    total_timesteps       | 178176      |
| train/                   |             |
|    approx_kl             | 0.003643274 |
|    clip_fraction         | 0.0367      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.728       |
|    cost_value_loss       | 0.369       |
|    cost_values           | 0.716       |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.00356     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 44.5        |
|    n_updates             | 860         |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.923       |
|    value_loss            | 92.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.7         |
| reward                   | -1.2059281  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 20          |
|    iterations            | 31          |
|    time_elapsed          | 3027        |
|    total_timesteps       | 163840      |
| train/                   |             |
|    approx_kl             | 0.005930293 |
|    clip_fraction         | 0.049       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.62        |
|    cost_value_loss       | 10          |
|    cost_values           | 1.79        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.0269      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.6        |
|    n_updates             | 790         |
|    policy_gradient_loss  | -0.00503    |
|    std                   | 0.986       |
|    value_loss            | 42          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8006342   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 36           |
|    time_elapsed          | 3215         |
|    total_timesteps       | 174080       |
| train/                   |              |
|    approx_kl             | 0.0046323687 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.32         |
|    cost_value_loss       | 2.09         |
|    cost_values           | 0.988        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.00682      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.8         |
|    n_updates             | 840          |
|    policy_gradient_loss  | -0.00389     |
|    std                   | 0.963        |
|    value_loss            | 65.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.49        |
| reward                   | -0.9876578  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 24          |
|    iterations            | 38          |
|    time_elapsed          | 3242        |
|    total_timesteps       | 178176      |
| train/                   |             |
|    approx_kl             | 0.005343755 |
|    clip_fraction         | 0.0731      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.898       |
|    cost_values           | 0.99        |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.00787     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.9        |
|    n_updates             | 860         |
|    policy_gradient_loss  | -0.00546    |
|    std                   | 1.03        |
|    value_loss            | 59.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.771       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.771       |
| reward                   | -0.5185239  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -887        |
| time/                    |             |
|    fps                   | 20          |
|    iterations            | 27          |
|    time_elapsed          | 2736        |
|    total_timesteps       | 155648      |
| train/                   |             |
|    approx_kl             | 0.008746032 |
|    clip_fraction         | 0.0749      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.62        |
|    cost_value_loss       | 17.4        |
|    cost_values           | 2.99        |
|    entropy               | -3          |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.0234      |
|    lagrangian_multiplier | 0.00348     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.13        |
|    n_updates             | 750         |
|    policy_gradient_loss  | -0.00838    |
|    std                   | 1.08        |
|    value_loss            | 8.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -1.8032999  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 20          |
|    iterations            | 31          |
|    time_elapsed          | 3172        |
|    total_timesteps       | 163840      |
| train/                   |             |
|    approx_kl             | 0.007380464 |
|    clip_fraction         | 0.0518      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 23.4        |
|    cost_values           | 1.05        |
|    entropy               | -2.88       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.0188      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 71.5        |
|    n_updates             | 790         |
|    policy_gradient_loss  | -0.0067     |
|    std                   | 1.02        |
|    value_loss            | 119         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -2.040298   |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.45e+03   |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 39          |
|    time_elapsed          | 3375        |
|    total_timesteps       | 180224      |
| train/                   |             |
|    approx_kl             | 0.007016126 |
|    clip_fraction         | 0.0589      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.686       |
|    cost_value_loss       | 0.184       |
|    cost_values           | 0.697       |
|    entropy               | -2.67       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.00618     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 39.8        |
|    n_updates             | 870         |
|    policy_gradient_loss  | -0.00536    |
|    std                   | 0.92        |
|    value_loss            | 81.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.62        |
| reward                   | -0.4224208  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 39          |
|    time_elapsed          | 3350        |
|    total_timesteps       | 180224      |
| train/                   |             |
|    approx_kl             | 0.004432325 |
|    clip_fraction         | 0.0271      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 1.52        |
|    cost_values           | 0.976       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.0115      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50.8        |
|    n_updates             | 870         |
|    policy_gradient_loss  | -0.00312    |
|    std                   | 1.02        |
|    value_loss            | 113         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.5564412  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 37          |
|    time_elapsed          | 3326        |
|    total_timesteps       | 176128      |
| train/                   |             |
|    approx_kl             | 0.001797327 |
|    clip_fraction         | 0.0134      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 4.2         |
|    cost_values           | 0.996       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.00912     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 94.2        |
|    n_updates             | 850         |
|    policy_gradient_loss  | -0.00254    |
|    std                   | 0.962       |
|    value_loss            | 199         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.04         |
| reward                   | -1.0141265   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 32           |
|    time_elapsed          | 3145         |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0028187516 |
|    clip_fraction         | 0.0489       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.65         |
|    cost_value_loss       | 7.88         |
|    cost_values           | 2.04         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0874       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.4         |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 0.987        |
|    value_loss            | 25.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.155        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.155        |
| reward                   | -0.458616    |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -878         |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 28           |
|    time_elapsed          | 2851         |
|    total_timesteps       | 157696       |
| train/                   |              |
|    approx_kl             | 0.0075117676 |
|    clip_fraction         | 0.0541       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.69         |
|    cost_value_loss       | 21.5         |
|    cost_values           | 2.86         |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.0353       |
|    lagrangian_multiplier | 0.00405      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.6          |
|    n_updates             | 760          |
|    policy_gradient_loss  | -0.000345    |
|    std                   | 1.08         |
|    value_loss            | 9.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.1         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.1         |
| reward                   | -0.29649708 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 32          |
|    time_elapsed          | 3300        |
|    total_timesteps       | 165888      |
| train/                   |             |
|    approx_kl             | 0.004581446 |
|    clip_fraction         | 0.0467      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.47        |
|    cost_value_loss       | 14          |
|    cost_values           | 1.03        |
|    entropy               | -2.89       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.0749      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 67.7        |
|    n_updates             | 800         |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 1.03        |
|    value_loss            | 125         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8939417   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.45e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 40           |
|    time_elapsed          | 3486         |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0040879482 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.686        |
|    cost_value_loss       | 0.295        |
|    cost_values           | 0.686        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00302      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 63.7         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 0.92         |
|    value_loss            | 119          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.97       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.97       |
| reward                   | -0.7863208 |
| rollout/                 |            |
|    ep_len_mean           | 990        |
|    ep_rew_mean           | -1.2e+03   |
| time/                    |            |
|    fps                   | 23         |
|    iterations            | 40         |
|    time_elapsed          | 3462       |
|    total_timesteps       | 182272     |
| train/                   |            |
|    approx_kl             | 0.0041719  |
|    clip_fraction         | 0.0437     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.24       |
|    cost_value_loss       | 3.65       |
|    cost_values           | 0.986      |
|    entropy               | -2.87      |
|    entropy_loss          | -2.88      |
|    explained_variance    | 0.0438     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 40.2       |
|    n_updates             | 880        |
|    policy_gradient_loss  | -0.00515   |
|    std                   | 1.02       |
|    value_loss            | 79.9       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.769        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.769        |
| reward                   | -0.68367565  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 38           |
|    time_elapsed          | 3440         |
|    total_timesteps       | 178176       |
| train/                   |              |
|    approx_kl             | 0.0042439755 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 0.568        |
|    cost_values           | 0.972        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.00279      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49.3         |
|    n_updates             | 860          |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 0.964        |
|    value_loss            | 106          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.5162559  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 20          |
|    iterations            | 33          |
|    time_elapsed          | 3265        |
|    total_timesteps       | 167936      |
| train/                   |             |
|    approx_kl             | 0.004911061 |
|    clip_fraction         | 0.043       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 5.02        |
|    cost_values           | 2.25        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.0778      |
|    lagrangian_multiplier | 0.00114     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.45        |
|    n_updates             | 810         |
|    policy_gradient_loss  | -0.0045     |
|    std                   | 0.985       |
|    value_loss            | 19.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.12         |
| reward                   | -0.35297382  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -849         |
| time/                    |              |
|    fps                   | 19           |
|    iterations            | 29           |
|    time_elapsed          | 2973         |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0056434944 |
|    clip_fraction         | 0.0792       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.62         |
|    cost_value_loss       | 28.8         |
|    cost_values           | 2.7          |
|    entropy               | -2.99        |
|    entropy_loss          | -3           |
|    explained_variance    | 0.155        |
|    lagrangian_multiplier | 0.00715      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.68         |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 1.08         |
|    value_loss            | 14.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.9004739   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.45e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 41           |
|    time_elapsed          | 3598         |
|    total_timesteps       | 184320       |
| train/                   |              |
|    approx_kl             | 0.0071689263 |
|    clip_fraction         | 0.0676       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.733        |
|    cost_value_loss       | 0.468        |
|    cost_values           | 0.721        |
|    entropy               | -2.66        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00866      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 55.4         |
|    n_updates             | 890          |
|    policy_gradient_loss  | -0.00594     |
|    std                   | 0.916        |
|    value_loss            | 111          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.9        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.9        |
| reward                   | -2.4329588 |
| rollout/                 |            |
|    ep_len_mean           | 992        |
|    ep_rew_mean           | -1.25e+03  |
| time/                    |            |
|    fps                   | 19         |
|    iterations            | 33         |
|    time_elapsed          | 3429       |
|    total_timesteps       | 167936     |
| train/                   |            |
|    approx_kl             | 0.00771886 |
|    clip_fraction         | 0.0528     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.65       |
|    cost_value_loss       | 26.2       |
|    cost_values           | 1.08       |
|    entropy               | -2.9       |
|    entropy_loss          | -2.9       |
|    explained_variance    | 0.0859     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 69.4       |
|    n_updates             | 810        |
|    policy_gradient_loss  | -0.00377   |
|    std                   | 1.03       |
|    value_loss            | 126        |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.96323687 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 41          |
|    time_elapsed          | 3571        |
|    total_timesteps       | 184320      |
| train/                   |             |
|    approx_kl             | 0.006809909 |
|    clip_fraction         | 0.0357      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 1.6         |
|    cost_values           | 0.974       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.0238      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30          |
|    n_updates             | 890         |
|    policy_gradient_loss  | -0.00408    |
|    std                   | 1.02        |
|    value_loss            | 60.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.1939164  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 39          |
|    time_elapsed          | 3556        |
|    total_timesteps       | 180224      |
| train/                   |             |
|    approx_kl             | 0.004246417 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.86        |
|    cost_value_loss       | 22.7        |
|    cost_values           | 1.16        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.00977     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50.5        |
|    n_updates             | 870         |
|    policy_gradient_loss  | -0.00494    |
|    std                   | 0.965       |
|    value_loss            | 79.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2038276   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 34           |
|    time_elapsed          | 3386         |
|    total_timesteps       | 169984       |
| train/                   |              |
|    approx_kl             | 0.0025575198 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.89         |
|    cost_value_loss       | 19.8         |
|    cost_values           | 2.15         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.228        |
|    lagrangian_multiplier | 0.0044       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 820          |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.989        |
|    value_loss            | 49.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.869       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.869       |
| reward                   | -0.4324834  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -832        |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 30          |
|    time_elapsed          | 3089        |
|    total_timesteps       | 161792      |
| train/                   |             |
|    approx_kl             | 0.003093528 |
|    clip_fraction         | 0.0121      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 7.2         |
|    cost_values           | 2.33        |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.125       |
|    lagrangian_multiplier | 0.00187     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.07        |
|    n_updates             | 780         |
|    policy_gradient_loss  | -0.00321    |
|    std                   | 1.08        |
|    value_loss            | 25.8        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.74       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.74       |
| reward                   | -1.9926392 |
| rollout/                 |            |
|    ep_len_mean           | 991        |
|    ep_rew_mean           | -1.44e+03  |
| time/                    |            |
|    fps                   | 23         |
|    iterations            | 42         |
|    time_elapsed          | 3711       |
|    total_timesteps       | 186368     |
| train/                   |            |
|    approx_kl             | 0.00722201 |
|    clip_fraction         | 0.061      |
|    clip_range            | 0.2        |
|    cost_returns          | 0.701      |
|    cost_value_loss       | 0.177      |
|    cost_values           | 0.713      |
|    entropy               | -2.67      |
|    entropy_loss          | -2.67      |
|    explained_variance    | 0.00476    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 63.9       |
|    n_updates             | 900        |
|    policy_gradient_loss  | -0.00659   |
|    std                   | 0.919      |
|    value_loss            | 139        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3173982   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 19           |
|    iterations            | 34           |
|    time_elapsed          | 3556         |
|    total_timesteps       | 169984       |
| train/                   |              |
|    approx_kl             | 0.0029557114 |
|    clip_fraction         | 0.0276       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 2.26         |
|    cost_values           | 1.06         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0244       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 81.7         |
|    n_updates             | 820          |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 1.04         |
|    value_loss            | 165          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5415586  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 42          |
|    time_elapsed          | 3684        |
|    total_timesteps       | 186368      |
| train/                   |             |
|    approx_kl             | 0.007987269 |
|    clip_fraction         | 0.0748      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 5.06        |
|    cost_values           | 0.99        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.0616      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.2        |
|    n_updates             | 900         |
|    policy_gradient_loss  | -0.0067     |
|    std                   | 1.01        |
|    value_loss            | 54          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.7578477   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 40           |
|    time_elapsed          | 3677         |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0034286007 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.91         |
|    cost_value_loss       | 31.8         |
|    cost_values           | 1.42         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.0153       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 75           |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.00283     |
|    std                   | 0.966        |
|    value_loss            | 121          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.9143565   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 35           |
|    time_elapsed          | 3508         |
|    total_timesteps       | 172032       |
| train/                   |              |
|    approx_kl             | 0.0037781906 |
|    clip_fraction         | 0.052        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 1.8          |
|    cost_values           | 1.59         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.278        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 830          |
|    policy_gradient_loss  | -0.0042      |
|    std                   | 0.988        |
|    value_loss            | 30.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.81         |
| reward                   | -0.6187975   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -828         |
| time/                    |              |
|    fps                   | 19           |
|    iterations            | 31           |
|    time_elapsed          | 3210         |
|    total_timesteps       | 163840       |
| train/                   |              |
|    approx_kl             | 0.0036544031 |
|    clip_fraction         | 0.00996      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.95         |
|    cost_value_loss       | 24.2         |
|    cost_values           | 1.8          |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.528        |
|    lagrangian_multiplier | 0.00483      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.09         |
|    n_updates             | 790          |
|    policy_gradient_loss  | -0.00357     |
|    std                   | 1.07         |
|    value_loss            | 17.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.101        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.101        |
| reward                   | -0.55013245  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.43e+03    |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 43           |
|    time_elapsed          | 3827         |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0044875024 |
|    clip_fraction         | 0.0496       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.64         |
|    cost_value_loss       | 0.184        |
|    cost_values           | 0.659        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00401      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.1         |
|    n_updates             | 910          |
|    policy_gradient_loss  | -0.0049      |
|    std                   | 0.92         |
|    value_loss            | 119          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1445382  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 23          |
|    iterations            | 43          |
|    time_elapsed          | 3800        |
|    total_timesteps       | 188416      |
| train/                   |             |
|    approx_kl             | 0.005500758 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 0.941       |
|    cost_values           | 0.961       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0117      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 33.7        |
|    n_updates             | 910         |
|    policy_gradient_loss  | -0.00451    |
|    std                   | 1           |
|    value_loss            | 71.6        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.74       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.74       |
| reward                   | -1.7222842 |
| rollout/                 |            |
|    ep_len_mean           | 992        |
|    ep_rew_mean           | -1.25e+03  |
| time/                    |            |
|    fps                   | 19         |
|    iterations            | 35         |
|    time_elapsed          | 3682       |
|    total_timesteps       | 172032     |
| train/                   |            |
|    approx_kl             | 0.00417904 |
|    clip_fraction         | 0.0312     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.22       |
|    cost_value_loss       | 15.1       |
|    cost_values           | 0.94       |
|    entropy               | -2.91      |
|    entropy_loss          | -2.91      |
|    explained_variance    | 0.0509     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 90.6       |
|    n_updates             | 830        |
|    policy_gradient_loss  | -0.0031    |
|    std                   | 1.04       |
|    value_loss            | 172        |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.93310356 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 41          |
|    time_elapsed          | 3797        |
|    total_timesteps       | 184320      |
| train/                   |             |
|    approx_kl             | 0.004662296 |
|    clip_fraction         | 0.0146      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 1.47        |
|    cost_values           | 1.23        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.0152      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 120         |
|    n_updates             | 890         |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.965       |
|    value_loss            | 251         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.7431352   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 36           |
|    time_elapsed          | 3631         |
|    total_timesteps       | 174080       |
| train/                   |              |
|    approx_kl             | 0.0048392154 |
|    clip_fraction         | 0.0393       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 1.29         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.492        |
|    lagrangian_multiplier | 0.000555     |
|    learning_rate         | 0.0003       |
|    loss                  | 19.7         |
|    n_updates             | 840          |
|    policy_gradient_loss  | -0.00475     |
|    std                   | 0.991        |
|    value_loss            | 39           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.13         |
| reward                   | -0.288871    |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -826         |
| time/                    |              |
|    fps                   | 19           |
|    iterations            | 32           |
|    time_elapsed          | 3329         |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0036615906 |
|    clip_fraction         | 0.0444       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 12.1         |
|    cost_values           | 1.48         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.589        |
|    lagrangian_multiplier | 0.000661     |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00311     |
|    std                   | 1.07         |
|    value_loss            | 26.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.84         |
| reward                   | -0.6455836   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 44           |
|    time_elapsed          | 3948         |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0031415594 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.562        |
|    cost_value_loss       | 0.126        |
|    cost_values           | 0.588        |
|    entropy               | -2.68        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00238      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 84.3         |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.00349     |
|    std                   | 0.923        |
|    value_loss            | 179          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -1.1892279   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 23           |
|    iterations            | 44           |
|    time_elapsed          | 3913         |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0061676353 |
|    clip_fraction         | 0.0581       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 2.58         |
|    cost_values           | 0.978        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0232       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18           |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.00572     |
|    std                   | 1            |
|    value_loss            | 38.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -1.5749319   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 19           |
|    iterations            | 36           |
|    time_elapsed          | 3811         |
|    total_timesteps       | 174080       |
| train/                   |              |
|    approx_kl             | 0.0064380374 |
|    clip_fraction         | 0.0584       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 2.33         |
|    cost_values           | 0.94         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.026        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.1         |
|    n_updates             | 840          |
|    policy_gradient_loss  | -0.00523     |
|    std                   | 1.04         |
|    value_loss            | 94.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.75798887  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 42           |
|    time_elapsed          | 3919         |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0031141269 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 9.26         |
|    cost_values           | 0.946        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.0168       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 101          |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00381     |
|    std                   | 0.971        |
|    value_loss            | 210          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.46         |
| reward                   | -0.5967526   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -823         |
| time/                    |              |
|    fps                   | 19           |
|    iterations            | 33           |
|    time_elapsed          | 3447         |
|    total_timesteps       | 167936       |
| train/                   |              |
|    approx_kl             | 0.0023979144 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.56         |
|    cost_value_loss       | 26.9         |
|    cost_values           | 1.44         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.499        |
|    lagrangian_multiplier | 0.000349     |
|    learning_rate         | 0.0003       |
|    loss                  | 36           |
|    n_updates             | 810          |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 1.07         |
|    value_loss            | 58.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.1          |
| reward                   | -0.3542283   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 37           |
|    time_elapsed          | 3755         |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0034772614 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 3.64         |
|    cost_values           | 0.925        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.257        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.8         |
|    n_updates             | 850          |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.992        |
|    value_loss            | 51.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.8866548   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 45           |
|    time_elapsed          | 4065         |
|    total_timesteps       | 192512       |
| train/                   |              |
|    approx_kl             | 0.0041532507 |
|    clip_fraction         | 0.0342       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.582        |
|    cost_value_loss       | 0.466        |
|    cost_values           | 0.57         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.00382      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 117          |
|    n_updates             | 930          |
|    policy_gradient_loss  | -0.003       |
|    std                   | 0.928        |
|    value_loss            | 238          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.337163    |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 45           |
|    time_elapsed          | 4027         |
|    total_timesteps       | 192512       |
| train/                   |              |
|    approx_kl             | 0.0064377286 |
|    clip_fraction         | 0.0633       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.887        |
|    cost_value_loss       | 0.278        |
|    cost_values           | 0.925        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0161       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.5         |
|    n_updates             | 930          |
|    policy_gradient_loss  | -0.00442     |
|    std                   | 1            |
|    value_loss            | 63.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -1.2456397  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 21          |
|    iterations            | 43          |
|    time_elapsed          | 4031        |
|    total_timesteps       | 188416      |
| train/                   |             |
|    approx_kl             | 0.004972862 |
|    clip_fraction         | 0.0422      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 1.54        |
|    cost_values           | 1           |
|    entropy               | -2.76       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.0226      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.3        |
|    n_updates             | 910         |
|    policy_gradient_loss  | -0.00644    |
|    std                   | 0.961       |
|    value_loss            | 27.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -1.8495301  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 37          |
|    time_elapsed          | 3943        |
|    total_timesteps       | 176128      |
| train/                   |             |
|    approx_kl             | 0.004075516 |
|    clip_fraction         | 0.0262      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 2.67        |
|    cost_values           | 0.956       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.0655      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 70.4        |
|    n_updates             | 850         |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 1.04        |
|    value_loss            | 152         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.04         |
| reward                   | -0.69730395  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -821         |
| time/                    |              |
|    fps                   | 19           |
|    iterations            | 34           |
|    time_elapsed          | 3568         |
|    total_timesteps       | 169984       |
| train/                   |              |
|    approx_kl             | 0.0021711926 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 11           |
|    cost_values           | 1.32         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.401        |
|    lagrangian_multiplier | 0.000272     |
|    learning_rate         | 0.0003       |
|    loss                  | 27.6         |
|    n_updates             | 820          |
|    policy_gradient_loss  | -0.00465     |
|    std                   | 1.07         |
|    value_loss            | 57.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.4          |
| reward                   | -0.6812922   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 20           |
|    iterations            | 38           |
|    time_elapsed          | 3884         |
|    total_timesteps       | 178176       |
| train/                   |              |
|    approx_kl             | 0.0025907485 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 14.6         |
|    cost_values           | 0.846        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.592        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36           |
|    n_updates             | 860          |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.995        |
|    value_loss            | 59.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.394191    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 46           |
|    time_elapsed          | 4187         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0065885955 |
|    clip_fraction         | 0.0728       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.564        |
|    cost_value_loss       | 0.168        |
|    cost_values           | 0.57         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.00351      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.8         |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.00602     |
|    std                   | 0.933        |
|    value_loss            | 105          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.233811    |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 46           |
|    time_elapsed          | 4141         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0047550527 |
|    clip_fraction         | 0.0347       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 2.8          |
|    cost_values           | 0.943        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0238       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.9         |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.00518     |
|    std                   | 1            |
|    value_loss            | 63.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -1.1157196  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 21          |
|    iterations            | 44          |
|    time_elapsed          | 4144        |
|    total_timesteps       | 190464      |
| train/                   |             |
|    approx_kl             | 0.005998456 |
|    clip_fraction         | 0.0598      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.21        |
|    cost_value_loss       | 2.49        |
|    cost_values           | 0.993       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.0288      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.3        |
|    n_updates             | 920         |
|    policy_gradient_loss  | -0.00619    |
|    std                   | 0.965       |
|    value_loss            | 33.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.25        |
| reward                   | -0.5747685  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -808        |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 35          |
|    time_elapsed          | 3688        |
|    total_timesteps       | 172032      |
| train/                   |             |
|    approx_kl             | 0.003914162 |
|    clip_fraction         | 0.0341      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 8.32        |
|    cost_values           | 1.23        |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.458       |
|    lagrangian_multiplier | 0.000232    |
|    learning_rate         | 0.0003      |
|    loss                  | 15.2        |
|    n_updates             | 830         |
|    policy_gradient_loss  | -0.00387    |
|    std                   | 1.07        |
|    value_loss            | 29.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0536       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0536       |
| reward                   | -0.3213245   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 19           |
|    iterations            | 38           |
|    time_elapsed          | 4076         |
|    total_timesteps       | 178176       |
| train/                   |              |
|    approx_kl             | 0.0029126394 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 8.78         |
|    cost_values           | 0.907        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0998       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 59.4         |
|    n_updates             | 860          |
|    policy_gradient_loss  | -0.00349     |
|    std                   | 1.04         |
|    value_loss            | 113          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.34         |
| reward                   | -0.6221156   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 19           |
|    iterations            | 39           |
|    time_elapsed          | 4013         |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0028523235 |
|    clip_fraction         | 0.0374       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.67         |
|    cost_value_loss       | 20.8         |
|    cost_values           | 0.918        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.59         |
|    lagrangian_multiplier | 0.00134      |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.00528     |
|    std                   | 0.994        |
|    value_loss            | 25           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9578908   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 47           |
|    time_elapsed          | 4257         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0035829896 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.38         |
|    cost_values           | 0.959        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.019        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 74.7         |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00447     |
|    std                   | 0.998        |
|    value_loss            | 142          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -0.9900996   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 47           |
|    time_elapsed          | 4306         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0043108203 |
|    clip_fraction         | 0.0376       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.521        |
|    cost_value_loss       | 0.178        |
|    cost_values           | 0.535        |
|    entropy               | -2.69        |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.00772      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 61           |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00386     |
|    std                   | 0.931        |
|    value_loss            | 148          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.9048045  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 21          |
|    iterations            | 45          |
|    time_elapsed          | 4255        |
|    total_timesteps       | 192512      |
| train/                   |             |
|    approx_kl             | 0.006150568 |
|    clip_fraction         | 0.0495      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.23        |
|    cost_value_loss       | 3.07        |
|    cost_values           | 0.984       |
|    entropy               | -2.74       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.0557      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.5        |
|    n_updates             | 930         |
|    policy_gradient_loss  | -0.0068     |
|    std                   | 0.953       |
|    value_loss            | 24.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.196       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.196       |
| reward                   | -0.5136447  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -798        |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 36          |
|    time_elapsed          | 3810        |
|    total_timesteps       | 174080      |
| train/                   |             |
|    approx_kl             | 0.005123635 |
|    clip_fraction         | 0.0273      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.44        |
|    cost_value_loss       | 17.1        |
|    cost_values           | 1.11        |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.696       |
|    lagrangian_multiplier | 0.0028      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.73        |
|    n_updates             | 840         |
|    policy_gradient_loss  | -0.00385    |
|    std                   | 1.07        |
|    value_loss            | 8.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.375        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.375        |
| reward                   | -0.54995656  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 39           |
|    time_elapsed          | 4205         |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0056274277 |
|    clip_fraction         | 0.0557       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 14.1         |
|    cost_values           | 0.939        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.123        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.1         |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.00648     |
|    std                   | 1.03         |
|    value_loss            | 57.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.76         |
| reward                   | -0.2856737   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 19           |
|    iterations            | 40           |
|    time_elapsed          | 4145         |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0065145437 |
|    clip_fraction         | 0.0374       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 4.15         |
|    cost_values           | 0.974        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.636        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.95         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 0.996        |
|    value_loss            | 16.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.6729065  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 22          |
|    iterations            | 48          |
|    time_elapsed          | 4379        |
|    total_timesteps       | 198656      |
| train/                   |             |
|    approx_kl             | 0.004736171 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.17        |
|    cost_value_loss       | 2.38        |
|    cost_values           | 0.992       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0233      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 115         |
|    n_updates             | 960         |
|    policy_gradient_loss  | -0.00336    |
|    std                   | 1           |
|    value_loss            | 244         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.99305964  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.43e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 48           |
|    time_elapsed          | 4428         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0066231955 |
|    clip_fraction         | 0.0535       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.525        |
|    cost_value_loss       | 0.255        |
|    cost_values           | 0.523        |
|    entropy               | -2.68        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.00784      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.8         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.00701     |
|    std                   | 0.923        |
|    value_loss            | 69.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -2.1697598   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 46           |
|    time_elapsed          | 4368         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0095996065 |
|    clip_fraction         | 0.0947       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.975        |
|    cost_value_loss       | 0.876        |
|    cost_values           | 0.947        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.0213       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.6         |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.00754     |
|    std                   | 0.945        |
|    value_loss            | 66.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.784       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.784       |
| reward                   | -0.72918385 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -805        |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 37          |
|    time_elapsed          | 3938        |
|    total_timesteps       | 176128      |
| train/                   |             |
|    approx_kl             | 0.004173854 |
|    clip_fraction         | 0.0205      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 19.2        |
|    cost_values           | 1.21        |
|    entropy               | -2.96       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.606       |
|    lagrangian_multiplier | 0.00365     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.53        |
|    n_updates             | 850         |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 1.06        |
|    value_loss            | 16.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.32        |
| reward                   | -0.695811   |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 18          |
|    iterations            | 40          |
|    time_elapsed          | 4344        |
|    total_timesteps       | 182272      |
| train/                   |             |
|    approx_kl             | 0.008821083 |
|    clip_fraction         | 0.0822      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 17.5        |
|    cost_values           | 1.18        |
|    entropy               | -2.92       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.137       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 47.4        |
|    n_updates             | 880         |
|    policy_gradient_loss  | -0.00893    |
|    std                   | 1.04        |
|    value_loss            | 82.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.59        |
| reward                   | -0.7070992  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 41          |
|    time_elapsed          | 4277        |
|    total_timesteps       | 184320      |
| train/                   |             |
|    approx_kl             | 0.006896844 |
|    clip_fraction         | 0.0303      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 0.884       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.59        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.1        |
|    n_updates             | 890         |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.998       |
|    value_loss            | 35          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.13         |
| reward                   | -0.88945085  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 49           |
|    time_elapsed          | 4502         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0033597306 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.82         |
|    cost_values           | 0.987        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0411       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79.9         |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.00307     |
|    std                   | 0.999        |
|    value_loss            | 167          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.70305777  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 47           |
|    time_elapsed          | 4480         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0032188594 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 1.71         |
|    cost_values           | 0.867        |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.0455       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 94.6         |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00428     |
|    std                   | 0.945        |
|    value_loss            | 178          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -1.290039    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 22           |
|    iterations            | 49           |
|    time_elapsed          | 4556         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0063844705 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.521        |
|    cost_value_loss       | 0.246        |
|    cost_values           | 0.522        |
|    entropy               | -2.66        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.00662      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.9         |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.00844     |
|    std                   | 0.916        |
|    value_loss            | 76.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.27        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.27        |
| reward                   | -0.4024263  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -799        |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 38          |
|    time_elapsed          | 4070        |
|    total_timesteps       | 178176      |
| train/                   |             |
|    approx_kl             | 0.005612133 |
|    clip_fraction         | 0.0579      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.45        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 1.09        |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.622       |
|    lagrangian_multiplier | 0.000826    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 860         |
|    policy_gradient_loss  | -0.00622    |
|    std                   | 1.06        |
|    value_loss            | 20.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.543       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.543       |
| reward                   | -0.47285897 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 18          |
|    iterations            | 41          |
|    time_elapsed          | 4486        |
|    total_timesteps       | 184320      |
| train/                   |             |
|    approx_kl             | 0.008325687 |
|    clip_fraction         | 0.0602      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 34.2        |
|    cost_values           | 1.43        |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.554       |
|    lagrangian_multiplier | 0.00331     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 890         |
|    policy_gradient_loss  | -0.00587    |
|    std                   | 1.05        |
|    value_loss            | 17.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.66         |
| reward                   | -0.74063975  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 19           |
|    iterations            | 42           |
|    time_elapsed          | 4411         |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0042657456 |
|    clip_fraction         | 0.0427       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.47         |
|    cost_value_loss       | 24.6         |
|    cost_values           | 1.2          |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.762        |
|    lagrangian_multiplier | 0.00378      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.69         |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00403     |
|    std                   | 1            |
|    value_loss            | 6.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.84853566  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 48           |
|    time_elapsed          | 4594         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0043625343 |
|    clip_fraction         | 0.0487       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 2.37         |
|    cost_values           | 0.84         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.0346       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 55           |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.00475     |
|    std                   | 0.948        |
|    value_loss            | 132          |
-------------------------------------------
----------------------------------
| avg_speed          | 6.99      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 6.99      |
| reward             | -2.632921 |
| rollout/           |           |
|    ep_len_mean     | 990       |
|    ep_rew_mean     | -1.22e+03 |
| time/              |           |
|    fps             | 17        |
|    iterations      | 1         |
|    time_elapsed    | 117       |
|    total_timesteps | 202752    |
----------------------------------
-----------------------------------
| avg_speed          | 7.95       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.95       |
| reward             | -1.1131904 |
| rollout/           |            |
|    ep_len_mean     | 991        |
|    ep_rew_mean     | -1.4e+03   |
| time/              |            |
|    fps             | 16         |
|    iterations      | 1          |
|    time_elapsed    | 122        |
|    total_timesteps | 202752     |
-----------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.9428424  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -783        |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 39          |
|    time_elapsed          | 4201        |
|    total_timesteps       | 180224      |
| train/                   |             |
|    approx_kl             | 0.004748367 |
|    clip_fraction         | 0.0556      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.3         |
|    cost_value_loss       | 13.4        |
|    cost_values           | 1.07        |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.669       |
|    lagrangian_multiplier | 0.00171     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.22        |
|    n_updates             | 870         |
|    policy_gradient_loss  | -0.00661    |
|    std                   | 1.06        |
|    value_loss            | 11.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7821181   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 21           |
|    iterations            | 49           |
|    time_elapsed          | 4710         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0055612996 |
|    clip_fraction         | 0.0588       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 2.73         |
|    cost_values           | 0.762        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.24         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.00748     |
|    std                   | 0.946        |
|    value_loss            | 27           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.4          |
| reward                   | -1.151722    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 17           |
|    iterations            | 2            |
|    time_elapsed          | 239          |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0066062524 |
|    clip_fraction         | 0.0511       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 1.33         |
|    cost_values           | 0.961        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.0177       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 64.8         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00483     |
|    std                   | 0.997        |
|    value_loss            | 144          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.5          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.5          |
| reward                   | -0.8102675   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 42           |
|    time_elapsed          | 4627         |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0056005367 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 6.24         |
|    cost_values           | 1.24         |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.307        |
|    lagrangian_multiplier | 0.000848     |
|    learning_rate         | 0.0003       |
|    loss                  | 19           |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.0047      |
|    std                   | 1.05         |
|    value_loss            | 47.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.86        |
| reward                   | -0.49453735 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1e+03      |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 43          |
|    time_elapsed          | 4546        |
|    total_timesteps       | 188416      |
| train/                   |             |
|    approx_kl             | 0.003068884 |
|    clip_fraction         | 0.0289      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 17.3        |
|    cost_values           | 1.17        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.763       |
|    lagrangian_multiplier | 0.00324     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.63        |
|    n_updates             | 910         |
|    policy_gradient_loss  | -0.00358    |
|    std                   | 1           |
|    value_loss            | 8.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.3687155   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 2            |
|    time_elapsed          | 245          |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0039332253 |
|    clip_fraction         | 0.0419       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.514        |
|    cost_value_loss       | 0.209        |
|    cost_values           | 0.517        |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.00939      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24           |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00365     |
|    std                   | 0.914        |
|    value_loss            | 50.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.115781    |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -772         |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 40           |
|    time_elapsed          | 4333         |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0037907944 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 7.03         |
|    cost_values           | 0.938        |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.653        |
|    lagrangian_multiplier | 0.000285     |
|    learning_rate         | 0.0003       |
|    loss                  | 15.6         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 1.06         |
|    value_loss            | 29.8         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8.05       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.05       |
| reward             | -1.2204986 |
| rollout/           |            |
|    ep_len_mean     | 981        |
|    ep_rew_mean     | -1.13e+03  |
| time/              |            |
|    fps             | 17         |
|    iterations      | 1          |
|    time_elapsed    | 114        |
|    total_timesteps | 202752     |
-----------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.565123   |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 3           |
|    time_elapsed          | 365         |
|    total_timesteps       | 206848      |
| train/                   |             |
|    approx_kl             | 0.004433306 |
|    clip_fraction         | 0.0341      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.998       |
|    cost_value_loss       | 1.02        |
|    cost_values           | 0.957       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.0309      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 94.6        |
|    n_updates             | 1000        |
|    policy_gradient_loss  | -0.00346    |
|    std                   | 0.994       |
|    value_loss            | 194         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.3032131   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 3            |
|    time_elapsed          | 372          |
|    total_timesteps       | 206848       |
| train/                   |              |
|    approx_kl             | 0.0043929406 |
|    clip_fraction         | 0.0364       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.533        |
|    cost_value_loss       | 0.712        |
|    cost_values           | 0.53         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.0121       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.7         |
|    n_updates             | 1000         |
|    policy_gradient_loss  | -0.0044      |
|    std                   | 0.913        |
|    value_loss            | 71.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.7815499  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -992        |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 44          |
|    time_elapsed          | 4682        |
|    total_timesteps       | 190464      |
| train/                   |             |
|    approx_kl             | 0.002141332 |
|    clip_fraction         | 0.0256      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.22        |
|    cost_value_loss       | 17.6        |
|    cost_values           | 0.828       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.655       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 51.3        |
|    n_updates             | 920         |
|    policy_gradient_loss  | -0.00214    |
|    std                   | 1           |
|    value_loss            | 94.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.55         |
| reward                   | -0.48581344  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 43           |
|    time_elapsed          | 4770         |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0038651638 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.58         |
|    cost_value_loss       | 16.8         |
|    cost_values           | 0.895        |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.435        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 73.5         |
|    n_updates             | 910          |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 1.05         |
|    value_loss            | 137          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.8688691   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 17           |
|    iterations            | 2            |
|    time_elapsed          | 233          |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0076871146 |
|    clip_fraction         | 0.077        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.837        |
|    cost_value_loss       | 1.51         |
|    cost_values           | 0.648        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.416        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.52         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00831     |
|    std                   | 0.939        |
|    value_loss            | 18.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -0.9735347   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 41           |
|    time_elapsed          | 4465         |
|    total_timesteps       | 184320       |
| train/                   |              |
|    approx_kl             | 0.0024805467 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.983        |
|    cost_value_loss       | 0.979        |
|    cost_values           | 0.771        |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.64         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.49         |
|    n_updates             | 890          |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 1.06         |
|    value_loss            | 17.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -1.2319837  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 4           |
|    time_elapsed          | 488         |
|    total_timesteps       | 208896      |
| train/                   |             |
|    approx_kl             | 0.010890506 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 1.49        |
|    cost_values           | 0.968       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.0411      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.47        |
|    n_updates             | 1010        |
|    policy_gradient_loss  | -0.00895    |
|    std                   | 0.985       |
|    value_loss            | 12.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.1399999  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 4           |
|    time_elapsed          | 505         |
|    total_timesteps       | 208896      |
| train/                   |             |
|    approx_kl             | 0.004896245 |
|    clip_fraction         | 0.0676      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.512       |
|    cost_value_loss       | 0.139       |
|    cost_values           | 0.514       |
|    entropy               | -2.63       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.00247     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.6        |
|    n_updates             | 1010        |
|    policy_gradient_loss  | -0.0067     |
|    std                   | 0.903       |
|    value_loss            | 55.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -1.4070939  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -966        |
| time/                    |             |
|    fps                   | 19          |
|    iterations            | 45          |
|    time_elapsed          | 4819        |
|    total_timesteps       | 192512      |
| train/                   |             |
|    approx_kl             | 0.005710179 |
|    clip_fraction         | 0.0154      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.74        |
|    cost_value_loss       | 40.6        |
|    cost_values           | 1.2         |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.838       |
|    lagrangian_multiplier | 0.00536     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.77        |
|    n_updates             | 930         |
|    policy_gradient_loss  | -0.0033     |
|    std                   | 1           |
|    value_loss            | 5.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.3552636   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 44           |
|    time_elapsed          | 4910         |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0030686199 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.83         |
|    cost_value_loss       | 19.6         |
|    cost_values           | 0.799        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.513        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.3         |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.00301     |
|    std                   | 1.05         |
|    value_loss            | 72.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.98225254 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 17          |
|    iterations            | 3           |
|    time_elapsed          | 354         |
|    total_timesteps       | 206848      |
| train/                   |             |
|    approx_kl             | 0.008037837 |
|    clip_fraction         | 0.0874      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.84        |
|    cost_value_loss       | 13          |
|    cost_values           | 0.711       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.712       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 1000        |
|    policy_gradient_loss  | -0.00869    |
|    std                   | 0.936       |
|    value_loss            | 16.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.99         |
| reward                   | -1.1344446   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 42           |
|    time_elapsed          | 4601         |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0050198985 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 13.8         |
|    cost_values           | 0.606        |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.54         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.6         |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 1.06         |
|    value_loss            | 90.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -1.4323388  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 5           |
|    time_elapsed          | 617         |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.007004698 |
|    clip_fraction         | 0.0606      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 0.945       |
|    cost_values           | 0.851       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.0749      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.2        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00489    |
|    std                   | 0.988       |
|    value_loss            | 41.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.95877886 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 5           |
|    time_elapsed          | 633         |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.007448671 |
|    clip_fraction         | 0.0836      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.545       |
|    cost_value_loss       | 0.222       |
|    cost_values           | 0.542       |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.00408     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 42.4        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00743    |
|    std                   | 0.903       |
|    value_loss            | 87.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.25        |
| reward                   | -0.7830069  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -958        |
| time/                    |             |
|    fps                   | 18          |
|    iterations            | 46          |
|    time_elapsed          | 4959        |
|    total_timesteps       | 194560      |
| train/                   |             |
|    approx_kl             | 0.005188807 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.39        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 1.03        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.689       |
|    lagrangian_multiplier | 0.00213     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.34        |
|    n_updates             | 940         |
|    policy_gradient_loss  | -0.00371    |
|    std                   | 0.998       |
|    value_loss            | 32.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.179       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.179       |
| reward                   | -0.5418581  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 18          |
|    iterations            | 45          |
|    time_elapsed          | 5052        |
|    total_timesteps       | 192512      |
| train/                   |             |
|    approx_kl             | 0.004245081 |
|    clip_fraction         | 0.0338      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.13        |
|    cost_value_loss       | 2.8         |
|    cost_values           | 0.619       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.326       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.1        |
|    n_updates             | 930         |
|    policy_gradient_loss  | -0.00466    |
|    std                   | 1.05        |
|    value_loss            | 33.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.9273383   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 17           |
|    iterations            | 4            |
|    time_elapsed          | 475          |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0074253753 |
|    clip_fraction         | 0.0915       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 1.19         |
|    cost_values           | 0.754        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.606        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.76         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.00914     |
|    std                   | 0.935        |
|    value_loss            | 15.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.0580244   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 6            |
|    time_elapsed          | 741          |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0031801355 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.789        |
|    cost_value_loss       | 0.756        |
|    cost_values           | 0.629        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.365        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.983        |
|    value_loss            | 37.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0843772   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -737         |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 43           |
|    time_elapsed          | 4736         |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0049966644 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 7.02         |
|    cost_values           | 0.75         |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.656        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 910          |
|    policy_gradient_loss  | -0.00555     |
|    std                   | 1.06         |
|    value_loss            | 14           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.3092828  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.37e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 6           |
|    time_elapsed          | 762         |
|    total_timesteps       | 212992      |
| train/                   |             |
|    approx_kl             | 0.008211328 |
|    clip_fraction         | 0.0685      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.509       |
|    cost_value_loss       | 0.2         |
|    cost_values           | 0.513       |
|    entropy               | -2.65       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.0111      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.4        |
|    n_updates             | 1030        |
|    policy_gradient_loss  | -0.0085     |
|    std                   | 0.911       |
|    value_loss            | 68.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.94         |
| reward                   | -0.6213892   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -961         |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 47           |
|    time_elapsed          | 5100         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0070336233 |
|    clip_fraction         | 0.0477       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.69         |
|    cost_value_loss       | 28.8         |
|    cost_values           | 0.992        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0.00227      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00549     |
|    std                   | 1            |
|    value_loss            | 14.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.27         |
| reward                   | -0.74755305  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 46           |
|    time_elapsed          | 5194         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0035550916 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.61         |
|    cost_value_loss       | 33.6         |
|    cost_values           | 0.865        |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.549        |
|    lagrangian_multiplier | 0.00151      |
|    learning_rate         | 0.0003       |
|    loss                  | 19.9         |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 1.05         |
|    value_loss            | 38.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.21        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.21        |
| reward                   | -0.3257078  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 17          |
|    iterations            | 5           |
|    time_elapsed          | 596         |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.005032393 |
|    clip_fraction         | 0.0552      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.911       |
|    cost_value_loss       | 1.14        |
|    cost_values           | 0.621       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.431       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28.9        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00689    |
|    std                   | 0.936       |
|    value_loss            | 61.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8114465  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 7           |
|    time_elapsed          | 866         |
|    total_timesteps       | 215040      |
| train/                   |             |
|    approx_kl             | 0.003410888 |
|    clip_fraction         | 0.0263      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.875       |
|    cost_value_loss       | 2.59        |
|    cost_values           | 0.625       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.273       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 103         |
|    n_updates             | 1040        |
|    policy_gradient_loss  | -0.00279    |
|    std                   | 0.981       |
|    value_loss            | 212         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.92221516  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 44           |
|    time_elapsed          | 4871         |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0035772165 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.11         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 0.779        |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.631        |
|    lagrangian_multiplier | 8.89e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 27.2         |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 1.06         |
|    value_loss            | 45.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -1.1121994   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 7            |
|    time_elapsed          | 896          |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0048152283 |
|    clip_fraction         | 0.0798       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.487        |
|    cost_value_loss       | 0.178        |
|    cost_values           | 0.489        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.00636      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.2         |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.00834     |
|    std                   | 0.91         |
|    value_loss            | 51.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9341829   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -952         |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 48           |
|    time_elapsed          | 5241         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0027561358 |
|    clip_fraction         | 0.00615      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 19.3         |
|    cost_values           | 0.785        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.716        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 43.1         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.000948    |
|    std                   | 1            |
|    value_loss            | 70.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.134        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.134        |
| reward                   | -0.4216184   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 6            |
|    time_elapsed          | 723          |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0045267656 |
|    clip_fraction         | 0.0392       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.819        |
|    cost_value_loss       | 1.09         |
|    cost_values           | 0.604        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.471        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51.5         |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 0.937        |
|    value_loss            | 109          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.59874684 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 18          |
|    iterations            | 47          |
|    time_elapsed          | 5337        |
|    total_timesteps       | 196608      |
| train/                   |             |
|    approx_kl             | 0.011928879 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.1         |
|    cost_value_loss       | 46.1        |
|    cost_values           | 1.15        |
|    entropy               | -2.91       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.827       |
|    lagrangian_multiplier | 0.00809     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.42        |
|    n_updates             | 950         |
|    policy_gradient_loss  | -0.00863    |
|    std                   | 1.04        |
|    value_loss            | 7.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.2716947   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 8            |
|    time_elapsed          | 988          |
|    total_timesteps       | 217088       |
| train/                   |              |
|    approx_kl             | 0.0051329075 |
|    clip_fraction         | 0.0378       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.812        |
|    cost_value_loss       | 1.12         |
|    cost_values           | 0.676        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.219        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 68.4         |
|    n_updates             | 1050         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 0.981        |
|    value_loss            | 135          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.73         |
| reward                   | -0.84366435  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -733         |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 45           |
|    time_elapsed          | 5011         |
|    total_timesteps       | 192512       |
| train/                   |              |
|    approx_kl             | 0.0018398447 |
|    clip_fraction         | 0.00962      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 30.9         |
|    cost_values           | 1            |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.756        |
|    lagrangian_multiplier | 0.00678      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.76         |
|    n_updates             | 930          |
|    policy_gradient_loss  | -0.00348     |
|    std                   | 1.06         |
|    value_loss            | 21.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.3629268  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.35e+03   |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 8           |
|    time_elapsed          | 1026        |
|    total_timesteps       | 217088      |
| train/                   |             |
|    approx_kl             | 0.010574926 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.479       |
|    cost_value_loss       | 0.103       |
|    cost_values           | 0.479       |
|    entropy               | -2.64       |
|    entropy_loss          | -2.65       |
|    explained_variance    | -0.0275     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.72        |
|    n_updates             | 1050        |
|    policy_gradient_loss  | -0.00354    |
|    std                   | 0.907       |
|    value_loss            | 9.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.361       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.361       |
| reward                   | -0.4194539  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 7           |
|    time_elapsed          | 851         |
|    total_timesteps       | 215040      |
| train/                   |             |
|    approx_kl             | 0.006603636 |
|    clip_fraction         | 0.0647      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 6.3         |
|    cost_values           | 0.664       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.65        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.2        |
|    n_updates             | 1040        |
|    policy_gradient_loss  | -0.00815    |
|    std                   | 0.936       |
|    value_loss            | 20          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.6627074  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -942        |
| time/                    |             |
|    fps                   | 18          |
|    iterations            | 49          |
|    time_elapsed          | 5384        |
|    total_timesteps       | 200704      |
| train/                   |             |
|    approx_kl             | 0.004394045 |
|    clip_fraction         | 0.0304      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 5.49        |
|    cost_values           | 0.717       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.742       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.5        |
|    n_updates             | 970         |
|    policy_gradient_loss  | -0.00455    |
|    std                   | 1           |
|    value_loss            | 35.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0485096   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 17           |
|    iterations            | 48           |
|    time_elapsed          | 5484         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0029881673 |
|    clip_fraction         | 0.0496       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 20.9         |
|    cost_values           | 1.01         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.659        |
|    lagrangian_multiplier | 0.00162      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 1.03         |
|    value_loss            | 38.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.77         |
| reward                   | -1.1742635   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 9            |
|    time_elapsed          | 1117         |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0038117808 |
|    clip_fraction         | 0.0516       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.826        |
|    cost_value_loss       | 2.56         |
|    cost_values           | 0.589        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.347        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.3         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00558     |
|    std                   | 0.984        |
|    value_loss            | 104          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.31371927  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 46           |
|    time_elapsed          | 5154         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0044550677 |
|    clip_fraction         | 0.0241       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 19.8         |
|    cost_values           | 0.933        |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.838        |
|    lagrangian_multiplier | 0.00175      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.19         |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 1.06         |
|    value_loss            | 10.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -1.3863492  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.34e+03   |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 9           |
|    time_elapsed          | 1157        |
|    total_timesteps       | 219136      |
| train/                   |             |
|    approx_kl             | 0.005029071 |
|    clip_fraction         | 0.0614      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.512       |
|    cost_value_loss       | 0.252       |
|    cost_values           | 0.511       |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.00651     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.1        |
|    n_updates             | 1060        |
|    policy_gradient_loss  | -0.00388    |
|    std                   | 0.904       |
|    value_loss            | 63          |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.05         |
| reward                   | -0.4803796   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 8            |
|    time_elapsed          | 981          |
|    total_timesteps       | 217088       |
| train/                   |              |
|    approx_kl             | 0.0066143516 |
|    clip_fraction         | 0.0742       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.53         |
|    cost_value_loss       | 32.9         |
|    cost_values           | 0.925        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.8          |
|    lagrangian_multiplier | 0.00105      |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 1050         |
|    policy_gradient_loss  | -0.00786     |
|    std                   | 0.931        |
|    value_loss            | 9.78         |
-------------------------------------------
------------------------------------
| avg_speed          | 2.49        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 2.49        |
| reward             | -0.63983625 |
| rollout/           |             |
|    ep_len_mean     | 953         |
|    ep_rew_mean     | -911        |
| time/              |             |
|    fps             | 14          |
|    iterations      | 1           |
|    time_elapsed    | 141         |
|    total_timesteps | 202752      |
------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -1.166574   |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 10          |
|    time_elapsed          | 1248        |
|    total_timesteps       | 221184      |
| train/                   |             |
|    approx_kl             | 0.009295941 |
|    clip_fraction         | 0.0626      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.886       |
|    cost_value_loss       | 1.89        |
|    cost_values           | 0.521       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.43        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26.4        |
|    n_updates             | 1070        |
|    policy_gradient_loss  | -0.00554    |
|    std                   | 0.983       |
|    value_loss            | 39.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5717856  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 17          |
|    iterations            | 49          |
|    time_elapsed          | 5629        |
|    total_timesteps       | 200704      |
| train/                   |             |
|    approx_kl             | 0.006532239 |
|    clip_fraction         | 0.0335      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 39.9        |
|    cost_values           | 0.981       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.703       |
|    lagrangian_multiplier | 0.00318     |
|    learning_rate         | 0.0003      |
|    loss                  | 15.6        |
|    n_updates             | 970         |
|    policy_gradient_loss  | -0.00399    |
|    std                   | 1.03        |
|    value_loss            | 35.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.1163398   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 47           |
|    time_elapsed          | 5293         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0039325166 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 16.4         |
|    cost_values           | 1.02         |
|    entropy               | -2.94        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.563        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00348     |
|    std                   | 1.05         |
|    value_loss            | 9.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2968942   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 10           |
|    time_elapsed          | 1297         |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0037524845 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.491        |
|    cost_value_loss       | 0.144        |
|    cost_values           | 0.494        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.00949      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 1070         |
|    policy_gradient_loss  | -0.00413     |
|    std                   | 0.902        |
|    value_loss            | 41.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.61953604  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 9            |
|    time_elapsed          | 1112         |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0056273527 |
|    clip_fraction         | 0.0376       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.33         |
|    cost_value_loss       | 19.5         |
|    cost_values           | 0.888        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.614        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44.2         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 0.932        |
|    value_loss            | 74.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.5598328  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 11          |
|    time_elapsed          | 1376        |
|    total_timesteps       | 223232      |
| train/                   |             |
|    approx_kl             | 0.004141338 |
|    clip_fraction         | 0.0155      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.953       |
|    cost_value_loss       | 5.03        |
|    cost_values           | 0.475       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.285       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 229         |
|    n_updates             | 1080        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.984       |
|    value_loss            | 477         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.77         |
| reward                   | -0.764573    |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -915         |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 2            |
|    time_elapsed          | 288          |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0038960408 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 0.59         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.775        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.4         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.999        |
|    value_loss            | 50.7         |
-------------------------------------------
----------------------------------
| avg_speed          | 7.44      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 7.44      |
| reward             | -1.688084 |
| rollout/           |           |
|    ep_len_mean     | 981       |
|    ep_rew_mean     | -1.11e+03 |
| time/              |           |
|    fps             | 14        |
|    iterations      | 1         |
|    time_elapsed    | 144       |
|    total_timesteps | 202752    |
----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3272758   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 11           |
|    time_elapsed          | 1433         |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0043271757 |
|    clip_fraction         | 0.035        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.486        |
|    cost_value_loss       | 0.205        |
|    cost_values           | 0.488        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.009        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49.8         |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.00404     |
|    std                   | 0.902        |
|    value_loss            | 102          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.43         |
| reward                   | -1.2049965   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 18           |
|    iterations            | 48           |
|    time_elapsed          | 5438         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0045487373 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 9.06         |
|    cost_values           | 1.02         |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.794        |
|    lagrangian_multiplier | 0.00171      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.57         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.00347     |
|    std                   | 1.05         |
|    value_loss            | 11.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -1.1217029  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 10          |
|    time_elapsed          | 1243        |
|    total_timesteps       | 221184      |
| train/                   |             |
|    approx_kl             | 0.007987128 |
|    clip_fraction         | 0.0726      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.22        |
|    cost_value_loss       | 15.9        |
|    cost_values           | 0.794       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.675       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 38          |
|    n_updates             | 1070        |
|    policy_gradient_loss  | -0.00782    |
|    std                   | 0.937       |
|    value_loss            | 67.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.586        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.586        |
| reward                   | -0.21415095  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 12           |
|    time_elapsed          | 1491         |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0040364973 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 6.14         |
|    cost_values           | 0.618        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.584        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.978        |
|    value_loss            | 21.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.96        |
| reward                   | -0.36408937 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -903        |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 3           |
|    time_elapsed          | 436         |
|    total_timesteps       | 206848      |
| train/                   |             |
|    approx_kl             | 0.004645527 |
|    clip_fraction         | 0.0239      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 6.9         |
|    cost_values           | 0.601       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 1000        |
|    policy_gradient_loss  | -0.00387    |
|    std                   | 0.997       |
|    value_loss            | 21.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0584       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0584       |
| reward                   | -0.26482534  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 2            |
|    time_elapsed          | 290          |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0040291636 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.72         |
|    cost_value_loss       | 25.9         |
|    cost_values           | 1.15         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.593        |
|    lagrangian_multiplier | 0.00261      |
|    learning_rate         | 0.0003       |
|    loss                  | 21.7         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.0045      |
|    std                   | 1.03         |
|    value_loss            | 67.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -1.3108033   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 12           |
|    time_elapsed          | 1573         |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0036337867 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.597        |
|    cost_value_loss       | 0.608        |
|    cost_values           | 0.587        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.0238       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.6         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.00456     |
|    std                   | 0.902        |
|    value_loss            | 78.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.11        |
| reward                   | -0.8604548  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -702        |
| time/                    |             |
|    fps                   | 17          |
|    iterations            | 49          |
|    time_elapsed          | 5579        |
|    total_timesteps       | 200704      |
| train/                   |             |
|    approx_kl             | 0.004300753 |
|    clip_fraction         | 0.0272      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.24        |
|    cost_value_loss       | 14          |
|    cost_values           | 0.798       |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.849       |
|    lagrangian_multiplier | 0.000143    |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 970         |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 1.06        |
|    value_loss            | 14.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.44         |
| reward                   | -0.5905053   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 13           |
|    time_elapsed          | 1605         |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0009978171 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.957        |
|    cost_value_loss       | 3.7          |
|    cost_values           | 0.657        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.404        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 138          |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.000492    |
|    std                   | 0.976        |
|    value_loss            | 304          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.4031616  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 11          |
|    time_elapsed          | 1376        |
|    total_timesteps       | 223232      |
| train/                   |             |
|    approx_kl             | 0.003990574 |
|    clip_fraction         | 0.0381      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.767       |
|    cost_value_loss       | 2.67        |
|    cost_values           | 0.518       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.483       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 95.8        |
|    n_updates             | 1080        |
|    policy_gradient_loss  | -0.00352    |
|    std                   | 0.939       |
|    value_loss            | 181         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.255        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.255        |
| reward                   | -0.8118779   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -890         |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 4            |
|    time_elapsed          | 583          |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0042274985 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 7.23         |
|    cost_values           | 0.639        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.862        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 0.996        |
|    value_loss            | 24.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -1.7697039   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 3            |
|    time_elapsed          | 441          |
|    total_timesteps       | 206848       |
| train/                   |              |
|    approx_kl             | 0.0061287815 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.98         |
|    cost_value_loss       | 47.2         |
|    cost_values           | 1.06         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.741        |
|    lagrangian_multiplier | 0.00453      |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 1000         |
|    policy_gradient_loss  | -0.00429     |
|    std                   | 1.03         |
|    value_loss            | 78.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.96        |
| reward                   | -0.81617045 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 14          |
|    time_elapsed          | 1720        |
|    total_timesteps       | 229376      |
| train/                   |             |
|    approx_kl             | 0.00400014  |
|    clip_fraction         | 0.0328      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.715       |
|    cost_value_loss       | 0.774       |
|    cost_values           | 0.566       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.449       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 119         |
|    n_updates             | 1110        |
|    policy_gradient_loss  | -0.00388    |
|    std                   | 0.975       |
|    value_loss            | 249         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1771932   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 13           |
|    time_elapsed          | 1714         |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0047143283 |
|    clip_fraction         | 0.0267       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.67         |
|    cost_value_loss       | 0.62         |
|    cost_values           | 0.655        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.0646       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.00392     |
|    std                   | 0.9          |
|    value_loss            | 24.2         |
-------------------------------------------
------------------------------------
| avg_speed          | 0.605       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.605       |
| reward             | -0.37633282 |
| rollout/           |             |
|    ep_len_mean     | 979         |
|    ep_rew_mean     | -706        |
| time/              |             |
|    fps             | 13          |
|    iterations      | 1           |
|    time_elapsed    | 146         |
|    total_timesteps | 202752      |
------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.56195444  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 12           |
|    time_elapsed          | 1511         |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0037583164 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 0.587        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.544        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 109          |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.00471     |
|    std                   | 0.938        |
|    value_loss            | 206          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.37         |
| reward                   | -0.9202003   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -878         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 5            |
|    time_elapsed          | 733          |
|    total_timesteps       | 210944       |
| train/                   |              |
|    approx_kl             | 0.0021309478 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.09         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 0.794        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.861        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 1020         |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 0.996        |
|    value_loss            | 13.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.56        |
| reward                   | -0.5604477  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 15          |
|    time_elapsed          | 1836        |
|    total_timesteps       | 231424      |
| train/                   |             |
|    approx_kl             | 0.003597818 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.688       |
|    cost_value_loss       | 1.3         |
|    cost_values           | 0.572       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.348       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 147         |
|    n_updates             | 1120        |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.975       |
|    value_loss            | 274         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.67         |
| reward                   | -1.1689676   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 4            |
|    time_elapsed          | 591          |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0052004443 |
|    clip_fraction         | 0.0301       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.06         |
|    cost_value_loss       | 48           |
|    cost_values           | 0.831        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.837        |
|    lagrangian_multiplier | 0.0029       |
|    learning_rate         | 0.0003       |
|    loss                  | 21.2         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.00505     |
|    std                   | 1.04         |
|    value_loss            | 56.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -2.0940616  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 14          |
|    time_elapsed          | 1858        |
|    total_timesteps       | 229376      |
| train/                   |             |
|    approx_kl             | 0.004401098 |
|    clip_fraction         | 0.0173      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.644       |
|    cost_value_loss       | 0.136       |
|    cost_values           | 0.655       |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.35        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.51        |
|    n_updates             | 1110        |
|    policy_gradient_loss  | -0.00395    |
|    std                   | 0.9         |
|    value_loss            | 21.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.03         |
| reward                   | -0.30573058  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 2            |
|    time_elapsed          | 291          |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0035721548 |
|    clip_fraction         | 0.0276       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 6.14         |
|    cost_values           | 0.693        |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.599        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.9         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 1.06         |
|    value_loss            | 88.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -0.90463936 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 13          |
|    time_elapsed          | 1648        |
|    total_timesteps       | 227328      |
| train/                   |             |
|    approx_kl             | 0.007189309 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.745       |
|    cost_value_loss       | 2.11        |
|    cost_values           | 0.512       |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.614       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 59.2        |
|    n_updates             | 1100        |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.938       |
|    value_loss            | 113         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.8214753  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 16          |
|    time_elapsed          | 1953        |
|    total_timesteps       | 233472      |
| train/                   |             |
|    approx_kl             | 0.004494106 |
|    clip_fraction         | 0.023       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 8.72        |
|    cost_values           | 0.711       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.545       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 29.5        |
|    n_updates             | 1130        |
|    policy_gradient_loss  | -0.00394    |
|    std                   | 0.974       |
|    value_loss            | 50.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.88         |
| reward                   | -0.44724113  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -875         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 6            |
|    time_elapsed          | 884          |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0024233754 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 44.8         |
|    cost_values           | 0.832        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.875        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.3         |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.998        |
|    value_loss            | 41.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.58        |
| reward                   | -1.600164   |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 5           |
|    time_elapsed          | 743         |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.006383242 |
|    clip_fraction         | 0.0315      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.25        |
|    cost_value_loss       | 59.1        |
|    cost_values           | 1.17        |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.87        |
|    lagrangian_multiplier | 0.00695     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00626    |
|    std                   | 1.04        |
|    value_loss            | 32.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.3442638  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 15          |
|    time_elapsed          | 2000        |
|    total_timesteps       | 231424      |
| train/                   |             |
|    approx_kl             | 0.005380612 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.573       |
|    cost_value_loss       | 0.171       |
|    cost_values           | 0.576       |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.376       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.9        |
|    n_updates             | 1120        |
|    policy_gradient_loss  | -0.005      |
|    std                   | 0.901       |
|    value_loss            | 70.7        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.71       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.71       |
| reward                   | -0.8768775 |
| rollout/                 |            |
|    ep_len_mean           | 991        |
|    ep_rew_mean           | -1.06e+03  |
| time/                    |            |
|    fps                   | 16         |
|    iterations            | 14         |
|    time_elapsed          | 1787       |
|    total_timesteps       | 229376     |
| train/                   |            |
|    approx_kl             | 0.00455326 |
|    clip_fraction         | 0.0442     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.06       |
|    cost_value_loss       | 4.39       |
|    cost_values           | 0.611      |
|    entropy               | -2.71      |
|    entropy_loss          | -2.71      |
|    explained_variance    | 0.633      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.31       |
|    n_updates             | 1110       |
|    policy_gradient_loss  | -0.00666   |
|    std                   | 0.938      |
|    value_loss            | 12.4       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.05        |
| reward                   | -0.43563756 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 3           |
|    time_elapsed          | 437         |
|    total_timesteps       | 206848      |
| train/                   |             |
|    approx_kl             | 0.006203688 |
|    clip_fraction         | 0.0426      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 0.823       |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.848       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.47        |
|    n_updates             | 1000        |
|    policy_gradient_loss  | -0.0062     |
|    std                   | 1.06        |
|    value_loss            | 8.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -1.7461345  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 17          |
|    time_elapsed          | 2074        |
|    total_timesteps       | 235520      |
| train/                   |             |
|    approx_kl             | 0.005540913 |
|    clip_fraction         | 0.0555      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.959       |
|    cost_value_loss       | 2.06        |
|    cost_values           | 0.725       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.498       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.5        |
|    n_updates             | 1140        |
|    policy_gradient_loss  | -0.00639    |
|    std                   | 0.971       |
|    value_loss            | 46.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.996        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.996        |
| reward                   | -0.4316253   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -863         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 7            |
|    time_elapsed          | 1037         |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0042045205 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 12.5         |
|    cost_values           | 0.931        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.805        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.2         |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 1            |
|    value_loss            | 44.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -1.2683363  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 6           |
|    time_elapsed          | 891         |
|    total_timesteps       | 212992      |
| train/                   |             |
|    approx_kl             | 0.006549633 |
|    clip_fraction         | 0.0442      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.4         |
|    cost_value_loss       | 62.7        |
|    cost_values           | 1.04        |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.828       |
|    lagrangian_multiplier | 0.00525     |
|    learning_rate         | 0.0003      |
|    loss                  | 14.6        |
|    n_updates             | 1030        |
|    policy_gradient_loss  | -0.00708    |
|    std                   | 1.04        |
|    value_loss            | 43.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3124888   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 16           |
|    time_elapsed          | 2145         |
|    total_timesteps       | 233472       |
| train/                   |              |
|    approx_kl             | 0.0033473014 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.542        |
|    cost_value_loss       | 0.253        |
|    cost_values           | 0.492        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.284        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.1         |
|    n_updates             | 1130         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.901        |
|    value_loss            | 102          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -0.8808521   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 15           |
|    time_elapsed          | 1926         |
|    total_timesteps       | 231424       |
| train/                   |              |
|    approx_kl             | 0.0074330335 |
|    clip_fraction         | 0.0696       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 19.2         |
|    cost_values           | 0.774        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.782        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 1120         |
|    policy_gradient_loss  | -0.00854     |
|    std                   | 0.936        |
|    value_loss            | 6.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.33         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.33         |
| reward                   | -0.46676     |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 4            |
|    time_elapsed          | 585          |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0015749846 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 3.63         |
|    cost_values           | 0.602        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.725        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.3         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.000622    |
|    std                   | 1.05         |
|    value_loss            | 55.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.53         |
| reward                   | -0.42396435  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 18           |
|    time_elapsed          | 2192         |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0041802507 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.895        |
|    cost_value_loss       | 2.41         |
|    cost_values           | 0.673        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.394        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 63.7         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 0.97         |
|    value_loss            | 120          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.49        |
| reward                   | -0.52905345 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -851        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 8           |
|    time_elapsed          | 1192        |
|    total_timesteps       | 217088      |
| train/                   |             |
|    approx_kl             | 0.003446526 |
|    clip_fraction         | 0.00664     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.21        |
|    cost_value_loss       | 29.6        |
|    cost_values           | 1.26        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | -0.055      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.1        |
|    n_updates             | 1050        |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 1           |
|    value_loss            | 22.7        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.84       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.84       |
| reward                   | -0.966652  |
| rollout/                 |            |
|    ep_len_mean           | 981        |
|    ep_rew_mean           | -1.06e+03  |
| time/                    |            |
|    fps                   | 13         |
|    iterations            | 7          |
|    time_elapsed          | 1043       |
|    total_timesteps       | 215040     |
| train/                   |            |
|    approx_kl             | 0.00921873 |
|    clip_fraction         | 0.0379     |
|    clip_range            | 0.2        |
|    cost_returns          | 6.63       |
|    cost_value_loss       | 57.5       |
|    cost_values           | 1.34       |
|    entropy               | -2.92      |
|    entropy_loss          | -2.92      |
|    explained_variance    | 0.906      |
|    lagrangian_multiplier | 0.00888    |
|    learning_rate         | 0.0003     |
|    loss                  | 7.1        |
|    n_updates             | 1040       |
|    policy_gradient_loss  | -0.00354   |
|    std                   | 1.04       |
|    value_loss            | 11.8       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 3.08         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.08         |
| reward                   | -0.6177385   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 17           |
|    time_elapsed          | 2289         |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0047809556 |
|    clip_fraction         | 0.0469       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.557        |
|    cost_value_loss       | 0.62         |
|    cost_values           | 0.519        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.505        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.00524     |
|    std                   | 0.902        |
|    value_loss            | 23           |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -1.0401295  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 16          |
|    time_elapsed          | 2078        |
|    total_timesteps       | 233472      |
| train/                   |             |
|    approx_kl             | 0.008040354 |
|    clip_fraction         | 0.065       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.54        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 0.727       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.75        |
|    n_updates             | 1130        |
|    policy_gradient_loss  | -0.00781    |
|    std                   | 0.934       |
|    value_loss            | 8.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.71         |
| reward                   | -1.1193144   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 19           |
|    time_elapsed          | 2313         |
|    total_timesteps       | 239616       |
| train/                   |              |
|    approx_kl             | 0.0031697706 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 3.75         |
|    cost_values           | 0.662        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.553        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 156          |
|    n_updates             | 1160         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.97         |
|    value_loss            | 321          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.5730138   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 5            |
|    time_elapsed          | 732          |
|    total_timesteps       | 210944       |
| train/                   |              |
|    approx_kl             | 0.0030824062 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 7.95         |
|    cost_values           | 0.469        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.731        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.9         |
|    n_updates             | 1020         |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 1.05         |
|    value_loss            | 46.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.51         |
| reward                   | -1.1463157   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 20           |
|    time_elapsed          | 2436         |
|    total_timesteps       | 241664       |
| train/                   |              |
|    approx_kl             | 0.0031573856 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 8.08         |
|    cost_values           | 0.7          |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.696        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30           |
|    n_updates             | 1170         |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 0.971        |
|    value_loss            | 56           |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.69        |
| reward                   | -1.0581803  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -833        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 9           |
|    time_elapsed          | 1347        |
|    total_timesteps       | 219136      |
| train/                   |             |
|    approx_kl             | 0.008021636 |
|    clip_fraction         | 0.0329      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.49        |
|    cost_value_loss       | 25.1        |
|    cost_values           | 1.35        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0.00475     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.63        |
|    n_updates             | 1060        |
|    policy_gradient_loss  | -0.00441    |
|    std                   | 1.01        |
|    value_loss            | 5.65        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.33525294  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 18           |
|    time_elapsed          | 2435         |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0041424558 |
|    clip_fraction         | 0.0375       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.524        |
|    cost_value_loss       | 0.337        |
|    cost_values           | 0.418        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.636        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.1         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.901        |
|    value_loss            | 51.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.092        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.092        |
| reward                   | -0.37112266  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 8            |
|    time_elapsed          | 1195         |
|    total_timesteps       | 217088       |
| train/                   |              |
|    approx_kl             | 0.0055091693 |
|    clip_fraction         | 0.0568       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.47         |
|    cost_value_loss       | 73.5         |
|    cost_values           | 1.23         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.911        |
|    lagrangian_multiplier | 0.00833      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.73         |
|    n_updates             | 1050         |
|    policy_gradient_loss  | -0.00641     |
|    std                   | 1.04         |
|    value_loss            | 12.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.6824324  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 17          |
|    time_elapsed          | 2231        |
|    total_timesteps       | 235520      |
| train/                   |             |
|    approx_kl             | 0.009557014 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.1         |
|    cost_value_loss       | 2.18        |
|    cost_values           | 0.656       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.8         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.28        |
|    n_updates             | 1140        |
|    policy_gradient_loss  | -0.0117     |
|    std                   | 0.935       |
|    value_loss            | 13.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.97        |
| reward                   | -0.6910854  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 6           |
|    time_elapsed          | 878         |
|    total_timesteps       | 212992      |
| train/                   |             |
|    approx_kl             | 0.004132547 |
|    clip_fraction         | 0.0311      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 8.03        |
|    cost_values           | 0.703       |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.82        |
|    n_updates             | 1030        |
|    policy_gradient_loss  | -0.00499    |
|    std                   | 1.05        |
|    value_loss            | 5.56        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.86       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.86       |
| reward                   | -0.5009402 |
| rollout/                 |            |
|    ep_len_mean           | 962        |
|    ep_rew_mean           | -1.19e+03  |
| time/                    |            |
|    fps                   | 16         |
|    iterations            | 21         |
|    time_elapsed          | 2559       |
|    total_timesteps       | 243712     |
| train/                   |            |
|    approx_kl             | 0.00640171 |
|    clip_fraction         | 0.0583     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.39       |
|    cost_value_loss       | 8.97       |
|    cost_values           | 0.734      |
|    entropy               | -2.78      |
|    entropy_loss          | -2.78      |
|    explained_variance    | 0.688      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 92.8       |
|    n_updates             | 1180       |
|    policy_gradient_loss  | -0.00449   |
|    std                   | 0.97       |
|    value_loss            | 179        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.71504307  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 19           |
|    time_elapsed          | 2585         |
|    total_timesteps       | 239616       |
| train/                   |              |
|    approx_kl             | 0.0040727984 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.846        |
|    cost_value_loss       | 0.564        |
|    cost_values           | 0.575        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.843        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.16         |
|    n_updates             | 1160         |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 0.901        |
|    value_loss            | 9.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.48        |
| reward                   | -1.0570611  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -818        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 10          |
|    time_elapsed          | 1503        |
|    total_timesteps       | 221184      |
| train/                   |             |
|    approx_kl             | 0.008067473 |
|    clip_fraction         | 0.0683      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 1.23        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0.00241     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.95        |
|    n_updates             | 1070        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 1.01        |
|    value_loss            | 10.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.265       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.265       |
| reward                   | -0.4369441  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.03e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 9           |
|    time_elapsed          | 1351        |
|    total_timesteps       | 219136      |
| train/                   |             |
|    approx_kl             | 0.005648615 |
|    clip_fraction         | 0.0308      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.97        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 0.951       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.813       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.8        |
|    n_updates             | 1060        |
|    policy_gradient_loss  | -0.00412    |
|    std                   | 1.05        |
|    value_loss            | 37.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.619       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.619       |
| reward                   | -0.382343   |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 7           |
|    time_elapsed          | 1028        |
|    total_timesteps       | 215040      |
| train/                   |             |
|    approx_kl             | 0.004044473 |
|    clip_fraction         | 0.027       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.83        |
|    cost_value_loss       | 20.2        |
|    cost_values           | 0.923       |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.761       |
|    lagrangian_multiplier | 0.00143     |
|    learning_rate         | 0.0003      |
|    loss                  | 17.8        |
|    n_updates             | 1040        |
|    policy_gradient_loss  | -0.00391    |
|    std                   | 1.05        |
|    value_loss            | 38.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.98798513 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.03e+03   |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 18          |
|    time_elapsed          | 2391        |
|    total_timesteps       | 237568      |
| train/                   |             |
|    approx_kl             | 0.009613694 |
|    clip_fraction         | 0.0913      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 1.87        |
|    cost_values           | 0.84        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.488       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.49        |
|    n_updates             | 1150        |
|    policy_gradient_loss  | -0.00824    |
|    std                   | 0.932       |
|    value_loss            | 7.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.68        |
| reward                   | -0.7751275  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 22          |
|    time_elapsed          | 2684        |
|    total_timesteps       | 245760      |
| train/                   |             |
|    approx_kl             | 0.003958192 |
|    clip_fraction         | 0.013       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.93        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 0.766       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.637       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 99.3        |
|    n_updates             | 1190        |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 0.968       |
|    value_loss            | 189         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9332347   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 20           |
|    time_elapsed          | 2736         |
|    total_timesteps       | 241664       |
| train/                   |              |
|    approx_kl             | 0.0051632375 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.299        |
|    cost_value_loss       | 0.171        |
|    cost_values           | 0.26         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.788        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.06         |
|    n_updates             | 1170         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 0.9          |
|    value_loss            | 11.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.31         |
| reward                   | -1.09824     |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -810         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 11           |
|    time_elapsed          | 1661         |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0034954688 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.13         |
|    cost_value_loss       | 27.5         |
|    cost_values           | 1.12         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.913        |
|    lagrangian_multiplier | 0.00453      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.3          |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.0044      |
|    std                   | 1.02         |
|    value_loss            | 15.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.5536625  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.02e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 10          |
|    time_elapsed          | 1507        |
|    total_timesteps       | 221184      |
| train/                   |             |
|    approx_kl             | 0.003982216 |
|    clip_fraction         | 0.026       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.92        |
|    cost_value_loss       | 94.9        |
|    cost_values           | 1.22        |
|    entropy               | -2.94       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0.0113      |
|    learning_rate         | 0.0003      |
|    loss                  | 9           |
|    n_updates             | 1070        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 1.05        |
|    value_loss            | 11.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.5          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.5          |
| reward                   | -0.66519797  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 8            |
|    time_elapsed          | 1181         |
|    total_timesteps       | 217088       |
| train/                   |              |
|    approx_kl             | 0.0050482694 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 4.14         |
|    cost_values           | 0.848        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.821        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 1050         |
|    policy_gradient_loss  | -0.00234     |
|    std                   | 1.05         |
|    value_loss            | 26.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.85         |
| reward                   | -0.68866295  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 19           |
|    time_elapsed          | 2549         |
|    total_timesteps       | 239616       |
| train/                   |              |
|    approx_kl             | 0.0047700293 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 3.02         |
|    cost_values           | 0.699        |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.687        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 29           |
|    n_updates             | 1160         |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.93         |
|    value_loss            | 63.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.622711   |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 23          |
|    time_elapsed          | 2811        |
|    total_timesteps       | 247808      |
| train/                   |             |
|    approx_kl             | 0.005032966 |
|    clip_fraction         | 0.0172      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 1.89        |
|    cost_values           | 0.782       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.713       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.85        |
|    n_updates             | 1200        |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.967       |
|    value_loss            | 10.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -1.0909474  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 21          |
|    time_elapsed          | 2891        |
|    total_timesteps       | 243712      |
| train/                   |             |
|    approx_kl             | 0.006063329 |
|    clip_fraction         | 0.0454      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.885       |
|    cost_value_loss       | 0.745       |
|    cost_values           | 0.739       |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.562       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.75        |
|    n_updates             | 1180        |
|    policy_gradient_loss  | -0.00547    |
|    std                   | 0.899       |
|    value_loss            | 7.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.2          |
| reward                   | -0.5081612   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -804         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 12           |
|    time_elapsed          | 1821         |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0061662765 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 0.815        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.903        |
|    lagrangian_multiplier | 0.00122      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.47         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 1.02         |
|    value_loss            | 16.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.24        |
| reward                   | -0.44394726 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1e+03      |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 11          |
|    time_elapsed          | 1666        |
|    total_timesteps       | 223232      |
| train/                   |             |
|    approx_kl             | 0.003934467 |
|    clip_fraction         | 0.0256      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 16.8        |
|    cost_values           | 1.18        |
|    entropy               | -2.92       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0.00304     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 1080        |
|    policy_gradient_loss  | -0.00445    |
|    std                   | 1.04        |
|    value_loss            | 12.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.83         |
| reward                   | -0.6747857   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 9            |
|    time_elapsed          | 1329         |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0037641402 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.85         |
|    cost_value_loss       | 25.1         |
|    cost_values           | 1.02         |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 0.00449      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.95         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 1.05         |
|    value_loss            | 17.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.96775186 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 24          |
|    time_elapsed          | 2937        |
|    total_timesteps       | 249856      |
| train/                   |             |
|    approx_kl             | 0.007594254 |
|    clip_fraction         | 0.0534      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.897       |
|    cost_value_loss       | 2.06        |
|    cost_values           | 0.724       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.663       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.5        |
|    n_updates             | 1210        |
|    policy_gradient_loss  | -0.00479    |
|    std                   | 0.969       |
|    value_loss            | 29.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.87035745 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 20          |
|    time_elapsed          | 2708        |
|    total_timesteps       | 241664      |
| train/                   |             |
|    approx_kl             | 0.007998755 |
|    clip_fraction         | 0.0932      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.35        |
|    cost_value_loss       | 19.1        |
|    cost_values           | 0.873       |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.773       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.5        |
|    n_updates             | 1170        |
|    policy_gradient_loss  | -0.00882    |
|    std                   | 0.929       |
|    value_loss            | 8.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9454376  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 22          |
|    time_elapsed          | 3044        |
|    total_timesteps       | 245760      |
| train/                   |             |
|    approx_kl             | 0.005036884 |
|    clip_fraction         | 0.0156      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.697       |
|    cost_value_loss       | 0.527       |
|    cost_values           | 0.553       |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.746       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.54        |
|    n_updates             | 1190        |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 0.898       |
|    value_loss            | 13.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -2.5378385   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 25           |
|    time_elapsed          | 3064         |
|    total_timesteps       | 251904       |
| train/                   |              |
|    approx_kl             | 0.0031530221 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 4.42         |
|    cost_values           | 0.706        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.702        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.09         |
|    n_updates             | 1220         |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 0.971        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.82         |
| reward                   | -0.64662707  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -796         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 13           |
|    time_elapsed          | 1978         |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0036752564 |
|    clip_fraction         | 0.0257       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 8.07         |
|    cost_values           | 1.12         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.79         |
|    lagrangian_multiplier | 0.00138      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.41         |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 1.02         |
|    value_loss            | 10.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7261257   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 10           |
|    time_elapsed          | 1481         |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0043837405 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 3.57         |
|    cost_values           | 0.694        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.869        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 1070         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 1.05         |
|    value_loss            | 27           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.163        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.163        |
| reward                   | -0.32424688  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -989         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 12           |
|    time_elapsed          | 1827         |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0039817854 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.95         |
|    cost_value_loss       | 99.5         |
|    cost_values           | 1.75         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.368        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49.5         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.00309     |
|    std                   | 1.04         |
|    value_loss            | 4.24         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.25        |
| reward                   | -0.8069417  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -991        |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 21          |
|    time_elapsed          | 2866        |
|    total_timesteps       | 243712      |
| train/                   |             |
|    approx_kl             | 0.010659869 |
|    clip_fraction         | 0.0899      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.58        |
|    cost_value_loss       | 17.6        |
|    cost_values           | 0.871       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.852       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 1180        |
|    policy_gradient_loss  | -0.0108     |
|    std                   | 0.935       |
|    value_loss            | 6.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -1.245763   |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 26          |
|    time_elapsed          | 3194        |
|    total_timesteps       | 253952      |
| train/                   |             |
|    approx_kl             | 0.005672242 |
|    clip_fraction         | 0.0139      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.82        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 0.77        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.572       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 44.8        |
|    n_updates             | 1230        |
|    policy_gradient_loss  | -0.00233    |
|    std                   | 0.972       |
|    value_loss            | 76.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.1685975   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 23           |
|    time_elapsed          | 3200         |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0070120483 |
|    clip_fraction         | 0.0363       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.618        |
|    cost_value_loss       | 0.19         |
|    cost_values           | 0.565        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.749        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.77         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.00462     |
|    std                   | 0.897        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.34         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.34         |
| reward                   | -0.63529176  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -710         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 11           |
|    time_elapsed          | 1633         |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0047394824 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 9.78         |
|    cost_values           | 0.712        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.934        |
|    lagrangian_multiplier | 0.000453     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.96         |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.00435     |
|    std                   | 1.05         |
|    value_loss            | 4.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.471        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.471        |
| reward                   | -0.5021223   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -784         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 14           |
|    time_elapsed          | 2138         |
|    total_timesteps       | 229376       |
| train/                   |              |
|    approx_kl             | 0.0019002825 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.27         |
|    cost_value_loss       | 30.7         |
|    cost_values           | 1.39         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.605        |
|    lagrangian_multiplier | 0.00045      |
|    learning_rate         | 0.0003       |
|    loss                  | 16.5         |
|    n_updates             | 1110         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 1.02         |
|    value_loss            | 11.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.142       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.142       |
| reward                   | -0.35715997 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -969        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 13          |
|    time_elapsed          | 1985        |
|    total_timesteps       | 227328      |
| train/                   |             |
|    approx_kl             | 0.003953412 |
|    clip_fraction         | 0.00654     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.02        |
|    cost_value_loss       | 51.9        |
|    cost_values           | 1.71        |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30          |
|    n_updates             | 1100        |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 1.04        |
|    value_loss            | 7.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5790883   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -982         |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 22           |
|    time_elapsed          | 3028         |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0055295746 |
|    clip_fraction         | 0.121        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.95         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 0.938        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.748        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 1190         |
|    policy_gradient_loss  | -0.0025      |
|    std                   | 0.935        |
|    value_loss            | 8.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -2.0180144  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 27          |
|    time_elapsed          | 3324        |
|    total_timesteps       | 256000      |
| train/                   |             |
|    approx_kl             | 0.003672141 |
|    clip_fraction         | 0.0311      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 2.42        |
|    cost_values           | 0.73        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.554       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 169         |
|    n_updates             | 1240        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.972       |
|    value_loss            | 346         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.77662873  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 24           |
|    time_elapsed          | 3354         |
|    total_timesteps       | 249856       |
| train/                   |              |
|    approx_kl             | 0.0046426747 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.762        |
|    cost_value_loss       | 0.446        |
|    cost_values           | 0.569        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.831        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.91         |
|    n_updates             | 1210         |
|    policy_gradient_loss  | -0.00443     |
|    std                   | 0.895        |
|    value_loss            | 13.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.32        |
| reward                   | -0.65740126 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -712        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 12          |
|    time_elapsed          | 1789        |
|    total_timesteps       | 225280      |
| train/                   |             |
|    approx_kl             | 0.004314174 |
|    clip_fraction         | 0.0528      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 22.3        |
|    cost_values           | 0.905       |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0.00485     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.27        |
|    n_updates             | 1090        |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 1.05        |
|    value_loss            | 7.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.244       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.244       |
| reward                   | -0.39734063 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -947        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 14          |
|    time_elapsed          | 2130        |
|    total_timesteps       | 229376      |
| train/                   |             |
|    approx_kl             | 0.008301921 |
|    clip_fraction         | 0.0465      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 153         |
|    cost_values           | 1.69        |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | -0.522      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 75          |
|    n_updates             | 1110        |
|    policy_gradient_loss  | -0.00523    |
|    std                   | 1.04        |
|    value_loss            | 2.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.357        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.357        |
| reward                   | -0.32327402  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -776         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 15           |
|    time_elapsed          | 2300         |
|    total_timesteps       | 231424       |
| train/                   |              |
|    approx_kl             | 0.0036748266 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.27         |
|    cost_value_loss       | 23.5         |
|    cost_values           | 1.1          |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0.00223      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.13         |
|    n_updates             | 1120         |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 1.02         |
|    value_loss            | 8.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.148        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.148        |
| reward                   | -0.34455988  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -971         |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 23           |
|    time_elapsed          | 3196         |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0074699433 |
|    clip_fraction         | 0.0722       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 13.2         |
|    cost_values           | 0.92         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.876        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.94         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.00886     |
|    std                   | 0.932        |
|    value_loss            | 7.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.0517762   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 28           |
|    time_elapsed          | 3455         |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0022546742 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 3.52         |
|    cost_values           | 0.744        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.721        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.8         |
|    n_updates             | 1250         |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 0.973        |
|    value_loss            | 87           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8538284  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 25          |
|    time_elapsed          | 3511        |
|    total_timesteps       | 251904      |
| train/                   |             |
|    approx_kl             | 0.006625498 |
|    clip_fraction         | 0.0442      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.689       |
|    cost_value_loss       | 0.624       |
|    cost_values           | 0.499       |
|    entropy               | -2.61       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.804       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.83        |
|    n_updates             | 1220        |
|    policy_gradient_loss  | -0.00604    |
|    std                   | 0.894       |
|    value_loss            | 15.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.315       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.315       |
| reward                   | -0.5560596  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -943        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 15          |
|    time_elapsed          | 2271        |
|    total_timesteps       | 231424      |
| train/                   |             |
|    approx_kl             | 0.005481075 |
|    clip_fraction         | 0.0187      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 141         |
|    cost_values           | 1.56        |
|    entropy               | -2.92       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0.00886     |
|    learning_rate         | 0.0003      |
|    loss                  | 16.3        |
|    n_updates             | 1120        |
|    policy_gradient_loss  | -0.00306    |
|    std                   | 1.04        |
|    value_loss            | 14.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.66         |
| reward                   | -0.7744431   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 13           |
|    time_elapsed          | 1943         |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0032981886 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 18.1         |
|    cost_values           | 0.895        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.884        |
|    lagrangian_multiplier | 0.00028      |
|    learning_rate         | 0.0003       |
|    loss                  | 19.5         |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 1.05         |
|    value_loss            | 27.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.177        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.177        |
| reward                   | -0.3853393   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -758         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 16           |
|    time_elapsed          | 2465         |
|    total_timesteps       | 233472       |
| train/                   |              |
|    approx_kl             | 0.0026921546 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.33         |
|    cost_value_loss       | 33.4         |
|    cost_values           | 1.22         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.894        |
|    lagrangian_multiplier | 0.00149      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 1130         |
|    policy_gradient_loss  | -0.00306     |
|    std                   | 1.02         |
|    value_loss            | 4.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -1.3580121  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 29          |
|    time_elapsed          | 3587        |
|    total_timesteps       | 260096      |
| train/                   |             |
|    approx_kl             | 0.003541844 |
|    clip_fraction         | 0.00952     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.09        |
|    cost_value_loss       | 17.1        |
|    cost_values           | 0.773       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.742       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 59          |
|    n_updates             | 1260        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.973       |
|    value_loss            | 99.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7929951  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -959        |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 24          |
|    time_elapsed          | 3362        |
|    total_timesteps       | 249856      |
| train/                   |             |
|    approx_kl             | 0.005938102 |
|    clip_fraction         | 0.0248      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.17        |
|    cost_value_loss       | 96.3        |
|    cost_values           | 1.68        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0.00678     |
|    learning_rate         | 0.0003      |
|    loss                  | 12          |
|    n_updates             | 1210        |
|    policy_gradient_loss  | -0.00324    |
|    std                   | 0.928       |
|    value_loss            | 5.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.9208858  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 26          |
|    time_elapsed          | 3666        |
|    total_timesteps       | 253952      |
| train/                   |             |
|    approx_kl             | 0.005452167 |
|    clip_fraction         | 0.00854     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.471       |
|    cost_value_loss       | 0.266       |
|    cost_values           | 0.37        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.776       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 1230        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.894       |
|    value_loss            | 28.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0179       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0179       |
| reward                   | -0.7087377   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -940         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 16           |
|    time_elapsed          | 2434         |
|    total_timesteps       | 233472       |
| train/                   |              |
|    approx_kl             | 0.0014979168 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 201          |
|    cost_values           | 1.6          |
|    entropy               | -2.91        |
|    entropy_loss          | -2.92        |
|    explained_variance    | -0.111       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 1130         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 1.04         |
|    value_loss            | 15.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.90478355 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -712        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 14          |
|    time_elapsed          | 2099        |
|    total_timesteps       | 229376      |
| train/                   |             |
|    approx_kl             | 0.004696438 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.31        |
|    cost_value_loss       | 12.1        |
|    cost_values           | 0.92        |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.23        |
|    n_updates             | 1110        |
|    policy_gradient_loss  | -0.00498    |
|    std                   | 1.05        |
|    value_loss            | 8.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0854       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0854       |
| reward                   | -0.49168804  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 17           |
|    time_elapsed          | 2630         |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0046196408 |
|    clip_fraction         | 0.0363       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.83         |
|    cost_value_loss       | 16.9         |
|    cost_values           | 1.03         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.794        |
|    lagrangian_multiplier | 0.00329      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.27         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 1.02         |
|    value_loss            | 22.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4380475   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 30           |
|    time_elapsed          | 3720         |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0021863994 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.945        |
|    cost_value_loss       | 1.44         |
|    cost_values           | 0.722        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.858        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.2         |
|    n_updates             | 1270         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.971        |
|    value_loss            | 32.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.61009556  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -945         |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 25           |
|    time_elapsed          | 3527         |
|    total_timesteps       | 251904       |
| train/                   |              |
|    approx_kl             | 0.0053328965 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.43         |
|    cost_value_loss       | 31.4         |
|    cost_values           | 1.32         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.887        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.2         |
|    n_updates             | 1220         |
|    policy_gradient_loss  | -0.00437     |
|    std                   | 0.927        |
|    value_loss            | 9.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -0.83886606  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 27           |
|    time_elapsed          | 3821         |
|    total_timesteps       | 256000       |
| train/                   |              |
|    approx_kl             | 0.0051960675 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.665        |
|    cost_value_loss       | 0.257        |
|    cost_values           | 0.557        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.856        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.4          |
|    n_updates             | 1240         |
|    policy_gradient_loss  | -0.00402     |
|    std                   | 0.893        |
|    value_loss            | 17.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.2292912   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -932         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 17           |
|    time_elapsed          | 2594         |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0040354165 |
|    clip_fraction         | 0.00537      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.4         |
|    cost_value_loss       | 98.4         |
|    cost_values           | 2.14         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.91        |
|    explained_variance    | -0.394       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47.5         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 1.04         |
|    value_loss            | 3.37         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.08        |
| reward                   | -0.7484112  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -714        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 15          |
|    time_elapsed          | 2258        |
|    total_timesteps       | 231424      |
| train/                   |             |
|    approx_kl             | 0.005709224 |
|    clip_fraction         | 0.0371      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.7         |
|    cost_value_loss       | 0.532       |
|    cost_values           | 0.545       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4           |
|    n_updates             | 1120        |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 1.05        |
|    value_loss            | 7.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7684222  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.18e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 31          |
|    time_elapsed          | 3855        |
|    total_timesteps       | 264192      |
| train/                   |             |
|    approx_kl             | 0.005741697 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 4.87        |
|    cost_values           | 0.759       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.739       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.7        |
|    n_updates             | 1280        |
|    policy_gradient_loss  | -0.0035     |
|    std                   | 0.969       |
|    value_loss            | 64.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.365        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.365        |
| reward                   | -0.35454232  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -743         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 18           |
|    time_elapsed          | 2795         |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0024294492 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.08         |
|    cost_value_loss       | 60.8         |
|    cost_values           | 1.45         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.333        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.5         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 1.01         |
|    value_loss            | 16.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.80304     |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -935         |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 26           |
|    time_elapsed          | 3699         |
|    total_timesteps       | 253952       |
| train/                   |              |
|    approx_kl             | 0.0058640833 |
|    clip_fraction         | 0.0357       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.76         |
|    cost_value_loss       | 22.3         |
|    cost_values           | 1.26         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.921        |
|    lagrangian_multiplier | 0.00132      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.44         |
|    n_updates             | 1230         |
|    policy_gradient_loss  | -0.00499     |
|    std                   | 0.926        |
|    value_loss            | 6.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -1.1652688  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 28          |
|    time_elapsed          | 3977        |
|    total_timesteps       | 258048      |
| train/                   |             |
|    approx_kl             | 0.005524325 |
|    clip_fraction         | 0.0433      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.616       |
|    cost_value_loss       | 0.492       |
|    cost_values           | 0.509       |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.82        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.86        |
|    n_updates             | 1250        |
|    policy_gradient_loss  | -0.00611    |
|    std                   | 0.891       |
|    value_loss            | 16.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -0.8360685   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 32           |
|    time_elapsed          | 3991         |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0026081852 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 13.8         |
|    cost_values           | 0.783        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.805        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.3         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00357     |
|    std                   | 0.969        |
|    value_loss            | 22.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.38        |
| reward                   | -0.45152876 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -705        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 16          |
|    time_elapsed          | 2418        |
|    total_timesteps       | 233472      |
| train/                   |             |
|    approx_kl             | 0.003827143 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.85        |
|    cost_value_loss       | 8.28        |
|    cost_values           | 0.618       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 1130        |
|    policy_gradient_loss  | -0.00422    |
|    std                   | 1.05        |
|    value_loss            | 14.2        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.091         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.091         |
| reward                   | -0.23486184   |
| rollout/                 |               |
|    ep_len_mean           | 978           |
|    ep_rew_mean           | -922          |
| time/                    |               |
|    fps                   | 13            |
|    iterations            | 18            |
|    time_elapsed          | 2761          |
|    total_timesteps       | 237568        |
| train/                   |               |
|    approx_kl             | 0.00089202356 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 7.18          |
|    cost_value_loss       | 67.6          |
|    cost_values           | 1.75          |
|    entropy               | -2.92         |
|    entropy_loss          | -2.92         |
|    explained_variance    | 0.947         |
|    lagrangian_multiplier | 0.093         |
|    learning_rate         | 0.0003        |
|    loss                  | 2.53          |
|    n_updates             | 1150          |
|    policy_gradient_loss  | -0.000849     |
|    std                   | 1.04          |
|    value_loss            | 13.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 2.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.24         |
| reward                   | -0.24062912  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -731         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 19           |
|    time_elapsed          | 2964         |
|    total_timesteps       | 239616       |
| train/                   |              |
|    approx_kl             | 0.0042271316 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 1.57         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.822        |
|    lagrangian_multiplier | 0.0013       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.55         |
|    n_updates             | 1160         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 1.02         |
|    value_loss            | 5.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.74        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.74        |
| reward                   | -0.55404115 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -927        |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 27          |
|    time_elapsed          | 3871        |
|    total_timesteps       | 256000      |
| train/                   |             |
|    approx_kl             | 0.00927338  |
|    clip_fraction         | 0.0567      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.07        |
|    cost_value_loss       | 101         |
|    cost_values           | 1.7         |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0.0154      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.65        |
|    n_updates             | 1240        |
|    policy_gradient_loss  | -0.0064     |
|    std                   | 0.923       |
|    value_loss            | 5.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -1.1618971   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 33           |
|    time_elapsed          | 4128         |
|    total_timesteps       | 268288       |
| train/                   |              |
|    approx_kl             | 0.0074449517 |
|    clip_fraction         | 0.0565       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 22           |
|    cost_values           | 0.782        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.713        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 92.5         |
|    n_updates             | 1300         |
|    policy_gradient_loss  | -0.00445     |
|    std                   | 0.97         |
|    value_loss            | 177          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.75030637 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.11e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 29          |
|    time_elapsed          | 4139        |
|    total_timesteps       | 260096      |
| train/                   |             |
|    approx_kl             | 0.006655393 |
|    clip_fraction         | 0.0656      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.571       |
|    cost_value_loss       | 0.534       |
|    cost_values           | 0.459       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.875       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5           |
|    n_updates             | 1260        |
|    policy_gradient_loss  | -0.00841    |
|    std                   | 0.89        |
|    value_loss            | 11.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.76         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.76         |
| reward                   | -0.33564618  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 17           |
|    time_elapsed          | 2579         |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0037309062 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.46         |
|    cost_value_loss       | 22.6         |
|    cost_values           | 0.947        |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.859        |
|    lagrangian_multiplier | 0.00183      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.73         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 1.05         |
|    value_loss            | 9.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.102       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.102       |
| reward                   | -0.45033324 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -896        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 19          |
|    time_elapsed          | 2924        |
|    total_timesteps       | 239616      |
| train/                   |             |
|    approx_kl             | 0.0035122   |
|    clip_fraction         | 0.0214      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.85        |
|    cost_value_loss       | 53.9        |
|    cost_values           | 0.999       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.00925     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.33        |
|    n_updates             | 1160        |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 1.04        |
|    value_loss            | 31.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.18        |
| reward                   | -0.76274335 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -716        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 20          |
|    time_elapsed          | 3133        |
|    total_timesteps       | 241664      |
| train/                   |             |
|    approx_kl             | 0.005268639 |
|    clip_fraction         | 0.0328      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.85        |
|    cost_value_loss       | 4.13        |
|    cost_values           | 1.01        |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0.000181    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.16        |
|    n_updates             | 1170        |
|    policy_gradient_loss  | -0.0054     |
|    std                   | 1.02        |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.41359085 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 34          |
|    time_elapsed          | 4268        |
|    total_timesteps       | 270336      |
| train/                   |             |
|    approx_kl             | 0.010495091 |
|    clip_fraction         | 0.074       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.91        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 0.771       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.87        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.8        |
|    n_updates             | 1310        |
|    policy_gradient_loss  | -0.00937    |
|    std                   | 0.969       |
|    value_loss            | 16          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.174        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.174        |
| reward                   | -0.5588642   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -916         |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 28           |
|    time_elapsed          | 4041         |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0021838883 |
|    clip_fraction         | 0.0395       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.74         |
|    cost_value_loss       | 44.4         |
|    cost_values           | 1.22         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.788        |
|    lagrangian_multiplier | 4.04e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 23.4         |
|    n_updates             | 1250         |
|    policy_gradient_loss  | 4.79e-05     |
|    std                   | 0.922        |
|    value_loss            | 12.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -1.1005613  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.09e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 30          |
|    time_elapsed          | 4301        |
|    total_timesteps       | 262144      |
| train/                   |             |
|    approx_kl             | 0.008202416 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.538       |
|    cost_value_loss       | 0.359       |
|    cost_values           | 0.434       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.38        |
|    n_updates             | 1270        |
|    policy_gradient_loss  | -0.00665    |
|    std                   | 0.889       |
|    value_loss            | 15.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.26        |
| reward                   | -1.0178483  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 18          |
|    time_elapsed          | 2740        |
|    total_timesteps       | 237568      |
| train/                   |             |
|    approx_kl             | 0.002815675 |
|    clip_fraction         | 0.00737     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.97        |
|    cost_value_loss       | 9.69        |
|    cost_values           | 0.823       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.774       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 1150        |
|    policy_gradient_loss  | -0.00315    |
|    std                   | 1.04        |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.245       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.245       |
| reward                   | -0.5305851  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -882        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 20          |
|    time_elapsed          | 3088        |
|    total_timesteps       | 241664      |
| train/                   |             |
|    approx_kl             | 0.008398164 |
|    clip_fraction         | 0.043       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 43          |
|    cost_values           | 1.19        |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0.00438     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.7         |
|    n_updates             | 1170        |
|    policy_gradient_loss  | -0.00803    |
|    std                   | 1.04        |
|    value_loss            | 7.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.52         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.52         |
| reward                   | -0.43847656  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 21           |
|    time_elapsed          | 3304         |
|    total_timesteps       | 243712       |
| train/                   |              |
|    approx_kl             | 0.0020506578 |
|    clip_fraction         | 0.0298       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.01         |
|    cost_value_loss       | 37           |
|    cost_values           | 1.13         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.157        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 1180         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 1.02         |
|    value_loss            | 6.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.12         |
| reward                   | -0.87117016  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 35           |
|    time_elapsed          | 4409         |
|    total_timesteps       | 272384       |
| train/                   |              |
|    approx_kl             | 0.0014281031 |
|    clip_fraction         | 0.00288      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 16.5         |
|    cost_values           | 0.808        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.715        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 81.2         |
|    n_updates             | 1320         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.968        |
|    value_loss            | 150          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.537       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.537       |
| reward                   | -0.26604468 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -906        |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 29          |
|    time_elapsed          | 4212        |
|    total_timesteps       | 260096      |
| train/                   |             |
|    approx_kl             | 0.010239357 |
|    clip_fraction         | 0.0838      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.33        |
|    cost_value_loss       | 13          |
|    cost_values           | 0.996       |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.688       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.07        |
|    n_updates             | 1260        |
|    policy_gradient_loss  | -0.00993    |
|    std                   | 0.918       |
|    value_loss            | 6.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.62566304 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 31          |
|    time_elapsed          | 4465        |
|    total_timesteps       | 264192      |
| train/                   |             |
|    approx_kl             | 0.007421081 |
|    clip_fraction         | 0.0611      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.773       |
|    cost_value_loss       | 0.488       |
|    cost_values           | 0.644       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.42        |
|    n_updates             | 1280        |
|    policy_gradient_loss  | -0.00819    |
|    std                   | 0.889       |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.72        |
| reward                   | -1.0695863  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 19          |
|    time_elapsed          | 2903        |
|    total_timesteps       | 239616      |
| train/                   |             |
|    approx_kl             | 0.004926159 |
|    clip_fraction         | 0.0394      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.77        |
|    cost_value_loss       | 7           |
|    cost_values           | 0.758       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.807       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8           |
|    n_updates             | 1160        |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 1.04        |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.66        |
| reward                   | -1.3853115  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -869        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 21          |
|    time_elapsed          | 3252        |
|    total_timesteps       | 243712      |
| train/                   |             |
|    approx_kl             | 0.005330309 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 123         |
|    cost_values           | 1.61        |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | -0.547      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 58.9        |
|    n_updates             | 1180        |
|    policy_gradient_loss  | -0.00271    |
|    std                   | 1.04        |
|    value_loss            | 1.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -0.84158975  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 36           |
|    time_elapsed          | 4551         |
|    total_timesteps       | 274432       |
| train/                   |              |
|    approx_kl             | 0.0061313184 |
|    clip_fraction         | 0.0704       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 16.6         |
|    cost_values           | 0.751        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.658        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 246          |
|    n_updates             | 1330         |
|    policy_gradient_loss  | -0.00588     |
|    std                   | 0.967        |
|    value_loss            | 485          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.31        |
| reward                   | -0.54111403 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 22          |
|    time_elapsed          | 3461        |
|    total_timesteps       | 245760      |
| train/                   |             |
|    approx_kl             | 0.003644655 |
|    clip_fraction         | 0.0135      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.46        |
|    cost_value_loss       | 3.92        |
|    cost_values           | 0.756       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0.000152    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 1190        |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 1.02        |
|    value_loss            | 22.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.76         |
| reward                   | -0.4857291   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -894         |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 30           |
|    time_elapsed          | 4385         |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0054636057 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.17         |
|    cost_value_loss       | 61.3         |
|    cost_values           | 1.05         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0.00642      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.77         |
|    n_updates             | 1270         |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 0.917        |
|    value_loss            | 9.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.0656462  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 32          |
|    time_elapsed          | 4624        |
|    total_timesteps       | 266240      |
| train/                   |             |
|    approx_kl             | 0.006086288 |
|    clip_fraction         | 0.0295      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.839       |
|    cost_value_loss       | 0.756       |
|    cost_values           | 0.541       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.6         |
|    n_updates             | 1290        |
|    policy_gradient_loss  | -0.0048     |
|    std                   | 0.889       |
|    value_loss            | 8.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.59        |
| reward                   | -0.7743404  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 20          |
|    time_elapsed          | 3067        |
|    total_timesteps       | 241664      |
| train/                   |             |
|    approx_kl             | 0.003332757 |
|    clip_fraction         | 0.0145      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.99        |
|    cost_value_loss       | 10.1        |
|    cost_values           | 0.801       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.841       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 1170        |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 1.04        |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.126        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.126        |
| reward                   | -0.50927556  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -864         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 22           |
|    time_elapsed          | 3414         |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0038961656 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.05         |
|    cost_value_loss       | 25.7         |
|    cost_values           | 1.05         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.911        |
|    lagrangian_multiplier | 0.000272     |
|    learning_rate         | 0.0003       |
|    loss                  | 22.6         |
|    n_updates             | 1190         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 1.04         |
|    value_loss            | 28.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -1.8349915  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 16          |
|    iterations            | 37          |
|    time_elapsed          | 4691        |
|    total_timesteps       | 276480      |
| train/                   |             |
|    approx_kl             | 0.004430109 |
|    clip_fraction         | 0.0462      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.18        |
|    cost_value_loss       | 17.7        |
|    cost_values           | 0.753       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.811       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 116         |
|    n_updates             | 1340        |
|    policy_gradient_loss  | -0.00399    |
|    std                   | 0.969       |
|    value_loss            | 220         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.6794986   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 23           |
|    time_elapsed          | 3611         |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0047643865 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 16.2         |
|    cost_values           | 0.596        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.913        |
|    lagrangian_multiplier | 0.00173      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.94         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 1.02         |
|    value_loss            | 17.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.451       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.451       |
| reward                   | -0.5094706  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -883        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 31          |
|    time_elapsed          | 4562        |
|    total_timesteps       | 264192      |
| train/                   |             |
|    approx_kl             | 0.003566941 |
|    clip_fraction         | 0.0427      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.18        |
|    cost_value_loss       | 54.5        |
|    cost_values           | 1.55        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0.00972     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.42        |
|    n_updates             | 1280        |
|    policy_gradient_loss  | -0.00528    |
|    std                   | 0.915       |
|    value_loss            | 4.58        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.31072173  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 33           |
|    time_elapsed          | 4792         |
|    total_timesteps       | 268288       |
| train/                   |              |
|    approx_kl             | 0.0049685156 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.584        |
|    cost_value_loss       | 0.558        |
|    cost_values           | 0.447        |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.811        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.7         |
|    n_updates             | 1300         |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.889        |
|    value_loss            | 57           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.35         |
| reward                   | -0.8880469   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 21           |
|    time_elapsed          | 3234         |
|    total_timesteps       | 243712       |
| train/                   |              |
|    approx_kl             | 0.0045269337 |
|    clip_fraction         | 0.0365       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.22         |
|    cost_value_loss       | 17.8         |
|    cost_values           | 1.03         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0.00281      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.23         |
|    n_updates             | 1180         |
|    policy_gradient_loss  | -0.00463     |
|    std                   | 1.04         |
|    value_loss            | 4.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.52        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.52        |
| reward                   | -0.48351976 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -850        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 23          |
|    time_elapsed          | 3583        |
|    total_timesteps       | 247808      |
| train/                   |             |
|    approx_kl             | 0.008027331 |
|    clip_fraction         | 0.0481      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.9         |
|    cost_value_loss       | 106         |
|    cost_values           | 0.908       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0.0147      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.14        |
|    n_updates             | 1200        |
|    policy_gradient_loss  | -0.00767    |
|    std                   | 1.04        |
|    value_loss            | 10.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0726       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0726       |
| reward                   | -0.49264953  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 38           |
|    time_elapsed          | 4837         |
|    total_timesteps       | 278528       |
| train/                   |              |
|    approx_kl             | 0.0045607476 |
|    clip_fraction         | 0.0278       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 0.717        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.806        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 133          |
|    n_updates             | 1350         |
|    policy_gradient_loss  | -0.00333     |
|    std                   | 0.972        |
|    value_loss            | 253          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.7858282  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 24          |
|    time_elapsed          | 3764        |
|    total_timesteps       | 249856      |
| train/                   |             |
|    approx_kl             | 0.005262264 |
|    clip_fraction         | 0.0345      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.67        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 0.598       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.851       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 1210        |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 1.01        |
|    value_loss            | 16.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.7017004  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 14          |
|    iterations            | 34          |
|    time_elapsed          | 4960        |
|    total_timesteps       | 270336      |
| train/                   |             |
|    approx_kl             | 0.010062849 |
|    clip_fraction         | 0.0898      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.976       |
|    cost_value_loss       | 0.595       |
|    cost_values           | 0.71        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.773       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.42        |
|    n_updates             | 1310        |
|    policy_gradient_loss  | -0.0101     |
|    std                   | 0.887       |
|    value_loss            | 16.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.15         |
| reward                   | -0.59737116  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -879         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 32           |
|    time_elapsed          | 4738         |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0084932055 |
|    clip_fraction         | 0.0547       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.16         |
|    cost_value_loss       | 47.9         |
|    cost_values           | 1.29         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.926        |
|    lagrangian_multiplier | 0.00608      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.3          |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00837     |
|    std                   | 0.915        |
|    value_loss            | 6.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.23         |
| reward                   | -0.8232532   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 16           |
|    iterations            | 39           |
|    time_elapsed          | 4983         |
|    total_timesteps       | 280576       |
| train/                   |              |
|    approx_kl             | 0.0044351006 |
|    clip_fraction         | 0.0328       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 17.1         |
|    cost_values           | 0.765        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.748        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 128          |
|    n_updates             | 1360         |
|    policy_gradient_loss  | -0.00472     |
|    std                   | 0.971        |
|    value_loss            | 240          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.42         |
| reward                   | -0.55619836  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -692         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 22           |
|    time_elapsed          | 3399         |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0049074716 |
|    clip_fraction         | 0.0588       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 2.36         |
|    cost_values           | 0.896        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.56         |
|    n_updates             | 1190         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 1.04         |
|    value_loss            | 4.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.08        |
| reward                   | -0.69420236 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -700        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 25          |
|    time_elapsed          | 3918        |
|    total_timesteps       | 251904      |
| train/                   |             |
|    approx_kl             | 0.009042569 |
|    clip_fraction         | 0.0582      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 5.62        |
|    cost_values           | 0.465       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.45        |
|    n_updates             | 1220        |
|    policy_gradient_loss  | -0.00685    |
|    std                   | 1.01        |
|    value_loss            | 8.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.16        |
| reward                   | -0.31349522 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -835        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 24          |
|    time_elapsed          | 3761        |
|    total_timesteps       | 249856      |
| train/                   |             |
|    approx_kl             | 0.007375163 |
|    clip_fraction         | 0.0851      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 168         |
|    cost_values           | 1.58        |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | -0.113      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 83.7        |
|    n_updates             | 1210        |
|    policy_gradient_loss  | -0.0068     |
|    std                   | 1.04        |
|    value_loss            | 2.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.32        |
| reward                   | -0.7217708  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 40          |
|    time_elapsed          | 5129        |
|    total_timesteps       | 282624      |
| train/                   |             |
|    approx_kl             | 0.004325799 |
|    clip_fraction         | 0.0239      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 49.5        |
|    cost_values           | 0.859       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 76          |
|    n_updates             | 1370        |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 0.971       |
|    value_loss            | 111         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7704422   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 35           |
|    time_elapsed          | 5129         |
|    total_timesteps       | 272384       |
| train/                   |              |
|    approx_kl             | 0.0070468993 |
|    clip_fraction         | 0.0601       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.796        |
|    cost_value_loss       | 0.745        |
|    cost_values           | 0.568        |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.862        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.08         |
|    n_updates             | 1320         |
|    policy_gradient_loss  | -0.00704     |
|    std                   | 0.886        |
|    value_loss            | 18.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.71806765 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -870        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 33          |
|    time_elapsed          | 4913        |
|    total_timesteps       | 268288      |
| train/                   |             |
|    approx_kl             | 0.004432423 |
|    clip_fraction         | 0.032       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 47.7        |
|    cost_values           | 1.35        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.853       |
|    lagrangian_multiplier | 0.00553     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.1         |
|    n_updates             | 1300        |
|    policy_gradient_loss  | -0.00655    |
|    std                   | 0.913       |
|    value_loss            | 6.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.418        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.418        |
| reward                   | -0.42094797  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -690         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 23           |
|    time_elapsed          | 3565         |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0048655546 |
|    clip_fraction         | 0.0275       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 11.6         |
|    cost_values           | 0.879        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.861        |
|    lagrangian_multiplier | 0.000102     |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 1.04         |
|    value_loss            | 17.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -1.0235162   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 26           |
|    time_elapsed          | 4071         |
|    total_timesteps       | 253952       |
| train/                   |              |
|    approx_kl             | 0.0035780105 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 9.93         |
|    cost_values           | 0.768        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.845        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 1230         |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 1.01         |
|    value_loss            | 16.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0533       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0533       |
| reward                   | -0.26241678  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -817         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 25           |
|    time_elapsed          | 3944         |
|    total_timesteps       | 251904       |
| train/                   |              |
|    approx_kl             | 0.0018220542 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 8.07         |
|    cost_value_loss       | 97           |
|    cost_values           | 1.28         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0.00104      |
|    learning_rate         | 0.0003       |
|    loss                  | 36.4         |
|    n_updates             | 1220         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 1.04         |
|    value_loss            | 12.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.8520979   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 41           |
|    time_elapsed          | 5277         |
|    total_timesteps       | 284672       |
| train/                   |              |
|    approx_kl             | 0.0037926577 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 8.95         |
|    cost_values           | 0.751        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 71.1         |
|    n_updates             | 1380         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.971        |
|    value_loss            | 142          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.44865295 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 36          |
|    time_elapsed          | 5294        |
|    total_timesteps       | 274432      |
| train/                   |             |
|    approx_kl             | 0.006123863 |
|    clip_fraction         | 0.0518      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.751       |
|    cost_value_loss       | 0.709       |
|    cost_values           | 0.491       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.8        |
|    n_updates             | 1330        |
|    policy_gradient_loss  | -0.00722    |
|    std                   | 0.889       |
|    value_loss            | 43.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.3397675   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -696         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 27           |
|    time_elapsed          | 4226         |
|    total_timesteps       | 256000       |
| train/                   |              |
|    approx_kl             | 0.0035983408 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.2          |
|    cost_value_loss       | 35.5         |
|    cost_values           | 0.933        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.822        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.1         |
|    n_updates             | 1240         |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 1.02         |
|    value_loss            | 10           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.378       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.378       |
| reward                   | -0.39935416 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -868        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 34          |
|    time_elapsed          | 5091        |
|    total_timesteps       | 270336      |
| train/                   |             |
|    approx_kl             | 0.00795809  |
|    clip_fraction         | 0.0744      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.35        |
|    cost_value_loss       | 44.7        |
|    cost_values           | 1.3         |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0.00697     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.55        |
|    n_updates             | 1310        |
|    policy_gradient_loss  | -0.0114     |
|    std                   | 0.908       |
|    value_loss            | 6.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0527       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0527       |
| reward                   | -0.50982076  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 24           |
|    time_elapsed          | 3736         |
|    total_timesteps       | 249856       |
| train/                   |              |
|    approx_kl             | 0.0021973818 |
|    clip_fraction         | 0.00479      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.97         |
|    cost_value_loss       | 15.7         |
|    cost_values           | 0.781        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0.00195      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.08         |
|    n_updates             | 1210         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 1.04         |
|    value_loss            | 7.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.281        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.281        |
| reward                   | -0.48243484  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -805         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 26           |
|    time_elapsed          | 4115         |
|    total_timesteps       | 253952       |
| train/                   |              |
|    approx_kl             | 0.0035109343 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 8.08         |
|    cost_values           | 0.794        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.896        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 1230         |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 1.04         |
|    value_loss            | 18           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.41498348  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 42           |
|    time_elapsed          | 5426         |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0051099975 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 2.68         |
|    cost_values           | 0.787        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.838        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.4         |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.00576     |
|    std                   | 0.97         |
|    value_loss            | 40.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.67469704  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 37           |
|    time_elapsed          | 5464         |
|    total_timesteps       | 276480       |
| train/                   |              |
|    approx_kl             | 0.0055920593 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.971        |
|    cost_value_loss       | 0.682        |
|    cost_values           | 0.749        |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.17         |
|    n_updates             | 1340         |
|    policy_gradient_loss  | -0.00364     |
|    std                   | 0.889        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.66135913 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 28          |
|    time_elapsed          | 4386        |
|    total_timesteps       | 258048      |
| train/                   |             |
|    approx_kl             | 0.003943934 |
|    clip_fraction         | 0.00747     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.59        |
|    cost_value_loss       | 7.21        |
|    cost_values           | 0.693       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.856       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.6        |
|    n_updates             | 1250        |
|    policy_gradient_loss  | -0.002      |
|    std                   | 1.01        |
|    value_loss            | 66.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.48679632 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 25          |
|    time_elapsed          | 3906        |
|    total_timesteps       | 251904      |
| train/                   |             |
|    approx_kl             | 0.005020581 |
|    clip_fraction         | 0.0319      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 15.9        |
|    cost_values           | 1.27        |
|    entropy               | -2.92       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.181       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.9        |
|    n_updates             | 1220        |
|    policy_gradient_loss  | -0.00338    |
|    std                   | 1.04        |
|    value_loss            | 20.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0339       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0339       |
| reward                   | -0.36521667  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -857         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 35           |
|    time_elapsed          | 5271         |
|    total_timesteps       | 272384       |
| train/                   |              |
|    approx_kl             | 0.0036299455 |
|    clip_fraction         | 0.0248       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.89         |
|    cost_value_loss       | 14.8         |
|    cost_values           | 1.12         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.721        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 86.5         |
|    n_updates             | 1320         |
|    policy_gradient_loss  | -0.000581    |
|    std                   | 0.908        |
|    value_loss            | 196          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.628        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.628        |
| reward                   | -0.41169024  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -792         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 27           |
|    time_elapsed          | 4283         |
|    total_timesteps       | 256000       |
| train/                   |              |
|    approx_kl             | 0.0032864804 |
|    clip_fraction         | 0.00322      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.3         |
|    cost_value_loss       | 138          |
|    cost_values           | 1.41         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | -0.855       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 67.8         |
|    n_updates             | 1240         |
|    policy_gradient_loss  | -0.000869    |
|    std                   | 1.04         |
|    value_loss            | 5.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.49100894  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 43           |
|    time_elapsed          | 5576         |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0045557492 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 0.695        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.865        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 78.9         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.0057      |
|    std                   | 0.973        |
|    value_loss            | 154          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.43         |
| reward                   | -0.6088574   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 29           |
|    time_elapsed          | 4548         |
|    total_timesteps       | 260096       |
| train/                   |              |
|    approx_kl             | 0.0031352378 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 6.42         |
|    cost_values           | 0.651        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.2         |
|    n_updates             | 1260         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 1.02         |
|    value_loss            | 30.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.776325   |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.02e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 38          |
|    time_elapsed          | 5635        |
|    total_timesteps       | 278528      |
| train/                   |             |
|    approx_kl             | 0.007275191 |
|    clip_fraction         | 0.0247      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 0.633       |
|    cost_values           | 0.823       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.651       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.17        |
|    n_updates             | 1350        |
|    policy_gradient_loss  | -0.00421    |
|    std                   | 0.888       |
|    value_loss            | 12          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.641        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.641        |
| reward                   | -0.30104274  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 26           |
|    time_elapsed          | 4078         |
|    total_timesteps       | 253952       |
| train/                   |              |
|    approx_kl             | 0.0040828073 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.76         |
|    cost_value_loss       | 19.2         |
|    cost_values           | 1.1          |
|    entropy               | -2.91        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.822        |
|    lagrangian_multiplier | 0.00277      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.2          |
|    n_updates             | 1230         |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 1.04         |
|    value_loss            | 9.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.374        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.374        |
| reward                   | -0.62569505  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -776         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 28           |
|    time_elapsed          | 4429         |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0128859095 |
|    clip_fraction         | 0.0804       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.11         |
|    cost_value_loss       | 60.6         |
|    cost_values           | 1.33         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.888        |
|    lagrangian_multiplier | 0.00381      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 1250         |
|    policy_gradient_loss  | -0.0108      |
|    std                   | 1.04         |
|    value_loss            | 11.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.827       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.827       |
| reward                   | -0.5272907  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -844        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 36          |
|    time_elapsed          | 5455        |
|    total_timesteps       | 274432      |
| train/                   |             |
|    approx_kl             | 0.005369921 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.85        |
|    cost_value_loss       | 33.4        |
|    cost_values           | 1.02        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.807       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 62.9        |
|    n_updates             | 1330        |
|    policy_gradient_loss  | -0.00438    |
|    std                   | 0.908       |
|    value_loss            | 99.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.9837828   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 44           |
|    time_elapsed          | 5728         |
|    total_timesteps       | 290816       |
| train/                   |              |
|    approx_kl             | 0.0031391124 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.4          |
|    cost_value_loss       | 17.5         |
|    cost_values           | 0.795        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.4         |
|    n_updates             | 1410         |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 0.978        |
|    value_loss            | 15.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.79        |
| reward                   | -0.6476867  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -706        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 30          |
|    time_elapsed          | 4707        |
|    total_timesteps       | 262144      |
| train/                   |             |
|    approx_kl             | 0.003970231 |
|    clip_fraction         | 0.0259      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.64        |
|    cost_value_loss       | 4.7         |
|    cost_values           | 0.76        |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.74        |
|    n_updates             | 1270        |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 1.02        |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.89        |
| reward                   | -0.2655727  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 39          |
|    time_elapsed          | 5807        |
|    total_timesteps       | 280576      |
| train/                   |             |
|    approx_kl             | 0.006337156 |
|    clip_fraction         | 0.0532      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 1.04        |
|    cost_values           | 0.86        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.831       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.87        |
|    n_updates             | 1360        |
|    policy_gradient_loss  | -0.00831    |
|    std                   | 0.887       |
|    value_loss            | 7.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0582      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0582      |
| reward                   | -0.592717   |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -763        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 29          |
|    time_elapsed          | 4577        |
|    total_timesteps       | 260096      |
| train/                   |             |
|    approx_kl             | 0.007425644 |
|    clip_fraction         | 0.0427      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 159         |
|    cost_values           | 1.56        |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0.00284     |
|    learning_rate         | 0.0003      |
|    loss                  | 33          |
|    n_updates             | 1260        |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 1.04        |
|    value_loss            | 2.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.48         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.48         |
| reward                   | -0.7483965   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -683         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 27           |
|    time_elapsed          | 4250         |
|    total_timesteps       | 256000       |
| train/                   |              |
|    approx_kl             | 0.0033894824 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 4.42         |
|    cost_values           | 0.583        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.42         |
|    n_updates             | 1240         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 1.04         |
|    value_loss            | 9.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.53        |
| reward                   | -0.7833018  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -842        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 37          |
|    time_elapsed          | 5637        |
|    total_timesteps       | 276480      |
| train/                   |             |
|    approx_kl             | 0.010475567 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 58.1        |
|    cost_values           | 1.18        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 5.32e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 32.1        |
|    n_updates             | 1340        |
|    policy_gradient_loss  | -0.0104     |
|    std                   | 0.907       |
|    value_loss            | 8.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.34         |
| reward                   | -1.2909538   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 45           |
|    time_elapsed          | 5880         |
|    total_timesteps       | 292864       |
| train/                   |              |
|    approx_kl             | 0.0053164684 |
|    clip_fraction         | 0.0242       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.35         |
|    cost_value_loss       | 12.6         |
|    cost_values           | 0.921        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 1420         |
|    policy_gradient_loss  | -0.00546     |
|    std                   | 0.976        |
|    value_loss            | 14.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -1.6301534  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -710        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 31          |
|    time_elapsed          | 4864        |
|    total_timesteps       | 264192      |
| train/                   |             |
|    approx_kl             | 0.004457934 |
|    clip_fraction         | 0.0253      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.81        |
|    cost_value_loss       | 7.25        |
|    cost_values           | 0.802       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 1280        |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 1.01        |
|    value_loss            | 24.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.31         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.31         |
| reward                   | -0.5137732   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -759         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 30           |
|    time_elapsed          | 4725         |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0018012959 |
|    clip_fraction         | 0.00225      |
|    clip_range            | 0.2          |
|    cost_returns          | 12.7         |
|    cost_value_loss       | 155          |
|    cost_values           | 2.1          |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.831        |
|    lagrangian_multiplier | 0.000254     |
|    learning_rate         | 0.0003       |
|    loss                  | 67.1         |
|    n_updates             | 1270         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 1.04         |
|    value_loss            | 4.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.5680104  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -990        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 40          |
|    time_elapsed          | 5980        |
|    total_timesteps       | 282624      |
| train/                   |             |
|    approx_kl             | 0.004955711 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 1.45        |
|    cost_values           | 0.745       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.48        |
|    n_updates             | 1370        |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 0.886       |
|    value_loss            | 6.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.226       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.226       |
| reward                   | -0.5386076  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -693        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 28          |
|    time_elapsed          | 4425        |
|    total_timesteps       | 258048      |
| train/                   |             |
|    approx_kl             | 0.006097259 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.45        |
|    cost_value_loss       | 13.7        |
|    cost_values           | 0.752       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.94        |
|    n_updates             | 1250        |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 1.04        |
|    value_loss            | 21.1        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.79       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.79       |
| reward                   | -0.6768407 |
| rollout/                 |            |
|    ep_len_mean           | 962        |
|    ep_rew_mean           | -1.15e+03  |
| time/                    |            |
|    fps                   | 15         |
|    iterations            | 46         |
|    time_elapsed          | 6033       |
|    total_timesteps       | 294912     |
| train/                   |            |
|    approx_kl             | 0.00526722 |
|    clip_fraction         | 0.0316     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.24       |
|    cost_value_loss       | 24.7       |
|    cost_values           | 0.906      |
|    entropy               | -2.79      |
|    entropy_loss          | -2.79      |
|    explained_variance    | 0.919      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 17.1       |
|    n_updates             | 1430       |
|    policy_gradient_loss  | -0.00565   |
|    std                   | 0.975      |
|    value_loss            | 14         |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.248        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.248        |
| reward                   | -0.4390286   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -839         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 38           |
|    time_elapsed          | 5819         |
|    total_timesteps       | 278528       |
| train/                   |              |
|    approx_kl             | 0.0037145114 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.99         |
|    cost_value_loss       | 63.7         |
|    cost_values           | 1.8          |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.872        |
|    lagrangian_multiplier | 0.00898      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.51         |
|    n_updates             | 1350         |
|    policy_gradient_loss  | -0.00396     |
|    std                   | 0.904        |
|    value_loss            | 3.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.91         |
| reward                   | -0.4247      |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 32           |
|    time_elapsed          | 5032         |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0049659754 |
|    clip_fraction         | 0.0398       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 2.84         |
|    cost_values           | 0.824        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 1.02         |
|    value_loss            | 23.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.425        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.425        |
| reward                   | -0.29405347  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -741         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 31           |
|    time_elapsed          | 4873         |
|    total_timesteps       | 264192       |
| train/                   |              |
|    approx_kl             | 0.0010590246 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 11.4         |
|    cost_value_loss       | 139          |
|    cost_values           | 1.73         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0.0319       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.95         |
|    n_updates             | 1280         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 1.04         |
|    value_loss            | 4.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8693724  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -982        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 41          |
|    time_elapsed          | 6156        |
|    total_timesteps       | 284672      |
| train/                   |             |
|    approx_kl             | 0.004796599 |
|    clip_fraction         | 0.0388      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.718       |
|    cost_value_loss       | 1.1         |
|    cost_values           | 0.442       |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.831       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.3        |
|    n_updates             | 1380        |
|    policy_gradient_loss  | -0.00586    |
|    std                   | 0.883       |
|    value_loss            | 38.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.31        |
| reward                   | -1.9075015  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 47          |
|    time_elapsed          | 6187        |
|    total_timesteps       | 296960      |
| train/                   |             |
|    approx_kl             | 0.003068308 |
|    clip_fraction         | 0.0115      |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 23          |
|    cost_values           | 0.872       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50.9        |
|    n_updates             | 1440        |
|    policy_gradient_loss  | -0.00337    |
|    std                   | 0.974       |
|    value_loss            | 88.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.63        |
| reward                   | -0.6610532  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 29          |
|    time_elapsed          | 4602        |
|    total_timesteps       | 260096      |
| train/                   |             |
|    approx_kl             | 0.003397744 |
|    clip_fraction         | 0.0191      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.63        |
|    cost_value_loss       | 15.3        |
|    cost_values           | 0.772       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.00267     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.98        |
|    n_updates             | 1260        |
|    policy_gradient_loss  | -0.00312    |
|    std                   | 1.04        |
|    value_loss            | 3.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.8299334   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -824         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 39           |
|    time_elapsed          | 6004         |
|    total_timesteps       | 280576       |
| train/                   |              |
|    approx_kl             | 0.0047865603 |
|    clip_fraction         | 0.0383       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.16         |
|    cost_value_loss       | 48.2         |
|    cost_values           | 1.53         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0.00287      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 1360         |
|    policy_gradient_loss  | -0.00369     |
|    std                   | 0.902        |
|    value_loss            | 3.81         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0632      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0632      |
| reward                   | -0.31328502 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -731        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 32          |
|    time_elapsed          | 5023        |
|    total_timesteps       | 266240      |
| train/                   |             |
|    approx_kl             | 0.00821621  |
|    clip_fraction         | 0.0353      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 147         |
|    cost_values           | 1.41        |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.0133      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 1290        |
|    policy_gradient_loss  | -0.0077     |
|    std                   | 1.04        |
|    value_loss            | 2.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.7876328   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 33           |
|    time_elapsed          | 5199         |
|    total_timesteps       | 268288       |
| train/                   |              |
|    approx_kl             | 0.0031686602 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.56         |
|    cost_value_loss       | 12           |
|    cost_values           | 0.95         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.801        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 1300         |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 1.02         |
|    value_loss            | 20.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.643       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.643       |
| reward                   | -0.37100923 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -961        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 42          |
|    time_elapsed          | 6333        |
|    total_timesteps       | 286720      |
| train/                   |             |
|    approx_kl             | 0.004633235 |
|    clip_fraction         | 0.0386      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.22        |
|    cost_value_loss       | 1.48        |
|    cost_values           | 0.626       |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.11        |
|    n_updates             | 1390        |
|    policy_gradient_loss  | -0.00532    |
|    std                   | 0.879       |
|    value_loss            | 13.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.50956774 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 15          |
|    iterations            | 48          |
|    time_elapsed          | 6345        |
|    total_timesteps       | 299008      |
| train/                   |             |
|    approx_kl             | 0.006493346 |
|    clip_fraction         | 0.0442      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.86        |
|    cost_value_loss       | 24.3        |
|    cost_values           | 0.9         |
|    entropy               | -2.79       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.3        |
|    n_updates             | 1450        |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 0.974       |
|    value_loss            | 49.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.461        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.461        |
| reward                   | -0.35801926  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 30           |
|    time_elapsed          | 4776         |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0042944197 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 0.785        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0.00191      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 1270         |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 1.04         |
|    value_loss            | 3.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.62         |
| reward                   | -0.6180979   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -811         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 40           |
|    time_elapsed          | 6190         |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0048133302 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.82         |
|    cost_value_loss       | 39.2         |
|    cost_values           | 1.2          |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.907        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.7         |
|    n_updates             | 1370         |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.903        |
|    value_loss            | 10.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.414       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.414       |
| reward                   | -0.5550568  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -713        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 33          |
|    time_elapsed          | 5175        |
|    total_timesteps       | 268288      |
| train/                   |             |
|    approx_kl             | 0.003994339 |
|    clip_fraction         | 0.0316      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.4        |
|    cost_value_loss       | 153         |
|    cost_values           | 1.56        |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.198       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 68.6        |
|    n_updates             | 1300        |
|    policy_gradient_loss  | -0.00452    |
|    std                   | 1.04        |
|    value_loss            | 1.76        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.9413733 |
| rollout/                 |            |
|    ep_len_mean           | 973        |
|    ep_rew_mean           | -708       |
| time/                    |            |
|    fps                   | 12         |
|    iterations            | 34         |
|    time_elapsed          | 5367       |
|    total_timesteps       | 270336     |
| train/                   |            |
|    approx_kl             | 0.00539457 |
|    clip_fraction         | 0.0215     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.21       |
|    cost_value_loss       | 9.34       |
|    cost_values           | 0.972      |
|    entropy               | -2.86      |
|    entropy_loss          | -2.87      |
|    explained_variance    | 0.851      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.76       |
|    n_updates             | 1310       |
|    policy_gradient_loss  | -0.00347   |
|    std                   | 1.01       |
|    value_loss            | 7.79       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 5.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.38         |
| reward                   | -2.0802987   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 15           |
|    iterations            | 49           |
|    time_elapsed          | 6503         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0019398294 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | 4            |
|    cost_value_loss       | 32.6         |
|    cost_values           | 0.961        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.3         |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.974        |
|    value_loss            | 32           |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.3         |
| reward                   | -0.51769024 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -951        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 43          |
|    time_elapsed          | 6514        |
|    total_timesteps       | 288768      |
| train/                   |             |
|    approx_kl             | 0.008834267 |
|    clip_fraction         | 0.0789      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.718       |
|    cost_value_loss       | 0.814       |
|    cost_values           | 0.43        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.25        |
|    n_updates             | 1400        |
|    policy_gradient_loss  | -0.00644    |
|    std                   | 0.878       |
|    value_loss            | 16.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.134       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.134       |
| reward                   | -0.80728203 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -683        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 31          |
|    time_elapsed          | 4954        |
|    total_timesteps       | 264192      |
| train/                   |             |
|    approx_kl             | 0.005919412 |
|    clip_fraction         | 0.0567      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 5.16        |
|    cost_values           | 0.669       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.854       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.15        |
|    n_updates             | 1280        |
|    policy_gradient_loss  | -0.00761    |
|    std                   | 1.04        |
|    value_loss            | 13.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0391      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0391      |
| reward                   | -0.48680627 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -703        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 34          |
|    time_elapsed          | 5328        |
|    total_timesteps       | 270336      |
| train/                   |             |
|    approx_kl             | 0.006522417 |
|    clip_fraction         | 0.0602      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.9         |
|    cost_value_loss       | 39.1        |
|    cost_values           | 2.03        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.91       |
|    explained_variance    | -0.131      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.2        |
|    n_updates             | 1310        |
|    policy_gradient_loss  | -0.00488    |
|    std                   | 1.03        |
|    value_loss            | 2.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.851       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.851       |
| reward                   | -0.7104187  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -800        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 41          |
|    time_elapsed          | 6380        |
|    total_timesteps       | 284672      |
| train/                   |             |
|    approx_kl             | 0.004635663 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 54          |
|    cost_values           | 0.934       |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.794       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 150         |
|    n_updates             | 1380        |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 0.903       |
|    value_loss            | 249         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.39         |
| reward                   | -0.46870995  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 35           |
|    time_elapsed          | 5532         |
|    total_timesteps       | 272384       |
| train/                   |              |
|    approx_kl             | 0.0034441312 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 6.02         |
|    cost_values           | 0.699        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.861        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.1         |
|    n_updates             | 1320         |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 1.01         |
|    value_loss            | 31.7         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/7xavsi5z
-----------------------------------
| avg_speed          | 7.68       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.68       |
| reward             | -1.4074636 |
| rollout/           |            |
|    ep_len_mean     | 961        |
|    ep_rew_mean     | -1.12e+03  |
| time/              |            |
|    fps             | 13         |
|    iterations      | 1          |
|    time_elapsed    | 156        |
|    total_timesteps | 303104     |
-----------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.49005827 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -937        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 44          |
|    time_elapsed          | 6688        |
|    total_timesteps       | 290816      |
| train/                   |             |
|    approx_kl             | 0.00712972  |
|    clip_fraction         | 0.0284      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.998       |
|    cost_value_loss       | 1.16        |
|    cost_values           | 0.583       |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.6         |
|    n_updates             | 1410        |
|    policy_gradient_loss  | -0.00463    |
|    std                   | 0.879       |
|    value_loss            | 16.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.7860028   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 32           |
|    time_elapsed          | 5133         |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0036765842 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.69         |
|    cost_value_loss       | 36           |
|    cost_values           | 1.09         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.677        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.6         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 1.04         |
|    value_loss            | 9.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.836       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.836       |
| reward                   | -0.4583836  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -691        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 35          |
|    time_elapsed          | 5482        |
|    total_timesteps       | 272384      |
| train/                   |             |
|    approx_kl             | 0.004594206 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.06        |
|    cost_value_loss       | 33.4        |
|    cost_values           | 2.03        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | -0.432      |
|    lagrangian_multiplier | 0.00169     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 1320        |
|    policy_gradient_loss  | -0.00457    |
|    std                   | 1.03        |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.297        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.297        |
| reward                   | -0.318476    |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 36           |
|    time_elapsed          | 5696         |
|    total_timesteps       | 274432       |
| train/                   |              |
|    approx_kl             | 0.0057505365 |
|    clip_fraction         | 0.0313       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.78         |
|    cost_value_loss       | 24.1         |
|    cost_values           | 0.773        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.865        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.2         |
|    n_updates             | 1330         |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 1.01         |
|    value_loss            | 32.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.152        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.152        |
| reward                   | -0.17349324  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -798         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 42           |
|    time_elapsed          | 6568         |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0043026344 |
|    clip_fraction         | 0.0265       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.98         |
|    cost_value_loss       | 25.6         |
|    cost_values           | 1.13         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.00496     |
|    std                   | 0.902        |
|    value_loss            | 5.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.9943596   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 2            |
|    time_elapsed          | 317          |
|    total_timesteps       | 305152       |
| train/                   |              |
|    approx_kl             | 0.0059204316 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.38         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 0.918        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.922        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.9         |
|    n_updates             | 1480         |
|    policy_gradient_loss  | -0.0033      |
|    std                   | 0.973        |
|    value_loss            | 31.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.79887205  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -920         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 45           |
|    time_elapsed          | 6864         |
|    total_timesteps       | 292864       |
| train/                   |              |
|    approx_kl             | 0.0061177174 |
|    clip_fraction         | 0.0471       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 1.37         |
|    cost_values           | 0.89         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.669        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.49         |
|    n_updates             | 1420         |
|    policy_gradient_loss  | -0.00397     |
|    std                   | 0.879        |
|    value_loss            | 15           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.465        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.465        |
| reward                   | -0.47479388  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -675         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 36           |
|    time_elapsed          | 5635         |
|    total_timesteps       | 274432       |
| train/                   |              |
|    approx_kl             | 0.0046561565 |
|    clip_fraction         | 0.0624       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.03         |
|    cost_value_loss       | 9.96         |
|    cost_values           | 2.21         |
|    entropy               | -2.89        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.481        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 1330         |
|    policy_gradient_loss  | -0.0051      |
|    std                   | 1.03         |
|    value_loss            | 0.714        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.5055691  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -675        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 33          |
|    time_elapsed          | 5314        |
|    total_timesteps       | 268288      |
| train/                   |             |
|    approx_kl             | 0.005279675 |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 0.744       |
|    cost_values           | 0.887       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.869       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.22        |
|    n_updates             | 1300        |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 1.04        |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.337        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.337        |
| reward                   | -0.34084496  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -699         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 37           |
|    time_elapsed          | 5867         |
|    total_timesteps       | 276480       |
| train/                   |              |
|    approx_kl             | 0.0048439503 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 5.16         |
|    cost_values           | 0.701        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.746        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.7         |
|    n_updates             | 1340         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 1.01         |
|    value_loss            | 69.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -0.4265603   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 3            |
|    time_elapsed          | 479          |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0066960203 |
|    clip_fraction         | 0.0527       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.75         |
|    cost_value_loss       | 19.7         |
|    cost_values           | 0.847        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.8         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00585     |
|    std                   | 0.974        |
|    value_loss            | 41.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.35553625  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -786         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 43           |
|    time_elapsed          | 6756         |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0054076803 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.06         |
|    cost_value_loss       | 81.6         |
|    cost_values           | 1.22         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.914        |
|    lagrangian_multiplier | 0.00694      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.904        |
|    value_loss            | 31           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.273        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.273        |
| reward                   | -0.47315392  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -662         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 37           |
|    time_elapsed          | 5790         |
|    total_timesteps       | 276480       |
| train/                   |              |
|    approx_kl             | 0.0021185307 |
|    clip_fraction         | 0.00518      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.88         |
|    cost_value_loss       | 95.1         |
|    cost_values           | 2.64         |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.839        |
|    lagrangian_multiplier | 0.00113      |
|    learning_rate         | 0.0003       |
|    loss                  | 32.2         |
|    n_updates             | 1340         |
|    policy_gradient_loss  | -0.000464    |
|    std                   | 1.03         |
|    value_loss            | 1.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.55441594  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -915         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 46           |
|    time_elapsed          | 7042         |
|    total_timesteps       | 294912       |
| train/                   |              |
|    approx_kl             | 0.0074166134 |
|    clip_fraction         | 0.0587       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 1.43         |
|    cost_values           | 0.886        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.805        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.41         |
|    n_updates             | 1430         |
|    policy_gradient_loss  | -0.00836     |
|    std                   | 0.878        |
|    value_loss            | 8.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.61        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.61        |
| reward                   | -0.9022478  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -675        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 34          |
|    time_elapsed          | 5496        |
|    total_timesteps       | 270336      |
| train/                   |             |
|    approx_kl             | 0.004592304 |
|    clip_fraction         | 0.0421      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.14        |
|    cost_value_loss       | 3.07        |
|    cost_values           | 0.688       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.849       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.56        |
|    n_updates             | 1310        |
|    policy_gradient_loss  | -0.00544    |
|    std                   | 1.03        |
|    value_loss            | 7.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.63        |
| reward                   | -0.28254756 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -695        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 38          |
|    time_elapsed          | 6040        |
|    total_timesteps       | 278528      |
| train/                   |             |
|    approx_kl             | 0.007575752 |
|    clip_fraction         | 0.0662      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 8.49        |
|    cost_values           | 0.692       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.847       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.21        |
|    n_updates             | 1350        |
|    policy_gradient_loss  | -0.00881    |
|    std                   | 1.01        |
|    value_loss            | 13.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.55347824  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 4            |
|    time_elapsed          | 642          |
|    total_timesteps       | 309248       |
| train/                   |              |
|    approx_kl             | 0.0027445825 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.75         |
|    cost_value_loss       | 31.4         |
|    cost_values           | 0.982        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.899        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.9         |
|    n_updates             | 1500         |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.974        |
|    value_loss            | 10.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.79401284  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 44           |
|    time_elapsed          | 6947         |
|    total_timesteps       | 290816       |
| train/                   |              |
|    approx_kl             | 0.0049176784 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.92         |
|    cost_value_loss       | 74           |
|    cost_values           | 1.51         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.902        |
|    lagrangian_multiplier | 0.00668      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 1410         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.905        |
|    value_loss            | 7.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.186        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.186        |
| reward                   | -0.72165877  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -657         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 38           |
|    time_elapsed          | 5946         |
|    total_timesteps       | 278528       |
| train/                   |              |
|    approx_kl             | 0.0069671078 |
|    clip_fraction         | 0.0473       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.6         |
|    cost_value_loss       | 134          |
|    cost_values           | 2.98         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0.0148       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 1350         |
|    policy_gradient_loss  | -0.00421     |
|    std                   | 1.02         |
|    value_loss            | 0.989        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.63381636 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -902        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 47          |
|    time_elapsed          | 7227        |
|    total_timesteps       | 296960      |
| train/                   |             |
|    approx_kl             | 0.006602577 |
|    clip_fraction         | 0.045       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.801       |
|    cost_value_loss       | 1.09        |
|    cost_values           | 0.565       |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.5        |
|    n_updates             | 1440        |
|    policy_gradient_loss  | -0.00627    |
|    std                   | 0.876       |
|    value_loss            | 32.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.62        |
| reward                   | -0.48532727 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -677        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 35          |
|    time_elapsed          | 5679        |
|    total_timesteps       | 272384      |
| train/                   |             |
|    approx_kl             | 0.0061472   |
|    clip_fraction         | 0.0406      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.35        |
|    cost_value_loss       | 4.94        |
|    cost_values           | 0.729       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.842       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.67        |
|    n_updates             | 1320        |
|    policy_gradient_loss  | -0.00727    |
|    std                   | 1.03        |
|    value_loss            | 12          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.943        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.943        |
| reward                   | -0.26593816  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 39           |
|    time_elapsed          | 6216         |
|    total_timesteps       | 280576       |
| train/                   |              |
|    approx_kl             | 0.0055520628 |
|    clip_fraction         | 0.043        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 17.9         |
|    cost_values           | 0.795        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.775        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 1360         |
|    policy_gradient_loss  | -0.00546     |
|    std                   | 1.01         |
|    value_loss            | 11.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0376       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0376       |
| reward                   | -0.3984126   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 5            |
|    time_elapsed          | 805          |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0011158471 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.36         |
|    cost_value_loss       | 26.9         |
|    cost_values           | 0.972        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.934        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20           |
|    n_updates             | 1510         |
|    policy_gradient_loss  | 0.000231     |
|    std                   | 0.975        |
|    value_loss            | 13.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.222        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.222        |
| reward                   | -0.24753892  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -650         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 39           |
|    time_elapsed          | 6105         |
|    total_timesteps       | 280576       |
| train/                   |              |
|    approx_kl             | 0.0020645577 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 18.3         |
|    cost_value_loss       | 242          |
|    cost_values           | 3            |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.589        |
|    lagrangian_multiplier | 0.0455       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.9          |
|    n_updates             | 1360         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 1.02         |
|    value_loss            | 3.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.896        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.896        |
| reward                   | -0.2107101   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -766         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 45           |
|    time_elapsed          | 7139         |
|    total_timesteps       | 292864       |
| train/                   |              |
|    approx_kl             | 0.0033355707 |
|    clip_fraction         | 0.00967      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.72         |
|    cost_value_loss       | 48.2         |
|    cost_values           | 1.22         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.805        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 109          |
|    n_updates             | 1420         |
|    policy_gradient_loss  | -0.000932    |
|    std                   | 0.904        |
|    value_loss            | 177          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5029684  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -893        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 48          |
|    time_elapsed          | 7413        |
|    total_timesteps       | 299008      |
| train/                   |             |
|    approx_kl             | 0.007006734 |
|    clip_fraction         | 0.0424      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 1.03        |
|    cost_values           | 0.889       |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.797       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 1450        |
|    policy_gradient_loss  | -0.00653    |
|    std                   | 0.875       |
|    value_loss            | 8.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.59        |
| reward                   | -0.33159795 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -678        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 36          |
|    time_elapsed          | 5862        |
|    total_timesteps       | 274432      |
| train/                   |             |
|    approx_kl             | 0.004953691 |
|    clip_fraction         | 0.0382      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.83        |
|    cost_value_loss       | 7.91        |
|    cost_values           | 0.766       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.01        |
|    n_updates             | 1330        |
|    policy_gradient_loss  | -0.00461    |
|    std                   | 1.03        |
|    value_loss            | 7           |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.469        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.469        |
| reward                   | -0.47296625  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 6            |
|    time_elapsed          | 968          |
|    total_timesteps       | 313344       |
| train/                   |              |
|    approx_kl             | 0.0020213905 |
|    clip_fraction         | 0.002        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.97         |
|    cost_value_loss       | 39           |
|    cost_values           | 0.904        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.948        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.5         |
|    n_updates             | 1520         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.976        |
|    value_loss            | 21.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.965        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.965        |
| reward                   | -0.5565171   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 40           |
|    time_elapsed          | 6385         |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0038213977 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 3.91         |
|    cost_values           | 0.598        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.6         |
|    n_updates             | 1370         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 1            |
|    value_loss            | 50.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.344        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.344        |
| reward                   | -0.4492091   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -641         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 40           |
|    time_elapsed          | 6263         |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0014019135 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 12.8         |
|    cost_value_loss       | 132          |
|    cost_values           | 3            |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.807        |
|    lagrangian_multiplier | 0.0121       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 1370         |
|    policy_gradient_loss  | -0.000901    |
|    std                   | 1.02         |
|    value_loss            | 4.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.018        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.018        |
| reward                   | -0.50237894  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 46           |
|    time_elapsed          | 7332         |
|    total_timesteps       | 294912       |
| train/                   |              |
|    approx_kl             | 0.0028202315 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.58         |
|    cost_value_loss       | 86.5         |
|    cost_values           | 1.11         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0.0204       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.98         |
|    n_updates             | 1430         |
|    policy_gradient_loss  | -0.00353     |
|    std                   | 0.906        |
|    value_loss            | 94.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.71112    |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -882        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 49          |
|    time_elapsed          | 7598        |
|    total_timesteps       | 301056      |
| train/                   |             |
|    approx_kl             | 0.002528002 |
|    clip_fraction         | 0.0107      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.961       |
|    cost_value_loss       | 1.16        |
|    cost_values           | 0.653       |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.98        |
|    n_updates             | 1460        |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.875       |
|    value_loss            | 17.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.65         |
| reward                   | -0.6329527   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 7            |
|    time_elapsed          | 1133         |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0043526064 |
|    clip_fraction         | 0.0265       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.87         |
|    cost_value_loss       | 16.6         |
|    cost_values           | 0.955        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.895        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.4         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 0.974        |
|    value_loss            | 14.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.56854457  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -675         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 37           |
|    time_elapsed          | 6048         |
|    total_timesteps       | 276480       |
| train/                   |              |
|    approx_kl             | 0.0053725885 |
|    clip_fraction         | 0.0429       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.42         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 0.853        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.838        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.5         |
|    n_updates             | 1340         |
|    policy_gradient_loss  | -0.00638     |
|    std                   | 1.03         |
|    value_loss            | 30.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.35         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.35         |
| reward                   | -0.36076757  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 41           |
|    time_elapsed          | 6560         |
|    total_timesteps       | 284672       |
| train/                   |              |
|    approx_kl             | 0.0060588066 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 6.96         |
|    cost_values           | 0.687        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.887        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 1380         |
|    policy_gradient_loss  | -0.00485     |
|    std                   | 1            |
|    value_loss            | 19.3         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.104      |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 0.104      |
| reward                   | -0.5242874 |
| rollout/                 |            |
|    ep_len_mean           | 987        |
|    ep_rew_mean           | -630       |
| time/                    |            |
|    fps                   | 13         |
|    iterations            | 41         |
|    time_elapsed          | 6424       |
|    total_timesteps       | 284672     |
| train/                   |            |
|    approx_kl             | 0.0088575  |
|    clip_fraction         | 0.054      |
|    clip_range            | 0.2        |
|    cost_returns          | 12         |
|    cost_value_loss       | 127        |
|    cost_values           | 2.96       |
|    entropy               | -2.88      |
|    entropy_loss          | -2.88      |
|    explained_variance    | 0.427      |
|    lagrangian_multiplier | 0.0154     |
|    learning_rate         | 0.0003     |
|    loss                  | 10.1       |
|    n_updates             | 1380       |
|    policy_gradient_loss  | -0.00543   |
|    std                   | 1.02       |
|    value_loss            | 3.07       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.644        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.644        |
| reward                   | -0.519651    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -736         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 47           |
|    time_elapsed          | 7528         |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0053246715 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.25         |
|    cost_value_loss       | 39.3         |
|    cost_values           | 1.42         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.842        |
|    lagrangian_multiplier | 0.00191      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.00604     |
|    std                   | 0.908        |
|    value_loss            | 14.7         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/pe6a45mq
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.9406772 |
| rollout/           |            |
|    ep_len_mean     | 973        |
|    ep_rew_mean     | -873       |
| time/              |            |
|    fps             | 11         |
|    iterations      | 1          |
|    time_elapsed    | 182        |
|    total_timesteps | 303104     |
-----------------------------------
-------------------------------------------
| avg_speed                | 2.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.5          |
| reward                   | -0.47664174  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 8            |
|    time_elapsed          | 1300         |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0051060542 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 12.5         |
|    cost_values           | 0.894        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.953        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.00476     |
|    std                   | 0.97         |
|    value_loss            | 13.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -0.71876097  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 38           |
|    time_elapsed          | 6237         |
|    total_timesteps       | 278528       |
| train/                   |              |
|    approx_kl             | 0.0050248294 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.17         |
|    cost_value_loss       | 17           |
|    cost_values           | 1.08         |
|    entropy               | -2.89        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.665        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.02         |
|    n_updates             | 1350         |
|    policy_gradient_loss  | -0.00531     |
|    std                   | 1.03         |
|    value_loss            | 3.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.51         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.51         |
| reward                   | -0.49079126  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 42           |
|    time_elapsed          | 6738         |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0064863763 |
|    clip_fraction         | 0.0599       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.06         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 0.714        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.884        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.9         |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.00678     |
|    std                   | 1            |
|    value_loss            | 35.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.3733701   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -618         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 42           |
|    time_elapsed          | 6585         |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0076596383 |
|    clip_fraction         | 0.0369       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.8         |
|    cost_value_loss       | 134          |
|    cost_values           | 2.92         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.869        |
|    lagrangian_multiplier | 0.0169       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.93         |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.00393     |
|    std                   | 1.02         |
|    value_loss            | 1.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0305       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0305       |
| reward                   | -0.35854757  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -729         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 48           |
|    time_elapsed          | 7723         |
|    total_timesteps       | 299008       |
| train/                   |              |
|    approx_kl             | 0.0057490068 |
|    clip_fraction         | 0.0624       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.41         |
|    cost_value_loss       | 61.1         |
|    cost_values           | 1.5          |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0.0103       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.68         |
|    n_updates             | 1450         |
|    policy_gradient_loss  | -0.008       |
|    std                   | 0.907        |
|    value_loss            | 5.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.39         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.39         |
| reward                   | -0.5773287   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 9            |
|    time_elapsed          | 1470         |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0067992797 |
|    clip_fraction         | 0.0411       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.11         |
|    cost_value_loss       | 18.5         |
|    cost_values           | 0.991        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.929        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 1550         |
|    policy_gradient_loss  | -0.00367     |
|    std                   | 0.968        |
|    value_loss            | 10.4         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.8613475 |
| rollout/                 |            |
|    ep_len_mean           | 964        |
|    ep_rew_mean           | -852       |
| time/                    |            |
|    fps                   | 11         |
|    iterations            | 2          |
|    time_elapsed          | 368        |
|    total_timesteps       | 305152     |
| train/                   |            |
|    approx_kl             | 0.00795349 |
|    clip_fraction         | 0.0273     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.694      |
|    cost_value_loss       | 0.267      |
|    cost_values           | 0.663      |
|    entropy               | -2.57      |
|    entropy_loss          | -2.57      |
|    explained_variance    | 0.883      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 5.66       |
|    n_updates             | 1480       |
|    policy_gradient_loss  | -0.00639   |
|    std                   | 0.875      |
|    value_loss            | 11.7       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.173        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.173        |
| reward                   | -0.31518573  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -605         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 43           |
|    time_elapsed          | 6749         |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0051439237 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.47         |
|    cost_value_loss       | 103          |
|    cost_values           | 2.68         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.789        |
|    lagrangian_multiplier | 0.00671      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 1.02         |
|    value_loss            | 2.81         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.56        |
| reward                   | -0.26167637 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -707        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 43          |
|    time_elapsed          | 6913        |
|    total_timesteps       | 288768      |
| train/                   |             |
|    approx_kl             | 0.004385284 |
|    clip_fraction         | 0.0393      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 4.25        |
|    cost_values           | 0.848       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7           |
|    n_updates             | 1400        |
|    policy_gradient_loss  | -0.00498    |
|    std                   | 0.997       |
|    value_loss            | 9.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7860955   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 39           |
|    time_elapsed          | 6425         |
|    total_timesteps       | 280576       |
| train/                   |              |
|    approx_kl             | 0.0048778197 |
|    clip_fraction         | 0.0595       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 1.88         |
|    cost_values           | 1.06         |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.32         |
|    n_updates             | 1360         |
|    policy_gradient_loss  | -0.00506     |
|    std                   | 1.03         |
|    value_loss            | 4.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.166        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.166        |
| reward                   | -0.54175025  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 10           |
|    time_elapsed          | 1639         |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0039496706 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 5.1          |
|    cost_values           | 0.96         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.93         |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.964        |
|    value_loss            | 11.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0256       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0256       |
| reward                   | -0.48154294  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 49           |
|    time_elapsed          | 7922         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0043738307 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.95         |
|    cost_value_loss       | 45.2         |
|    cost_values           | 1.87         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.877        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 0.905        |
|    value_loss            | 0.726        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.74295896 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -843        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 3           |
|    time_elapsed          | 557         |
|    total_timesteps       | 307200      |
| train/                   |             |
|    approx_kl             | 0.010468023 |
|    clip_fraction         | 0.0325      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.996       |
|    cost_value_loss       | 0.865       |
|    cost_values           | 0.849       |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.539       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.3        |
|    n_updates             | 1490        |
|    policy_gradient_loss  | -0.00684    |
|    std                   | 0.875       |
|    value_loss            | 18.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.251        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.251        |
| reward                   | -0.34441337  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -591         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 44           |
|    time_elapsed          | 6914         |
|    total_timesteps       | 290816       |
| train/                   |              |
|    approx_kl             | 0.0047278823 |
|    clip_fraction         | 0.014        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.57         |
|    cost_value_loss       | 70.2         |
|    cost_values           | 2.56         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.925        |
|    lagrangian_multiplier | 0.0116       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.07         |
|    n_updates             | 1410         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 1.02         |
|    value_loss            | 2.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.96554404  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 44           |
|    time_elapsed          | 7088         |
|    total_timesteps       | 290816       |
| train/                   |              |
|    approx_kl             | 0.0043867663 |
|    clip_fraction         | 0.0348       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.47         |
|    cost_value_loss       | 28           |
|    cost_values           | 0.903        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 1410         |
|    policy_gradient_loss  | -0.00554     |
|    std                   | 0.995        |
|    value_loss            | 4.96         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -1.0916418  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -661        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 40          |
|    time_elapsed          | 6611        |
|    total_timesteps       | 282624      |
| train/                   |             |
|    approx_kl             | 0.006740818 |
|    clip_fraction         | 0.0545      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 17          |
|    cost_values           | 0.978       |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0.00116     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.51        |
|    n_updates             | 1370        |
|    policy_gradient_loss  | -0.00836    |
|    std                   | 1.02        |
|    value_loss            | 5.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.11        |
| reward                   | -0.49721158 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 11          |
|    time_elapsed          | 1808        |
|    total_timesteps       | 323584      |
| train/                   |             |
|    approx_kl             | 0.007052681 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 1           |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.813       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 1570        |
|    policy_gradient_loss  | -0.00459    |
|    std                   | 0.96        |
|    value_loss            | 7.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.562       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.562       |
| reward                   | -0.5483583  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -587        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 45          |
|    time_elapsed          | 7075        |
|    total_timesteps       | 292864      |
| train/                   |             |
|    approx_kl             | 0.004410628 |
|    clip_fraction         | 0.02        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 113         |
|    cost_values           | 2.9         |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0.0167      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.96        |
|    n_updates             | 1420        |
|    policy_gradient_loss  | -0.00307    |
|    std                   | 1.01        |
|    value_loss            | 1.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -0.89845103  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -705         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 45           |
|    time_elapsed          | 7264         |
|    total_timesteps       | 292864       |
| train/                   |              |
|    approx_kl             | 0.0071393894 |
|    clip_fraction         | 0.0525       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.32         |
|    cost_value_loss       | 6.14         |
|    cost_values           | 1.29         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.857        |
|    lagrangian_multiplier | 0.00058      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.99         |
|    n_updates             | 1420         |
|    policy_gradient_loss  | -0.0073      |
|    std                   | 0.996        |
|    value_loss            | 4.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.7938702  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -832        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 4           |
|    time_elapsed          | 748         |
|    total_timesteps       | 309248      |
| train/                   |             |
|    approx_kl             | 0.002789989 |
|    clip_fraction         | 0.00361     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 1.65        |
|    cost_values           | 0.738       |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.745       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.37        |
|    n_updates             | 1500        |
|    policy_gradient_loss  | -0.00122    |
|    std                   | 0.875       |
|    value_loss            | 10.2        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/4ts77xgw
-----------------------------------
| avg_speed          | 0.39       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.39       |
| reward             | -0.4072058 |
| rollout/           |            |
|    ep_len_mean     | 980        |
|    ep_rew_mean     | -714       |
| time/              |            |
|    fps             | 10         |
|    iterations      | 1          |
|    time_elapsed    | 198        |
|    total_timesteps | 303104     |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -0.4509572   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 41           |
|    time_elapsed          | 6802         |
|    total_timesteps       | 284672       |
| train/                   |              |
|    approx_kl             | 0.0062966812 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 18.4         |
|    cost_values           | 1.1          |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0.00204      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.49         |
|    n_updates             | 1380         |
|    policy_gradient_loss  | -0.00415     |
|    std                   | 1.02         |
|    value_loss            | 8.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0906       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0906       |
| reward                   | -0.46661428  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 12           |
|    time_elapsed          | 1980         |
|    total_timesteps       | 325632       |
| train/                   |              |
|    approx_kl             | 0.0057221237 |
|    clip_fraction         | 0.04         |
|    clip_range            | 0.2          |
|    cost_returns          | 5.32         |
|    cost_value_loss       | 39.4         |
|    cost_values           | 1.09         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.715        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.1         |
|    n_updates             | 1580         |
|    policy_gradient_loss  | -0.00554     |
|    std                   | 0.96         |
|    value_loss            | 19.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.307       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.307       |
| reward                   | -0.41137552 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -576        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 46          |
|    time_elapsed          | 7241        |
|    total_timesteps       | 294912      |
| train/                   |             |
|    approx_kl             | 0.002565969 |
|    clip_fraction         | 0.0322      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.97        |
|    cost_value_loss       | 2.63        |
|    cost_values           | 2.83        |
|    entropy               | -2.87       |
|    entropy_loss          | -2.86       |
|    explained_variance    | -16.2       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.76        |
|    n_updates             | 1430        |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 1.01        |
|    value_loss            | 1.93        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.76373506  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 46           |
|    time_elapsed          | 7443         |
|    total_timesteps       | 294912       |
| train/                   |              |
|    approx_kl             | 0.0060204924 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 7.03         |
|    cost_values           | 0.922        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.884        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.2         |
|    n_updates             | 1430         |
|    policy_gradient_loss  | -0.00583     |
|    std                   | 1            |
|    value_loss            | 34.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5827852  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -828        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 5           |
|    time_elapsed          | 940         |
|    total_timesteps       | 311296      |
| train/                   |             |
|    approx_kl             | 0.005379234 |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 1.3         |
|    cost_values           | 0.869       |
|    entropy               | -2.56       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.735       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.67        |
|    n_updates             | 1510        |
|    policy_gradient_loss  | -0.00456    |
|    std                   | 0.872       |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.139       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.139       |
| reward                   | -0.47754136 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -706        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 2           |
|    time_elapsed          | 397         |
|    total_timesteps       | 305152      |
| train/                   |             |
|    approx_kl             | 0.001479157 |
|    clip_fraction         | 0.00117     |
|    clip_range            | 0.2         |
|    cost_returns          | 8.68        |
|    cost_value_loss       | 79.5        |
|    cost_values           | 2.13        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.831       |
|    lagrangian_multiplier | 0.0594      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.36        |
|    n_updates             | 1480        |
|    policy_gradient_loss  | -0.000992   |
|    std                   | 0.91        |
|    value_loss            | 15.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.67454845 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -660        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 42          |
|    time_elapsed          | 6994        |
|    total_timesteps       | 286720      |
| train/                   |             |
|    approx_kl             | 0.005706327 |
|    clip_fraction         | 0.0473      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.94        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 0.832       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0.000153    |
|    learning_rate         | 0.0003      |
|    loss                  | 18.8        |
|    n_updates             | 1390        |
|    policy_gradient_loss  | -0.00539    |
|    std                   | 1.02        |
|    value_loss            | 32          |
------------------------------------------
------------------------------------------
| avg_speed                | 0.169       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.169       |
| reward                   | -0.4197835  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -980        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 13          |
|    time_elapsed          | 2154        |
|    total_timesteps       | 327680      |
| train/                   |             |
|    approx_kl             | 0.005445138 |
|    clip_fraction         | 0.0541      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.44        |
|    cost_value_loss       | 40.6        |
|    cost_values           | 1.4         |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.79        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.3        |
|    n_updates             | 1590        |
|    policy_gradient_loss  | -0.00661    |
|    std                   | 0.959       |
|    value_loss            | 5.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.226       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.226       |
| reward                   | -0.55165964 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -569        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 47          |
|    time_elapsed          | 7410        |
|    total_timesteps       | 296960      |
| train/                   |             |
|    approx_kl             | 0.005374152 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.3         |
|    cost_value_loss       | 34.4        |
|    cost_values           | 2.89        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0.00609     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.14        |
|    n_updates             | 1440        |
|    policy_gradient_loss  | 0.00189     |
|    std                   | 1.01        |
|    value_loss            | 1.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.9556317   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 47           |
|    time_elapsed          | 7625         |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0060250573 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 4.05         |
|    cost_values           | 1.09         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.813        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.43         |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.00424     |
|    std                   | 1            |
|    value_loss            | 8.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.7845901   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -821         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 6            |
|    time_elapsed          | 1131         |
|    total_timesteps       | 313344       |
| train/                   |              |
|    approx_kl             | 0.0069923615 |
|    clip_fraction         | 0.0568       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 0.926        |
|    cost_values           | 0.908        |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.514        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.06         |
|    n_updates             | 1520         |
|    policy_gradient_loss  | -0.00607     |
|    std                   | 0.87         |
|    value_loss            | 5.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.333        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.333        |
| reward                   | -0.58915293  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -698         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 3            |
|    time_elapsed          | 599          |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0038283458 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.76         |
|    cost_value_loss       | 86.2         |
|    cost_values           | 1.82         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.876        |
|    lagrangian_multiplier | 0.0128       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.93         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.909        |
|    value_loss            | 2.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.49         |
| reward                   | -0.6545588   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -657         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 43           |
|    time_elapsed          | 7189         |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0052558016 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.58         |
|    cost_value_loss       | 39.1         |
|    cost_values           | 1.15         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.898        |
|    lagrangian_multiplier | 0.00419      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.32         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 1.02         |
|    value_loss            | 6.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.215       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.215       |
| reward                   | -0.3667955  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -559        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 48          |
|    time_elapsed          | 7580        |
|    total_timesteps       | 299008      |
| train/                   |             |
|    approx_kl             | 0.010873123 |
|    clip_fraction         | 0.0681      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 33.4        |
|    cost_values           | 2.91        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.00384     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.56        |
|    n_updates             | 1450        |
|    policy_gradient_loss  | -0.00602    |
|    std                   | 1.01        |
|    value_loss            | 0.883       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.703       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.703       |
| reward                   | -0.31883174 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -967        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 14          |
|    time_elapsed          | 2329        |
|    total_timesteps       | 329728      |
| train/                   |             |
|    approx_kl             | 0.008635394 |
|    clip_fraction         | 0.0434      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 9.7         |
|    cost_values           | 1.62        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.789       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.02        |
|    n_updates             | 1600        |
|    policy_gradient_loss  | -0.00438    |
|    std                   | 0.956       |
|    value_loss            | 5.02        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.13         |
| reward                   | -0.4947917   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 48           |
|    time_elapsed          | 7808         |
|    total_timesteps       | 299008       |
| train/                   |              |
|    approx_kl             | 0.0036787682 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 5.16         |
|    cost_values           | 0.789        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.853        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.4         |
|    n_updates             | 1450         |
|    policy_gradient_loss  | -0.000518    |
|    std                   | 1            |
|    value_loss            | 45.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.81674826 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -811        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 7           |
|    time_elapsed          | 1328        |
|    total_timesteps       | 315392      |
| train/                   |             |
|    approx_kl             | 0.004743981 |
|    clip_fraction         | 0.0587      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 1.15        |
|    cost_values           | 0.867       |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.18        |
|    n_updates             | 1530        |
|    policy_gradient_loss  | -0.00677    |
|    std                   | 0.871       |
|    value_loss            | 5.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.323       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.323       |
| reward                   | -0.37613106 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -686        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 4           |
|    time_elapsed          | 801         |
|    total_timesteps       | 309248      |
| train/                   |             |
|    approx_kl             | 0.004116673 |
|    clip_fraction         | 0.0464      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 118         |
|    cost_values           | 2.12        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.446       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 56          |
|    n_updates             | 1500        |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 0.908       |
|    value_loss            | 0.658       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -0.5383988   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -657         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 44           |
|    time_elapsed          | 7380         |
|    total_timesteps       | 290816       |
| train/                   |              |
|    approx_kl             | 0.0034276543 |
|    clip_fraction         | 0.0392       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 0.728        |
|    cost_values           | 0.873        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.886        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.72         |
|    n_updates             | 1410         |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 1.02         |
|    value_loss            | 5.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.005        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.005        |
| reward                   | -0.46801442  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -558         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 49           |
|    time_elapsed          | 7750         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0020286413 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.17         |
|    cost_value_loss       | 55.1         |
|    cost_values           | 2.95         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.305        |
|    lagrangian_multiplier | 0.00866      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.7          |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 1.01         |
|    value_loss            | 2.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0122      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0122      |
| reward                   | -0.32058102 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -954        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 15          |
|    time_elapsed          | 2504        |
|    total_timesteps       | 331776      |
| train/                   |             |
|    approx_kl             | 0.006952957 |
|    clip_fraction         | 0.0489      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.86        |
|    cost_value_loss       | 42.1        |
|    cost_values           | 1.92        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.759       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.6        |
|    n_updates             | 1610        |
|    policy_gradient_loss  | -0.00321    |
|    std                   | 0.952       |
|    value_loss            | 3.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.51        |
| reward                   | -0.5766518  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -703        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 49          |
|    time_elapsed          | 7994        |
|    total_timesteps       | 301056      |
| train/                   |             |
|    approx_kl             | 0.005778432 |
|    clip_fraction         | 0.046       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 0.717       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12          |
|    n_updates             | 1460        |
|    policy_gradient_loss  | -0.00759    |
|    std                   | 1           |
|    value_loss            | 13.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.96410084 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -799        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 8           |
|    time_elapsed          | 1528        |
|    total_timesteps       | 317440      |
| train/                   |             |
|    approx_kl             | 0.009185635 |
|    clip_fraction         | 0.098       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.73        |
|    cost_value_loss       | 2.24        |
|    cost_values           | 0.942       |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.523       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.5        |
|    n_updates             | 1540        |
|    policy_gradient_loss  | -0.00948    |
|    std                   | 0.871       |
|    value_loss            | 19.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.191        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.191        |
| reward                   | -0.62213     |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 5            |
|    time_elapsed          | 1005         |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0037556128 |
|    clip_fraction         | 0.00879      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 108          |
|    cost_values           | 2.73         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.953        |
|    lagrangian_multiplier | 0.0137       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.71         |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.9          |
|    value_loss            | 0.982        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.913       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.913       |
| reward                   | -0.42904934 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -653        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 45          |
|    time_elapsed          | 7576        |
|    total_timesteps       | 292864      |
| train/                   |             |
|    approx_kl             | 0.00669408  |
|    clip_fraction         | 0.0692      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.58        |
|    cost_value_loss       | 5.18        |
|    cost_values           | 0.927       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.415       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.7         |
|    n_updates             | 1420        |
|    policy_gradient_loss  | -0.00816    |
|    std                   | 1.01        |
|    value_loss            | 6.17        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/uhktx3ql
------------------------------------
| avg_speed          | 0.129       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.129       |
| reward             | -0.37036768 |
| rollout/           |             |
|    ep_len_mean     | 999         |
|    ep_rew_mean     | -553        |
| time/              |             |
|    fps             | 12          |
|    iterations      | 1           |
|    time_elapsed    | 166         |
|    total_timesteps | 303104      |
------------------------------------
------------------------------------------
| avg_speed                | 0.0416      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0416      |
| reward                   | -0.6644302  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -935        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 16          |
|    time_elapsed          | 2682        |
|    total_timesteps       | 333824      |
| train/                   |             |
|    approx_kl             | 0.004297127 |
|    clip_fraction         | 0.0235      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.01        |
|    cost_value_loss       | 11          |
|    cost_values           | 2.14        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.99        |
|    n_updates             | 1620        |
|    policy_gradient_loss  | -0.00204    |
|    std                   | 0.955       |
|    value_loss            | 7.22        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/mtgakx2v
------------------------------------
| avg_speed          | 8.01        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.01        |
| reward             | -0.35377178 |
| rollout/           |             |
|    ep_len_mean     | 979         |
|    ep_rew_mean     | -699        |
| time/              |             |
|    fps             | 10          |
|    iterations      | 1           |
|    time_elapsed    | 187         |
|    total_timesteps | 303104      |
------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.91590726  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -796         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 9            |
|    time_elapsed          | 1722         |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0048603616 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 1.33         |
|    cost_values           | 0.951        |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.617        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.67         |
|    n_updates             | 1550         |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 0.87         |
|    value_loss            | 6.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.112       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.112       |
| reward                   | -0.56904227 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -548        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 2           |
|    time_elapsed          | 338         |
|    total_timesteps       | 305152      |
| train/                   |             |
|    approx_kl             | 0.008076421 |
|    clip_fraction         | 0.0564      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.03        |
|    cost_value_loss       | 0.0875      |
|    cost_values           | 2.2         |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -0.702      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.327       |
|    n_updates             | 1480        |
|    policy_gradient_loss  | -0.00443    |
|    std                   | 1.01        |
|    value_loss            | 0.914       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.72        |
| reward                   | -0.6884855  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -652        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 46          |
|    time_elapsed          | 7772        |
|    total_timesteps       | 294912      |
| train/                   |             |
|    approx_kl             | 0.004106075 |
|    clip_fraction         | 0.0214      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.14        |
|    cost_value_loss       | 62.1        |
|    cost_values           | 1.21        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | -0.747      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.4        |
|    n_updates             | 1430        |
|    policy_gradient_loss  | -0.00403    |
|    std                   | 1.01        |
|    value_loss            | 2.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.63         |
| reward                   | -1.5152302   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -910         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 17           |
|    time_elapsed          | 2859         |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0024807293 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.57         |
|    cost_value_loss       | 39.5         |
|    cost_values           | 2.01         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.344        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.5         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.000694    |
|    std                   | 0.954        |
|    value_loss            | 10.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.161       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.161       |
| reward                   | -0.42347768 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -675        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 6           |
|    time_elapsed          | 1208        |
|    total_timesteps       | 313344      |
| train/                   |             |
|    approx_kl             | 0.007283011 |
|    clip_fraction         | 0.0816      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.7         |
|    cost_value_loss       | 79.6        |
|    cost_values           | 2.95        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0.0121      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.2         |
|    n_updates             | 1520        |
|    policy_gradient_loss  | -0.00514    |
|    std                   | 0.894       |
|    value_loss            | 1.18        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.664        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.664        |
| reward                   | -0.66462564  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -689         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 2            |
|    time_elapsed          | 378          |
|    total_timesteps       | 305152       |
| train/                   |              |
|    approx_kl             | 0.0054259393 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 7.97         |
|    cost_values           | 0.966        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.729        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.74         |
|    n_updates             | 1480         |
|    policy_gradient_loss  | -0.00501     |
|    std                   | 1            |
|    value_loss            | 8.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.407        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.407        |
| reward                   | -0.4520865   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -535         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 3            |
|    time_elapsed          | 511          |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0021983832 |
|    clip_fraction         | 0.106        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.14         |
|    cost_value_loss       | 53.1         |
|    cost_values           | 2.09         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.25         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.9         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | 0.00849      |
|    std                   | 1.01         |
|    value_loss            | 2.74         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.806498   |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -791        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 10          |
|    time_elapsed          | 1923        |
|    total_timesteps       | 321536      |
| train/                   |             |
|    approx_kl             | 0.004431772 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 1.73        |
|    cost_values           | 0.945       |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.366       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.1        |
|    n_updates             | 1560        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.869       |
|    value_loss            | 31.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0932      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0932      |
| reward                   | -0.43232787 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -887        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 18          |
|    time_elapsed          | 3038        |
|    total_timesteps       | 337920      |
| train/                   |             |
|    approx_kl             | 0.006872361 |
|    clip_fraction         | 0.0636      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 19.6        |
|    cost_values           | 2.1         |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0.00183     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.75        |
|    n_updates             | 1640        |
|    policy_gradient_loss  | -0.00427    |
|    std                   | 0.952       |
|    value_loss            | 7.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.37        |
| reward                   | -0.53332597 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -649        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 47          |
|    time_elapsed          | 7970        |
|    total_timesteps       | 296960      |
| train/                   |             |
|    approx_kl             | 0.00574107  |
|    clip_fraction         | 0.0423      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.81        |
|    cost_value_loss       | 14.9        |
|    cost_values           | 1.65        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.416       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.37        |
|    n_updates             | 1440        |
|    policy_gradient_loss  | -0.00473    |
|    std                   | 1.01        |
|    value_loss            | 3.72        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.32         |
| reward                   | -0.99200004  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -661         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 7            |
|    time_elapsed          | 1412         |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0032470801 |
|    clip_fraction         | 0.123        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.71         |
|    cost_value_loss       | 41.2         |
|    cost_values           | 2.52         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0.00642      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.28         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | 0.00378      |
|    std                   | 0.895        |
|    value_loss            | 2.01         |
-------------------------------------------
srun: error: io_init_msg_read_from_fd: reading slurm_io_init_msg failed: No error
srun: error: failed reading io init message
-------------------------------------------
| avg_speed                | 1.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.25         |
| reward                   | -0.34969586  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 3            |
|    time_elapsed          | 569          |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0067941593 |
|    clip_fraction         | 0.0424       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.09         |
|    cost_value_loss       | 53           |
|    cost_values           | 0.991        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.674        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.6         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 1            |
|    value_loss            | 26.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0198       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0198       |
| reward                   | -0.45677608  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -531         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 4            |
|    time_elapsed          | 686          |
|    total_timesteps       | 309248       |
| train/                   |              |
|    approx_kl             | 0.0030334415 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 0.134        |
|    cost_values           | 2.08         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.328        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.398        |
|    n_updates             | 1500         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.991        |
|    value_loss            | 0.934        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.012       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.012       |
| reward                   | -0.47843906 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -866        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 19          |
|    time_elapsed          | 3220        |
|    total_timesteps       | 339968      |
| train/                   |             |
|    approx_kl             | 0.004697402 |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.01        |
|    cost_value_loss       | 26.7        |
|    cost_values           | 1.53        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.000163    |
|    learning_rate         | 0.0003      |
|    loss                  | 16.8        |
|    n_updates             | 1650        |
|    policy_gradient_loss  | -0.00178    |
|    std                   | 0.954       |
|    value_loss            | 17          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.6243386  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -784        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 11          |
|    time_elapsed          | 2124        |
|    total_timesteps       | 323584      |
| train/                   |             |
|    approx_kl             | 0.006375404 |
|    clip_fraction         | 0.0119      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 0.678       |
|    cost_values           | 0.888       |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.88        |
|    n_updates             | 1570        |
|    policy_gradient_loss  | -0.00213    |
|    std                   | 0.869       |
|    value_loss            | 12.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00388     |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.00388     |
| reward                   | -0.6082822  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -642        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 48          |
|    time_elapsed          | 8172        |
|    total_timesteps       | 299008      |
| train/                   |             |
|    approx_kl             | 0.005362801 |
|    clip_fraction         | 0.0344      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.63        |
|    cost_value_loss       | 82.7        |
|    cost_values           | 2.01        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.842       |
|    lagrangian_multiplier | 0.00728     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 1450        |
|    policy_gradient_loss  | -0.00449    |
|    std                   | 1.01        |
|    value_loss            | 3.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.197        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.197        |
| reward                   | -0.7407123   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -653         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 8            |
|    time_elapsed          | 1619         |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0018224923 |
|    clip_fraction         | 0.0438       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.8          |
|    cost_value_loss       | 38           |
|    cost_values           | 1.85         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.858        |
|    lagrangian_multiplier | 0.0043       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.81         |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.895        |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.97        |
| reward                   | -0.5159312  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -679        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 4           |
|    time_elapsed          | 764         |
|    total_timesteps       | 309248      |
| train/                   |             |
|    approx_kl             | 0.004365152 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.26        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 1.04        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0.00017     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 1500        |
|    policy_gradient_loss  | -0.00366    |
|    std                   | 1           |
|    value_loss            | 15.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.067        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.067        |
| reward                   | -0.50958616  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -522         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 5            |
|    time_elapsed          | 861          |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0024538254 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.92         |
|    cost_value_loss       | 24.9         |
|    cost_values           | 1.96         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.757        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -0.00337     |
|    std                   | 0.987        |
|    value_loss            | 1.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.83         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.83         |
| reward                   | -0.5943478   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -848         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 20           |
|    time_elapsed          | 3404         |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0061247055 |
|    clip_fraction         | 0.0477       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.5          |
|    cost_value_loss       | 44.3         |
|    cost_values           | 1.35         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.801        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00332     |
|    std                   | 0.95         |
|    value_loss            | 3.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.97660345 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -762        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 12          |
|    time_elapsed          | 2325        |
|    total_timesteps       | 325632      |
| train/                   |             |
|    approx_kl             | 0.005215439 |
|    clip_fraction         | 0.069       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 0.926       |
|    cost_values           | 0.979       |
|    entropy               | -2.55       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.745       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.54        |
|    n_updates             | 1580        |
|    policy_gradient_loss  | -0.00978    |
|    std                   | 0.868       |
|    value_loss            | 4.99        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.599        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.599        |
| reward                   | -0.43290222  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -635         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 49           |
|    time_elapsed          | 8372         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0030567516 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.39         |
|    cost_value_loss       | 33.8         |
|    cost_values           | 1.97         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.562        |
|    lagrangian_multiplier | 0.00399      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.83         |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00218     |
|    std                   | 1.01         |
|    value_loss            | 5.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.157        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.157        |
| reward                   | -0.41721871  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -640         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 9            |
|    time_elapsed          | 1829         |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0021369837 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.65         |
|    cost_value_loss       | 7.63         |
|    cost_values           | 1.57         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.862        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.56         |
|    n_updates             | 1550         |
|    policy_gradient_loss  | -0.000745    |
|    std                   | 0.896        |
|    value_loss            | 8.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0597       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0597       |
| reward                   | -0.70811784  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -521         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 6            |
|    time_elapsed          | 1037         |
|    total_timesteps       | 313344       |
| train/                   |              |
|    approx_kl             | 0.0024675229 |
|    clip_fraction         | 0.00508      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.7          |
|    cost_value_loss       | 35.7         |
|    cost_values           | 2.09         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.491        |
|    lagrangian_multiplier | 0.00582      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.15         |
|    n_updates             | 1520         |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 0.987        |
|    value_loss            | 2.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.304        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.304        |
| reward                   | -0.36995476  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 5            |
|    time_elapsed          | 958          |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0044991993 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.19         |
|    cost_value_loss       | 36.1         |
|    cost_values           | 1.31         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.596        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.9         |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 1            |
|    value_loss            | 6.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0409       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0409       |
| reward                   | -0.3480341   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -841         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 21           |
|    time_elapsed          | 3588         |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0048135244 |
|    clip_fraction         | 0.0613       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.87         |
|    cost_value_loss       | 21.7         |
|    cost_values           | 1.52         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.905        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.00549     |
|    std                   | 0.946        |
|    value_loss            | 15.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.7415199   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -751         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 13           |
|    time_elapsed          | 2528         |
|    total_timesteps       | 327680       |
| train/                   |              |
|    approx_kl             | 0.0051734326 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 0.911        |
|    cost_values           | 0.964        |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.643        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.29         |
|    n_updates             | 1590         |
|    policy_gradient_loss  | -0.00307     |
|    std                   | 0.865        |
|    value_loss            | 21.1         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/p13vkfbg
------------------------------------
| avg_speed          | 0.366       |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.366       |
| reward             | -0.55388457 |
| rollout/           |             |
|    ep_len_mean     | 983         |
|    ep_rew_mean     | -634        |
| time/              |             |
|    fps             | 10          |
|    iterations      | 1           |
|    time_elapsed    | 199         |
|    total_timesteps | 303104      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.13         |
| reward                   | -0.27410197  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -623         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 10           |
|    time_elapsed          | 2035         |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0049135173 |
|    clip_fraction         | 0.0258       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.7         |
|    cost_value_loss       | 112          |
|    cost_values           | 1.66         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.773        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.9         |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 0.896        |
|    value_loss            | 1.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.165        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.165        |
| reward                   | -0.6209103   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -517         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 7            |
|    time_elapsed          | 1214         |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0019359477 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 7.69         |
|    cost_value_loss       | 79.5         |
|    cost_values           | 1.94         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.519        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 42.8         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | -0.000708    |
|    std                   | 0.987        |
|    value_loss            | 4.39         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 3.34       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.34       |
| reward                   | -0.588079  |
| rollout/                 |            |
|    ep_len_mean           | 977        |
|    ep_rew_mean           | -679       |
| time/                    |            |
|    fps                   | 10         |
|    iterations            | 6          |
|    time_elapsed          | 1148       |
|    total_timesteps       | 313344     |
| train/                   |            |
|    approx_kl             | 0.00779335 |
|    clip_fraction         | 0.093      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.45       |
|    cost_value_loss       | 16.5       |
|    cost_values           | 1.65       |
|    entropy               | -2.83      |
|    entropy_loss          | -2.83      |
|    explained_variance    | 0.598      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 9.82       |
|    n_updates             | 1520       |
|    policy_gradient_loss  | -0.00934   |
|    std                   | 1          |
|    value_loss            | 7          |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.562        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.562        |
| reward                   | -0.4411648   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -831         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 22           |
|    time_elapsed          | 3771         |
|    total_timesteps       | 346112       |
| train/                   |              |
|    approx_kl             | 0.0020897468 |
|    clip_fraction         | 0.0436       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.35         |
|    cost_value_loss       | 6.16         |
|    cost_values           | 1.42         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 1680         |
|    policy_gradient_loss  | -0.00493     |
|    std                   | 0.947        |
|    value_loss            | 21.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6641696   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -742         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 14           |
|    time_elapsed          | 2734         |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0067702327 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.729        |
|    cost_values           | 0.834        |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.11         |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00541     |
|    std                   | 0.865        |
|    value_loss            | 5.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.325       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.325       |
| reward                   | -0.6010742  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -626        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 2           |
|    time_elapsed          | 402         |
|    total_timesteps       | 305152      |
| train/                   |             |
|    approx_kl             | 0.005323927 |
|    clip_fraction         | 0.0288      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.72        |
|    cost_value_loss       | 33.2        |
|    cost_values           | 1.24        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.851       |
|    lagrangian_multiplier | 0.00371     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.35        |
|    n_updates             | 1480        |
|    policy_gradient_loss  | -0.00324    |
|    std                   | 1.01        |
|    value_loss            | 6.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.131        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.131        |
| reward                   | -0.49572662  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 8            |
|    time_elapsed          | 1397         |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0027615628 |
|    clip_fraction         | 0.00459      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.02         |
|    cost_value_loss       | 43.9         |
|    cost_values           | 2.19         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -3.34        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.9         |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.000866    |
|    std                   | 0.987        |
|    value_loss            | 6.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0186       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0186       |
| reward                   | -0.2976528   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -604         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 11           |
|    time_elapsed          | 2245         |
|    total_timesteps       | 323584       |
| train/                   |              |
|    approx_kl             | 0.0028046584 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.95         |
|    cost_value_loss       | 15.7         |
|    cost_values           | 1.99         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.378        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.39         |
|    n_updates             | 1570         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.897        |
|    value_loss            | 2.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.455        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.455        |
| reward                   | -0.4218585   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -676         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 7            |
|    time_elapsed          | 1341         |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0031872955 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.91         |
|    cost_value_loss       | 29.4         |
|    cost_values           | 1.98         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.77         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.7         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.998        |
|    value_loss            | 3.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.503        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.503        |
| reward                   | -0.5478902   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -829         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 23           |
|    time_elapsed          | 3958         |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0035533337 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.43         |
|    cost_value_loss       | 29.7         |
|    cost_values           | 1.37         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -0.0649      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.943        |
|    value_loss            | 2.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5799437   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -730         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 15           |
|    time_elapsed          | 2941         |
|    total_timesteps       | 331776       |
| train/                   |              |
|    approx_kl             | 0.0051400373 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 1.32         |
|    cost_values           | 0.975        |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.792        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.56         |
|    n_updates             | 1610         |
|    policy_gradient_loss  | -0.0049      |
|    std                   | 0.864        |
|    value_loss            | 6.84         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.84        |
| reward                   | -0.48650354 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -619        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 3           |
|    time_elapsed          | 606         |
|    total_timesteps       | 307200      |
| train/                   |             |
|    approx_kl             | 0.004001283 |
|    clip_fraction         | 0.0423      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.41        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 1.33        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.785       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.39        |
|    n_updates             | 1490        |
|    policy_gradient_loss  | -0.00386    |
|    std                   | 1.01        |
|    value_loss            | 4.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.221        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.221        |
| reward                   | -0.58850694  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -511         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 9            |
|    time_elapsed          | 1577         |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0018039811 |
|    clip_fraction         | 0.00513      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 2            |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.66         |
|    lagrangian_multiplier | 0.0589       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.11         |
|    n_updates             | 1550         |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 0.987        |
|    value_loss            | 23.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0841       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0841       |
| reward                   | -0.37048998  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -601         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 12           |
|    time_elapsed          | 2457         |
|    total_timesteps       | 325632       |
| train/                   |              |
|    approx_kl             | 0.0051599224 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.54         |
|    cost_value_loss       | 33.8         |
|    cost_values           | 2.44         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.716        |
|    lagrangian_multiplier | 0.00161      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 1580         |
|    policy_gradient_loss  | -0.00502     |
|    std                   | 0.896        |
|    value_loss            | 0.709        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.07         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.07         |
| reward                   | -0.5846591   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 8            |
|    time_elapsed          | 1533         |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0029351753 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.2          |
|    cost_value_loss       | 12.5         |
|    cost_values           | 2.18         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.35         |
|    lagrangian_multiplier | 0.00176      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.0024      |
|    std                   | 0.994        |
|    value_loss            | 23.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.209       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.209       |
| reward                   | -0.24386999 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -800        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 24          |
|    time_elapsed          | 4145        |
|    total_timesteps       | 350208      |
| train/                   |             |
|    approx_kl             | 0.003602922 |
|    clip_fraction         | 0.0063      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.53        |
|    cost_value_loss       | 17          |
|    cost_values           | 1.4         |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 1700        |
|    policy_gradient_loss  | -0.000588   |
|    std                   | 0.941       |
|    value_loss            | 6.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.21400976 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -726        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 16          |
|    time_elapsed          | 3150        |
|    total_timesteps       | 333824      |
| train/                   |             |
|    approx_kl             | 0.005990441 |
|    clip_fraction         | 0.0578      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 1.58        |
|    cost_values           | 0.995       |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.338       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.15        |
|    n_updates             | 1620        |
|    policy_gradient_loss  | -0.00691    |
|    std                   | 0.863       |
|    value_loss            | 3.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.187       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.187       |
| reward                   | -0.27359056 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -512        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 10          |
|    time_elapsed          | 1760        |
|    total_timesteps       | 321536      |
| train/                   |             |
|    approx_kl             | 0.004436246 |
|    clip_fraction         | 0.0506      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.14        |
|    cost_value_loss       | 5.66        |
|    cost_values           | 1.6         |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.558       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.05        |
|    n_updates             | 1560        |
|    policy_gradient_loss  | -0.00337    |
|    std                   | 0.988       |
|    value_loss            | 0.672       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.218        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.218        |
| reward                   | -0.7237319   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -618         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 4            |
|    time_elapsed          | 811          |
|    total_timesteps       | 309248       |
| train/                   |              |
|    approx_kl             | 0.0059003057 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.29         |
|    cost_value_loss       | 36.3         |
|    cost_values           | 1.53         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.237        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.1         |
|    n_updates             | 1500         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 1.01         |
|    value_loss            | 5.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.23         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.23         |
| reward                   | -0.6032677   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -674         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 9            |
|    time_elapsed          | 1734         |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0024776182 |
|    clip_fraction         | 0.00337      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.42         |
|    cost_value_loss       | 5.03         |
|    cost_values           | 1.53         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0.00233      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.87         |
|    n_updates             | 1550         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.992        |
|    value_loss            | 10.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.427       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.427       |
| reward                   | -0.16106199 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -599        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 13          |
|    time_elapsed          | 2673        |
|    total_timesteps       | 327680      |
| train/                   |             |
|    approx_kl             | 0.003638561 |
|    clip_fraction         | 0.0209      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 22.2        |
|    cost_values           | 2.27        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0.0134      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.59        |
|    n_updates             | 1590        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.896       |
|    value_loss            | 7.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.87         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.87         |
| reward                   | -0.4996803   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -785         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 25           |
|    time_elapsed          | 4335         |
|    total_timesteps       | 352256       |
| train/                   |              |
|    approx_kl             | 0.0067724185 |
|    clip_fraction         | 0.0522       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.15         |
|    cost_value_loss       | 14.1         |
|    cost_values           | 1.47         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.645        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.75         |
|    n_updates             | 1710         |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 0.937        |
|    value_loss            | 1.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.146        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.146        |
| reward                   | -0.5555545   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -511         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 11           |
|    time_elapsed          | 1943         |
|    total_timesteps       | 323584       |
| train/                   |              |
|    approx_kl             | 0.0017578969 |
|    clip_fraction         | 0.00151      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 0.0548       |
|    cost_values           | 1.34         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.848        |
|    lagrangian_multiplier | 0.000598     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.3          |
|    n_updates             | 1570         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.99         |
|    value_loss            | 10.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5533075  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -718        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 17          |
|    time_elapsed          | 3357        |
|    total_timesteps       | 335872      |
| train/                   |             |
|    approx_kl             | 0.007375602 |
|    clip_fraction         | 0.0858      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 0.659       |
|    cost_values           | 0.965       |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.794       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.26        |
|    n_updates             | 1630        |
|    policy_gradient_loss  | -0.0107     |
|    std                   | 0.863       |
|    value_loss            | 10          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.57        |
| reward                   | -0.6915418  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -612        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 5           |
|    time_elapsed          | 1018        |
|    total_timesteps       | 311296      |
| train/                   |             |
|    approx_kl             | 0.005040922 |
|    clip_fraction         | 0.0363      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.49        |
|    cost_value_loss       | 65          |
|    cost_values           | 1.89        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -0.177      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.6        |
|    n_updates             | 1510        |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 1.01        |
|    value_loss            | 2.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.298        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.298        |
| reward                   | -0.43166736  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -769         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 26           |
|    time_elapsed          | 4525         |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0031906376 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.14         |
|    cost_value_loss       | 42.5         |
|    cost_values           | 2.01         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.504        |
|    lagrangian_multiplier | 0.000289     |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 1720         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.934        |
|    value_loss            | 9.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.603        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.603        |
| reward                   | -0.3915798   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -673         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 10           |
|    time_elapsed          | 1946         |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0064297207 |
|    clip_fraction         | 0.0595       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.09         |
|    cost_value_loss       | 20.7         |
|    cost_values           | 1.13         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.852        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.00766     |
|    std                   | 0.993        |
|    value_loss            | 3.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.171       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.171       |
| reward                   | -0.47915846 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -590        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 14          |
|    time_elapsed          | 2904        |
|    total_timesteps       | 329728      |
| train/                   |             |
|    approx_kl             | 0.006544512 |
|    clip_fraction         | 0.0227      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.6        |
|    cost_value_loss       | 143         |
|    cost_values           | 2.12        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.62       |
|    explained_variance    | -0.0777     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 70.1        |
|    n_updates             | 1600        |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.894       |
|    value_loss            | 2.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.156       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.156       |
| reward                   | -0.64052415 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -510        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 12          |
|    time_elapsed          | 2128        |
|    total_timesteps       | 325632      |
| train/                   |             |
|    approx_kl             | 0.006002632 |
|    clip_fraction         | 0.0406      |
|    clip_range            | 0.2         |
|    cost_returns          | 1           |
|    cost_value_loss       | 0.0193      |
|    cost_values           | 1.04        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | -0.386      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.632       |
|    n_updates             | 1580        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.98        |
|    value_loss            | 1.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6814513  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -716        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 18          |
|    time_elapsed          | 3566        |
|    total_timesteps       | 337920      |
| train/                   |             |
|    approx_kl             | 0.008226558 |
|    clip_fraction         | 0.0777      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.4         |
|    cost_value_loss       | 0.995       |
|    cost_values           | 0.981       |
|    entropy               | -2.53       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.819       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.81        |
|    n_updates             | 1640        |
|    policy_gradient_loss  | -0.00672    |
|    std                   | 0.859       |
|    value_loss            | 3.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.45         |
| reward                   | -0.45179257  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -611         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 6            |
|    time_elapsed          | 1231         |
|    total_timesteps       | 313344       |
| train/                   |              |
|    approx_kl             | 0.0008101666 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 7.05         |
|    cost_value_loss       | 73.9         |
|    cost_values           | 1.56         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0.00574      |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 1520         |
|    policy_gradient_loss  | -0.00025     |
|    std                   | 1.01         |
|    value_loss            | 20.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0251      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0251      |
| reward                   | -0.24302684 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -759        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 27          |
|    time_elapsed          | 4715        |
|    total_timesteps       | 356352      |
| train/                   |             |
|    approx_kl             | 0.00939996  |
|    clip_fraction         | 0.0523      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.16        |
|    cost_value_loss       | 47.3        |
|    cost_values           | 2.46        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.129       |
|    lagrangian_multiplier | 0.00561     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.76        |
|    n_updates             | 1730        |
|    policy_gradient_loss  | -0.0041     |
|    std                   | 0.924       |
|    value_loss            | 2.65        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.79         |
| reward                   | -0.37492687  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -674         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 11           |
|    time_elapsed          | 2150         |
|    total_timesteps       | 323584       |
| train/                   |              |
|    approx_kl             | 0.0036008735 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.98         |
|    cost_value_loss       | 19.7         |
|    cost_values           | 1.21         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.854        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 1570         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.994        |
|    value_loss            | 3.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0807       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0807       |
| reward                   | -0.47353935  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -589         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 15           |
|    time_elapsed          | 3131         |
|    total_timesteps       | 331776       |
| train/                   |              |
|    approx_kl             | 0.0072747297 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.6         |
|    cost_value_loss       | 114          |
|    cost_values           | 2.62         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.0525       |
|    lagrangian_multiplier | 0.02         |
|    learning_rate         | 0.0003       |
|    loss                  | 7.85         |
|    n_updates             | 1610         |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 0.895        |
|    value_loss            | 12.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.1159124   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 13           |
|    time_elapsed          | 2316         |
|    total_timesteps       | 327680       |
| train/                   |              |
|    approx_kl             | 0.0036372608 |
|    clip_fraction         | 0.0433       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.795        |
|    cost_value_loss       | 0.0241       |
|    cost_values           | 0.919        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -0.537       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0457       |
|    n_updates             | 1590         |
|    policy_gradient_loss  | -0.00022     |
|    std                   | 0.967        |
|    value_loss            | 0.785        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5631822   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 19           |
|    time_elapsed          | 3775         |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0057842834 |
|    clip_fraction         | 0.0404       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 0.769        |
|    cost_values           | 0.988        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.704        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.89         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 0.853        |
|    value_loss            | 3.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.207        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.207        |
| reward                   | -0.37243214  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -607         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 7            |
|    time_elapsed          | 1438         |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0046584336 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.98         |
|    cost_value_loss       | 6.64         |
|    cost_values           | 1.07         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0.00029      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.64         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | -0.00552     |
|    std                   | 1.01         |
|    value_loss            | 6.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.06        |
| reward                   | -0.28035513 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -743        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 28          |
|    time_elapsed          | 4906        |
|    total_timesteps       | 358400      |
| train/                   |             |
|    approx_kl             | 0.007469962 |
|    clip_fraction         | 0.361       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.32        |
|    cost_value_loss       | 10          |
|    cost_values           | 2.32        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.867       |
|    lagrangian_multiplier | 0.00311     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.12        |
|    n_updates             | 1740        |
|    policy_gradient_loss  | 0.0318      |
|    std                   | 0.92        |
|    value_loss            | 6.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.34         |
| reward                   | -0.6997129   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 12           |
|    time_elapsed          | 2356         |
|    total_timesteps       | 325632       |
| train/                   |              |
|    approx_kl             | 0.0062851324 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 14.9         |
|    cost_values           | 1.17         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.898        |
|    lagrangian_multiplier | 0.00018      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 1580         |
|    policy_gradient_loss  | -0.0054      |
|    std                   | 0.996        |
|    value_loss            | 8.35         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.207       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.207       |
| reward                   | -0.49603048 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -513        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 14          |
|    time_elapsed          | 2500        |
|    total_timesteps       | 329728      |
| train/                   |             |
|    approx_kl             | 0.009514043 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.38        |
|    cost_value_loss       | 85.5        |
|    cost_values           | 0.965       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.428       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 44.1        |
|    n_updates             | 1600        |
|    policy_gradient_loss  | 0.00316     |
|    std                   | 0.962       |
|    value_loss            | 6.96        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.178        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.178        |
| reward                   | -0.46296138  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -585         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 16           |
|    time_elapsed          | 3354         |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0026998715 |
|    clip_fraction         | 0.00347      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.68         |
|    cost_value_loss       | 39           |
|    cost_values           | 2.04         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.875        |
|    lagrangian_multiplier | 0.133        |
|    learning_rate         | 0.0003       |
|    loss                  | 2.55         |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.895        |
|    value_loss            | 45.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.6936854  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 20          |
|    time_elapsed          | 3988        |
|    total_timesteps       | 342016      |
| train/                   |             |
|    approx_kl             | 0.006355971 |
|    clip_fraction         | 0.06        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.35        |
|    cost_value_loss       | 0.73        |
|    cost_values           | 0.988       |
|    entropy               | -2.51       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.77        |
|    n_updates             | 1660        |
|    policy_gradient_loss  | -0.00711    |
|    std                   | 0.85        |
|    value_loss            | 2.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.209       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.209       |
| reward                   | -0.33421186 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -736        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 29          |
|    time_elapsed          | 5100        |
|    total_timesteps       | 360448      |
| train/                   |             |
|    approx_kl             | 0.009838229 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 10.4        |
|    cost_values           | 1.85        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.459       |
|    lagrangian_multiplier | 0.000154    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.85        |
|    n_updates             | 1750        |
|    policy_gradient_loss  | -0.00992    |
|    std                   | 0.915       |
|    value_loss            | 2.24        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.36         |
| reward                   | -0.46493205  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -601         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 8            |
|    time_elapsed          | 1644         |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0049499106 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.53         |
|    cost_value_loss       | 30.8         |
|    cost_values           | 1.05         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.797        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.9         |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.00369     |
|    std                   | 1.01         |
|    value_loss            | 6.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0211       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0211       |
| reward                   | -0.34479797  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 13           |
|    time_elapsed          | 2558         |
|    total_timesteps       | 327680       |
| train/                   |              |
|    approx_kl             | 0.0016874974 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.11         |
|    cost_value_loss       | 24.4         |
|    cost_values           | 1.28         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.706        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 1590         |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 0.992        |
|    value_loss            | 6.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0895       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0895       |
| reward                   | -0.46950257  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -515         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 15           |
|    time_elapsed          | 2687         |
|    total_timesteps       | 331776       |
| train/                   |              |
|    approx_kl             | 0.0014585401 |
|    clip_fraction         | 0.00742      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.89         |
|    cost_value_loss       | 83.8         |
|    cost_values           | 1.18         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.873        |
|    lagrangian_multiplier | 0.0128       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.78         |
|    n_updates             | 1610         |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 0.963        |
|    value_loss            | 4.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.348        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.348        |
| reward                   | -0.3979999   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -573         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 17           |
|    time_elapsed          | 3577         |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0041969074 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.41         |
|    cost_value_loss       | 18.1         |
|    cost_values           | 1.29         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0.00197      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.54         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.00505     |
|    std                   | 0.897        |
|    value_loss            | 17.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.119         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.119         |
| reward                   | -0.5357832    |
| rollout/                 |               |
|    ep_len_mean           | 965           |
|    ep_rew_mean           | -717          |
| time/                    |               |
|    fps                   | 11            |
|    iterations            | 30            |
|    time_elapsed          | 5295          |
|    total_timesteps       | 362496        |
| train/                   |               |
|    approx_kl             | 0.00059257494 |
|    clip_fraction         | 0.158         |
|    clip_range            | 0.2           |
|    cost_returns          | 3             |
|    cost_value_loss       | 18.8          |
|    cost_values           | 1.79          |
|    entropy               | -2.65         |
|    entropy_loss          | -2.65         |
|    explained_variance    | 0.956         |
|    lagrangian_multiplier | 0.00101       |
|    learning_rate         | 0.0003        |
|    loss                  | 7.34          |
|    n_updates             | 1760          |
|    policy_gradient_loss  | 0.00875       |
|    std                   | 0.913         |
|    value_loss            | 6.68          |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.8883307  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -699        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 21          |
|    time_elapsed          | 4195        |
|    total_timesteps       | 344064      |
| train/                   |             |
|    approx_kl             | 0.007627112 |
|    clip_fraction         | 0.0755      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 1.2         |
|    cost_values           | 0.981       |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.27        |
|    n_updates             | 1670        |
|    policy_gradient_loss  | -0.00511    |
|    std                   | 0.85        |
|    value_loss            | 3.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.7212416  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -597        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 9           |
|    time_elapsed          | 1854        |
|    total_timesteps       | 319488      |
| train/                   |             |
|    approx_kl             | 0.004113532 |
|    clip_fraction         | 0.0299      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.74        |
|    cost_value_loss       | 21.2        |
|    cost_values           | 1.15        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.851       |
|    lagrangian_multiplier | 0.000837    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.53        |
|    n_updates             | 1550        |
|    policy_gradient_loss  | -0.00321    |
|    std                   | 1.01        |
|    value_loss            | 6.66        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.577        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.577        |
| reward                   | -0.5126827   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -664         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 14           |
|    time_elapsed          | 2765         |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0076546296 |
|    clip_fraction         | 0.0576       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.85         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 1.42         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.33         |
|    lagrangian_multiplier | 1.06e-06     |
|    learning_rate         | 0.0003       |
|    loss                  | 26           |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.0056      |
|    std                   | 0.989        |
|    value_loss            | 30.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0553       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0553       |
| reward                   | -0.7335957   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -514         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 16           |
|    time_elapsed          | 2876         |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0018130156 |
|    clip_fraction         | 0.00557      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.153        |
|    cost_values           | 1.05         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.909        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.742        |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -0.00406     |
|    std                   | 0.964        |
|    value_loss            | 2.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0282       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0282       |
| reward                   | -0.41430187  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -586         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 18           |
|    time_elapsed          | 3797         |
|    total_timesteps       | 337920       |
| train/                   |              |
|    approx_kl             | 0.0092787985 |
|    clip_fraction         | 0.0969       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 25           |
|    cost_values           | 1.05         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.849        |
|    lagrangian_multiplier | 0.00251      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.66         |
|    n_updates             | 1640         |
|    policy_gradient_loss  | -0.0109      |
|    std                   | 0.895        |
|    value_loss            | 8.61         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.287       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.287       |
| reward                   | -0.28103158 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -713        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 31          |
|    time_elapsed          | 5491        |
|    total_timesteps       | 364544      |
| train/                   |             |
|    approx_kl             | 0.004437268 |
|    clip_fraction         | 0.0412      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.81        |
|    cost_value_loss       | 22.9        |
|    cost_values           | 1.82        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.155       |
|    lagrangian_multiplier | 0.000933    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.43        |
|    n_updates             | 1770        |
|    policy_gradient_loss  | -0.00493    |
|    std                   | 0.903       |
|    value_loss            | 0.695       |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.84       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.84       |
| reward                   | -1.6635834 |
| rollout/                 |            |
|    ep_len_mean           | 959        |
|    ep_rew_mean           | -696       |
| time/                    |            |
|    fps                   | 10         |
|    iterations            | 22         |
|    time_elapsed          | 4409       |
|    total_timesteps       | 346112     |
| train/                   |            |
|    approx_kl             | 0.00690957 |
|    clip_fraction         | 0.032      |
|    clip_range            | 0.2        |
|    cost_returns          | 1.11       |
|    cost_value_loss       | 0.596      |
|    cost_values           | 0.941      |
|    entropy               | -2.51      |
|    entropy_loss          | -2.51      |
|    explained_variance    | 0.797      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.7        |
|    n_updates             | 1680       |
|    policy_gradient_loss  | -0.00274   |
|    std                   | 0.849      |
|    value_loss            | 6.66       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.0657       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0657       |
| reward                   | -0.68414724  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -596         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 10           |
|    time_elapsed          | 2065         |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0035835593 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.63         |
|    cost_value_loss       | 40.7         |
|    cost_values           | 1.45         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0279       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.5         |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.00357     |
|    std                   | 1.01         |
|    value_loss            | 4.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.78        |
| reward                   | -0.53269583 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -663        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 15          |
|    time_elapsed          | 2980        |
|    total_timesteps       | 331776      |
| train/                   |             |
|    approx_kl             | 0.005394211 |
|    clip_fraction         | 0.0309      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.92        |
|    cost_value_loss       | 52.4        |
|    cost_values           | 1.66        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.713       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.1        |
|    n_updates             | 1610        |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 0.988       |
|    value_loss            | 4.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.279        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.279        |
| reward                   | -0.53453165  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 17           |
|    time_elapsed          | 3066         |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0032120286 |
|    clip_fraction         | 0.00615      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.8         |
|    cost_value_loss       | 146          |
|    cost_values           | 1.12         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.927        |
|    lagrangian_multiplier | 0.0192       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.06         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.00176     |
|    std                   | 0.964        |
|    value_loss            | 8.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.294       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.294       |
| reward                   | -0.2027836  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -582        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 19          |
|    time_elapsed          | 4016        |
|    total_timesteps       | 339968      |
| train/                   |             |
|    approx_kl             | 0.004214886 |
|    clip_fraction         | 0.0557      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 7.86        |
|    cost_values           | 0.496       |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0.00192     |
|    learning_rate         | 0.0003      |
|    loss                  | 38.4        |
|    n_updates             | 1650        |
|    policy_gradient_loss  | -0.00522    |
|    std                   | 0.894       |
|    value_loss            | 169         |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.13       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.13       |
| reward                   | -0.3074433 |
| rollout/                 |            |
|    ep_len_mean           | 966        |
|    ep_rew_mean           | -707       |
| time/                    |            |
|    fps                   | 11         |
|    iterations            | 32         |
|    time_elapsed          | 5689       |
|    total_timesteps       | 366592     |
| train/                   |            |
|    approx_kl             | 0.00526256 |
|    clip_fraction         | 0.0303     |
|    clip_range            | 0.2        |
|    cost_returns          | 4.05       |
|    cost_value_loss       | 25.2       |
|    cost_values           | 2.05       |
|    entropy               | -2.61      |
|    entropy_loss          | -2.62      |
|    explained_variance    | 0.437      |
|    lagrangian_multiplier | 0.00242    |
|    learning_rate         | 0.0003     |
|    loss                  | 7.45       |
|    n_updates             | 1780       |
|    policy_gradient_loss  | -0.0049    |
|    std                   | 0.896      |
|    value_loss            | 8.17       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.72432834  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 23           |
|    time_elapsed          | 4625         |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0028229512 |
|    clip_fraction         | 0.00552      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.412        |
|    cost_values           | 0.827        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.04         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.848        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.735        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.735        |
| reward                   | -0.30720666  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -595         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 11           |
|    time_elapsed          | 2279         |
|    total_timesteps       | 323584       |
| train/                   |              |
|    approx_kl             | 0.0033202898 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 13.6         |
|    cost_values           | 1.41         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.895        |
|    lagrangian_multiplier | 0.0022       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.1          |
|    n_updates             | 1570         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 1.01         |
|    value_loss            | 6.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.102       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.102       |
| reward                   | -0.3885978  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -502        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 18          |
|    time_elapsed          | 3255        |
|    total_timesteps       | 337920      |
| train/                   |             |
|    approx_kl             | 0.005141784 |
|    clip_fraction         | 0.0395      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.68        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 1.18        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | -0.1        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.2         |
|    n_updates             | 1640        |
|    policy_gradient_loss  | -0.00449    |
|    std                   | 0.965       |
|    value_loss            | 0.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.45        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.45        |
| reward                   | -0.52754885 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -664        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 16          |
|    time_elapsed          | 3187        |
|    total_timesteps       | 333824      |
| train/                   |             |
|    approx_kl             | 0.007494914 |
|    clip_fraction         | 0.0313      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.03        |
|    cost_value_loss       | 26          |
|    cost_values           | 1.94        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.759       |
|    lagrangian_multiplier | 0.00209     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.85        |
|    n_updates             | 1620        |
|    policy_gradient_loss  | -0.00382    |
|    std                   | 0.983       |
|    value_loss            | 2.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.296       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.296       |
| reward                   | -0.3650443  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -679        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 33          |
|    time_elapsed          | 5888        |
|    total_timesteps       | 368640      |
| train/                   |             |
|    approx_kl             | 0.007914299 |
|    clip_fraction         | 0.033       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.36        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 1.93        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -1.04       |
|    lagrangian_multiplier | 0.00118     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.81        |
|    n_updates             | 1790        |
|    policy_gradient_loss  | -0.00177    |
|    std                   | 0.894       |
|    value_loss            | 1.78        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -2.0250456   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -585         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 20           |
|    time_elapsed          | 4238         |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0044419607 |
|    clip_fraction         | 0.0973       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.31         |
|    cost_value_loss       | 22.2         |
|    cost_values           | 0.663        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.753        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17           |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00617     |
|    std                   | 0.891        |
|    value_loss            | 8.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.2985896   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 24           |
|    time_elapsed          | 4839         |
|    total_timesteps       | 350208       |
| train/                   |              |
|    approx_kl             | 0.0038699685 |
|    clip_fraction         | 0.00903      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 1.35         |
|    cost_values           | 0.895        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.866        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.8          |
|    n_updates             | 1700         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.848        |
|    value_loss            | 12.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.16         |
| reward                   | -0.45688444  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 19           |
|    time_elapsed          | 3446         |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0038792307 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.0623       |
|    cost_values           | 1.28         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.146        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.25         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.000375    |
|    std                   | 0.965        |
|    value_loss            | 3.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.179       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.179       |
| reward                   | -0.50736994 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -595        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 12          |
|    time_elapsed          | 2493        |
|    total_timesteps       | 325632      |
| train/                   |             |
|    approx_kl             | 0.002950416 |
|    clip_fraction         | 0.00796     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.25        |
|    cost_value_loss       | 56.4        |
|    cost_values           | 1.21        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0.00846     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.91        |
|    n_updates             | 1580        |
|    policy_gradient_loss  | -0.00175    |
|    std                   | 1.01        |
|    value_loss            | 9.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.905        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.905        |
| reward                   | -0.36644349  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -660         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 17           |
|    time_elapsed          | 3398         |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0031092027 |
|    clip_fraction         | 0.117        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 4.98         |
|    cost_values           | 1.66         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.743        |
|    lagrangian_multiplier | 0.012        |
|    learning_rate         | 0.0003       |
|    loss                  | 2.39         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.981        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.51        |
| reward                   | -0.6258817  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -654        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 34          |
|    time_elapsed          | 6089        |
|    total_timesteps       | 370688      |
| train/                   |             |
|    approx_kl             | 0.038971715 |
|    clip_fraction         | 0.232       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.98        |
|    cost_value_loss       | 1.19        |
|    cost_values           | 2           |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -0.09       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.749       |
|    n_updates             | 1800        |
|    policy_gradient_loss  | 0.0131      |
|    std                   | 0.895       |
|    value_loss            | 0.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0661      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0661      |
| reward                   | -0.28427956 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -611        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 21          |
|    time_elapsed          | 4462        |
|    total_timesteps       | 344064      |
| train/                   |             |
|    approx_kl             | 0.00777023  |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.724       |
|    cost_value_loss       | 2.26        |
|    cost_values           | 0.519       |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 82.2        |
|    n_updates             | 1670        |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.891       |
|    value_loss            | 172         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.448        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.448        |
| reward                   | -0.4406045   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 20           |
|    time_elapsed          | 3638         |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0036321408 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 10           |
|    cost_values           | 1.18         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.836        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.82         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.963        |
|    value_loss            | 2.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.50813574  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 25           |
|    time_elapsed          | 5057         |
|    total_timesteps       | 352256       |
| train/                   |              |
|    approx_kl             | 0.0036257154 |
|    clip_fraction         | 0.00542      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 0.544        |
|    cost_values           | 0.872        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.934        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.51         |
|    n_updates             | 1710         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.848        |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -0.71125853  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -590         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 13           |
|    time_elapsed          | 2706         |
|    total_timesteps       | 327680       |
| train/                   |              |
|    approx_kl             | 0.0040665786 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.66         |
|    cost_value_loss       | 53.4         |
|    cost_values           | 1.21         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0.00903      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.26         |
|    n_updates             | 1590         |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 1.01         |
|    value_loss            | 7.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.764        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.764        |
| reward                   | -0.35844043  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -660         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 18           |
|    time_elapsed          | 3613         |
|    total_timesteps       | 337920       |
| train/                   |              |
|    approx_kl             | 0.0066357586 |
|    clip_fraction         | 0.0521       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 9.74         |
|    cost_values           | 1.41         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.5          |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 1640         |
|    policy_gradient_loss  | -0.00454     |
|    std                   | 0.981        |
|    value_loss            | 18.7         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.398      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.398      |
| reward                   | -0.5391541 |
| rollout/                 |            |
|    ep_len_mean           | 966        |
|    ep_rew_mean           | -633       |
| time/                    |            |
|    fps                   | 11         |
|    iterations            | 35         |
|    time_elapsed          | 6292       |
|    total_timesteps       | 372736     |
| train/                   |            |
|    approx_kl             | 0.13566914 |
|    clip_fraction         | 0.612      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.77       |
|    cost_value_loss       | 10.5       |
|    cost_values           | 1.6        |
|    entropy               | -2.62      |
|    entropy_loss          | -2.61      |
|    explained_variance    | 0.819      |
|    lagrangian_multiplier | 0.000486   |
|    learning_rate         | 0.0003     |
|    loss                  | 8.38       |
|    n_updates             | 1810       |
|    policy_gradient_loss  | 0.0697     |
|    std                   | 0.897      |
|    value_loss            | 15.4       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.228        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.228        |
| reward                   | -0.38721612  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -492         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 21           |
|    time_elapsed          | 3833         |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0033619618 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.0316       |
|    cost_values           | 1.14         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -0.672       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.148        |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.961        |
|    value_loss            | 0.806        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.128        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.128        |
| reward                   | -0.3979618   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -625         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 22           |
|    time_elapsed          | 4688         |
|    total_timesteps       | 346112       |
| train/                   |              |
|    approx_kl             | 0.0061892504 |
|    clip_fraction         | 0.0744       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 28.7         |
|    cost_values           | 0.336        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.902        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 135          |
|    n_updates             | 1680         |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 0.892        |
|    value_loss            | 266          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.3985828  |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -679        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 26          |
|    time_elapsed          | 5275        |
|    total_timesteps       | 354304      |
| train/                   |             |
|    approx_kl             | 0.005606833 |
|    clip_fraction         | 0.0423      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.43        |
|    cost_value_loss       | 1.22        |
|    cost_values           | 0.929       |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.58        |
|    n_updates             | 1720        |
|    policy_gradient_loss  | -0.00597    |
|    std                   | 0.849       |
|    value_loss            | 5           |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.8493186   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -584         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 14           |
|    time_elapsed          | 2922         |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0045026666 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.46         |
|    cost_value_loss       | 32           |
|    cost_values           | 1.42         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.577        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.3         |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00532     |
|    std                   | 1.01         |
|    value_loss            | 4.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.297        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.297        |
| reward                   | -0.5780776   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -661         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 19           |
|    time_elapsed          | 3828         |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0017819636 |
|    clip_fraction         | 0.00244      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 44.6         |
|    cost_values           | 0.921        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0.00179      |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.00074     |
|    std                   | 0.98         |
|    value_loss            | 8.93         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.125       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.125       |
| reward                   | -0.32306734 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -608        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 36          |
|    time_elapsed          | 6493        |
|    total_timesteps       | 374784      |
| train/                   |             |
|    approx_kl             | 0.002705567 |
|    clip_fraction         | 0.0177      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.05        |
|    cost_value_loss       | 29.5        |
|    cost_values           | 1.5         |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.192       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.3        |
|    n_updates             | 1820        |
|    policy_gradient_loss  | -0.0025     |
|    std                   | 0.897       |
|    value_loss            | 0.855       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.2087361  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -488        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 22          |
|    time_elapsed          | 4029        |
|    total_timesteps       | 346112      |
| train/                   |             |
|    approx_kl             | 0.002765471 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 41.5        |
|    cost_values           | 1.15        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.005       |
|    learning_rate         | 0.0003      |
|    loss                  | 6.98        |
|    n_updates             | 1680        |
|    policy_gradient_loss  | -0.00118    |
|    std                   | 0.959       |
|    value_loss            | 2.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.8056592   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -622         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 23           |
|    time_elapsed          | 4912         |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0057367454 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.38         |
|    cost_value_loss       | 22.4         |
|    cost_values           | 0.445        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.926        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 89.5         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.00278     |
|    std                   | 0.896        |
|    value_loss            | 175          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.41708428 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -675        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 27          |
|    time_elapsed          | 5497        |
|    total_timesteps       | 356352      |
| train/                   |             |
|    approx_kl             | 0.004999287 |
|    clip_fraction         | 0.051       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 1.46        |
|    cost_values           | 0.986       |
|    entropy               | -2.5        |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.415       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.6         |
|    n_updates             | 1730        |
|    policy_gradient_loss  | -0.00549    |
|    std                   | 0.847       |
|    value_loss            | 4.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.81256     |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -585         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 15           |
|    time_elapsed          | 3140         |
|    total_timesteps       | 331776       |
| train/                   |              |
|    approx_kl             | 0.0040217787 |
|    clip_fraction         | 0.00737      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.2          |
|    cost_value_loss       | 45.1         |
|    cost_values           | 1.35         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0.00829      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.5          |
|    n_updates             | 1610         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 1.01         |
|    value_loss            | 9.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.83         |
| reward                   | -0.71437323  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -657         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 20           |
|    time_elapsed          | 4048         |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0040873187 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.98         |
|    cost_value_loss       | 26.1         |
|    cost_values           | 0.784        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0.0066       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00445     |
|    std                   | 0.985        |
|    value_loss            | 11.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.253       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.253       |
| reward                   | -0.22675018 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -588        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 37          |
|    time_elapsed          | 6696        |
|    total_timesteps       | 376832      |
| train/                   |             |
|    approx_kl             | 0.005970007 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.19        |
|    cost_value_loss       | 7.62        |
|    cost_values           | 1.67        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -0.0642     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.58        |
|    n_updates             | 1830        |
|    policy_gradient_loss  | -0.00179    |
|    std                   | 0.895       |
|    value_loss            | 2.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.31         |
| reward                   | -0.77583075  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -490         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 23           |
|    time_elapsed          | 4228         |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0035376693 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 45           |
|    cost_values           | 1.25         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0.00364      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 0.959        |
|    value_loss            | 3.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.49         |
| reward                   | -0.61240953  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -636         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 24           |
|    time_elapsed          | 5138         |
|    total_timesteps       | 350208       |
| train/                   |              |
|    approx_kl             | 0.0036054298 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.72         |
|    cost_value_loss       | 98.2         |
|    cost_values           | 0.812        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0.00731      |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 1700         |
|    policy_gradient_loss  | -0.00239     |
|    std                   | 0.896        |
|    value_loss            | 31           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -0.60665095  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -582         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 16           |
|    time_elapsed          | 3361         |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0049246666 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 15.6         |
|    cost_values           | 1.1          |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 0.00206      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.27         |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -0.00481     |
|    std                   | 1.01         |
|    value_loss            | 7.57         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.59822565 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -670        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 28          |
|    time_elapsed          | 5719        |
|    total_timesteps       | 358400      |
| train/                   |             |
|    approx_kl             | 0.004345191 |
|    clip_fraction         | 0.0535      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.55        |
|    cost_value_loss       | 1           |
|    cost_values           | 0.991       |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.524       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.44        |
|    n_updates             | 1740        |
|    policy_gradient_loss  | -0.00443    |
|    std                   | 0.846       |
|    value_loss            | 2.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.3         |
| reward                   | -0.45133835 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -653        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 21          |
|    time_elapsed          | 4273        |
|    total_timesteps       | 344064      |
| train/                   |             |
|    approx_kl             | 0.005870921 |
|    clip_fraction         | 0.0343      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.51        |
|    cost_value_loss       | 17          |
|    cost_values           | 0.756       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.12        |
|    n_updates             | 1670        |
|    policy_gradient_loss  | -0.00543    |
|    std                   | 0.986       |
|    value_loss            | 7.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.294        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.294        |
| reward                   | -0.48077458  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -575         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 38           |
|    time_elapsed          | 6902         |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0072143143 |
|    clip_fraction         | 0.0839       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 2.02         |
|    cost_values           | 1.65         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.61        |
|    explained_variance    | -1.88        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.919        |
|    n_updates             | 1840         |
|    policy_gradient_loss  | 8.31e-05     |
|    std                   | 0.89         |
|    value_loss            | 2.13         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.12          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.12          |
| reward                   | -0.2847108    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -490          |
| time/                    |               |
|    fps                   | 11            |
|    iterations            | 24            |
|    time_elapsed          | 4426          |
|    total_timesteps       | 350208        |
| train/                   |               |
|    approx_kl             | 0.00091124215 |
|    clip_fraction         | 0.000146      |
|    clip_range            | 0.2           |
|    cost_returns          | 8.36          |
|    cost_value_loss       | 95.4          |
|    cost_values           | 1.58          |
|    entropy               | -2.75         |
|    entropy_loss          | -2.75         |
|    explained_variance    | -0.548        |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 53            |
|    n_updates             | 1700          |
|    policy_gradient_loss  | -0.00105      |
|    std                   | 0.959         |
|    value_loss            | 13.9          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.2129571   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -633         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 25           |
|    time_elapsed          | 5367         |
|    total_timesteps       | 352256       |
| train/                   |              |
|    approx_kl             | 0.0030706422 |
|    clip_fraction         | 0.0186       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.96         |
|    cost_value_loss       | 60.5         |
|    cost_values           | 0.78         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.899        |
|    lagrangian_multiplier | 0.00434      |
|    learning_rate         | 0.0003       |
|    loss                  | 27.1         |
|    n_updates             | 1710         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.895        |
|    value_loss            | 139          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -1.2826408   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -579         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 17           |
|    time_elapsed          | 3582         |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0061592567 |
|    clip_fraction         | 0.0663       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.22         |
|    cost_value_loss       | 90.7         |
|    cost_values           | 1.28         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0.00786      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.00626     |
|    std                   | 1.01         |
|    value_loss            | 3.89         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.13        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.13        |
| reward                   | -0.4712283  |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -650        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 29          |
|    time_elapsed          | 5942        |
|    total_timesteps       | 360448      |
| train/                   |             |
|    approx_kl             | 0.007674888 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 0.888       |
|    cost_values           | 0.986       |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.636       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 1750        |
|    policy_gradient_loss  | -0.00594    |
|    std                   | 0.846       |
|    value_loss            | 4.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -0.57912594  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -648         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 22           |
|    time_elapsed          | 4506         |
|    total_timesteps       | 346112       |
| train/                   |              |
|    approx_kl             | 0.0033104839 |
|    clip_fraction         | 0.0358       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.01         |
|    cost_value_loss       | 27           |
|    cost_values           | 1.11         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.58         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 1680         |
|    policy_gradient_loss  | -0.00499     |
|    std                   | 0.981        |
|    value_loss            | 5.91         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0179      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0179      |
| reward                   | -0.2986293  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -563        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 39          |
|    time_elapsed          | 7109        |
|    total_timesteps       | 380928      |
| train/                   |             |
|    approx_kl             | 0.011292267 |
|    clip_fraction         | 0.0399      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 0.801       |
|    cost_values           | 1.38        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | -0.199      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.645       |
|    n_updates             | 1850        |
|    policy_gradient_loss  | 0.000334    |
|    std                   | 0.891       |
|    value_loss            | 2.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.279        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.279        |
| reward                   | -0.53830606  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 25           |
|    time_elapsed          | 4625         |
|    total_timesteps       | 352256       |
| train/                   |              |
|    approx_kl             | 0.0034054099 |
|    clip_fraction         | 0.00186      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.05         |
|    cost_value_loss       | 47.1         |
|    cost_values           | 2            |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.255        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.7         |
|    n_updates             | 1710         |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 0.958        |
|    value_loss            | 6.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.6413602   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -639         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 26           |
|    time_elapsed          | 5598         |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0024199563 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.39         |
|    cost_value_loss       | 70.8         |
|    cost_values           | 0.794        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.946        |
|    lagrangian_multiplier | 0.00491      |
|    learning_rate         | 0.0003       |
|    loss                  | 18.2         |
|    n_updates             | 1720         |
|    policy_gradient_loss  | -0.00288     |
|    std                   | 0.896        |
|    value_loss            | 56.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.5409402  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -581        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 18          |
|    time_elapsed          | 3800        |
|    total_timesteps       | 337920      |
| train/                   |             |
|    approx_kl             | 0.003521631 |
|    clip_fraction         | 0.0188      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.08        |
|    cost_value_loss       | 37          |
|    cost_values           | 1.28        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0.00417     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.89        |
|    n_updates             | 1640        |
|    policy_gradient_loss  | -0.00299    |
|    std                   | 1.01        |
|    value_loss            | 6.99        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.29         |
| reward                   | -0.58178484  |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -646         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 30           |
|    time_elapsed          | 6163         |
|    total_timesteps       | 362496       |
| train/                   |              |
|    approx_kl             | 0.0052652415 |
|    clip_fraction         | 0.074        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 1.28         |
|    cost_values           | 0.984        |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.411        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.27         |
|    n_updates             | 1760         |
|    policy_gradient_loss  | -0.00553     |
|    std                   | 0.843        |
|    value_loss            | 14           |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.04        |
| reward                   | -0.6568883  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -552        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 40          |
|    time_elapsed          | 7313        |
|    total_timesteps       | 382976      |
| train/                   |             |
|    approx_kl             | 0.005007641 |
|    clip_fraction         | 0.0675      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 21          |
|    cost_values           | 1.38        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -0.926      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 1860        |
|    policy_gradient_loss  | -0.00377    |
|    std                   | 0.893       |
|    value_loss            | 0.885       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.55        |
| reward                   | -0.48260087 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -648        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 23          |
|    time_elapsed          | 4740        |
|    total_timesteps       | 348160      |
| train/                   |             |
|    approx_kl             | 0.003613602 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.53        |
|    cost_value_loss       | 24.4        |
|    cost_values           | 1.45        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.459       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 1690        |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 0.982       |
|    value_loss            | 6.96        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -0.43134537  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 26           |
|    time_elapsed          | 4826         |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0028801858 |
|    clip_fraction         | 0.00435      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 0.945        |
|    cost_values           | 1.97         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -8.51        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.756        |
|    n_updates             | 1720         |
|    policy_gradient_loss  | -0.000942    |
|    std                   | 0.951        |
|    value_loss            | 2.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.195       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.195       |
| reward                   | -0.65083563 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -580        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 19          |
|    time_elapsed          | 4023        |
|    total_timesteps       | 339968      |
| train/                   |             |
|    approx_kl             | 0.006355712 |
|    clip_fraction         | 0.0317      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.63        |
|    cost_value_loss       | 1.64        |
|    cost_values           | 1.18        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.874       |
|    lagrangian_multiplier | 8.48e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.99        |
|    n_updates             | 1650        |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 1.01        |
|    value_loss            | 17.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0294       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0294       |
| reward                   | -0.48428172  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -650         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 27           |
|    time_elapsed          | 5831         |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0057978905 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.72         |
|    cost_value_loss       | 40.4         |
|    cost_values           | 0.886        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.897        |
|    lagrangian_multiplier | 0.000369     |
|    learning_rate         | 0.0003       |
|    loss                  | 51.5         |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.00398     |
|    std                   | 0.898        |
|    value_loss            | 83.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -0.392931    |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -633         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 31           |
|    time_elapsed          | 6386         |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0059540374 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 1.63         |
|    cost_values           | 0.985        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.898        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.59         |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.0062      |
|    std                   | 0.84         |
|    value_loss            | 8.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.176        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.176        |
| reward                   | -0.33224288  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -535         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 41           |
|    time_elapsed          | 7521         |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0031188345 |
|    clip_fraction         | 0.0278       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 1.76         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | -0.55        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.49         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 0.888        |
|    value_loss            | 1.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.118        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.118        |
| reward                   | -0.32228392  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 27           |
|    time_elapsed          | 5028         |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0024881558 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.85         |
|    cost_value_loss       | 15.6         |
|    cost_values           | 1.76         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.434        |
|    lagrangian_multiplier | 0.000869     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.5          |
|    n_updates             | 1730         |
|    policy_gradient_loss  | 0.00017      |
|    std                   | 0.945        |
|    value_loss            | 2.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.31         |
| reward                   | -0.5858202   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -645         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 24           |
|    time_elapsed          | 4972         |
|    total_timesteps       | 350208       |
| train/                   |              |
|    approx_kl             | 0.0036021178 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.43         |
|    cost_value_loss       | 22.9         |
|    cost_values           | 1.63         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.491        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 1700         |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 0.982        |
|    value_loss            | 2.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.373       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.373       |
| reward                   | -0.59275776 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -584        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 20          |
|    time_elapsed          | 4248        |
|    total_timesteps       | 342016      |
| train/                   |             |
|    approx_kl             | 0.003951627 |
|    clip_fraction         | 0.023       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.88        |
|    cost_value_loss       | 62.5        |
|    cost_values           | 1.49        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.229       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.3        |
|    n_updates             | 1660        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 1.01        |
|    value_loss            | 4.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.53164405  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -625         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 32           |
|    time_elapsed          | 6609         |
|    total_timesteps       | 366592       |
| train/                   |              |
|    approx_kl             | 0.0051784813 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 0.979        |
|    cost_values           | 0.984        |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.814        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.88         |
|    n_updates             | 1780         |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.838        |
|    value_loss            | 15.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.285        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.285        |
| reward                   | -0.42087856  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -644         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 28           |
|    time_elapsed          | 6063         |
|    total_timesteps       | 358400       |
| train/                   |              |
|    approx_kl             | 0.0026001683 |
|    clip_fraction         | 0.0253       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.05         |
|    cost_value_loss       | 63.7         |
|    cost_values           | 0.646        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.942        |
|    lagrangian_multiplier | 0.00179      |
|    learning_rate         | 0.0003       |
|    loss                  | 48.1         |
|    n_updates             | 1740         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.899        |
|    value_loss            | 130          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0284       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0284       |
| reward                   | -0.33689037  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 28           |
|    time_elapsed          | 5230         |
|    total_timesteps       | 358400       |
| train/                   |              |
|    approx_kl             | 0.0035894106 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.71         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 2.25         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -0.225       |
|    lagrangian_multiplier | 0.00158      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.4          |
|    n_updates             | 1740         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.946        |
|    value_loss            | 3.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.432        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.432        |
| reward                   | -0.25146317  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -531         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 42           |
|    time_elapsed          | 7729         |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0031069063 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 2.36         |
|    cost_values           | 1.92         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | -1.38        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.57         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.885        |
|    value_loss            | 3.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.284        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.284        |
| reward                   | -0.7419806   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -635         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 25           |
|    time_elapsed          | 5207         |
|    total_timesteps       | 352256       |
| train/                   |              |
|    approx_kl             | 0.0073224977 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.28         |
|    cost_value_loss       | 17.9         |
|    cost_values           | 1.84         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.751        |
|    lagrangian_multiplier | 0.00169      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.38         |
|    n_updates             | 1710         |
|    policy_gradient_loss  | -0.00361     |
|    std                   | 0.989        |
|    value_loss            | 3.84         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.5596054   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -590         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 21           |
|    time_elapsed          | 4472         |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0017757032 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.46         |
|    cost_value_loss       | 45.6         |
|    cost_values           | 1.27         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.951        |
|    lagrangian_multiplier | 0.00296      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 1.01         |
|    value_loss            | 11.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.249        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.249        |
| reward                   | -0.5974347   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 29           |
|    time_elapsed          | 5435         |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0039681545 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 2.79         |
|    cost_values           | 2.19         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -0.552       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.7          |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.95         |
|    value_loss            | 0.666        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6594901  |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -623        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 33          |
|    time_elapsed          | 6835        |
|    total_timesteps       | 368640      |
| train/                   |             |
|    approx_kl             | 0.008377451 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 1.22        |
|    cost_values           | 0.993       |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.635       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.74        |
|    n_updates             | 1790        |
|    policy_gradient_loss  | -0.00828    |
|    std                   | 0.838       |
|    value_loss            | 4.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.147       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.147       |
| reward                   | -0.5527563  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -523        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 43          |
|    time_elapsed          | 7940        |
|    total_timesteps       | 389120      |
| train/                   |             |
|    approx_kl             | 0.004121595 |
|    clip_fraction         | 0.0549      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.28        |
|    cost_value_loss       | 3.25        |
|    cost_values           | 1.77        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.59       |
|    explained_variance    | -0.3        |
|    lagrangian_multiplier | 7.96e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.07        |
|    n_updates             | 1890        |
|    policy_gradient_loss  | -0.00349    |
|    std                   | 0.883       |
|    value_loss            | 4.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.142        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.142        |
| reward                   | -0.47652847  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -658         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 29           |
|    time_elapsed          | 6296         |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0027237828 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.65         |
|    cost_value_loss       | 62.6         |
|    cost_values           | 1.06         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.821        |
|    lagrangian_multiplier | 0.0053       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.896        |
|    value_loss            | 19           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.77         |
| reward                   | -0.38406366  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -631         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 26           |
|    time_elapsed          | 5443         |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0056125056 |
|    clip_fraction         | 0.044        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.07         |
|    cost_value_loss       | 18.4         |
|    cost_values           | 1.97         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.524        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 1720         |
|    policy_gradient_loss  | -0.00374     |
|    std                   | 0.991        |
|    value_loss            | 4.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.26         |
| reward                   | -0.55896425  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 30           |
|    time_elapsed          | 5640         |
|    total_timesteps       | 362496       |
| train/                   |              |
|    approx_kl             | 0.0072280644 |
|    clip_fraction         | 0.0346       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.01         |
|    cost_value_loss       | 60.9         |
|    cost_values           | 2.29         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.474        |
|    lagrangian_multiplier | 0.0139       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.17         |
|    n_updates             | 1760         |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 0.95         |
|    value_loss            | 2.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.147       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.147       |
| reward                   | -0.47343004 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -512        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 44          |
|    time_elapsed          | 8151        |
|    total_timesteps       | 391168      |
| train/                   |             |
|    approx_kl             | 0.004373556 |
|    clip_fraction         | 0.0897      |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 4.72        |
|    cost_values           | 1.76        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.59       |
|    explained_variance    | -0.135      |
|    lagrangian_multiplier | 0.000118    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 1900        |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.892       |
|    value_loss            | 3.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.33        |
| reward                   | -0.708624   |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -588        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 22          |
|    time_elapsed          | 4695        |
|    total_timesteps       | 346112      |
| train/                   |             |
|    approx_kl             | 0.005486901 |
|    clip_fraction         | 0.027       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.76        |
|    cost_value_loss       | 8.61        |
|    cost_values           | 0.905       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.35        |
|    n_updates             | 1680        |
|    policy_gradient_loss  | -0.00453    |
|    std                   | 1.01        |
|    value_loss            | 8.72        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.43671194  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -618         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 34           |
|    time_elapsed          | 7063         |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0061808405 |
|    clip_fraction         | 0.0665       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 2.43         |
|    cost_values           | 1.04         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.259        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.81         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.00673     |
|    std                   | 0.836        |
|    value_loss            | 3.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.432        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.432        |
| reward                   | -0.58052933  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -672         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 30           |
|    time_elapsed          | 6532         |
|    total_timesteps       | 362496       |
| train/                   |              |
|    approx_kl             | 0.0035365373 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 6            |
|    cost_value_loss       | 74.4         |
|    cost_values           | 0.693        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 142          |
|    n_updates             | 1760         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.894        |
|    value_loss            | 204          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.269        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.269        |
| reward                   | -0.48804435  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -630         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 27           |
|    time_elapsed          | 5682         |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0028989152 |
|    clip_fraction         | 0.0313       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.42         |
|    cost_value_loss       | 21.2         |
|    cost_values           | 2.07         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.641        |
|    lagrangian_multiplier | 0.00321      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.9          |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.00408     |
|    std                   | 0.99         |
|    value_loss            | 4.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.185       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.185       |
| reward                   | -0.77058816 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 31          |
|    time_elapsed          | 5850        |
|    total_timesteps       | 364544      |
| train/                   |             |
|    approx_kl             | 0.003970922 |
|    clip_fraction         | 0.0203      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 123         |
|    cost_values           | 2.37        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0.0178      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.16        |
|    n_updates             | 1770        |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.95        |
|    value_loss            | 1.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.306        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.306        |
| reward                   | -0.28208056  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 45           |
|    time_elapsed          | 8364         |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0018054602 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.37         |
|    cost_value_loss       | 23.7         |
|    cost_values           | 1.77         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.142        |
|    lagrangian_multiplier | 0.00204      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.3          |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -9.31e-05    |
|    std                   | 0.893        |
|    value_loss            | 1.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.71         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.71         |
| reward                   | -0.52661145  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -587         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 23           |
|    time_elapsed          | 4921         |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0065832804 |
|    clip_fraction         | 0.0379       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.59         |
|    cost_value_loss       | 2.71         |
|    cost_values           | 0.971        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.732        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.25         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.0038      |
|    std                   | 1.01         |
|    value_loss            | 7.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.548212   |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -615        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 35          |
|    time_elapsed          | 7294        |
|    total_timesteps       | 372736      |
| train/                   |             |
|    approx_kl             | 0.009227624 |
|    clip_fraction         | 0.0917      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.14        |
|    cost_value_loss       | 2.37        |
|    cost_values           | 1.13        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.94        |
|    n_updates             | 1810        |
|    policy_gradient_loss  | -0.00756    |
|    std                   | 0.832       |
|    value_loss            | 3.87        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0553       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0553       |
| reward                   | -0.59329957  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 31           |
|    time_elapsed          | 6766         |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0069334996 |
|    clip_fraction         | 0.0499       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.48         |
|    cost_value_loss       | 84.9         |
|    cost_values           | 0.676        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.92         |
|    lagrangian_multiplier | 0.00718      |
|    learning_rate         | 0.0003       |
|    loss                  | 29.5         |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.00387     |
|    std                   | 0.897        |
|    value_loss            | 203          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.38         |
| reward                   | -0.5336163   |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -618         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 28           |
|    time_elapsed          | 5918         |
|    total_timesteps       | 358400       |
| train/                   |              |
|    approx_kl             | 0.0043541295 |
|    clip_fraction         | 0.044        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.24         |
|    cost_value_loss       | 16.4         |
|    cost_values           | 2.22         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.418        |
|    lagrangian_multiplier | 0.00184      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.21         |
|    n_updates             | 1740         |
|    policy_gradient_loss  | -0.00383     |
|    std                   | 0.985        |
|    value_loss            | 3.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.42        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.42        |
| reward                   | -0.37218678 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -481        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 32          |
|    time_elapsed          | 6059        |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.004089141 |
|    clip_fraction         | 0.00894     |
|    clip_range            | 0.2         |
|    cost_returns          | 9.45        |
|    cost_value_loss       | 90.4        |
|    cost_values           | 2.31        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.412       |
|    lagrangian_multiplier | 0.011       |
|    learning_rate         | 0.0003      |
|    loss                  | 9.06        |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.000781   |
|    std                   | 0.949       |
|    value_loss            | 3.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.147        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.147        |
| reward                   | -0.4649751   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 46           |
|    time_elapsed          | 8578         |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0024611135 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 1.5          |
|    cost_values           | 1.72         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.0313       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.47         |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.882        |
|    value_loss            | 2.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.28        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.28        |
| reward                   | -0.59554976 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -590        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 24          |
|    time_elapsed          | 5149        |
|    total_timesteps       | 350208      |
| train/                   |             |
|    approx_kl             | 0.004122494 |
|    clip_fraction         | 0.0156      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.03        |
|    cost_value_loss       | 60.3        |
|    cost_values           | 1.28        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.5         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.5        |
|    n_updates             | 1700        |
|    policy_gradient_loss  | -0.00301    |
|    std                   | 1           |
|    value_loss            | 4.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.74168915 |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -614        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 36          |
|    time_elapsed          | 7523        |
|    total_timesteps       | 374784      |
| train/                   |             |
|    approx_kl             | 0.007482711 |
|    clip_fraction         | 0.0565      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.25        |
|    cost_value_loss       | 2.82        |
|    cost_values           | 1.03        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.559       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.27        |
|    n_updates             | 1820        |
|    policy_gradient_loss  | -0.00473    |
|    std                   | 0.829       |
|    value_loss            | 2.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.192       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.192       |
| reward                   | -0.36810783 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -669        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 32          |
|    time_elapsed          | 7001        |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.007395752 |
|    clip_fraction         | 0.0501      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 56.7        |
|    cost_values           | 0.683       |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00532     |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.897       |
|    value_loss            | 37.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.53689605 |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -614        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 29          |
|    time_elapsed          | 6155        |
|    total_timesteps       | 360448      |
| train/                   |             |
|    approx_kl             | 0.004313548 |
|    clip_fraction         | 0.0389      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.8         |
|    cost_value_loss       | 26.7        |
|    cost_values           | 2.04        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.396       |
|    lagrangian_multiplier | 0.000965    |
|    learning_rate         | 0.0003      |
|    loss                  | 16          |
|    n_updates             | 1750        |
|    policy_gradient_loss  | -0.00311    |
|    std                   | 0.983       |
|    value_loss            | 16.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.22         |
| reward                   | -0.5326061   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 33           |
|    time_elapsed          | 6267         |
|    total_timesteps       | 368640       |
| train/                   |              |
|    approx_kl             | 0.0027095973 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.26         |
|    cost_value_loss       | 86.2         |
|    cost_values           | 2.21         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.524        |
|    lagrangian_multiplier | 0.0107       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.99         |
|    n_updates             | 1790         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.948        |
|    value_loss            | 5.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.978        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.978        |
| reward                   | -0.40458757  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 47           |
|    time_elapsed          | 8795         |
|    total_timesteps       | 397312       |
| train/                   |              |
|    approx_kl             | 0.0055493126 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 1.51         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.533        |
|    lagrangian_multiplier | 0.000464     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.11         |
|    n_updates             | 1930         |
|    policy_gradient_loss  | 8.72e-05     |
|    std                   | 0.881        |
|    value_loss            | 3.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.98        |
| reward                   | -0.56985503 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -590        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 25          |
|    time_elapsed          | 5378        |
|    total_timesteps       | 352256      |
| train/                   |             |
|    approx_kl             | 0.004059039 |
|    clip_fraction         | 0.0268      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.64        |
|    cost_value_loss       | 3.14        |
|    cost_values           | 1.11        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 1710        |
|    policy_gradient_loss  | -0.00264    |
|    std                   | 1           |
|    value_loss            | 20.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.5871222  |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -616        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 37          |
|    time_elapsed          | 7752        |
|    total_timesteps       | 376832      |
| train/                   |             |
|    approx_kl             | 0.006324106 |
|    clip_fraction         | 0.0752      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.66        |
|    cost_value_loss       | 1.39        |
|    cost_values           | 1.01        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.392       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 1830        |
|    policy_gradient_loss  | -0.00701    |
|    std                   | 0.827       |
|    value_loss            | 3.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.41297    |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -652        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 33          |
|    time_elapsed          | 7235        |
|    total_timesteps       | 368640      |
| train/                   |             |
|    approx_kl             | 0.006094184 |
|    clip_fraction         | 0.0227      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.31        |
|    cost_value_loss       | 65.7        |
|    cost_values           | 1.3         |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | -0.508      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.2        |
|    n_updates             | 1790        |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 0.898       |
|    value_loss            | 1.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.32         |
| reward                   | -0.56668776  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -610         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 30           |
|    time_elapsed          | 6394         |
|    total_timesteps       | 362496       |
| train/                   |              |
|    approx_kl             | 0.0036896178 |
|    clip_fraction         | 0.00957      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.46         |
|    cost_value_loss       | 15.5         |
|    cost_values           | 1.69         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 0.0129       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.84         |
|    n_updates             | 1760         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.983        |
|    value_loss            | 8.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0599       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0599       |
| reward                   | -0.251456    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 34           |
|    time_elapsed          | 6479         |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0031789592 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.8          |
|    cost_value_loss       | 88.9         |
|    cost_values           | 2.27         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -0.0223      |
|    lagrangian_multiplier | 0.0151       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.36         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.949        |
|    value_loss            | 3            |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.129       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.129       |
| reward                   | -0.29659367 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 48          |
|    time_elapsed          | 9012        |
|    total_timesteps       | 399360      |
| train/                   |             |
|    approx_kl             | 0.002756677 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.31        |
|    cost_value_loss       | 17.8        |
|    cost_values           | 1.3         |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.26        |
|    lagrangian_multiplier | 0.000949    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.42        |
|    n_updates             | 1940        |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.882       |
|    value_loss            | 2.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.94         |
| reward                   | -0.44235826  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -593         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 26           |
|    time_elapsed          | 5608         |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0017054481 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.64         |
|    cost_value_loss       | 25.3         |
|    cost_values           | 1.07         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.948        |
|    lagrangian_multiplier | 0.00223      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.97         |
|    n_updates             | 1720         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 1            |
|    value_loss            | 8.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.5848098   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -607         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 38           |
|    time_elapsed          | 7985         |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0021793928 |
|    clip_fraction         | 0.0586       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 0.968        |
|    entropy               | -2.45        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.657        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.63         |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.00065     |
|    std                   | 0.826        |
|    value_loss            | 5.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.34         |
| reward                   | -0.4039478   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -677         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 34           |
|    time_elapsed          | 7473         |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0040027658 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.21         |
|    cost_value_loss       | 40.6         |
|    cost_values           | 0.97         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.7         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 0.899        |
|    value_loss            | 88.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.227       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.227       |
| reward                   | -0.3903365  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -474        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 35          |
|    time_elapsed          | 6691        |
|    total_timesteps       | 372736      |
| train/                   |             |
|    approx_kl             | 0.003459806 |
|    clip_fraction         | 0.0196      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.47        |
|    cost_value_loss       | 91          |
|    cost_values           | 2.12        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.415       |
|    lagrangian_multiplier | 0.014       |
|    learning_rate         | 0.0003      |
|    loss                  | 7.54        |
|    n_updates             | 1810        |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.948       |
|    value_loss            | 2.29        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.037        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.037        |
| reward                   | -0.41320884  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -599         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 31           |
|    time_elapsed          | 6633         |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0019841003 |
|    clip_fraction         | 0.00449      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.64         |
|    cost_value_loss       | 16.2         |
|    cost_values           | 1.46         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.498        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.67         |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.983        |
|    value_loss            | 6.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.447       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.447       |
| reward                   | -0.5284309  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 49          |
|    time_elapsed          | 9229        |
|    total_timesteps       | 401408      |
| train/                   |             |
|    approx_kl             | 0.007082027 |
|    clip_fraction         | 0.0619      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.14        |
|    cost_value_loss       | 0.563       |
|    cost_values           | 1.16        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.477       |
|    n_updates             | 1950        |
|    policy_gradient_loss  | -0.00396    |
|    std                   | 0.882       |
|    value_loss            | 0.558       |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.06         |
| reward                   | -0.4762967   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -587         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 27           |
|    time_elapsed          | 5836         |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0039970474 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.89         |
|    cost_value_loss       | 33.6         |
|    cost_values           | 1.47         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.589        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17           |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.00328     |
|    std                   | 1.01         |
|    value_loss            | 2.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.77612245  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -603         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 39           |
|    time_elapsed          | 8220         |
|    total_timesteps       | 380928       |
| train/                   |              |
|    approx_kl             | 0.0069462964 |
|    clip_fraction         | 0.0727       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 3.49         |
|    cost_values           | 1.15         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.716        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.59         |
|    n_updates             | 1850         |
|    policy_gradient_loss  | -0.0078      |
|    std                   | 0.822        |
|    value_loss            | 2.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.185        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.185        |
| reward                   | -0.6011837   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 35           |
|    time_elapsed          | 7712         |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 0.0035689534 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 19.5         |
|    cost_values           | 0.413        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 1810         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.901        |
|    value_loss            | 204          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.21        |
| reward                   | -0.62160665 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -475        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 36          |
|    time_elapsed          | 6906        |
|    total_timesteps       | 374784      |
| train/                   |             |
|    approx_kl             | 0.009382844 |
|    clip_fraction         | 0.0356      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.99        |
|    cost_value_loss       | 74.1        |
|    cost_values           | 1.87        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.727       |
|    lagrangian_multiplier | 0.0105      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.52        |
|    n_updates             | 1820        |
|    policy_gradient_loss  | -0.00396    |
|    std                   | 0.949       |
|    value_loss            | 2           |
------------------------------------------
-----------------------------------
| avg_speed          | 0.0604     |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.0604     |
| reward             | -0.3022536 |
| rollout/           |            |
|    ep_len_mean     | 976        |
|    ep_rew_mean     | -464       |
| time/              |            |
|    fps             | 9          |
|    iterations      | 1          |
|    time_elapsed    | 216        |
|    total_timesteps | 403456     |
-----------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -0.45181417 |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -593        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 32          |
|    time_elapsed          | 6876        |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.005864828 |
|    clip_fraction         | 0.0268      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.95        |
|    cost_value_loss       | 6.31        |
|    cost_values           | 1.14        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0.00428     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.49        |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.00196    |
|    std                   | 0.984       |
|    value_loss            | 22.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.53        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.53        |
| reward                   | -0.33082113 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -585        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 28          |
|    time_elapsed          | 6068        |
|    total_timesteps       | 358400      |
| train/                   |             |
|    approx_kl             | 0.004452375 |
|    clip_fraction         | 0.0187      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.42        |
|    cost_value_loss       | 22          |
|    cost_values           | 1.87        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.441       |
|    lagrangian_multiplier | 0.00322     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.53        |
|    n_updates             | 1740        |
|    policy_gradient_loss  | -0.00284    |
|    std                   | 1.01        |
|    value_loss            | 4.02        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.42231146  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -600         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 40           |
|    time_elapsed          | 8454         |
|    total_timesteps       | 382976       |
| train/                   |              |
|    approx_kl             | 0.0057946844 |
|    clip_fraction         | 0.0353       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 1.87         |
|    cost_values           | 1.31         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.879        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.96         |
|    n_updates             | 1860         |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 0.821        |
|    value_loss            | 5.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -2.0239418   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 36           |
|    time_elapsed          | 7949         |
|    total_timesteps       | 374784       |
| train/                   |              |
|    approx_kl             | 0.0034038804 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.4          |
|    cost_value_loss       | 19.9         |
|    cost_values           | 0.593        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.961        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.4         |
|    n_updates             | 1820         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.903        |
|    value_loss            | 80.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.148       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.148       |
| reward                   | -0.34183463 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -473        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 37          |
|    time_elapsed          | 7120        |
|    total_timesteps       | 376832      |
| train/                   |             |
|    approx_kl             | 0.003295876 |
|    clip_fraction         | 0.0108      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.5         |
|    cost_value_loss       | 27.6        |
|    cost_values           | 1.41        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0.00676     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.01        |
|    n_updates             | 1830        |
|    policy_gradient_loss  | -0.00284    |
|    std                   | 0.95        |
|    value_loss            | 10.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.3008942  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 2           |
|    time_elapsed          | 437         |
|    total_timesteps       | 405504      |
| train/                   |             |
|    approx_kl             | 0.008335903 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.85        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 0.893       |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.797       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 1970        |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.881       |
|    value_loss            | 1.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.595       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.595       |
| reward                   | -0.701104   |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -596        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 33          |
|    time_elapsed          | 7117        |
|    total_timesteps       | 368640      |
| train/                   |             |
|    approx_kl             | 0.005393642 |
|    clip_fraction         | 0.0402      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.45        |
|    cost_value_loss       | 24.8        |
|    cost_values           | 0.798       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.00334     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.26        |
|    n_updates             | 1790        |
|    policy_gradient_loss  | -0.00457    |
|    std                   | 0.985       |
|    value_loss            | 5.92        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.62         |
| reward                   | -0.372351    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -582         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 29           |
|    time_elapsed          | 6302         |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0055793272 |
|    clip_fraction         | 0.0436       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.1          |
|    cost_value_loss       | 36.8         |
|    cost_values           | 1.91         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.704        |
|    lagrangian_multiplier | 0.00419      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.13         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.00579     |
|    std                   | 1            |
|    value_loss            | 5.84         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.47075298 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -598        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 41          |
|    time_elapsed          | 8690        |
|    total_timesteps       | 385024      |
| train/                   |             |
|    approx_kl             | 0.010002324 |
|    clip_fraction         | 0.0707      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 1.54        |
|    cost_values           | 0.994       |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.41        |
|    n_updates             | 1870        |
|    policy_gradient_loss  | -0.00751    |
|    std                   | 0.822       |
|    value_loss            | 4.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.249        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.249        |
| reward                   | -0.49653542  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 38           |
|    time_elapsed          | 7332         |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0040873326 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.23         |
|    cost_value_loss       | 53.1         |
|    cost_values           | 1.18         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.792        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.1         |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.95         |
|    value_loss            | 3.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.9157412   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 37           |
|    time_elapsed          | 8189         |
|    total_timesteps       | 376832       |
| train/                   |              |
|    approx_kl             | 0.0042134807 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 9.88         |
|    cost_values           | 0.396        |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.894        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 116          |
|    n_updates             | 1830         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.903        |
|    value_loss            | 240          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.65         |
| reward                   | -0.4484061   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 3            |
|    time_elapsed          | 659          |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0014193375 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.623        |
|    cost_value_loss       | 0.0211       |
|    cost_values           | 0.745        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.425        |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.000415    |
|    std                   | 0.882        |
|    value_loss            | 1.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.642        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.642        |
| reward                   | -0.4397859   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -588         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 34           |
|    time_elapsed          | 7361         |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0038745692 |
|    clip_fraction         | 0.0382       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 9.41         |
|    cost_values           | 0.808        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.732        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.59         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.00489     |
|    std                   | 0.986        |
|    value_loss            | 7.35         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.46        |
| reward                   | -0.49491635 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -582        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 30          |
|    time_elapsed          | 6537        |
|    total_timesteps       | 362496      |
| train/                   |             |
|    approx_kl             | 0.004804512 |
|    clip_fraction         | 0.0299      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.3         |
|    cost_value_loss       | 4.4         |
|    cost_values           | 1.56        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0.000336    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.5         |
|    n_updates             | 1760        |
|    policy_gradient_loss  | -0.00468    |
|    std                   | 0.999       |
|    value_loss            | 5.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.74838626 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -597        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 42          |
|    time_elapsed          | 8928        |
|    total_timesteps       | 387072      |
| train/                   |             |
|    approx_kl             | 0.008796556 |
|    clip_fraction         | 0.0928      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 1.27        |
|    cost_values           | 0.924       |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.831       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.22        |
|    n_updates             | 1880        |
|    policy_gradient_loss  | -0.00789    |
|    std                   | 0.821       |
|    value_loss            | 7.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.66        |
| reward                   | -2.796818   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -477        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 39          |
|    time_elapsed          | 7547        |
|    total_timesteps       | 380928      |
| train/                   |             |
|    approx_kl             | 0.002774762 |
|    clip_fraction         | 0.0326      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.908       |
|    cost_value_loss       | 0.0314      |
|    cost_values           | 1.02        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | -0.0417     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.42        |
|    n_updates             | 1850        |
|    policy_gradient_loss  | -0.00272    |
|    std                   | 0.953       |
|    value_loss            | 0.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.734        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.734        |
| reward                   | -0.500808    |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 38           |
|    time_elapsed          | 8432         |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0045632403 |
|    clip_fraction         | 0.0412       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.486        |
|    cost_value_loss       | 2.33         |
|    cost_values           | 0.268        |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.655        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 111          |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 0.906        |
|    value_loss            | 250          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.123        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.123        |
| reward                   | -0.2959615   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 4            |
|    time_elapsed          | 882          |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0030775785 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 11.4         |
|    cost_values           | 0.69         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | -1.03        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.55         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.881        |
|    value_loss            | 0.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.74         |
| reward                   | -0.39262065  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -592         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 35           |
|    time_elapsed          | 7606         |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 0.0043695085 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.17         |
|    cost_value_loss       | 20.7         |
|    cost_values           | 1.09         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.389        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 1810         |
|    policy_gradient_loss  | -0.00449     |
|    std                   | 0.977        |
|    value_loss            | 3.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.37919053 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -580        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 31          |
|    time_elapsed          | 6769        |
|    total_timesteps       | 364544      |
| train/                   |             |
|    approx_kl             | 0.006390267 |
|    clip_fraction         | 0.0534      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.3         |
|    cost_value_loss       | 5.71        |
|    cost_values           | 1.23        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.145       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.91        |
|    n_updates             | 1770        |
|    policy_gradient_loss  | -0.00551    |
|    std                   | 1           |
|    value_loss            | 4.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.191        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.191        |
| reward                   | -0.27890608  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -494         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 40           |
|    time_elapsed          | 7765         |
|    total_timesteps       | 382976       |
| train/                   |              |
|    approx_kl             | 0.0020107625 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.11         |
|    cost_value_loss       | 38.6         |
|    cost_values           | 0.565        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.864        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 136          |
|    n_updates             | 1860         |
|    policy_gradient_loss  | 0.00165      |
|    std                   | 0.956        |
|    value_loss            | 270          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4827578   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -584         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 43           |
|    time_elapsed          | 9164         |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0075243083 |
|    clip_fraction         | 0.0591       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.83         |
|    cost_value_loss       | 2.35         |
|    cost_values           | 0.958        |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.783        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.62         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.00717     |
|    std                   | 0.818        |
|    value_loss            | 5.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -2.018953    |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 39           |
|    time_elapsed          | 8675         |
|    total_timesteps       | 380928       |
| train/                   |              |
|    approx_kl             | 0.0044450574 |
|    clip_fraction         | 0.04         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 32.6         |
|    cost_values           | 0.521        |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 60.9         |
|    n_updates             | 1850         |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 0.906        |
|    value_loss            | 100          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.216        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.216        |
| reward                   | -0.5380354   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 5            |
|    time_elapsed          | 1104         |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0036521875 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.997        |
|    cost_value_loss       | 1.34         |
|    cost_values           | 0.803        |
|    entropy               | -2.57        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.64         |
|    n_updates             | 2000         |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.879        |
|    value_loss            | 0.521        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.57         |
| reward                   | -0.53908193  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -582         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 36           |
|    time_elapsed          | 7852         |
|    total_timesteps       | 374784       |
| train/                   |              |
|    approx_kl             | 0.0027438335 |
|    clip_fraction         | 0.0129       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.9          |
|    cost_value_loss       | 9.14         |
|    cost_values           | 0.863        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.922        |
|    lagrangian_multiplier | 0.000256     |
|    learning_rate         | 0.0003       |
|    loss                  | 16.6         |
|    n_updates             | 1820         |
|    policy_gradient_loss  | -0.0025      |
|    std                   | 0.975        |
|    value_loss            | 31.4         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.047      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.047      |
| reward                   | -0.3915979 |
| rollout/                 |            |
|    ep_len_mean           | 989        |
|    ep_rew_mean           | -575       |
| time/                    |            |
|    fps                   | 9          |
|    iterations            | 32         |
|    time_elapsed          | 7004       |
|    total_timesteps       | 366592     |
| train/                   |            |
|    approx_kl             | 0.0066888  |
|    clip_fraction         | 0.0271     |
|    clip_range            | 0.2        |
|    cost_returns          | 6.69       |
|    cost_value_loss       | 64         |
|    cost_values           | 1.1        |
|    entropy               | -2.83      |
|    entropy_loss          | -2.84      |
|    explained_variance    | 0.901      |
|    lagrangian_multiplier | 0.00642    |
|    learning_rate         | 0.0003     |
|    loss                  | 9.95       |
|    n_updates             | 1780       |
|    policy_gradient_loss  | -0.00278   |
|    std                   | 0.999      |
|    value_loss            | 22.5       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.25525138  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 41           |
|    time_elapsed          | 7986         |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0012548459 |
|    clip_fraction         | 0.0105       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.464        |
|    cost_value_loss       | 0.392        |
|    cost_values           | 0.493        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.787        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.33         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.00655     |
|    std                   | 0.958        |
|    value_loss            | 15.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.67235696 |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -581        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 44          |
|    time_elapsed          | 9405        |
|    total_timesteps       | 391168      |
| train/                   |             |
|    approx_kl             | 0.008218918 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 2.37        |
|    cost_values           | 0.999       |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.311       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.76        |
|    n_updates             | 1900        |
|    policy_gradient_loss  | -0.0051     |
|    std                   | 0.816       |
|    value_loss            | 15.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.221        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.221        |
| reward                   | -0.45815936  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 6            |
|    time_elapsed          | 1328         |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0032196331 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.61         |
|    cost_value_loss       | 32.4         |
|    cost_values           | 1.07         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.943        |
|    lagrangian_multiplier | 0.0003       |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.878        |
|    value_loss            | 1.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -2.45061    |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -770        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 40          |
|    time_elapsed          | 8915        |
|    total_timesteps       | 382976      |
| train/                   |             |
|    approx_kl             | 0.005842974 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 16          |
|    cost_values           | 0.406       |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 107         |
|    n_updates             | 1860        |
|    policy_gradient_loss  | -0.00355    |
|    std                   | 0.907       |
|    value_loss            | 201         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.53        |
| reward                   | -0.57743424 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -578        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 37          |
|    time_elapsed          | 8097        |
|    total_timesteps       | 376832      |
| train/                   |             |
|    approx_kl             | 0.00492186  |
|    clip_fraction         | 0.0411      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.47        |
|    cost_value_loss       | 16.8        |
|    cost_values           | 1.06        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.77        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.01        |
|    n_updates             | 1830        |
|    policy_gradient_loss  | -0.00413    |
|    std                   | 0.974       |
|    value_loss            | 2.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.466        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.466        |
| reward                   | -0.3143944   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -576         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 33           |
|    time_elapsed          | 7241         |
|    total_timesteps       | 368640       |
| train/                   |              |
|    approx_kl             | 0.0013115731 |
|    clip_fraction         | 0.0146       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.06         |
|    cost_value_loss       | 24           |
|    cost_values           | 1.36         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -0.144       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.2         |
|    n_updates             | 1790         |
|    policy_gradient_loss  | -0.0047      |
|    std                   | 0.997        |
|    value_loss            | 13.1         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.107         |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.107         |
| reward                   | -0.5552624    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -507          |
| time/                    |               |
|    fps                   | 10            |
|    iterations            | 42            |
|    time_elapsed          | 8203          |
|    total_timesteps       | 387072        |
| train/                   |               |
|    approx_kl             | 0.00052614056 |
|    clip_fraction         | 0.00405       |
|    clip_range            | 0.2           |
|    cost_returns          | 7.11          |
|    cost_value_loss       | 95.4          |
|    cost_values           | 0.724         |
|    entropy               | -2.75         |
|    entropy_loss          | -2.75         |
|    explained_variance    | 0.909         |
|    lagrangian_multiplier | 0.0106        |
|    learning_rate         | 0.0003        |
|    loss                  | 14.3          |
|    n_updates             | 1880          |
|    policy_gradient_loss  | -0.000543     |
|    std                   | 0.959         |
|    value_loss            | 80.4          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.4308097   |
| rollout/                 |              |
|    ep_len_mean           | 941          |
|    ep_rew_mean           | -578         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 45           |
|    time_elapsed          | 9647         |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0064701005 |
|    clip_fraction         | 0.0586       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.24         |
|    cost_value_loss       | 2.98         |
|    cost_values           | 1.06         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.611        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.64         |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -0.00616     |
|    std                   | 0.813        |
|    value_loss            | 2.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.287        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.287        |
| reward                   | -0.2775242   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 7            |
|    time_elapsed          | 1554         |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0031911014 |
|    clip_fraction         | 0.00664      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 7.23         |
|    cost_values           | 1.3          |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.935        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.02         |
|    n_updates             | 2020         |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.879        |
|    value_loss            | 1.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.202        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.202        |
| reward                   | -0.55476505  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -793         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 41           |
|    time_elapsed          | 9158         |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0046380567 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 8.31         |
|    cost_values           | 0.386        |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.953        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 55.4         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.907        |
|    value_loss            | 113          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0169       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0169       |
| reward                   | -0.55975306  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -517         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 43           |
|    time_elapsed          | 8423         |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0026657798 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.4          |
|    cost_value_loss       | 67.4         |
|    cost_values           | 0.837        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.943        |
|    lagrangian_multiplier | 0.00671      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.002       |
|    std                   | 0.959        |
|    value_loss            | 30.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -0.8082233   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -572         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 38           |
|    time_elapsed          | 8346         |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0033684487 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 12.8         |
|    cost_values           | 0.723        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0.00152      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.42         |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.973        |
|    value_loss            | 7.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.39063475 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -568        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 34          |
|    time_elapsed          | 7476        |
|    total_timesteps       | 370688      |
| train/                   |             |
|    approx_kl             | 0.005018738 |
|    clip_fraction         | 0.0136      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.24        |
|    cost_value_loss       | 25.7        |
|    cost_values           | 1.19        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0.00193     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.63        |
|    n_updates             | 1800        |
|    policy_gradient_loss  | -0.00116    |
|    std                   | 0.996       |
|    value_loss            | 8.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.7040136  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -577        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 46          |
|    time_elapsed          | 9892        |
|    total_timesteps       | 395264      |
| train/                   |             |
|    approx_kl             | 0.012289245 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.67        |
|    cost_value_loss       | 2.97        |
|    cost_values           | 1.42        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.528       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 1920        |
|    policy_gradient_loss  | -0.00848    |
|    std                   | 0.811       |
|    value_loss            | 2.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0727      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0727      |
| reward                   | -0.33033964 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 8           |
|    time_elapsed          | 1782        |
|    total_timesteps       | 417792      |
| train/                   |             |
|    approx_kl             | 0.001274503 |
|    clip_fraction         | 0.00806     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 19.1        |
|    cost_values           | 1.3         |
|    entropy               | -2.58       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.411       |
|    lagrangian_multiplier | 0.00144     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.33        |
|    n_updates             | 2030        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.881       |
|    value_loss            | 1.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0729       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0729       |
| reward                   | -0.5991815   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -776         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 42           |
|    time_elapsed          | 9405         |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0059488164 |
|    clip_fraction         | 0.0369       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 23.1         |
|    cost_values           | 0.569        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 84.7         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.00354     |
|    std                   | 0.909        |
|    value_loss            | 159          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.132        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.132        |
| reward                   | -0.371347    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -524         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 44           |
|    time_elapsed          | 8647         |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0040230434 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.4          |
|    cost_value_loss       | 66.1         |
|    cost_values           | 0.763        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.937        |
|    lagrangian_multiplier | 0.00414      |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 0.959        |
|    value_loss            | 65.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.51         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.51         |
| reward                   | -0.29155937  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -566         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 35           |
|    time_elapsed          | 7714         |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 0.0058849594 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.65         |
|    cost_value_loss       | 33.8         |
|    cost_values           | 1.4          |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -0.277       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.5         |
|    n_updates             | 1810         |
|    policy_gradient_loss  | -0.00439     |
|    std                   | 0.998        |
|    value_loss            | 4.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.47         |
| reward                   | -0.42886958  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -566         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 39           |
|    time_elapsed          | 8595         |
|    total_timesteps       | 380928       |
| train/                   |              |
|    approx_kl             | 0.0036102005 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 12.3         |
|    cost_values           | 0.911        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.808        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.94         |
|    n_updates             | 1850         |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 0.973        |
|    value_loss            | 5.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4214604  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -571        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 47          |
|    time_elapsed          | 10136       |
|    total_timesteps       | 397312      |
| train/                   |             |
|    approx_kl             | 0.005731727 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 2.78        |
|    cost_values           | 1.71        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.556       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.18        |
|    n_updates             | 1930        |
|    policy_gradient_loss  | -0.00135    |
|    std                   | 0.81        |
|    value_loss            | 6.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.12        |
| reward                   | -0.46550253 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 9           |
|    time_elapsed          | 2012        |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.008100515 |
|    clip_fraction         | 0.0745      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.75        |
|    cost_value_loss       | 35.3        |
|    cost_values           | 1.48        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.842       |
|    lagrangian_multiplier | 0.00348     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.58        |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -0.00658    |
|    std                   | 0.881       |
|    value_loss            | 1.32        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0544       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0544       |
| reward                   | -0.22699879  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 43           |
|    time_elapsed          | 9653         |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0028327415 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.58         |
|    cost_value_loss       | 73.7         |
|    cost_values           | 1.12         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | -0.0496      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.7         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.908        |
|    value_loss            | 5.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0884       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0884       |
| reward                   | -0.43834993  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -534         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 45           |
|    time_elapsed          | 8870         |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0010572874 |
|    clip_fraction         | 0.00459      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.61         |
|    cost_value_loss       | 39.5         |
|    cost_values           | 0.807        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.935        |
|    lagrangian_multiplier | 0.00192      |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.959        |
|    value_loss            | 29.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.12         |
| reward                   | -0.5824811   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -562         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 36           |
|    time_elapsed          | 7948         |
|    total_timesteps       | 374784       |
| train/                   |              |
|    approx_kl             | 0.0042021084 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.95         |
|    cost_value_loss       | 16.4         |
|    cost_values           | 1.82         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.172        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.73         |
|    n_updates             | 1820         |
|    policy_gradient_loss  | -0.00329     |
|    std                   | 1            |
|    value_loss            | 5.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.33         |
| reward                   | -0.65314597  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -561         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 40           |
|    time_elapsed          | 8844         |
|    total_timesteps       | 382976       |
| train/                   |              |
|    approx_kl             | 0.0048382613 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 6.26         |
|    cost_values           | 0.927        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.582        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.57         |
|    n_updates             | 1860         |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 0.97         |
|    value_loss            | 4.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.5485398   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 10           |
|    time_elapsed          | 2240         |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0021424969 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.96         |
|    cost_value_loss       | 23.9         |
|    cost_values           | 1.37         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0.00238      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.36         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.000808    |
|    std                   | 0.88         |
|    value_loss            | 1.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6577399  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -571        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 48          |
|    time_elapsed          | 10381       |
|    total_timesteps       | 399360      |
| train/                   |             |
|    approx_kl             | 0.008202497 |
|    clip_fraction         | 0.0764      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.3         |
|    cost_value_loss       | 3.58        |
|    cost_values           | 1.92        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.531       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.23        |
|    n_updates             | 1940        |
|    policy_gradient_loss  | -0.00469    |
|    std                   | 0.806       |
|    value_loss            | 3.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.31976753  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -802         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 44           |
|    time_elapsed          | 9903         |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0047241393 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 0.784        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.4         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.909        |
|    value_loss            | 32.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0664       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0664       |
| reward                   | -0.36734277  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -532         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 46           |
|    time_elapsed          | 9094         |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0032948733 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.53         |
|    cost_value_loss       | 36.6         |
|    cost_values           | 0.761        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.854        |
|    lagrangian_multiplier | 0.00139      |
|    learning_rate         | 0.0003       |
|    loss                  | 44           |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 0.959        |
|    value_loss            | 123          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.13         |
| reward                   | -0.36485654  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -557         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 37           |
|    time_elapsed          | 8186         |
|    total_timesteps       | 376832       |
| train/                   |              |
|    approx_kl             | 0.0040420555 |
|    clip_fraction         | 0.0474       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.96         |
|    cost_value_loss       | 8.79         |
|    cost_values           | 2.3          |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.0612      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.54         |
|    n_updates             | 1830         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 1.01         |
|    value_loss            | 3.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.31        |
| reward                   | -0.45222408 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -562        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 41          |
|    time_elapsed          | 9095        |
|    total_timesteps       | 385024      |
| train/                   |             |
|    approx_kl             | 0.012776993 |
|    clip_fraction         | 0.0663      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.89        |
|    cost_value_loss       | 29.7        |
|    cost_values           | 1.22        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.1        |
|    n_updates             | 1870        |
|    policy_gradient_loss  | -0.00691    |
|    std                   | 0.965       |
|    value_loss            | 1.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0205       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0205       |
| reward                   | -0.25306222  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 11           |
|    time_elapsed          | 2470         |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0037362347 |
|    clip_fraction         | 0.0597       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.38         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 1.33         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.201        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.01         |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.879        |
|    value_loss            | 2.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4592889   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -573         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 49           |
|    time_elapsed          | 10626        |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0064054593 |
|    clip_fraction         | 0.0698       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.54         |
|    cost_value_loss       | 4.27         |
|    cost_values           | 2.1          |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.83         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.59         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.00579     |
|    std                   | 0.802        |
|    value_loss            | 3.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0943       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0943       |
| reward                   | -0.52810025  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -819         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 45           |
|    time_elapsed          | 10149        |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0048011374 |
|    clip_fraction         | 0.0428       |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 58.8         |
|    cost_values           | 0.711        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 3.79e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 39.4         |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -0.00415     |
|    std                   | 0.911        |
|    value_loss            | 26           |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.31          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 7.31          |
| reward                   | -1.3196474    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -530          |
| time/                    |               |
|    fps                   | 10            |
|    iterations            | 47            |
|    time_elapsed          | 9319          |
|    total_timesteps       | 397312        |
| train/                   |               |
|    approx_kl             | 0.00040440744 |
|    clip_fraction         | 9.77e-05      |
|    clip_range            | 0.2           |
|    cost_returns          | 9.93          |
|    cost_value_loss       | 129           |
|    cost_values           | 1.38          |
|    entropy               | -2.75         |
|    entropy_loss          | -2.75         |
|    explained_variance    | 0.524         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 67.3          |
|    n_updates             | 1930          |
|    policy_gradient_loss  | -0.00102      |
|    std                   | 0.959         |
|    value_loss            | 9.02          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 4.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.43         |
| reward                   | -0.26660854  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -554         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 38           |
|    time_elapsed          | 8426         |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0043259705 |
|    clip_fraction         | 0.0883       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.65         |
|    cost_value_loss       | 38.5         |
|    cost_values           | 2.49         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.539        |
|    lagrangian_multiplier | 0.00663      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.44         |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.00418     |
|    std                   | 1            |
|    value_loss            | 4            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.32         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.32         |
| reward                   | -0.41510892  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -554         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 42           |
|    time_elapsed          | 9345         |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0032921447 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.24         |
|    cost_value_loss       | 17.1         |
|    cost_values           | 1.54         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.858        |
|    lagrangian_multiplier | 0.000179     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.94         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.964        |
|    value_loss            | 4.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.53         |
| reward                   | -0.6091245   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 12           |
|    time_elapsed          | 2704         |
|    total_timesteps       | 425984       |
| train/                   |              |
|    approx_kl             | 0.0048220344 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.46         |
|    cost_value_loss       | 41.2         |
|    cost_values           | 1.5          |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.856        |
|    lagrangian_multiplier | 0.00394      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.1          |
|    n_updates             | 2070         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.881        |
|    value_loss            | 1.68         |
-------------------------------------------
-----------------------------------
| avg_speed          | 7.81       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.81       |
| reward             | -0.4031385 |
| rollout/           |            |
|    ep_len_mean     | 949        |
|    ep_rew_mean     | -568       |
| time/              |            |
|    fps             | 8          |
|    iterations      | 1          |
|    time_elapsed    | 241        |
|    total_timesteps | 403456     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.367        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.367        |
| reward                   | -0.43164912  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -548         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 48           |
|    time_elapsed          | 9546         |
|    total_timesteps       | 399360       |
| train/                   |              |
|    approx_kl             | 0.0014265229 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.6          |
|    cost_value_loss       | 58.7         |
|    cost_values           | 1.17         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.875        |
|    lagrangian_multiplier | 0.0052       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 1940         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.96         |
|    value_loss            | 21.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.52        |
| reward                   | -0.5303897  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -819        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 46          |
|    time_elapsed          | 10401       |
|    total_timesteps       | 395264      |
| train/                   |             |
|    approx_kl             | 0.005675776 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 8.51        |
|    cost_values           | 0.463       |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 49.3        |
|    n_updates             | 1920        |
|    policy_gradient_loss  | -0.00218    |
|    std                   | 0.909       |
|    value_loss            | 99.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.175       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.175       |
| reward                   | -0.4702243  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -550        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 39          |
|    time_elapsed          | 8672        |
|    total_timesteps       | 380928      |
| train/                   |             |
|    approx_kl             | 0.010125721 |
|    clip_fraction         | 0.0487      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.44        |
|    cost_value_loss       | 41.4        |
|    cost_values           | 2.53        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.544       |
|    lagrangian_multiplier | 0.00448     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.53        |
|    n_updates             | 1850        |
|    policy_gradient_loss  | -0.00219    |
|    std                   | 0.995       |
|    value_loss            | 2.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.195       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.195       |
| reward                   | -0.37357858 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 13          |
|    time_elapsed          | 2939        |
|    total_timesteps       | 428032      |
| train/                   |             |
|    approx_kl             | 0.007299634 |
|    clip_fraction         | 0.0456      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.92        |
|    cost_value_loss       | 6.76        |
|    cost_values           | 1.42        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.721       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.82        |
|    n_updates             | 2080        |
|    policy_gradient_loss  | -0.00409    |
|    std                   | 0.882       |
|    value_loss            | 7.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.641        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.641        |
| reward                   | -0.34193107  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -551         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 43           |
|    time_elapsed          | 9598         |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0024901743 |
|    clip_fraction         | 0.00527      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.53         |
|    cost_value_loss       | 19.6         |
|    cost_values           | 1.27         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.886        |
|    lagrangian_multiplier | 0.00564      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.23         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.000905    |
|    std                   | 0.964        |
|    value_loss            | 19.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5154471   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -555         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 2            |
|    time_elapsed          | 489          |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0069271936 |
|    clip_fraction         | 0.0584       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.72         |
|    cost_value_loss       | 3.66         |
|    cost_values           | 2.4          |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.298        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.92         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -0.00369     |
|    std                   | 0.802        |
|    value_loss            | 14.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.132        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.132        |
| reward                   | -0.54593235  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -546         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 49           |
|    time_elapsed          | 9774         |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0042137066 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 26           |
|    cost_values           | 0.528        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.904        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 92.1         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.96         |
|    value_loss            | 166          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.3         |
| reward                   | -0.57404417 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -819        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 47          |
|    time_elapsed          | 10654       |
|    total_timesteps       | 397312      |
| train/                   |             |
|    approx_kl             | 0.006508559 |
|    clip_fraction         | 0.074       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 23.5        |
|    cost_values           | 1.03        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.8        |
|    n_updates             | 1930        |
|    policy_gradient_loss  | -0.00539    |
|    std                   | 0.906       |
|    value_loss            | 1.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.586       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.586       |
| reward                   | -0.32574314 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -540        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 40          |
|    time_elapsed          | 8926        |
|    total_timesteps       | 382976      |
| train/                   |             |
|    approx_kl             | 0.011912217 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 26.8        |
|    cost_values           | 2.64        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.804       |
|    lagrangian_multiplier | 0.00269     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.78        |
|    n_updates             | 1860        |
|    policy_gradient_loss  | -0.00762    |
|    std                   | 0.997       |
|    value_loss            | 0.982       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.155       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.155       |
| reward                   | -0.4616843  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 14          |
|    time_elapsed          | 3175        |
|    total_timesteps       | 430080      |
| train/                   |             |
|    approx_kl             | 0.004906538 |
|    clip_fraction         | 0.00786     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.5         |
|    cost_value_loss       | 5.49        |
|    cost_values           | 1.12        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0.000239    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.26        |
|    n_updates             | 2090        |
|    policy_gradient_loss  | -0.00253    |
|    std                   | 0.883       |
|    value_loss            | 11.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.21         |
| reward                   | -1.0958099   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -538         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 44           |
|    time_elapsed          | 9851         |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0026802686 |
|    clip_fraction         | 0.00762      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.54         |
|    cost_value_loss       | 35.4         |
|    cost_values           | 0.967        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.808        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.2         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 0.965        |
|    value_loss            | 7.27         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.4082814 |
| rollout/                 |            |
|    ep_len_mean           | 930        |
|    ep_rew_mean           | -552       |
| time/                    |            |
|    fps                   | 8          |
|    iterations            | 3          |
|    time_elapsed          | 735        |
|    total_timesteps       | 407552     |
| train/                   |            |
|    approx_kl             | 0.01005382 |
|    clip_fraction         | 0.0815     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.85       |
|    cost_value_loss       | 4.05       |
|    cost_values           | 2.36       |
|    entropy               | -2.39      |
|    entropy_loss          | -2.39      |
|    explained_variance    | 0.224      |
|    lagrangian_multiplier | 0.0011     |
|    learning_rate         | 0.0003     |
|    loss                  | 7.49       |
|    n_updates             | 1980       |
|    policy_gradient_loss  | -0.00508   |
|    std                   | 0.801      |
|    value_loss            | 26.6       |
-----------------------------------------
------------------------------------
| avg_speed          | 0.206       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.206       |
| reward             | -0.30928776 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -549        |
| time/              |             |
|    fps             | 9           |
|    iterations      | 1           |
|    time_elapsed    | 226         |
|    total_timesteps | 403456      |
------------------------------------
------------------------------------------
| avg_speed                | 0.576       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.576       |
| reward                   | -0.48763385 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -819        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 48          |
|    time_elapsed          | 10906       |
|    total_timesteps       | 399360      |
| train/                   |             |
|    approx_kl             | 0.010219898 |
|    clip_fraction         | 0.0915      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.09        |
|    cost_value_loss       | 14.8        |
|    cost_values           | 1.01        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.769       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.61        |
|    n_updates             | 1940        |
|    policy_gradient_loss  | 0.00157     |
|    std                   | 0.902       |
|    value_loss            | 3.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.34        |
| reward                   | -0.26371998 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -540        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 41          |
|    time_elapsed          | 9170        |
|    total_timesteps       | 385024      |
| train/                   |             |
|    approx_kl             | 0.003964382 |
|    clip_fraction         | 0.0252      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.61        |
|    cost_value_loss       | 44.9        |
|    cost_values           | 2.66        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | -0.119      |
|    lagrangian_multiplier | 0.00708     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.63        |
|    n_updates             | 1870        |
|    policy_gradient_loss  | -0.00376    |
|    std                   | 0.998       |
|    value_loss            | 13.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.222        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.222        |
| reward                   | -0.4221285   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 15           |
|    time_elapsed          | 3412         |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0030453475 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.45         |
|    cost_value_loss       | 19.7         |
|    cost_values           | 0.979        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.592        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.44         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.882        |
|    value_loss            | 1.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.344        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.344        |
| reward                   | -0.37659508  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -535         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 45           |
|    time_elapsed          | 10108        |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0044202926 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.63         |
|    cost_value_loss       | 33.9         |
|    cost_values           | 0.942        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.873        |
|    lagrangian_multiplier | 0.00437      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.82         |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.963        |
|    value_loss            | 21.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.4025826  |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -561        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 4           |
|    time_elapsed          | 985         |
|    total_timesteps       | 409600      |
| train/                   |             |
|    approx_kl             | 0.008544055 |
|    clip_fraction         | 0.0687      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.4         |
|    cost_value_loss       | 3.69        |
|    cost_values           | 2.21        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.663       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.11        |
|    n_updates             | 1990        |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 0.801       |
|    value_loss            | 3.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.86         |
| reward                   | -0.64488065  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -549         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 2            |
|    time_elapsed          | 454          |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0033621443 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 4.67         |
|    cost_values           | 0.664        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.682        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.74         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.955        |
|    value_loss            | 1.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0203      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0203      |
| reward                   | -0.40477058 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -819        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 49          |
|    time_elapsed          | 11160       |
|    total_timesteps       | 401408      |
| train/                   |             |
|    approx_kl             | 0.006521387 |
|    clip_fraction         | 0.0716      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.31        |
|    cost_value_loss       | 29.7        |
|    cost_values           | 0.893       |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0.000217    |
|    learning_rate         | 0.0003      |
|    loss                  | 15          |
|    n_updates             | 1950        |
|    policy_gradient_loss  | -0.0064     |
|    std                   | 0.902       |
|    value_loss            | 2.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.301       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.301       |
| reward                   | -0.39706036 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -537        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 42          |
|    time_elapsed          | 9415        |
|    total_timesteps       | 387072      |
| train/                   |             |
|    approx_kl             | 0.009857066 |
|    clip_fraction         | 0.0974      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 24.7        |
|    cost_values           | 2.74        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.259       |
|    lagrangian_multiplier | 0.00229     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.06        |
|    n_updates             | 1880        |
|    policy_gradient_loss  | -0.00541    |
|    std                   | 0.995       |
|    value_loss            | 1.02        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.243        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.243        |
| reward                   | -0.54629254  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 16           |
|    time_elapsed          | 3651         |
|    total_timesteps       | 434176       |
| train/                   |              |
|    approx_kl             | 0.0023280582 |
|    clip_fraction         | 0.0534       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 3.23         |
|    cost_values           | 0.985        |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.75         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.9          |
|    n_updates             | 2110         |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 0.88         |
|    value_loss            | 1.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.324        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.324        |
| reward                   | -0.4680859   |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 46           |
|    time_elapsed          | 10363        |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0033422254 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.53         |
|    cost_value_loss       | 29.7         |
|    cost_values           | 1.14         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.871        |
|    lagrangian_multiplier | 0.00284      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.06         |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -0.00386     |
|    std                   | 0.963        |
|    value_loss            | 4.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.124        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.124        |
| reward                   | -0.25860474  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -550         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 3            |
|    time_elapsed          | 685          |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0025493829 |
|    clip_fraction         | 0.00889      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.98         |
|    cost_value_loss       | 54.1         |
|    cost_values           | 1.06         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.53         |
|    lagrangian_multiplier | 0.00113      |
|    learning_rate         | 0.0003       |
|    loss                  | 20.3         |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.955        |
|    value_loss            | 6.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.99156207  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -566         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 5            |
|    time_elapsed          | 1242         |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0021695187 |
|    clip_fraction         | 0.138        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 2.57         |
|    cost_values           | 1.87         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.768        |
|    lagrangian_multiplier | 0.00251      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.39         |
|    n_updates             | 2000         |
|    policy_gradient_loss  | 0.00644      |
|    std                   | 0.801        |
|    value_loss            | 19.9         |
-------------------------------------------
------------------------------------
| avg_speed          | 0.33        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.33        |
| reward             | -0.43849212 |
| rollout/           |             |
|    ep_len_mean     | 962         |
|    ep_rew_mean     | -818        |
| time/              |             |
|    fps             | 8           |
|    iterations      | 1           |
|    time_elapsed    | 250         |
|    total_timesteps | 403456      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.317        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.317        |
| reward                   | -0.51560634  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 17           |
|    time_elapsed          | 3890         |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0010063678 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 5.82         |
|    cost_values           | 0.757        |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0.000342     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.56         |
|    n_updates             | 2120         |
|    policy_gradient_loss  | 0.000355     |
|    std                   | 0.88         |
|    value_loss            | 6.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.37        |
| reward                   | -0.43116793 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -534        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 43          |
|    time_elapsed          | 9667        |
|    total_timesteps       | 389120      |
| train/                   |             |
|    approx_kl             | 0.008812982 |
|    clip_fraction         | 0.0602      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 8.28        |
|    cost_values           | 2.7         |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.367       |
|    lagrangian_multiplier | 0.000999    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.67        |
|    n_updates             | 1890        |
|    policy_gradient_loss  | -0.0056     |
|    std                   | 0.991       |
|    value_loss            | 1.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.275        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.275        |
| reward                   | -0.21414334  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -550         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 4            |
|    time_elapsed          | 917          |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0010777432 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.02         |
|    cost_value_loss       | 62           |
|    cost_values           | 0.964        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0.00299      |
|    learning_rate         | 0.0003       |
|    loss                  | 14.8         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.955        |
|    value_loss            | 9.81         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.938       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.938       |
| reward                   | -0.34769547 |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -526        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 47          |
|    time_elapsed          | 10623       |
|    total_timesteps       | 397312      |
| train/                   |             |
|    approx_kl             | 0.005165967 |
|    clip_fraction         | 0.0291      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.3         |
|    cost_value_loss       | 18.9        |
|    cost_values           | 1.34        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.781       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.3        |
|    n_updates             | 1930        |
|    policy_gradient_loss  | -0.00458    |
|    std                   | 0.962       |
|    value_loss            | 14          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.47105274  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -570         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 6            |
|    time_elapsed          | 1497         |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0017791458 |
|    clip_fraction         | 0.0594       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 1.67         |
|    cost_values           | 1.16         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.42         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.801        |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0967       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0967       |
| reward                   | -0.40766412  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -818         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 2            |
|    time_elapsed          | 508          |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0055443114 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.55         |
|    cost_value_loss       | 39.6         |
|    cost_values           | 1.55         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.951        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.6         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -0.00333     |
|    std                   | 0.9          |
|    value_loss            | 0.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0168       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0168       |
| reward                   | -0.5344903   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 18           |
|    time_elapsed          | 4130         |
|    total_timesteps       | 438272       |
| train/                   |              |
|    approx_kl             | 0.0052227858 |
|    clip_fraction         | 0.0615       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.641        |
|    cost_value_loss       | 0.0952       |
|    cost_values           | 0.647        |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.112        |
|    n_updates             | 2130         |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 0.881        |
|    value_loss            | 0.341        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.918        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.918        |
| reward                   | -0.3839089   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -532         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 44           |
|    time_elapsed          | 9924         |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0041125827 |
|    clip_fraction         | 0.0384       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.03         |
|    cost_value_loss       | 24           |
|    cost_values           | 2.76         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.25         |
|    lagrangian_multiplier | 0.00164      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.08         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.00202     |
|    std                   | 0.986        |
|    value_loss            | 2.18         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.83       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.83       |
| reward                   | -1.3099316 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -547       |
| time/                    |            |
|    fps                   | 8          |
|    iterations            | 5          |
|    time_elapsed          | 1156       |
|    total_timesteps       | 411648     |
| train/                   |            |
|    approx_kl             | 0.00384867 |
|    clip_fraction         | 0.0199     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.45       |
|    cost_value_loss       | 23.1       |
|    cost_values           | 0.922      |
|    entropy               | -2.74      |
|    entropy_loss          | -2.74      |
|    explained_variance    | 0.889      |
|    lagrangian_multiplier | 2.68e-05   |
|    learning_rate         | 0.0003     |
|    loss                  | 9.65       |
|    n_updates             | 2000       |
|    policy_gradient_loss  | -0.00342   |
|    std                   | 0.954      |
|    value_loss            | 1.8        |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.244       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.244       |
| reward                   | -0.39316595 |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -525        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 48          |
|    time_elapsed          | 10882       |
|    total_timesteps       | 399360      |
| train/                   |             |
|    approx_kl             | 0.001845993 |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.23        |
|    cost_value_loss       | 63.5        |
|    cost_values           | 1.74        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.665       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 33.2        |
|    n_updates             | 1940        |
|    policy_gradient_loss  | -0.00297    |
|    std                   | 0.959       |
|    value_loss            | 4.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5784668  |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -567        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 7           |
|    time_elapsed          | 1750        |
|    total_timesteps       | 415744      |
| train/                   |             |
|    approx_kl             | 0.006669362 |
|    clip_fraction         | 0.0626      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 5.31        |
|    cost_values           | 1.23        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.846       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 2020        |
|    policy_gradient_loss  | -0.0072     |
|    std                   | 0.801       |
|    value_loss            | 6.72        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.233        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.233        |
| reward                   | -0.380342    |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -818         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 3            |
|    time_elapsed          | 766          |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0069158813 |
|    clip_fraction         | 0.0567       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.94         |
|    cost_value_loss       | 67.7         |
|    cost_values           | 2.14         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0.00601      |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.00477     |
|    std                   | 0.898        |
|    value_loss            | 0.687        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.315        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.315        |
| reward                   | -0.23361899  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 19           |
|    time_elapsed          | 4372         |
|    total_timesteps       | 440320       |
| train/                   |              |
|    approx_kl             | 0.0024710018 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 22           |
|    cost_values           | 0.766        |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.927        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.73         |
|    n_updates             | 2140         |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 0.88         |
|    value_loss            | 0.811        |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.466      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.466      |
| reward                   | -0.4735328 |
| rollout/                 |            |
|    ep_len_mean           | 985        |
|    ep_rew_mean           | -530       |
| time/                    |            |
|    fps                   | 9          |
|    iterations            | 45         |
|    time_elapsed          | 10173      |
|    total_timesteps       | 393216     |
| train/                   |            |
|    approx_kl             | 0.00903064 |
|    clip_fraction         | 0.0521     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.65       |
|    cost_value_loss       | 11         |
|    cost_values           | 2.62       |
|    entropy               | -2.8       |
|    entropy_loss          | -2.8       |
|    explained_variance    | -0.0987    |
|    lagrangian_multiplier | 0.00124    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.69       |
|    n_updates             | 1910       |
|    policy_gradient_loss  | -0.00353   |
|    std                   | 0.982      |
|    value_loss            | 2.24       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.161        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.161        |
| reward                   | -0.31786025  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -549         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 6            |
|    time_elapsed          | 1391         |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0005747973 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.7          |
|    cost_value_loss       | 46.2         |
|    cost_values           | 1.11         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.933        |
|    lagrangian_multiplier | 0.00112      |
|    learning_rate         | 0.0003       |
|    loss                  | 19.7         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.000717    |
|    std                   | 0.954        |
|    value_loss            | 15.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.603       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.603       |
| reward                   | -0.29712003 |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -524        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 49          |
|    time_elapsed          | 11140       |
|    total_timesteps       | 401408      |
| train/                   |             |
|    approx_kl             | 0.005577456 |
|    clip_fraction         | 0.0237      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.63        |
|    cost_value_loss       | 15.8        |
|    cost_values           | 2.02        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.719       |
|    lagrangian_multiplier | 0.00162     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.67        |
|    n_updates             | 1950        |
|    policy_gradient_loss  | -0.00405    |
|    std                   | 0.956       |
|    value_loss            | 4.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.6329046  |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -554        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 8           |
|    time_elapsed          | 2006        |
|    total_timesteps       | 417792      |
| train/                   |             |
|    approx_kl             | 0.011602839 |
|    clip_fraction         | 0.0918      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.75        |
|    cost_value_loss       | 4.26        |
|    cost_values           | 1.18        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.01        |
|    n_updates             | 2030        |
|    policy_gradient_loss  | -0.0072     |
|    std                   | 0.8         |
|    value_loss            | 4.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.206       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.206       |
| reward                   | -0.34679702 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -814        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 4           |
|    time_elapsed          | 1026        |
|    total_timesteps       | 409600      |
| train/                   |             |
|    approx_kl             | 0.009532422 |
|    clip_fraction         | 0.0453      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.56        |
|    cost_value_loss       | 54.5        |
|    cost_values           | 2.41        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.296       |
|    lagrangian_multiplier | 0.00897     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.11        |
|    n_updates             | 1990        |
|    policy_gradient_loss  | -0.00268    |
|    std                   | 0.897       |
|    value_loss            | 1.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.106        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.106        |
| reward                   | -0.46773255  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 20           |
|    time_elapsed          | 4615         |
|    total_timesteps       | 442368       |
| train/                   |              |
|    approx_kl             | 0.0046071485 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 20.7         |
|    cost_values           | 1.02         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0.00106      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.3          |
|    n_updates             | 2150         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.879        |
|    value_loss            | 0.711        |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.61        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.61        |
| reward                   | -0.21057998 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -528        |
| time/                    |             |
|    fps                   | 9           |
|    iterations            | 46          |
|    time_elapsed          | 10421       |
|    total_timesteps       | 395264      |
| train/                   |             |
|    approx_kl             | 0.006373384 |
|    clip_fraction         | 0.0492      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 16.9        |
|    cost_values           | 2.69        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.161       |
|    lagrangian_multiplier | 0.00267     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 1920        |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 0.986       |
|    value_loss            | 11.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.147        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.147        |
| reward                   | -0.6012237   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -549         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 7            |
|    time_elapsed          | 1625         |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0016169951 |
|    clip_fraction         | 0.00308      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.323        |
|    cost_value_loss       | 0.0236       |
|    cost_values           | 0.461        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.951        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.97         |
|    n_updates             | 2020         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.955        |
|    value_loss            | 12.7         |
-------------------------------------------
------------------------------------
| avg_speed          | 0.816       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.816       |
| reward             | -0.23083042 |
| rollout/           |             |
|    ep_len_mean     | 933         |
|    ep_rew_mean     | -523        |
| time/              |             |
|    fps             | 8           |
|    iterations      | 1           |
|    time_elapsed    | 248         |
|    total_timesteps | 403456      |
------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.47305778 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -558        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 9           |
|    time_elapsed          | 2265        |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.004213055 |
|    clip_fraction         | 0.0903      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 5.75        |
|    cost_values           | 1.22        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.446       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.46        |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 0.8         |
|    value_loss            | 22.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.439       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.439       |
| reward                   | -0.47725457 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 21          |
|    time_elapsed          | 4859        |
|    total_timesteps       | 444416      |
| train/                   |             |
|    approx_kl             | 0.00530544  |
|    clip_fraction         | 0.0447      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.804       |
|    cost_value_loss       | 0.0822      |
|    cost_values           | 0.781       |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.877       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.327       |
|    n_updates             | 2160        |
|    policy_gradient_loss  | -0.00222    |
|    std                   | 0.879       |
|    value_loss            | 1.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.913        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.913        |
| reward                   | -0.4705144   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -817         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 5            |
|    time_elapsed          | 1284         |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0051693097 |
|    clip_fraction         | 0.0665       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.11         |
|    cost_value_loss       | 47.1         |
|    cost_values           | 2.37         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0.00649      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.11         |
|    n_updates             | 2000         |
|    policy_gradient_loss  | -0.00551     |
|    std                   | 0.896        |
|    value_loss            | 1.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.763        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.763        |
| reward                   | -0.26871398  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -529         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 47           |
|    time_elapsed          | 10677        |
|    total_timesteps       | 397312       |
| train/                   |              |
|    approx_kl             | 0.0048195925 |
|    clip_fraction         | 0.0298       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.49         |
|    cost_value_loss       | 57           |
|    cost_values           | 2.57         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -0.241       |
|    lagrangian_multiplier | 0.00676      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.51         |
|    n_updates             | 1930         |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 0.986        |
|    value_loss            | 12.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.138        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.138        |
| reward                   | -0.47839454  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -545         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 8            |
|    time_elapsed          | 1864         |
|    total_timesteps       | 417792       |
| train/                   |              |
|    approx_kl             | 0.0023553886 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.08         |
|    cost_value_loss       | 67.1         |
|    cost_values           | 0.672        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0.00813      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.01         |
|    n_updates             | 2030         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.955        |
|    value_loss            | 9.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.19         |
| reward                   | -0.69864064  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -523         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 2            |
|    time_elapsed          | 503          |
|    total_timesteps       | 405504       |
| train/                   |              |
|    approx_kl             | 0.0046782847 |
|    clip_fraction         | 0.0448       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.22         |
|    cost_value_loss       | 30.6         |
|    cost_values           | 2.01         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.761        |
|    lagrangian_multiplier | 0.00122      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 1970         |
|    policy_gradient_loss  | -0.00451     |
|    std                   | 0.953        |
|    value_loss            | 4            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.71995807  |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -553         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 10           |
|    time_elapsed          | 2523         |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0046624173 |
|    clip_fraction         | 0.0506       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 4.72         |
|    cost_values           | 1.26         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.36         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.00495     |
|    std                   | 0.802        |
|    value_loss            | 3.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0154       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0154       |
| reward                   | -0.20886876  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 22           |
|    time_elapsed          | 5104         |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0057316483 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 14.7         |
|    cost_values           | 0.594        |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.835        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.57         |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 0.878        |
|    value_loss            | 0.792        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0962      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0962      |
| reward                   | -0.5165913  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -814        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 6           |
|    time_elapsed          | 1546        |
|    total_timesteps       | 413696      |
| train/                   |             |
|    approx_kl             | 0.007979983 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.25        |
|    cost_value_loss       | 39.6        |
|    cost_values           | 2.28        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.853       |
|    lagrangian_multiplier | 0.00419     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.21        |
|    n_updates             | 2010        |
|    policy_gradient_loss  | 0.000463    |
|    std                   | 0.9         |
|    value_loss            | 0.957       |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.03          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.03          |
| reward                   | -0.88449556   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -544          |
| time/                    |               |
|    fps                   | 8             |
|    iterations            | 9             |
|    time_elapsed          | 2103          |
|    total_timesteps       | 419840        |
| train/                   |               |
|    approx_kl             | 0.00079028937 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 8             |
|    cost_value_loss       | 107           |
|    cost_values           | 0.956         |
|    entropy               | -2.75         |
|    entropy_loss          | -2.75         |
|    explained_variance    | 0.96          |
|    lagrangian_multiplier | 0.00205       |
|    learning_rate         | 0.0003        |
|    loss                  | 27            |
|    n_updates             | 2040          |
|    policy_gradient_loss  | -0.000422     |
|    std                   | 0.955         |
|    value_loss            | 1.16          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.399        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.399        |
| reward                   | -0.4478559   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -519         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 48           |
|    time_elapsed          | 10935        |
|    total_timesteps       | 399360       |
| train/                   |              |
|    approx_kl             | 0.0007027122 |
|    clip_fraction         | 0.000537     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.01         |
|    cost_value_loss       | 8.08         |
|    cost_values           | 2.07         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.929        |
|    lagrangian_multiplier | 0.0153       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.41         |
|    n_updates             | 1940         |
|    policy_gradient_loss  | 0.0013       |
|    std                   | 0.984        |
|    value_loss            | 4.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.243       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.243       |
| reward                   | -0.80851144 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -519        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 3           |
|    time_elapsed          | 760         |
|    total_timesteps       | 407552      |
| train/                   |             |
|    approx_kl             | 0.00491839  |
|    clip_fraction         | 0.0438      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 19.1        |
|    cost_values           | 2.01        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.000561    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.68        |
|    n_updates             | 1980        |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 0.954       |
|    value_loss            | 2.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -0.5731088   |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -548         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 11           |
|    time_elapsed          | 2780         |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0136362985 |
|    clip_fraction         | 0.122        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.9          |
|    cost_value_loss       | 3.83         |
|    cost_values           | 1.48         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.69         |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.0112      |
|    std                   | 0.801        |
|    value_loss            | 2.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.332        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.332        |
| reward                   | -0.4751983   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 23           |
|    time_elapsed          | 5350         |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0052224905 |
|    clip_fraction         | 0.0467       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 27.7         |
|    cost_values           | 0.708        |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.611        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.9         |
|    n_updates             | 2180         |
|    policy_gradient_loss  | -0.00483     |
|    std                   | 0.876        |
|    value_loss            | 3.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.159        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.159        |
| reward                   | -0.60668963  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -542         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 10           |
|    time_elapsed          | 2344         |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0038001477 |
|    clip_fraction         | 0.0084       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.95         |
|    cost_value_loss       | 62.2         |
|    cost_values           | 1.05         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.737        |
|    lagrangian_multiplier | 0.00199      |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.00413     |
|    std                   | 0.955        |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0573       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0573       |
| reward                   | -0.5757149   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -813         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 7            |
|    time_elapsed          | 1810         |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0049551986 |
|    clip_fraction         | 0.0969       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.72         |
|    cost_value_loss       | 80           |
|    cost_values           | 2.32         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.857        |
|    lagrangian_multiplier | 0.0115       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.36         |
|    n_updates             | 2020         |
|    policy_gradient_loss  | 0.00147      |
|    std                   | 0.899        |
|    value_loss            | 1.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.438        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.438        |
| reward                   | -0.2817193   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -517         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 49           |
|    time_elapsed          | 11203        |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0024335373 |
|    clip_fraction         | 0.00791      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 5.34         |
|    cost_values           | 1.59         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.249        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.985        |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0346       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0346       |
| reward                   | -0.6897174   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 4            |
|    time_elapsed          | 1020         |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0033668284 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.41         |
|    cost_value_loss       | 36.4         |
|    cost_values           | 2.3          |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.114        |
|    lagrangian_multiplier | 0.00103      |
|    learning_rate         | 0.0003       |
|    loss                  | 21.3         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 0.95         |
|    value_loss            | 20           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.52740574 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -546        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 12          |
|    time_elapsed          | 3038        |
|    total_timesteps       | 425984      |
| train/                   |             |
|    approx_kl             | 0.015893353 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 2.72        |
|    cost_values           | 1.74        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.356       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.77        |
|    n_updates             | 2070        |
|    policy_gradient_loss  | -0.00449    |
|    std                   | 0.8         |
|    value_loss            | 13.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0135       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0135       |
| reward                   | -0.35188046  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 24           |
|    time_elapsed          | 5597         |
|    total_timesteps       | 450560       |
| train/                   |              |
|    approx_kl             | 0.0035079229 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.982        |
|    cost_value_loss       | 3.07         |
|    cost_values           | 0.694        |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | -0.487       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.77         |
|    n_updates             | 2190         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.873        |
|    value_loss            | 3.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.72         |
| reward                   | -1.2554173   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -543         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 11           |
|    time_elapsed          | 2583         |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0034580142 |
|    clip_fraction         | 0.0389       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.673        |
|    cost_value_loss       | 0.138        |
|    cost_values           | 0.732        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.234        |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.00531     |
|    std                   | 0.955        |
|    value_loss            | 1.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.59983605  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 8            |
|    time_elapsed          | 2073         |
|    total_timesteps       | 417792       |
| train/                   |              |
|    approx_kl             | 0.0067925537 |
|    clip_fraction         | 0.0574       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.37         |
|    cost_value_loss       | 5.48         |
|    cost_values           | 1.93         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.0343       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.52         |
|    n_updates             | 2030         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.898        |
|    value_loss            | 0.383        |
-------------------------------------------
------------------------------------
| avg_speed          | 2.04        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 2.04        |
| reward             | -0.60541856 |
| rollout/           |             |
|    ep_len_mean     | 978         |
|    ep_rew_mean     | -512        |
| time/              |             |
|    fps             | 7           |
|    iterations      | 1           |
|    time_elapsed    | 257         |
|    total_timesteps | 403456      |
------------------------------------
------------------------------------------
| avg_speed                | 0.0646      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0646      |
| reward                   | -0.6734852  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -523        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 5           |
|    time_elapsed          | 1279        |
|    total_timesteps       | 411648      |
| train/                   |             |
|    approx_kl             | 0.007042826 |
|    clip_fraction         | 0.0346      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.08        |
|    cost_value_loss       | 42.9        |
|    cost_values           | 2.69        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.73       |
|    explained_variance    | -1.1        |
|    lagrangian_multiplier | 0.00682     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.51        |
|    n_updates             | 2000        |
|    policy_gradient_loss  | -0.00346    |
|    std                   | 0.945       |
|    value_loss            | 7.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.25808674 |
| rollout/                 |             |
|    ep_len_mean           | 925         |
|    ep_rew_mean           | -543        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 13          |
|    time_elapsed          | 3301        |
|    total_timesteps       | 428032      |
| train/                   |             |
|    approx_kl             | 0.00833764  |
|    clip_fraction         | 0.062       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.97        |
|    cost_value_loss       | 6.89        |
|    cost_values           | 1.76        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.624       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 2080        |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 0.801       |
|    value_loss            | 2.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.413        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.413        |
| reward                   | -0.3655654   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 25           |
|    time_elapsed          | 5848         |
|    total_timesteps       | 452608       |
| train/                   |              |
|    approx_kl             | 0.0045860005 |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.775        |
|    cost_value_loss       | 1.19         |
|    cost_values           | 0.691        |
|    entropy               | -2.54        |
|    entropy_loss          | -2.55        |
|    explained_variance    | -0.183       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.604        |
|    n_updates             | 2200         |
|    policy_gradient_loss  | 0.000712     |
|    std                   | 0.866        |
|    value_loss            | 0.669        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.686        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.686        |
| reward                   | -0.493291    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -543         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 12           |
|    time_elapsed          | 2824         |
|    total_timesteps       | 425984       |
| train/                   |              |
|    approx_kl             | 0.0036865664 |
|    clip_fraction         | 0.00786      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 10.9         |
|    cost_values           | 0.532        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.45         |
|    n_updates             | 2070         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.953        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0589      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0589      |
| reward                   | -0.43760768 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -818        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 9           |
|    time_elapsed          | 2335        |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.004141734 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.59        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 1.69        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.000555    |
|    learning_rate         | 0.0003      |
|    loss                  | 6           |
|    n_updates             | 2040        |
|    policy_gradient_loss  | 0.00712     |
|    std                   | 0.902       |
|    value_loss            | 0.731       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.215       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.215       |
| reward                   | -0.49464086 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -510        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 2           |
|    time_elapsed          | 513         |
|    total_timesteps       | 405504      |
| train/                   |             |
|    approx_kl             | 0.004582709 |
|    clip_fraction         | 0.0155      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.87        |
|    cost_value_loss       | 24.1        |
|    cost_values           | 2.26        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.353       |
|    lagrangian_multiplier | 0.00131     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.32        |
|    n_updates             | 1970        |
|    policy_gradient_loss  | -0.00208    |
|    std                   | 0.984       |
|    value_loss            | 1.75        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0139       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0139       |
| reward                   | -0.55051535  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -521         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 6            |
|    time_elapsed          | 1540         |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0046321154 |
|    clip_fraction         | 0.0742       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.37         |
|    cost_value_loss       | 27           |
|    cost_values           | 2.78         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.526        |
|    lagrangian_multiplier | 0.00467      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.15         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.00396     |
|    std                   | 0.937        |
|    value_loss            | 3.46         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.79876083 |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -534        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 14          |
|    time_elapsed          | 3565        |
|    total_timesteps       | 430080      |
| train/                   |             |
|    approx_kl             | 0.009058023 |
|    clip_fraction         | 0.0682      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.5         |
|    cost_value_loss       | 3.93        |
|    cost_values           | 1.98        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.333       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 2090        |
|    policy_gradient_loss  | -0.00505    |
|    std                   | 0.801       |
|    value_loss            | 14.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0408      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0408      |
| reward                   | -0.44801366 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -412        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 26          |
|    time_elapsed          | 6099        |
|    total_timesteps       | 454656      |
| train/                   |             |
|    approx_kl             | 0.003960484 |
|    clip_fraction         | 0.0362      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 0.925       |
|    entropy               | -2.55       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.749       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.56        |
|    n_updates             | 2210        |
|    policy_gradient_loss  | -0.00328    |
|    std                   | 0.87        |
|    value_loss            | 0.295       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.18         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.18         |
| reward                   | -0.41082156  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -542         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 13           |
|    time_elapsed          | 3069         |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0032472317 |
|    clip_fraction         | 0.031        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.746        |
|    cost_value_loss       | 2.02         |
|    cost_values           | 0.579        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.842        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.87         |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.0038      |
|    std                   | 0.95         |
|    value_loss            | 2.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.133        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.133        |
| reward                   | -0.37205774  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -815         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 10           |
|    time_elapsed          | 2598         |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0062005706 |
|    clip_fraction         | 0.0348       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.09         |
|    cost_value_loss       | 38.9         |
|    cost_values           | 1.61         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0.00456      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.77         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.903        |
|    value_loss            | 0.367        |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.31        |
| reward                   | -0.7498164  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -505        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 3           |
|    time_elapsed          | 770         |
|    total_timesteps       | 407552      |
| train/                   |             |
|    approx_kl             | 0.011924666 |
|    clip_fraction         | 0.0666      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 9.28        |
|    cost_values           | 2.45        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.387       |
|    lagrangian_multiplier | 0.000566    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 1980        |
|    policy_gradient_loss  | -0.00319    |
|    std                   | 0.984       |
|    value_loss            | 2.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.26        |
| reward                   | -0.47093743 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -516        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 7           |
|    time_elapsed          | 1800        |
|    total_timesteps       | 415744      |
| train/                   |             |
|    approx_kl             | 0.008947409 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.26        |
|    cost_value_loss       | 46.5        |
|    cost_values           | 2.87        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.7        |
|    explained_variance    | -0.0669     |
|    lagrangian_multiplier | 0.00677     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.38        |
|    n_updates             | 2020        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.937       |
|    value_loss            | 4           |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5313383  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -530        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 15          |
|    time_elapsed          | 3831        |
|    total_timesteps       | 432128      |
| train/                   |             |
|    approx_kl             | 0.011771873 |
|    clip_fraction         | 0.0933      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.85        |
|    cost_value_loss       | 5.4         |
|    cost_values           | 1.99        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.218       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.6        |
|    n_updates             | 2100        |
|    policy_gradient_loss  | -0.00677    |
|    std                   | 0.797       |
|    value_loss            | 24.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0184      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0184      |
| reward                   | -0.54954475 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 27          |
|    time_elapsed          | 6350        |
|    total_timesteps       | 456704      |
| train/                   |             |
|    approx_kl             | 0.005065396 |
|    clip_fraction         | 0.0349      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.11        |
|    cost_value_loss       | 15.8        |
|    cost_values           | 1.15        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.55       |
|    explained_variance    | -0.198      |
|    lagrangian_multiplier | 0.00193     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.5         |
|    n_updates             | 2220        |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.867       |
|    value_loss            | 0.968       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.242       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.242       |
| reward                   | -0.20012994 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -541        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 14          |
|    time_elapsed          | 3314        |
|    total_timesteps       | 430080      |
| train/                   |             |
|    approx_kl             | 0.005488652 |
|    clip_fraction         | 0.0598      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.91        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 0.861       |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.816       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.36        |
|    n_updates             | 2090        |
|    policy_gradient_loss  | -0.00558    |
|    std                   | 0.949       |
|    value_loss            | 0.326       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.131       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.131       |
| reward                   | -0.55965525 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -813        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 11          |
|    time_elapsed          | 2865        |
|    total_timesteps       | 423936      |
| train/                   |             |
|    approx_kl             | 0.008249225 |
|    clip_fraction         | 0.0604      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 41.3        |
|    cost_values           | 1.54        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0.00397     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.75        |
|    n_updates             | 2060        |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.904       |
|    value_loss            | 1.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.52        |
| reward                   | -0.39726788 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -499        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 4           |
|    time_elapsed          | 1029        |
|    total_timesteps       | 409600      |
| train/                   |             |
|    approx_kl             | 0.021037135 |
|    clip_fraction         | 0.328       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 9.38        |
|    cost_values           | 1.99        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.793       |
|    lagrangian_multiplier | 0.00288     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.1         |
|    n_updates             | 1990        |
|    policy_gradient_loss  | 0.017       |
|    std                   | 0.985       |
|    value_loss            | 15.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.341       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.341       |
| reward                   | -0.41958106 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -513        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 8           |
|    time_elapsed          | 2065        |
|    total_timesteps       | 417792      |
| train/                   |             |
|    approx_kl             | 0.010781325 |
|    clip_fraction         | 0.0672      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 13.5        |
|    cost_values           | 2.84        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.236       |
|    lagrangian_multiplier | 0.00358     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.01        |
|    n_updates             | 2030        |
|    policy_gradient_loss  | -0.00359    |
|    std                   | 0.939       |
|    value_loss            | 15.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.59        |
| reward                   | -0.46272725 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -532        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 16          |
|    time_elapsed          | 4100        |
|    total_timesteps       | 434176      |
| train/                   |             |
|    approx_kl             | 0.008843246 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 7.1         |
|    cost_values           | 2.12        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.63        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.36        |
|    n_updates             | 2110        |
|    policy_gradient_loss  | -0.00639    |
|    std                   | 0.794       |
|    value_loss            | 11.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0189       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0189       |
| reward                   | -0.4162844   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -541         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 15           |
|    time_elapsed          | 3558         |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0031245684 |
|    clip_fraction         | 0.00708      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.59         |
|    cost_value_loss       | 69.6         |
|    cost_values           | 1.43         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.674        |
|    lagrangian_multiplier | 0.00322      |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.000341    |
|    std                   | 0.949        |
|    value_loss            | 5.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0223       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0223       |
| reward                   | -0.5381592   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 28           |
|    time_elapsed          | 6602         |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0026914729 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 7.13         |
|    cost_values           | 1.24         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.341        |
|    lagrangian_multiplier | 0.000913     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.9          |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 0.871        |
|    value_loss            | 0.685        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0694      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0694      |
| reward                   | -0.43519142 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -817        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 12          |
|    time_elapsed          | 3133        |
|    total_timesteps       | 425984      |
| train/                   |             |
|    approx_kl             | 0.006385657 |
|    clip_fraction         | 0.0894      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.3         |
|    cost_value_loss       | 86.9        |
|    cost_values           | 1.62        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.0166      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.56        |
|    n_updates             | 2070        |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.903       |
|    value_loss            | 0.406       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.41        |
| reward                   | -0.40056524 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -502        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 5           |
|    time_elapsed          | 1287        |
|    total_timesteps       | 411648      |
| train/                   |             |
|    approx_kl             | 0.004830186 |
|    clip_fraction         | 0.0919      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.33        |
|    cost_value_loss       | 0.0269      |
|    cost_values           | 1.38        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0448      |
|    n_updates             | 2000        |
|    policy_gradient_loss  | -0.00561    |
|    std                   | 0.983       |
|    value_loss            | 0.286       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.22        |
| reward                   | -0.7538381  |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -509        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 9           |
|    time_elapsed          | 2331        |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.002211771 |
|    clip_fraction         | 0.0207      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 22.5        |
|    cost_values           | 2.8         |
|    entropy               | -2.7        |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.47        |
|    lagrangian_multiplier | 0.00507     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -0.00271    |
|    std                   | 0.937       |
|    value_loss            | 3.62        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.203        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.203        |
| reward                   | -0.5328967   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -540         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 16           |
|    time_elapsed          | 3800         |
|    total_timesteps       | 434176       |
| train/                   |              |
|    approx_kl             | 0.0144919325 |
|    clip_fraction         | 0.166        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 34.9         |
|    cost_values           | 1.81         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.574        |
|    lagrangian_multiplier | 0.00372      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.69         |
|    n_updates             | 2110         |
|    policy_gradient_loss  | -0.0156      |
|    std                   | 0.95         |
|    value_loss            | 5.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0155      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0155      |
| reward                   | -0.257813   |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 29          |
|    time_elapsed          | 6857        |
|    total_timesteps       | 460800      |
| train/                   |             |
|    approx_kl             | 0.002347629 |
|    clip_fraction         | 0.00298     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 2.42        |
|    cost_values           | 1.11        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 8.69e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.44        |
|    n_updates             | 2240        |
|    policy_gradient_loss  | -0.000356   |
|    std                   | 0.874       |
|    value_loss            | 2.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.5567825  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -527        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 17          |
|    time_elapsed          | 4371        |
|    total_timesteps       | 436224      |
| train/                   |             |
|    approx_kl             | 0.008004249 |
|    clip_fraction         | 0.0745      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.79        |
|    cost_value_loss       | 5.43        |
|    cost_values           | 2.15        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.718       |
|    lagrangian_multiplier | 2.03e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.28        |
|    n_updates             | 2120        |
|    policy_gradient_loss  | -0.00685    |
|    std                   | 0.794       |
|    value_loss            | 4.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.659        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.659        |
| reward                   | -0.3743351   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 6            |
|    time_elapsed          | 1549         |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0034785892 |
|    clip_fraction         | 0.116        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.13         |
|    cost_value_loss       | 83.5         |
|    cost_values           | 1.54         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.714        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44           |
|    n_updates             | 2010         |
|    policy_gradient_loss  | 0.00568      |
|    std                   | 0.981        |
|    value_loss            | 1.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0931      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0931      |
| reward                   | -0.1816555  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -817        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 13          |
|    time_elapsed          | 3403        |
|    total_timesteps       | 428032      |
| train/                   |             |
|    approx_kl             | 0.008697487 |
|    clip_fraction         | 0.0861      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.48        |
|    cost_value_loss       | 41.1        |
|    cost_values           | 1.69        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.00652     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.58        |
|    n_updates             | 2080        |
|    policy_gradient_loss  | -0.00588    |
|    std                   | 0.898       |
|    value_loss            | 0.259       |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.94         |
| reward                   | -0.23212355  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 10           |
|    time_elapsed          | 2592         |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0029665898 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.54         |
|    cost_value_loss       | 22.4         |
|    cost_values           | 2.86         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.0337       |
|    lagrangian_multiplier | 0.00602      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.39         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.000897    |
|    std                   | 0.932        |
|    value_loss            | 16.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.4          |
| reward                   | -0.20160896  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -540         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 17           |
|    time_elapsed          | 4047         |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0033216444 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.48         |
|    cost_value_loss       | 35.3         |
|    cost_values           | 1.33         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.64         |
|    lagrangian_multiplier | 0.00699      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.82         |
|    n_updates             | 2120         |
|    policy_gradient_loss  | 0.000457     |
|    std                   | 0.95         |
|    value_loss            | 45.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.33         |
| reward                   | -0.37006733  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 30           |
|    time_elapsed          | 7112         |
|    total_timesteps       | 462848       |
| train/                   |              |
|    approx_kl             | 0.0062162774 |
|    clip_fraction         | 0.0733       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.914        |
|    cost_value_loss       | 0.803        |
|    cost_values           | 0.85         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.827        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.456        |
|    n_updates             | 2250         |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.875        |
|    value_loss            | 0.864        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.54         |
| reward                   | -0.67795455  |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -517         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 18           |
|    time_elapsed          | 4641         |
|    total_timesteps       | 438272       |
| train/                   |              |
|    approx_kl             | 0.0069209673 |
|    clip_fraction         | 0.0587       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.97         |
|    cost_value_loss       | 4.95         |
|    cost_values           | 2.29         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.746        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.83         |
|    n_updates             | 2130         |
|    policy_gradient_loss  | -0.00786     |
|    std                   | 0.787        |
|    value_loss            | 1.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.639        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.639        |
| reward                   | -0.3803982   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 7            |
|    time_elapsed          | 1814         |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0016321884 |
|    clip_fraction         | 0.00229      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.36         |
|    cost_value_loss       | 35.2         |
|    cost_values           | 1.82         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.432        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.3         |
|    n_updates             | 2020         |
|    policy_gradient_loss  | -0.000975    |
|    std                   | 0.979        |
|    value_loss            | 2.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.468       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.468       |
| reward                   | -0.4073338  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -801        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 14          |
|    time_elapsed          | 3670        |
|    total_timesteps       | 430080      |
| train/                   |             |
|    approx_kl             | 0.002446148 |
|    clip_fraction         | 0.0168      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.62        |
|    cost_value_loss       | 16.2        |
|    cost_values           | 1.56        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.000645    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.7         |
|    n_updates             | 2090        |
|    policy_gradient_loss  | -0.00057    |
|    std                   | 0.895       |
|    value_loss            | 1.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.194        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.194        |
| reward                   | -0.51884884  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -539         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 18           |
|    time_elapsed          | 4297         |
|    total_timesteps       | 438272       |
| train/                   |              |
|    approx_kl             | 0.0043615913 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 3.05         |
|    cost_values           | 0.763        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.866        |
|    lagrangian_multiplier | 3.22e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 1.13         |
|    n_updates             | 2130         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.946        |
|    value_loss            | 0.817        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.129       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.129       |
| reward                   | -0.5281962  |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -517        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 11          |
|    time_elapsed          | 2858        |
|    total_timesteps       | 423936      |
| train/                   |             |
|    approx_kl             | 0.009136589 |
|    clip_fraction         | 0.0793      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.81        |
|    cost_value_loss       | 33.5        |
|    cost_values           | 2.89        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.378       |
|    lagrangian_multiplier | 0.00838     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.82        |
|    n_updates             | 2060        |
|    policy_gradient_loss  | -0.00603    |
|    std                   | 0.926       |
|    value_loss            | 2.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.356        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.356        |
| reward                   | -0.55541277  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 31           |
|    time_elapsed          | 7367         |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0026863057 |
|    clip_fraction         | 0.0469       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 9.02         |
|    cost_values           | 0.77         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.487        |
|    lagrangian_multiplier | 0.000243     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.49         |
|    n_updates             | 2260         |
|    policy_gradient_loss  | 0.00052      |
|    std                   | 0.877        |
|    value_loss            | 3.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.24        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.24        |
| reward                   | -0.49691764 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -508        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 19          |
|    time_elapsed          | 4911        |
|    total_timesteps       | 440320      |
| train/                   |             |
|    approx_kl             | 0.008677571 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 4.66        |
|    cost_values           | 2.52        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.209       |
|    lagrangian_multiplier | 0.000537    |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 2140        |
|    policy_gradient_loss  | -0.0035     |
|    std                   | 0.781       |
|    value_loss            | 12.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.155       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.155       |
| reward                   | -0.33274242 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -499        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 8           |
|    time_elapsed          | 2078        |
|    total_timesteps       | 417792      |
| train/                   |             |
|    approx_kl             | 0.00486309  |
|    clip_fraction         | 0.0222      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.85        |
|    cost_value_loss       | 52.3        |
|    cost_values           | 2.3         |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.172       |
|    lagrangian_multiplier | 0.00197     |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 2030        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.977       |
|    value_loss            | 5.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.155        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.155        |
| reward                   | -0.32870072  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -802         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 15           |
|    time_elapsed          | 3941         |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0042344043 |
|    clip_fraction         | 0.0141       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.9          |
|    cost_value_loss       | 29.2         |
|    cost_values           | 1.58         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.57         |
|    lagrangian_multiplier | 0.00101      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 0.892        |
|    value_loss            | 9.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.297        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.297        |
| reward                   | -0.4479051   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -544         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 19           |
|    time_elapsed          | 4548         |
|    total_timesteps       | 440320       |
| train/                   |              |
|    approx_kl             | 0.0054795505 |
|    clip_fraction         | 0.075        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.73         |
|    cost_value_loss       | 48.9         |
|    cost_values           | 1.29         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.732        |
|    lagrangian_multiplier | 0.00536      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.1          |
|    n_updates             | 2140         |
|    policy_gradient_loss  | -0.00985     |
|    std                   | 0.942        |
|    value_loss            | 3.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.467        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.467        |
| reward                   | -0.37471268  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 12           |
|    time_elapsed          | 3127         |
|    total_timesteps       | 425984       |
| train/                   |              |
|    approx_kl             | 0.0043688295 |
|    clip_fraction         | 0.0497       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.78         |
|    cost_value_loss       | 64.9         |
|    cost_values           | 2.91         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -0.552       |
|    lagrangian_multiplier | 0.00981      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.09         |
|    n_updates             | 2070         |
|    policy_gradient_loss  | -0.000928    |
|    std                   | 0.924        |
|    value_loss            | 4.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.02         |
| reward                   | -0.45152658  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 32           |
|    time_elapsed          | 7622         |
|    total_timesteps       | 466944       |
| train/                   |              |
|    approx_kl             | 0.0016233886 |
|    clip_fraction         | 0.00991      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 6.3          |
|    cost_values           | 0.782        |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.59         |
|    lagrangian_multiplier | 0.000761     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.95         |
|    n_updates             | 2270         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.876        |
|    value_loss            | 1.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34348032 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -510        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 20          |
|    time_elapsed          | 5185        |
|    total_timesteps       | 442368      |
| train/                   |             |
|    approx_kl             | 0.005208517 |
|    clip_fraction         | 0.0794      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 7.66        |
|    cost_values           | 2.6         |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.32        |
|    lagrangian_multiplier | 0.000739    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.92        |
|    n_updates             | 2150        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.78        |
|    value_loss            | 14.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.357       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.357       |
| reward                   | -0.26169565 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -495        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 9           |
|    time_elapsed          | 2344        |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.011606054 |
|    clip_fraction         | 0.0944      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.45        |
|    cost_value_loss       | 2.41        |
|    cost_values           | 2.43        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | -1.29       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.34        |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -0.00587    |
|    std                   | 0.972       |
|    value_loss            | 0.502       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0367       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0367       |
| reward                   | -0.45388013  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -791         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 16           |
|    time_elapsed          | 4215         |
|    total_timesteps       | 434176       |
| train/                   |              |
|    approx_kl             | 0.0028218203 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.34         |
|    cost_value_loss       | 29.2         |
|    cost_values           | 1.48         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 0.00372      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.01         |
|    n_updates             | 2110         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.892        |
|    value_loss            | 1.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.631       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.631       |
| reward                   | -0.5636778  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -541        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 20          |
|    time_elapsed          | 4797        |
|    total_timesteps       | 442368      |
| train/                   |             |
|    approx_kl             | 0.002019499 |
|    clip_fraction         | 0.00122     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 4.16        |
|    cost_values           | 0.95        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0.00367     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.87        |
|    n_updates             | 2150        |
|    policy_gradient_loss  | -0.00074    |
|    std                   | 0.942       |
|    value_loss            | 12.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.446       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.446       |
| reward                   | -0.45620707 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 33          |
|    time_elapsed          | 7880        |
|    total_timesteps       | 468992      |
| train/                   |             |
|    approx_kl             | 0.008625481 |
|    clip_fraction         | 0.0449      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.563       |
|    cost_value_loss       | 0.0168      |
|    cost_values           | 0.664       |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.673       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.103       |
|    n_updates             | 2280        |
|    policy_gradient_loss  | -0.00134    |
|    std                   | 0.875       |
|    value_loss            | 1.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.625        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.625        |
| reward                   | -0.31400803  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -509         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 13           |
|    time_elapsed          | 3398         |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0051242956 |
|    clip_fraction         | 0.0365       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.19         |
|    cost_value_loss       | 21.4         |
|    cost_values           | 2.88         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -0.101       |
|    lagrangian_multiplier | 0.00182      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.00442     |
|    std                   | 0.923        |
|    value_loss            | 22.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.6001898   |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -507         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 21           |
|    time_elapsed          | 5460         |
|    total_timesteps       | 444416       |
| train/                   |              |
|    approx_kl             | 0.0027844333 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.79         |
|    cost_value_loss       | 5.74         |
|    cost_values           | 2.27         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.476        |
|    lagrangian_multiplier | 0.00902      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.5          |
|    n_updates             | 2160         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.781        |
|    value_loss            | 7.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.6174581   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 10           |
|    time_elapsed          | 2606         |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0029851147 |
|    clip_fraction         | 0.212        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.24         |
|    cost_value_loss       | 16.2         |
|    cost_values           | 2.43         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.437        |
|    lagrangian_multiplier | 0.000395     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.01         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | 0.00914      |
|    std                   | 0.972        |
|    value_loss            | 1.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0832       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0832       |
| reward                   | -0.4597199   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -782         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 17           |
|    time_elapsed          | 4490         |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0027284871 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.06         |
|    cost_value_loss       | 82.4         |
|    cost_values           | 1.49         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.862        |
|    lagrangian_multiplier | 0.00677      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 2120         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.892        |
|    value_loss            | 0.746        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.406        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.406        |
| reward                   | -0.39867455  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -547         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 21           |
|    time_elapsed          | 5050         |
|    total_timesteps       | 444416       |
| train/                   |              |
|    approx_kl             | 0.0053302846 |
|    clip_fraction         | 0.0473       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 5.27         |
|    cost_values           | 0.819        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.645        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.5          |
|    n_updates             | 2160         |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 0.941        |
|    value_loss            | 1.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0162      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0162      |
| reward                   | -0.4436889  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 34          |
|    time_elapsed          | 8141        |
|    total_timesteps       | 471040      |
| train/                   |             |
|    approx_kl             | 0.009475114 |
|    clip_fraction         | 0.0214      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.696       |
|    cost_value_loss       | 1.45        |
|    cost_values           | 0.513       |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.718       |
|    n_updates             | 2290        |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 0.871       |
|    value_loss            | 0.269       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.281       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.281       |
| reward                   | -0.41035414 |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -509        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 14          |
|    time_elapsed          | 3669        |
|    total_timesteps       | 430080      |
| train/                   |             |
|    approx_kl             | 0.006803342 |
|    clip_fraction         | 0.0298      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.19        |
|    cost_value_loss       | 25.4        |
|    cost_values           | 2.74        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.493       |
|    lagrangian_multiplier | 0.00477     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.94        |
|    n_updates             | 2090        |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.92        |
|    value_loss            | 6.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.28467387 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -508        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 22          |
|    time_elapsed          | 5736        |
|    total_timesteps       | 446464      |
| train/                   |             |
|    approx_kl             | 0.007350292 |
|    clip_fraction         | 0.0789      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 6.83        |
|    cost_values           | 1.96        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.72        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.12        |
|    n_updates             | 2170        |
|    policy_gradient_loss  | -0.00606    |
|    std                   | 0.781       |
|    value_loss            | 2.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.113       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.113       |
| reward                   | -0.42306113 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -489        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 11          |
|    time_elapsed          | 2873        |
|    total_timesteps       | 423936      |
| train/                   |             |
|    approx_kl             | 0.004550883 |
|    clip_fraction         | 0.00884     |
|    clip_range            | 0.2         |
|    cost_returns          | 8.16        |
|    cost_value_loss       | 66.3        |
|    cost_values           | 2.63        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.202       |
|    lagrangian_multiplier | 0.0087      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.22        |
|    n_updates             | 2060        |
|    policy_gradient_loss  | -0.00135    |
|    std                   | 0.971       |
|    value_loss            | 5.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.256       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.256       |
| reward                   | -0.46520433 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -785        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 18          |
|    time_elapsed          | 4757        |
|    total_timesteps       | 438272      |
| train/                   |             |
|    approx_kl             | 0.009624319 |
|    clip_fraction         | 0.0683      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 141         |
|    cost_values           | 1.84        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.71        |
|    lagrangian_multiplier | 0.0147      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 2130        |
|    policy_gradient_loss  | -0.00764    |
|    std                   | 0.891       |
|    value_loss            | 1.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.308        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.308        |
| reward                   | -0.5801758   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -547         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 22           |
|    time_elapsed          | 5302         |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0058014407 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 3.53         |
|    cost_value_loss       | 35.6         |
|    cost_values           | 0.721        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.931        |
|    lagrangian_multiplier | 0.000459     |
|    learning_rate         | 0.0003       |
|    loss                  | 36.3         |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.941        |
|    value_loss            | 54.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.558        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.558        |
| reward                   | -0.266859    |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 35           |
|    time_elapsed          | 8403         |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0038905218 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.42         |
|    cost_value_loss       | 25.5         |
|    cost_values           | 0.694        |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.896        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00307     |
|    std                   | 0.869        |
|    value_loss            | 0.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.655       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.655       |
| reward                   | -0.66828984 |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -502        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 15          |
|    time_elapsed          | 3944        |
|    total_timesteps       | 432128      |
| train/                   |             |
|    approx_kl             | 0.004507609 |
|    clip_fraction         | 0.0224      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.09        |
|    cost_value_loss       | 32          |
|    cost_values           | 2.79        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | -1.55       |
|    lagrangian_multiplier | 0.00476     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.21        |
|    n_updates             | 2100        |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.916       |
|    value_loss            | 3.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5338358  |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -510        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 23          |
|    time_elapsed          | 6010        |
|    total_timesteps       | 448512      |
| train/                   |             |
|    approx_kl             | 0.010173998 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.18        |
|    cost_value_loss       | 5.08        |
|    cost_values           | 2.39        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0.00116     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.95        |
|    n_updates             | 2180        |
|    policy_gradient_loss  | -0.0101     |
|    std                   | 0.78        |
|    value_loss            | 2.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.322       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.322       |
| reward                   | -0.44584423 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -486        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 12          |
|    time_elapsed          | 3142        |
|    total_timesteps       | 425984      |
| train/                   |             |
|    approx_kl             | 0.004885741 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.76        |
|    cost_value_loss       | 45.5        |
|    cost_values           | 2.57        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.249       |
|    lagrangian_multiplier | 0.00604     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.38        |
|    n_updates             | 2070        |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.97        |
|    value_loss            | 4.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0407       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0407       |
| reward                   | -0.48820224  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -543         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 23           |
|    time_elapsed          | 5557         |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0020749085 |
|    clip_fraction         | 0.0635       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.513        |
|    cost_value_loss       | 0.219        |
|    cost_values           | 0.555        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.064        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.678        |
|    n_updates             | 2180         |
|    policy_gradient_loss  | 0.00102      |
|    std                   | 0.94         |
|    value_loss            | 1.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.251       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.251       |
| reward                   | -0.52381647 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -758        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 19          |
|    time_elapsed          | 5031        |
|    total_timesteps       | 440320      |
| train/                   |             |
|    approx_kl             | 0.006070423 |
|    clip_fraction         | 0.0506      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.9         |
|    cost_value_loss       | 46.9        |
|    cost_values           | 1.82        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0.00801     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.45        |
|    n_updates             | 2140        |
|    policy_gradient_loss  | -0.00395    |
|    std                   | 0.886       |
|    value_loss            | 0.579       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.161        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.161        |
| reward                   | -0.3289759   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 36           |
|    time_elapsed          | 8664         |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0020259805 |
|    clip_fraction         | 0.00215      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.91         |
|    cost_value_loss       | 53.4         |
|    cost_values           | 1.26         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0.00539      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.53         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.869        |
|    value_loss            | 2.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.138       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.138       |
| reward                   | -0.6305195  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -502        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 16          |
|    time_elapsed          | 4220        |
|    total_timesteps       | 434176      |
| train/                   |             |
|    approx_kl             | 0.006390685 |
|    clip_fraction         | 0.0743      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.35        |
|    cost_value_loss       | 45.4        |
|    cost_values           | 2.89        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.261       |
|    lagrangian_multiplier | 0.00716     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.19        |
|    n_updates             | 2110        |
|    policy_gradient_loss  | -0.00613    |
|    std                   | 0.914       |
|    value_loss            | 4.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.48        |
| reward                   | -0.547488   |
| rollout/                 |             |
|    ep_len_mean           | 901         |
|    ep_rew_mean           | -510        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 24          |
|    time_elapsed          | 6287        |
|    total_timesteps       | 450560      |
| train/                   |             |
|    approx_kl             | 0.003477146 |
|    clip_fraction         | 0.0459      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.22        |
|    cost_value_loss       | 4.3         |
|    cost_values           | 2.1         |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0.000865    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.19        |
|    n_updates             | 2190        |
|    policy_gradient_loss  | -0.000502   |
|    std                   | 0.78        |
|    value_loss            | 6.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.5          |
| reward                   | -0.5261546   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 13           |
|    time_elapsed          | 3414         |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0038198791 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 2.45         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.212        |
|    lagrangian_multiplier | 0.000732     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.12         |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.00302     |
|    std                   | 0.965        |
|    value_loss            | 1.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.147        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.147        |
| reward                   | -0.47113886  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -543         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 24           |
|    time_elapsed          | 5815         |
|    total_timesteps       | 450560       |
| train/                   |              |
|    approx_kl             | 0.0055931946 |
|    clip_fraction         | 0.0496       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.28         |
|    cost_value_loss       | 34           |
|    cost_values           | 0.861        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.783        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 2190         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.939        |
|    value_loss            | 2.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0156       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0156       |
| reward                   | -0.34083247  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 20           |
|    time_elapsed          | 5298         |
|    total_timesteps       | 442368       |
| train/                   |              |
|    approx_kl             | 0.0029557534 |
|    clip_fraction         | 0.0168       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.56         |
|    cost_value_loss       | 81.2         |
|    cost_values           | 1.85         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.745        |
|    lagrangian_multiplier | 0.0113       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.02         |
|    n_updates             | 2150         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.885        |
|    value_loss            | 1.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0264       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0264       |
| reward                   | -0.35081378  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 37           |
|    time_elapsed          | 8927         |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0029180418 |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 6.18         |
|    cost_values           | 0.92         |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.881        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.93         |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.000275    |
|    std                   | 0.868        |
|    value_loss            | 1.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0732      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0732      |
| reward                   | -0.3104473  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -503        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 17          |
|    time_elapsed          | 4495        |
|    total_timesteps       | 436224      |
| train/                   |             |
|    approx_kl             | 0.007001318 |
|    clip_fraction         | 0.0948      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 33.8        |
|    cost_values           | 2.35        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0.149       |
|    learning_rate         | 0.0003      |
|    loss                  | 2.39        |
|    n_updates             | 2120        |
|    policy_gradient_loss  | 0.00579     |
|    std                   | 0.913       |
|    value_loss            | 10.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5346745  |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -506        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 25          |
|    time_elapsed          | 6567        |
|    total_timesteps       | 452608      |
| train/                   |             |
|    approx_kl             | 0.008017691 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.12        |
|    cost_value_loss       | 6.64        |
|    cost_values           | 1.91        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.606       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 2200        |
|    policy_gradient_loss  | -0.0061     |
|    std                   | 0.782       |
|    value_loss            | 13.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.204        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.204        |
| reward                   | -0.43296233  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 14           |
|    time_elapsed          | 3682         |
|    total_timesteps       | 430080       |
| train/                   |              |
|    approx_kl             | 0.0029051923 |
|    clip_fraction         | 0.00703      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 3.49         |
|    cost_values           | 2.1          |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0.00648      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.38         |
|    n_updates             | 2090         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.963        |
|    value_loss            | 3.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.471        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.471        |
| reward                   | -0.57226884  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -541         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 25           |
|    time_elapsed          | 6073         |
|    total_timesteps       | 452608       |
| train/                   |              |
|    approx_kl             | 0.0005811153 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 8.25         |
|    cost_value_loss       | 101          |
|    cost_values           | 1.6          |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | -0.732       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49.3         |
|    n_updates             | 2200         |
|    policy_gradient_loss  | 0.000139     |
|    std                   | 0.939        |
|    value_loss            | 4.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.107       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.107       |
| reward                   | -0.37231988 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -730        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 21          |
|    time_elapsed          | 5569        |
|    total_timesteps       | 444416      |
| train/                   |             |
|    approx_kl             | 0.005244553 |
|    clip_fraction         | 0.0128      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 119         |
|    cost_values           | 2.08        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.705       |
|    lagrangian_multiplier | 0.0131      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.97        |
|    n_updates             | 2160        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.884       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.398       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.398       |
| reward                   | -0.37011588 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 38          |
|    time_elapsed          | 9191        |
|    total_timesteps       | 479232      |
| train/                   |             |
|    approx_kl             | 0.008637366 |
|    clip_fraction         | 0.0712      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 31.1        |
|    cost_values           | 1.02        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0.00247     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.31        |
|    n_updates             | 2330        |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.866       |
|    value_loss            | 0.518       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0189       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0189       |
| reward                   | -0.3478888   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 18           |
|    time_elapsed          | 4771         |
|    total_timesteps       | 438272       |
| train/                   |              |
|    approx_kl             | 0.0033132364 |
|    clip_fraction         | 0.00659      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.01         |
|    cost_value_loss       | 65.3         |
|    cost_values           | 1.57         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.923        |
|    lagrangian_multiplier | 0.00738      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.83         |
|    n_updates             | 2130         |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.913        |
|    value_loss            | 9.24         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.53905773 |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -504        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 26          |
|    time_elapsed          | 6848        |
|    total_timesteps       | 454656      |
| train/                   |             |
|    approx_kl             | 0.012014357 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 8.24        |
|    cost_values           | 2.12        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.566       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.49        |
|    n_updates             | 2210        |
|    policy_gradient_loss  | -0.00967    |
|    std                   | 0.781       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0821       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0821       |
| reward                   | -0.2519286   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -542         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 26           |
|    time_elapsed          | 6329         |
|    total_timesteps       | 454656       |
| train/                   |              |
|    approx_kl             | 0.0008737281 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 8.19         |
|    cost_value_loss       | 78.4         |
|    cost_values           | 2.14         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.163        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.5         |
|    n_updates             | 2210         |
|    policy_gradient_loss  | -0.000759    |
|    std                   | 0.939        |
|    value_loss            | 1.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.336       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.336       |
| reward                   | -0.4372212  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -485        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 15          |
|    time_elapsed          | 3966        |
|    total_timesteps       | 432128      |
| train/                   |             |
|    approx_kl             | 0.002598947 |
|    clip_fraction         | 0.00601     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.32        |
|    cost_value_loss       | 30.4        |
|    cost_values           | 1.74        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.568       |
|    lagrangian_multiplier | 0.00405     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.22        |
|    n_updates             | 2100        |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.963       |
|    value_loss            | 4.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.19         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.19         |
| reward                   | -0.4890173   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 22           |
|    time_elapsed          | 5844         |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0059540793 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.45         |
|    cost_value_loss       | 26.4         |
|    cost_values           | 2.13         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.835        |
|    lagrangian_multiplier | 0.004        |
|    learning_rate         | 0.0003       |
|    loss                  | 5.73         |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.0038      |
|    std                   | 0.884        |
|    value_loss            | 0.766        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.211       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.211       |
| reward                   | -0.41978136 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 39          |
|    time_elapsed          | 9456        |
|    total_timesteps       | 481280      |
| train/                   |             |
|    approx_kl             | 0.003392113 |
|    clip_fraction         | 0.0303      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 2.12        |
|    cost_values           | 0.854       |
|    entropy               | -2.53       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.168       |
|    lagrangian_multiplier | 0.000106    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.3         |
|    n_updates             | 2340        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.865       |
|    value_loss            | 0.915       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.302        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.302        |
| reward                   | -0.24010594  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -500         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 19           |
|    time_elapsed          | 5050         |
|    total_timesteps       | 440320       |
| train/                   |              |
|    approx_kl             | 0.0029930824 |
|    clip_fraction         | 0.0141       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.17         |
|    cost_value_loss       | 28.8         |
|    cost_values           | 1.16         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.876        |
|    lagrangian_multiplier | 0.00124      |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 2140         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.914        |
|    value_loss            | 22.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.4606127  |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -510        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 27          |
|    time_elapsed          | 7127        |
|    total_timesteps       | 456704      |
| train/                   |             |
|    approx_kl             | 0.009609135 |
|    clip_fraction         | 0.0928      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 8.37        |
|    cost_values           | 2.51        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.42        |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.83        |
|    n_updates             | 2220        |
|    policy_gradient_loss  | -0.00888    |
|    std                   | 0.78        |
|    value_loss            | 2.03        |
------------------------------------------
--------------------------------------------
| avg_speed                | 1.79          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.79          |
| reward                   | -0.52375054   |
| rollout/                 |               |
|    ep_len_mean           | 994           |
|    ep_rew_mean           | -540          |
| time/                    |               |
|    fps                   | 8             |
|    iterations            | 27            |
|    time_elapsed          | 6589          |
|    total_timesteps       | 456704        |
| train/                   |               |
|    approx_kl             | 0.00012015941 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 8.34          |
|    cost_value_loss       | 91.1          |
|    cost_values           | 2.11          |
|    entropy               | -2.71         |
|    entropy_loss          | -2.71         |
|    explained_variance    | 0.0898        |
|    lagrangian_multiplier | 0.00952       |
|    learning_rate         | 0.0003        |
|    loss                  | 10.2          |
|    n_updates             | 2220          |
|    policy_gradient_loss  | -7.05e-05     |
|    std                   | 0.939         |
|    value_loss            | 9.3           |
--------------------------------------------
------------------------------------------
| avg_speed                | 0.292       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.292       |
| reward                   | -0.48668483 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -481        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 16          |
|    time_elapsed          | 4244        |
|    total_timesteps       | 434176      |
| train/                   |             |
|    approx_kl             | 0.009681434 |
|    clip_fraction         | 0.0509      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 5.64        |
|    cost_values           | 1.82        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 7.87e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.39        |
|    n_updates             | 2110        |
|    policy_gradient_loss  | -0.0053     |
|    std                   | 0.962       |
|    value_loss            | 0.792       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00338     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00338     |
| reward                   | -0.5382751  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -712        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 23          |
|    time_elapsed          | 6114        |
|    total_timesteps       | 448512      |
| train/                   |             |
|    approx_kl             | 0.007992048 |
|    clip_fraction         | 0.0686      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 168         |
|    cost_values           | 2.27        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0.0238      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.5         |
|    n_updates             | 2180        |
|    policy_gradient_loss  | -0.00438    |
|    std                   | 0.885       |
|    value_loss            | 0.462       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0777       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0777       |
| reward                   | -0.39336586  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 40           |
|    time_elapsed          | 9725         |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0047625666 |
|    clip_fraction         | 0.0195       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.662        |
|    cost_value_loss       | 0.018        |
|    cost_values           | 0.758        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0.000142     |
|    learning_rate         | 0.0003       |
|    loss                  | 0.131        |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.86         |
|    value_loss            | 0.236        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.425        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.425        |
| reward                   | -0.5272586   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -498         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 20           |
|    time_elapsed          | 5333         |
|    total_timesteps       | 442368       |
| train/                   |              |
|    approx_kl             | 0.0075100022 |
|    clip_fraction         | 0.048        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.3          |
|    cost_value_loss       | 52.3         |
|    cost_values           | 1.1          |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0.0059       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.54         |
|    n_updates             | 2150         |
|    policy_gradient_loss  | -0.00837     |
|    std                   | 0.916        |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.248        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.248        |
| reward                   | -0.4932715   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -548         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 28           |
|    time_elapsed          | 6853         |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0014103462 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.94         |
|    cost_value_loss       | 35.9         |
|    cost_values           | 1.47         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.78         |
|    lagrangian_multiplier | 0.0086       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.6          |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.000816    |
|    std                   | 0.937        |
|    value_loss            | 3.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.788117   |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -511        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 28          |
|    time_elapsed          | 7410        |
|    total_timesteps       | 458752      |
| train/                   |             |
|    approx_kl             | 0.009108865 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.33        |
|    cost_value_loss       | 8.02        |
|    cost_values           | 2.84        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.371       |
|    lagrangian_multiplier | 0.00172     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.96        |
|    n_updates             | 2230        |
|    policy_gradient_loss  | -0.00372    |
|    std                   | 0.778       |
|    value_loss            | 15.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.371        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.371        |
| reward                   | -0.51821494  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 17           |
|    time_elapsed          | 4523         |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0035150053 |
|    clip_fraction         | 0.0525       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.09         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 1.95         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.738        |
|    lagrangian_multiplier | 0.00156      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 2120         |
|    policy_gradient_loss  | 0.0011       |
|    std                   | 0.961        |
|    value_loss            | 2.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -2.464463    |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 24           |
|    time_elapsed          | 6384         |
|    total_timesteps       | 450560       |
| train/                   |              |
|    approx_kl             | 0.0054764217 |
|    clip_fraction         | 0.0412       |
|    clip_range            | 0.2          |
|    cost_returns          | 10           |
|    cost_value_loss       | 120          |
|    cost_values           | 2.1          |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.863        |
|    lagrangian_multiplier | 0.0114       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 2190         |
|    policy_gradient_loss  | -0.00427     |
|    std                   | 0.887        |
|    value_loss            | 0.676        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.399        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.399        |
| reward                   | -0.5531246   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 41           |
|    time_elapsed          | 9994         |
|    total_timesteps       | 485376       |
| train/                   |              |
|    approx_kl             | 0.0044352296 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.579        |
|    cost_value_loss       | 0.00856      |
|    cost_values           | 0.59         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | -2.51        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0507       |
|    n_updates             | 2360         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.863        |
|    value_loss            | 0.367        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0544       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0544       |
| reward                   | -0.5741292   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 21           |
|    time_elapsed          | 5616         |
|    total_timesteps       | 444416       |
| train/                   |              |
|    approx_kl             | 0.0069551254 |
|    clip_fraction         | 0.068        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.26         |
|    cost_value_loss       | 19.4         |
|    cost_values           | 1.35         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.384        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 2160         |
|    policy_gradient_loss  | -0.00649     |
|    std                   | 0.913        |
|    value_loss            | 6.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.17         |
| reward                   | -0.8088435   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -548         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 29           |
|    time_elapsed          | 7111         |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0037236176 |
|    clip_fraction         | 0.0472       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.36         |
|    cost_value_loss       | 30.5         |
|    cost_values           | 0.902        |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.904        |
|    lagrangian_multiplier | 0.0129       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.23         |
|    n_updates             | 2240         |
|    policy_gradient_loss  | 0.00211      |
|    std                   | 0.937        |
|    value_loss            | 20.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.63621354 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -512        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 29          |
|    time_elapsed          | 7695        |
|    total_timesteps       | 460800      |
| train/                   |             |
|    approx_kl             | 0.009601141 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.49        |
|    cost_value_loss       | 9.48        |
|    cost_values           | 2.81        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.748       |
|    lagrangian_multiplier | 0.00343     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 2240        |
|    policy_gradient_loss  | -0.0109     |
|    std                   | 0.777       |
|    value_loss            | 2.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0383      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0383      |
| reward                   | -0.49192965 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -474        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 18          |
|    time_elapsed          | 4799        |
|    total_timesteps       | 438272      |
| train/                   |             |
|    approx_kl             | 0.003186483 |
|    clip_fraction         | 0.0459      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 0.0536      |
|    cost_values           | 1.57        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | -0.0878     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.47        |
|    n_updates             | 2130        |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.961       |
|    value_loss            | 3.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.167       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.167       |
| reward                   | -0.4600784  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -708        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 25          |
|    time_elapsed          | 6660        |
|    total_timesteps       | 452608      |
| train/                   |             |
|    approx_kl             | 0.003497211 |
|    clip_fraction         | 0.0149      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.49        |
|    cost_value_loss       | 69.7        |
|    cost_values           | 1.75        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.216       |
|    lagrangian_multiplier | 0.033       |
|    learning_rate         | 0.0003      |
|    loss                  | 3.65        |
|    n_updates             | 2200        |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.888       |
|    value_loss            | 11          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0467       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0467       |
| reward                   | -0.5225357   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 42           |
|    time_elapsed          | 10263        |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0054128794 |
|    clip_fraction         | 0.0294       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.729        |
|    cost_value_loss       | 2.47         |
|    cost_values           | 0.549        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.899        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.42         |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.864        |
|    value_loss            | 1.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.27         |
| reward                   | -0.45946747  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -493         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 22           |
|    time_elapsed          | 5896         |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0038806312 |
|    clip_fraction         | 0.0285       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.92         |
|    cost_value_loss       | 63.9         |
|    cost_values           | 1.77         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | -0.0769      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.5         |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.00533     |
|    std                   | 0.911        |
|    value_loss            | 2.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.3423633   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -553         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 30           |
|    time_elapsed          | 7371         |
|    total_timesteps       | 462848       |
| train/                   |              |
|    approx_kl             | 0.0071511595 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.68         |
|    cost_value_loss       | 80.1         |
|    cost_values           | 1.04         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.846        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.6         |
|    n_updates             | 2250         |
|    policy_gradient_loss  | -0.00465     |
|    std                   | 0.937        |
|    value_loss            | 3.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.67731994 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -513        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 30          |
|    time_elapsed          | 7985        |
|    total_timesteps       | 462848      |
| train/                   |             |
|    approx_kl             | 0.009544311 |
|    clip_fraction         | 0.0739      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.91        |
|    cost_value_loss       | 5.07        |
|    cost_values           | 2.51        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.616       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.41        |
|    n_updates             | 2250        |
|    policy_gradient_loss  | -0.00523    |
|    std                   | 0.778       |
|    value_loss            | 2.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.281       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.281       |
| reward                   | -0.55232286 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -467        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 19          |
|    time_elapsed          | 5073        |
|    total_timesteps       | 440320      |
| train/                   |             |
|    approx_kl             | 0.006818401 |
|    clip_fraction         | 0.0752      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.12        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 1.43        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | -0.232      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 2140        |
|    policy_gradient_loss  | -0.0061     |
|    std                   | 0.958       |
|    value_loss            | 0.93        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0665       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0665       |
| reward                   | -0.3330719   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 26           |
|    time_elapsed          | 6933         |
|    total_timesteps       | 454656       |
| train/                   |              |
|    approx_kl             | 0.0029283478 |
|    clip_fraction         | 0.00796      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.19         |
|    cost_value_loss       | 24           |
|    cost_values           | 1.17         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.647        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 2210         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.888        |
|    value_loss            | 55           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.349        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.349        |
| reward                   | -0.42202258  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 43           |
|    time_elapsed          | 10534        |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0051349523 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.398        |
|    cost_value_loss       | 0.00839      |
|    cost_values           | 0.425        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0902       |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 0.862        |
|    value_loss            | 0.405        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.12         |
| reward                   | -0.58935744  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -492         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 23           |
|    time_elapsed          | 6177         |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0038928483 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.53         |
|    cost_value_loss       | 21.7         |
|    cost_values           | 2.14         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | -0.5         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 2180         |
|    policy_gradient_loss  | -0.0039      |
|    std                   | 0.907        |
|    value_loss            | 5.88         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 5.15          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 5.15          |
| reward                   | -0.7928646    |
| rollout/                 |               |
|    ep_len_mean           | 987           |
|    ep_rew_mean           | -548          |
| time/                    |               |
|    fps                   | 8             |
|    iterations            | 31            |
|    time_elapsed          | 7634          |
|    total_timesteps       | 464896        |
| train/                   |               |
|    approx_kl             | 0.00076254073 |
|    clip_fraction         | 0.000391      |
|    clip_range            | 0.2           |
|    cost_returns          | 1.66          |
|    cost_value_loss       | 9.35          |
|    cost_values           | 0.735         |
|    entropy               | -2.71         |
|    entropy_loss          | -2.71         |
|    explained_variance    | 0.957         |
|    lagrangian_multiplier | 0.000606      |
|    learning_rate         | 0.0003        |
|    loss                  | 11.4          |
|    n_updates             | 2260          |
|    policy_gradient_loss  | -0.00092      |
|    std                   | 0.937         |
|    value_loss            | 19.6          |
--------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.40338004 |
| rollout/                 |             |
|    ep_len_mean           | 904         |
|    ep_rew_mean           | -510        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 31          |
|    time_elapsed          | 8270        |
|    total_timesteps       | 464896      |
| train/                   |             |
|    approx_kl             | 0.017477551 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.55        |
|    cost_value_loss       | 8.08        |
|    cost_values           | 2.39        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.288       |
|    lagrangian_multiplier | 0.00396     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.11        |
|    n_updates             | 2260        |
|    policy_gradient_loss  | -0.00997    |
|    std                   | 0.77        |
|    value_loss            | 1.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.5418942   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -695         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 27           |
|    time_elapsed          | 7205         |
|    total_timesteps       | 456704       |
| train/                   |              |
|    approx_kl             | 0.0076755164 |
|    clip_fraction         | 0.0591       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.67         |
|    cost_value_loss       | 70.2         |
|    cost_values           | 1.06         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.679        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.4         |
|    n_updates             | 2220         |
|    policy_gradient_loss  | -0.00717     |
|    std                   | 0.888        |
|    value_loss            | 1.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.275        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.275        |
| reward                   | -0.38869277  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -465         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 20           |
|    time_elapsed          | 5357         |
|    total_timesteps       | 442368       |
| train/                   |              |
|    approx_kl             | 0.0041875374 |
|    clip_fraction         | 0.0172       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 0.0632       |
|    cost_values           | 1.49         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -0.0377      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.968        |
|    n_updates             | 2150         |
|    policy_gradient_loss  | -0.000588    |
|    std                   | 0.958        |
|    value_loss            | 2.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.136        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.136        |
| reward                   | -0.3748014   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 44           |
|    time_elapsed          | 10808        |
|    total_timesteps       | 491520       |
| train/                   |              |
|    approx_kl             | 0.0033539967 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.815        |
|    cost_value_loss       | 6.03         |
|    cost_values           | 0.435        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.92         |
|    n_updates             | 2390         |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.859        |
|    value_loss            | 0.524        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0438      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0438      |
| reward                   | -0.3738287  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -556        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 32          |
|    time_elapsed          | 7900        |
|    total_timesteps       | 466944      |
| train/                   |             |
|    approx_kl             | 0.004261565 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.47        |
|    cost_value_loss       | 19.4        |
|    cost_values           | 0.86        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.647       |
|    lagrangian_multiplier | 0.00207     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.74        |
|    n_updates             | 2270        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.937       |
|    value_loss            | 9.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0494       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0494       |
| reward                   | -0.49627048  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -489         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 24           |
|    time_elapsed          | 6464         |
|    total_timesteps       | 450560       |
| train/                   |              |
|    approx_kl             | 0.0065589193 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.5         |
|    cost_value_loss       | 102          |
|    cost_values           | 2.59         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.564        |
|    lagrangian_multiplier | 0.0149       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.32         |
|    n_updates             | 2190         |
|    policy_gradient_loss  | -0.00506     |
|    std                   | 0.905        |
|    value_loss            | 4.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.49569038 |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -505        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 32          |
|    time_elapsed          | 8556        |
|    total_timesteps       | 466944      |
| train/                   |             |
|    approx_kl             | 0.012563722 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.97        |
|    cost_value_loss       | 5.66        |
|    cost_values           | 2.27        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.852       |
|    lagrangian_multiplier | 0.00279     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.99        |
|    n_updates             | 2270        |
|    policy_gradient_loss  | -0.0093     |
|    std                   | 0.765       |
|    value_loss            | 2.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0924       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0924       |
| reward                   | -0.33200523  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -678         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 28           |
|    time_elapsed          | 7481         |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0014437338 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 147          |
|    cost_values           | 1.62         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.838        |
|    lagrangian_multiplier | 0.000394     |
|    learning_rate         | 0.0003       |
|    loss                  | 63           |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.887        |
|    value_loss            | 1.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.364       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.364       |
| reward                   | -0.49551144 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 21          |
|    time_elapsed          | 5644        |
|    total_timesteps       | 444416      |
| train/                   |             |
|    approx_kl             | 0.007523486 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.05        |
|    cost_value_loss       | 0.231       |
|    cost_values           | 1.02        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.41        |
|    n_updates             | 2160        |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.959       |
|    value_loss            | 3.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.296       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.296       |
| reward                   | -0.3465489  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 45          |
|    time_elapsed          | 11080       |
|    total_timesteps       | 493568      |
| train/                   |             |
|    approx_kl             | 0.007758689 |
|    clip_fraction         | 0.0279      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.547       |
|    cost_value_loss       | 0.976       |
|    cost_values           | 0.466       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.592       |
|    n_updates             | 2400        |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 0.86        |
|    value_loss            | 0.305       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.517        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.517        |
| reward                   | -0.38616297  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -555         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 33           |
|    time_elapsed          | 8164         |
|    total_timesteps       | 468992       |
| train/                   |              |
|    approx_kl             | 0.0019164175 |
|    clip_fraction         | 0.00249      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.11         |
|    cost_value_loss       | 23.4         |
|    cost_values           | 0.767        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.7         |
|    n_updates             | 2280         |
|    policy_gradient_loss  | 0.00014      |
|    std                   | 0.936        |
|    value_loss            | 22.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.5         |
| reward                   | -0.46305132 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -489        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 25          |
|    time_elapsed          | 6752        |
|    total_timesteps       | 452608      |
| train/                   |             |
|    approx_kl             | 0.005345591 |
|    clip_fraction         | 0.0435      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.95        |
|    cost_value_loss       | 32.1        |
|    cost_values           | 2.74        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.515       |
|    lagrangian_multiplier | 0.0037      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.1         |
|    n_updates             | 2200        |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.903       |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.47706774  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -660         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 29           |
|    time_elapsed          | 7759         |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0048400164 |
|    clip_fraction         | 0.0062       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.5         |
|    cost_value_loss       | 166          |
|    cost_values           | 2.22         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0.0189       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.86         |
|    n_updates             | 2240         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.887        |
|    value_loss            | 1.41         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -0.5122977  |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -504        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 33          |
|    time_elapsed          | 8847        |
|    total_timesteps       | 468992      |
| train/                   |             |
|    approx_kl             | 0.008563662 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.04        |
|    cost_value_loss       | 8.94        |
|    cost_values           | 2.36        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.392       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.43        |
|    n_updates             | 2280        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.765       |
|    value_loss            | 12.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.323       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.323       |
| reward                   | -0.47227648 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 46          |
|    time_elapsed          | 11352       |
|    total_timesteps       | 495616      |
| train/                   |             |
|    approx_kl             | 0.005850006 |
|    clip_fraction         | 0.023       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.706       |
|    cost_value_loss       | 3.85        |
|    cost_values           | 0.42        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.836       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.99        |
|    n_updates             | 2410        |
|    policy_gradient_loss  | -0.000867   |
|    std                   | 0.862       |
|    value_loss            | 0.563       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.057        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.057        |
| reward                   | -0.3711018   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 22           |
|    time_elapsed          | 5927         |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0020333936 |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 1.26         |
|    cost_values           | 0.985        |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.654        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.19         |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.958        |
|    value_loss            | 1.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.568       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.568       |
| reward                   | -0.52543813 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -560        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 34          |
|    time_elapsed          | 8431        |
|    total_timesteps       | 471040      |
| train/                   |             |
|    approx_kl             | 0.011588837 |
|    clip_fraction         | 0.0667      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.452       |
|    cost_value_loss       | 0.481       |
|    cost_values           | 0.407       |
|    entropy               | -2.69       |
|    entropy_loss          | -2.7        |
|    explained_variance    | -0.114      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.473       |
|    n_updates             | 2290        |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.93        |
|    value_loss            | 0.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.96687096 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -485        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 26          |
|    time_elapsed          | 7041        |
|    total_timesteps       | 454656      |
| train/                   |             |
|    approx_kl             | 0.009439417 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.45        |
|    cost_value_loss       | 57.8        |
|    cost_values           | 2.85        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.176       |
|    lagrangian_multiplier | 0.00624     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.22        |
|    n_updates             | 2210        |
|    policy_gradient_loss  | -0.00331    |
|    std                   | 0.9         |
|    value_loss            | 1.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.242        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.242        |
| reward                   | -0.3780365   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 47           |
|    time_elapsed          | 11625        |
|    total_timesteps       | 497664       |
| train/                   |              |
|    approx_kl             | 0.0034581472 |
|    clip_fraction         | 0.0415       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.23         |
|    cost_value_loss       | 35.4         |
|    cost_values           | 0.826        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0.00528      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.3          |
|    n_updates             | 2420         |
|    policy_gradient_loss  | -0.000732    |
|    std                   | 0.862        |
|    value_loss            | 1.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.126       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.126       |
| reward                   | -0.485943   |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -651        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 30          |
|    time_elapsed          | 8039        |
|    total_timesteps       | 462848      |
| train/                   |             |
|    approx_kl             | 0.004796629 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 201         |
|    cost_values           | 2.43        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.796       |
|    lagrangian_multiplier | 0.0233      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 2250        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.888       |
|    value_loss            | 2.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.62975687  |
| rollout/                 |              |
|    ep_len_mean           | 897          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 34           |
|    time_elapsed          | 9141         |
|    total_timesteps       | 471040       |
| train/                   |              |
|    approx_kl             | 0.0072331717 |
|    clip_fraction         | 0.0879       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.62         |
|    cost_value_loss       | 5.67         |
|    cost_values           | 2.66         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.678        |
|    lagrangian_multiplier | 0.00353      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.93         |
|    n_updates             | 2290         |
|    policy_gradient_loss  | -0.00888     |
|    std                   | 0.764        |
|    value_loss            | 1.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.371        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.371        |
| reward                   | -0.39437988  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 23           |
|    time_elapsed          | 6221         |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0056787794 |
|    clip_fraction         | 0.0716       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.19         |
|    cost_value_loss       | 25.6         |
|    cost_values           | 1.1          |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0.000678     |
|    learning_rate         | 0.0003       |
|    loss                  | 9.39         |
|    n_updates             | 2180         |
|    policy_gradient_loss  | -0.00565     |
|    std                   | 0.957        |
|    value_loss            | 0.884        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.214       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.214       |
| reward                   | -0.3878151  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -564        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 35          |
|    time_elapsed          | 8698        |
|    total_timesteps       | 473088      |
| train/                   |             |
|    approx_kl             | 0.008157464 |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 21.4        |
|    cost_values           | 0.68        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 5.09e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 2300        |
|    policy_gradient_loss  | 0.0248      |
|    std                   | 0.928       |
|    value_loss            | 5.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.479        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.479        |
| reward                   | -0.4820794   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 27           |
|    time_elapsed          | 7330         |
|    total_timesteps       | 456704       |
| train/                   |              |
|    approx_kl             | 0.0028764538 |
|    clip_fraction         | 0.00879      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.78         |
|    cost_value_loss       | 33           |
|    cost_values           | 2.56         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.892        |
|    lagrangian_multiplier | 0.0285       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.36         |
|    n_updates             | 2220         |
|    policy_gradient_loss  | -0.000755    |
|    std                   | 0.9          |
|    value_loss            | 3.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.443        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.443        |
| reward                   | -0.5024944   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 48           |
|    time_elapsed          | 11903        |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0029863766 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 3.76         |
|    cost_values           | 0.767        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | -3.56        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.27         |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.000746    |
|    std                   | 0.863        |
|    value_loss            | 2.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.506        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.506        |
| reward                   | -0.4609001   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -652         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 31           |
|    time_elapsed          | 8320         |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0056811864 |
|    clip_fraction         | 0.0511       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 4.51         |
|    cost_values           | 2.01         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.318        |
|    lagrangian_multiplier | 0.000454     |
|    learning_rate         | 0.0003       |
|    loss                  | 2            |
|    n_updates             | 2260         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.891        |
|    value_loss            | 0.156        |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.5078893 |
| rollout/                 |            |
|    ep_len_mean           | 897        |
|    ep_rew_mean           | -496       |
| time/                    |            |
|    fps                   | 7          |
|    iterations            | 35         |
|    time_elapsed          | 9434       |
|    total_timesteps       | 473088     |
| train/                   |            |
|    approx_kl             | 0.01017276 |
|    clip_fraction         | 0.196      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.98       |
|    cost_value_loss       | 7.86       |
|    cost_values           | 2.65       |
|    entropy               | -2.29      |
|    entropy_loss          | -2.29      |
|    explained_variance    | 0.483      |
|    lagrangian_multiplier | 0.0013     |
|    learning_rate         | 0.0003     |
|    loss                  | 6.62       |
|    n_updates             | 2300       |
|    policy_gradient_loss  | -0.00163   |
|    std                   | 0.763      |
|    value_loss            | 11.4       |
-----------------------------------------
------------------------------------------
| avg_speed                | 6.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.38        |
| reward                   | -0.40372118 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 24          |
|    time_elapsed          | 6511        |
|    total_timesteps       | 450560      |
| train/                   |             |
|    approx_kl             | 0.007840815 |
|    clip_fraction         | 0.0402      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.11        |
|    cost_value_loss       | 96.3        |
|    cost_values           | 1.48        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0.0114      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.34        |
|    n_updates             | 2190        |
|    policy_gradient_loss  | -0.00672    |
|    std                   | 0.956       |
|    value_loss            | 2.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.243        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.243        |
| reward                   | -0.16313261  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -562         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 36           |
|    time_elapsed          | 8970         |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0029756718 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 8.23         |
|    cost_values           | 0.601        |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 1.56e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.33         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 0.928        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.82         |
| reward                   | -0.47765777  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -491         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 28           |
|    time_elapsed          | 7621         |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0023777897 |
|    clip_fraction         | 0.00254      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.84         |
|    cost_value_loss       | 20.6         |
|    cost_values           | 1.44         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0.0021       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.19         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00099     |
|    std                   | 0.9          |
|    value_loss            | 9.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.495        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.495        |
| reward                   | -0.24743892  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 49           |
|    time_elapsed          | 12180        |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0035304474 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 9.11         |
|    cost_values           | 0.646        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.517        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.2          |
|    n_updates             | 2440         |
|    policy_gradient_loss  | 0.000134     |
|    std                   | 0.864        |
|    value_loss            | 2.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.473       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.473       |
| reward                   | -0.3869844  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -656        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 32          |
|    time_elapsed          | 8607        |
|    total_timesteps       | 466944      |
| train/                   |             |
|    approx_kl             | 0.008540807 |
|    clip_fraction         | 0.0673      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.44        |
|    cost_value_loss       | 5.63        |
|    cost_values           | 1.96        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -0.247      |
|    lagrangian_multiplier | 0.00143     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.82        |
|    n_updates             | 2270        |
|    policy_gradient_loss  | 0.000379    |
|    std                   | 0.895       |
|    value_loss            | 0.687       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.711944   |
| rollout/                 |             |
|    ep_len_mean           | 888         |
|    ep_rew_mean           | -489        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 36          |
|    time_elapsed          | 9724        |
|    total_timesteps       | 475136      |
| train/                   |             |
|    approx_kl             | 0.006881926 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 7.36        |
|    cost_values           | 2.64        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0.00338     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.32        |
|    n_updates             | 2310        |
|    policy_gradient_loss  | -0.0106     |
|    std                   | 0.76        |
|    value_loss            | 2.1         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.99019635  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 25           |
|    time_elapsed          | 6797         |
|    total_timesteps       | 452608       |
| train/                   |              |
|    approx_kl             | 0.0020797425 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.58         |
|    cost_value_loss       | 46           |
|    cost_values           | 0.966        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.852        |
|    lagrangian_multiplier | 0.00737      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.04         |
|    n_updates             | 2200         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.955        |
|    value_loss            | 5.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.268        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.268        |
| reward                   | -0.5329133   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -563         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 37           |
|    time_elapsed          | 9243         |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0030358625 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.73         |
|    cost_value_loss       | 37.2         |
|    cost_values           | 1.07         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.464        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.2         |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.00451     |
|    std                   | 0.928        |
|    value_loss            | 3.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.34         |
| reward                   | -0.41633144  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 29           |
|    time_elapsed          | 7914         |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0048258463 |
|    clip_fraction         | 0.0317       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.7          |
|    cost_value_loss       | 32.3         |
|    cost_values           | 1.04         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.948        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18           |
|    n_updates             | 2240         |
|    policy_gradient_loss  | -0.0053      |
|    std                   | 0.899        |
|    value_loss            | 6.19         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/7xavsi5z
------------------------------------
| avg_speed          | 0.454       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.454       |
| reward             | -0.55934745 |
| rollout/           |             |
|    ep_len_mean     | 980         |
|    ep_rew_mean     | -413        |
| time/              |             |
|    fps             | 7           |
|    iterations      | 1           |
|    time_elapsed    | 275         |
|    total_timesteps | 503808      |
------------------------------------
------------------------------------------
| avg_speed                | 0.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.25        |
| reward                   | -0.47179446 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -647        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 33          |
|    time_elapsed          | 8887        |
|    total_timesteps       | 468992      |
| train/                   |             |
|    approx_kl             | 0.004891517 |
|    clip_fraction         | 0.0334      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 144         |
|    cost_values           | 2.19        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0.0213      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.17        |
|    n_updates             | 2280        |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.894       |
|    value_loss            | 0.612       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -0.6763549   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 26           |
|    time_elapsed          | 7081         |
|    total_timesteps       | 454656       |
| train/                   |              |
|    approx_kl             | 0.0050835065 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 0.605        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.949        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.28         |
|    n_updates             | 2210         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.956        |
|    value_loss            | 6.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5473777  |
| rollout/                 |             |
|    ep_len_mean           | 878         |
|    ep_rew_mean           | -485        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 37          |
|    time_elapsed          | 10018       |
|    total_timesteps       | 477184      |
| train/                   |             |
|    approx_kl             | 0.006223033 |
|    clip_fraction         | 0.0821      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.68        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 2.85        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.501       |
|    lagrangian_multiplier | 0.0044      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 2320        |
|    policy_gradient_loss  | -0.00601    |
|    std                   | 0.758       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.197        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.197        |
| reward                   | -0.49437183  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -554         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 38           |
|    time_elapsed          | 9512         |
|    total_timesteps       | 479232       |
| train/                   |              |
|    approx_kl             | 0.0035312194 |
|    clip_fraction         | 0.0186       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.69         |
|    cost_value_loss       | 23.6         |
|    cost_values           | 1.21         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.864        |
|    lagrangian_multiplier | 0.00223      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.01         |
|    n_updates             | 2330         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.93         |
|    value_loss            | 2.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.68669707 |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -484        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 30          |
|    time_elapsed          | 8207        |
|    total_timesteps       | 462848      |
| train/                   |             |
|    approx_kl             | 0.003801988 |
|    clip_fraction         | 0.0167      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.97        |
|    cost_value_loss       | 76.4        |
|    cost_values           | 1.21        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 35.4        |
|    n_updates             | 2250        |
|    policy_gradient_loss  | -0.0047     |
|    std                   | 0.898       |
|    value_loss            | 2.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.202       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.202       |
| reward                   | -0.45756242 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 2           |
|    time_elapsed          | 555         |
|    total_timesteps       | 505856      |
| train/                   |             |
|    approx_kl             | 0.009980446 |
|    clip_fraction         | 0.0702      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.81        |
|    cost_value_loss       | 14.8        |
|    cost_values           | 0.616       |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.65        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 2460        |
|    policy_gradient_loss  | -0.00405    |
|    std                   | 0.863       |
|    value_loss            | 6.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.372        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.372        |
| reward                   | -0.49497795  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -632         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 34           |
|    time_elapsed          | 9170         |
|    total_timesteps       | 471040       |
| train/                   |              |
|    approx_kl             | 0.0050405045 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.37         |
|    cost_value_loss       | 79.2         |
|    cost_values           | 1.72         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.841        |
|    lagrangian_multiplier | 0.00851      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.46         |
|    n_updates             | 2290         |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.895        |
|    value_loss            | 0.468        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.08         |
| reward                   | -0.57305694  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 27           |
|    time_elapsed          | 7370         |
|    total_timesteps       | 456704       |
| train/                   |              |
|    approx_kl             | 0.0052379663 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.38         |
|    cost_value_loss       | 41.7         |
|    cost_values           | 0.944        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0.00537      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.81         |
|    n_updates             | 2220         |
|    policy_gradient_loss  | -0.00696     |
|    std                   | 0.955        |
|    value_loss            | 3.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.73364496 |
| rollout/                 |             |
|    ep_len_mean           | 885         |
|    ep_rew_mean           | -488        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 38          |
|    time_elapsed          | 10314       |
|    total_timesteps       | 479232      |
| train/                   |             |
|    approx_kl             | 0.007671345 |
|    clip_fraction         | 0.0514      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 9.28        |
|    cost_values           | 2.36        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.578       |
|    lagrangian_multiplier | 0.00256     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.36        |
|    n_updates             | 2330        |
|    policy_gradient_loss  | -0.00356    |
|    std                   | 0.758       |
|    value_loss            | 7.97        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.22         |
| reward                   | -0.4818129   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -545         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 39           |
|    time_elapsed          | 9785         |
|    total_timesteps       | 481280       |
| train/                   |              |
|    approx_kl             | 0.0032524364 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.44         |
|    cost_value_loss       | 20.9         |
|    cost_values           | 1.75         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.439        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 2340         |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 0.933        |
|    value_loss            | 2.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.95         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.95         |
| reward                   | -0.35511974  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 31           |
|    time_elapsed          | 8500         |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0049448204 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 44.5         |
|    cost_values           | 1.51         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 2260         |
|    policy_gradient_loss  | -0.00472     |
|    std                   | 0.897        |
|    value_loss            | 2.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0242       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0242       |
| reward                   | -0.2818273   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 3            |
|    time_elapsed          | 836          |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0070694215 |
|    clip_fraction         | 0.0512       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.779        |
|    cost_value_loss       | 3.11         |
|    cost_values           | 0.575        |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.1          |
|    n_updates             | 2470         |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 0.862        |
|    value_loss            | 0.756        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0067       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0067       |
| reward                   | -0.27629176  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -620         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 35           |
|    time_elapsed          | 9457         |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0036207088 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.12         |
|    cost_value_loss       | 71.4         |
|    cost_values           | 1.53         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.913        |
|    lagrangian_multiplier | 0.0123       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.89         |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.895        |
|    value_loss            | 0.721        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.194        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.194        |
| reward                   | -0.5852786   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 28           |
|    time_elapsed          | 7656         |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0056351684 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.54         |
|    cost_value_loss       | 34           |
|    cost_values           | 0.903        |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.627        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.2         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00234     |
|    std                   | 0.955        |
|    value_loss            | 5.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.437        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.437        |
| reward                   | -0.44078162  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -537         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 40           |
|    time_elapsed          | 10061        |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0026083027 |
|    clip_fraction         | 0.00718      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 15.4         |
|    cost_values           | 1.03         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0.0237       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.79         |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.000383    |
|    std                   | 0.933        |
|    value_loss            | 25.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4260348  |
| rollout/                 |             |
|    ep_len_mean           | 877         |
|    ep_rew_mean           | -484        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 39          |
|    time_elapsed          | 10610       |
|    total_timesteps       | 481280      |
| train/                   |             |
|    approx_kl             | 0.009898883 |
|    clip_fraction         | 0.0735      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 8.86        |
|    cost_values           | 2.14        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.28       |
|    explained_variance    | -0.0425     |
|    lagrangian_multiplier | 0.0042      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.18        |
|    n_updates             | 2340        |
|    policy_gradient_loss  | -0.00776    |
|    std                   | 0.756       |
|    value_loss            | 1.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.58        |
| reward                   | -0.5619672  |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -478        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 32          |
|    time_elapsed          | 8795        |
|    total_timesteps       | 466944      |
| train/                   |             |
|    approx_kl             | 0.008068711 |
|    clip_fraction         | 0.0529      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.67        |
|    cost_value_loss       | 47.6        |
|    cost_values           | 1.68        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.0063      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.6         |
|    n_updates             | 2270        |
|    policy_gradient_loss  | -0.00679    |
|    std                   | 0.896       |
|    value_loss            | 2.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.705       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.705       |
| reward                   | -0.32717276 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 4           |
|    time_elapsed          | 1120        |
|    total_timesteps       | 509952      |
| train/                   |             |
|    approx_kl             | 0.004911323 |
|    clip_fraction         | 0.0331      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.539       |
|    cost_value_loss       | 0.273       |
|    cost_values           | 0.502       |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.29        |
|    n_updates             | 2480        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.861       |
|    value_loss            | 0.461       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.218        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.218        |
| reward                   | -0.4380815   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -591         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 36           |
|    time_elapsed          | 9741         |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0073944544 |
|    clip_fraction         | 0.0384       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.82         |
|    cost_value_loss       | 121          |
|    cost_values           | 1.86         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0.0187       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.0043      |
|    std                   | 0.894        |
|    value_loss            | 0.621        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.189       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.189       |
| reward                   | -0.54907995 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 29          |
|    time_elapsed          | 7944        |
|    total_timesteps       | 460800      |
| train/                   |             |
|    approx_kl             | 0.005190799 |
|    clip_fraction         | 0.0279      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.44        |
|    cost_value_loss       | 31.4        |
|    cost_values           | 1.11        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.318       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.2        |
|    n_updates             | 2240        |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 0.954       |
|    value_loss            | 2.64        |
------------------------------------------
--------------------------------------------
| avg_speed                | 8.01          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 8.01          |
| reward                   | -1.0264093    |
| rollout/                 |               |
|    ep_len_mean           | 985           |
|    ep_rew_mean           | -537          |
| time/                    |               |
|    fps                   | 8             |
|    iterations            | 41            |
|    time_elapsed          | 10337         |
|    total_timesteps       | 485376        |
| train/                   |               |
|    approx_kl             | 0.00051182706 |
|    clip_fraction         | 0.000537      |
|    clip_range            | 0.2           |
|    cost_returns          | 6.99          |
|    cost_value_loss       | 77            |
|    cost_values           | 1.21          |
|    entropy               | -2.7          |
|    entropy_loss          | -2.7          |
|    explained_variance    | -0.119        |
|    lagrangian_multiplier | 0.000549      |
|    learning_rate         | 0.0003        |
|    loss                  | 34.3          |
|    n_updates             | 2360          |
|    policy_gradient_loss  | -0.00339      |
|    std                   | 0.933         |
|    value_loss            | 16.1          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 2.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.69         |
| reward                   | -0.26288533  |
| rollout/                 |              |
|    ep_len_mean           | 874          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 40           |
|    time_elapsed          | 10904        |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0057752486 |
|    clip_fraction         | 0.114        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.93         |
|    cost_value_loss       | 8.61         |
|    cost_values           | 2.43         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.857        |
|    lagrangian_multiplier | 0.000142     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.13         |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.754        |
|    value_loss            | 7.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0396       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0396       |
| reward                   | -0.5664345   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 5            |
|    time_elapsed          | 1400         |
|    total_timesteps       | 512000       |
| train/                   |              |
|    approx_kl             | 0.0065916916 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.543        |
|    cost_value_loss       | 1.7          |
|    cost_values           | 0.459        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.64         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.47         |
|    n_updates             | 2490         |
|    policy_gradient_loss  | -0.00395     |
|    std                   | 0.858        |
|    value_loss            | 1.37         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.466       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.466       |
| reward                   | -0.3169134  |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -477        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 33          |
|    time_elapsed          | 9090        |
|    total_timesteps       | 468992      |
| train/                   |             |
|    approx_kl             | 0.007456181 |
|    clip_fraction         | 0.0554      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.47        |
|    cost_value_loss       | 18.2        |
|    cost_values           | 1.72        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 7.35e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.47        |
|    n_updates             | 2280        |
|    policy_gradient_loss  | -0.00503    |
|    std                   | 0.894       |
|    value_loss            | 3.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.2109225   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -563         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 37           |
|    time_elapsed          | 10021        |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0021544911 |
|    clip_fraction         | 0.00381      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.4         |
|    cost_value_loss       | 135          |
|    cost_values           | 1.71         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0.0526       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.93         |
|    n_updates             | 2320         |
|    policy_gradient_loss  | 0.000193     |
|    std                   | 0.894        |
|    value_loss            | 4.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.388        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.388        |
| reward                   | -0.5096816   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -538         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 42           |
|    time_elapsed          | 10615        |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0021696035 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.21         |
|    cost_value_loss       | 2.28         |
|    cost_values           | 0.849        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.92         |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.933        |
|    value_loss            | 9.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.308        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.308        |
| reward                   | -0.31050158  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 30           |
|    time_elapsed          | 8234         |
|    total_timesteps       | 462848       |
| train/                   |              |
|    approx_kl             | 0.0030616792 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 5.41         |
|    cost_values           | 1.29         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | -0.0918      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.93         |
|    n_updates             | 2250         |
|    policy_gradient_loss  | -0.00342     |
|    std                   | 0.952        |
|    value_loss            | 2.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2660753   |
| rollout/                 |              |
|    ep_len_mean           | 868          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 41           |
|    time_elapsed          | 11201        |
|    total_timesteps       | 485376       |
| train/                   |              |
|    approx_kl             | 0.0063103805 |
|    clip_fraction         | 0.07         |
|    clip_range            | 0.2          |
|    cost_returns          | 4.67         |
|    cost_value_loss       | 6.59         |
|    cost_values           | 2.59         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.661        |
|    lagrangian_multiplier | 0.00255      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.05         |
|    n_updates             | 2360         |
|    policy_gradient_loss  | -0.00564     |
|    std                   | 0.753        |
|    value_loss            | 16.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.088       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.088       |
| reward                   | -0.47105706 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 6           |
|    time_elapsed          | 1686        |
|    total_timesteps       | 514048      |
| train/                   |             |
|    approx_kl             | 0.002234754 |
|    clip_fraction         | 0.0279      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.571       |
|    cost_value_loss       | 1.51        |
|    cost_values           | 0.473       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.41        |
|    n_updates             | 2500        |
|    policy_gradient_loss  | -0.00168    |
|    std                   | 0.857       |
|    value_loss            | 1.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.464       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.464       |
| reward                   | -0.5430918  |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 34          |
|    time_elapsed          | 9387        |
|    total_timesteps       | 471040      |
| train/                   |             |
|    approx_kl             | 0.002050921 |
|    clip_fraction         | 0.00815     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.27        |
|    cost_value_loss       | 48.5        |
|    cost_values           | 1.98        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0.00398     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 2290        |
|    policy_gradient_loss  | -0.00278    |
|    std                   | 0.894       |
|    value_loss            | 2.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.154       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.154       |
| reward                   | -0.17001024 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -550        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 38          |
|    time_elapsed          | 10307       |
|    total_timesteps       | 479232      |
| train/                   |             |
|    approx_kl             | 0.001302569 |
|    clip_fraction         | 0.000439    |
|    clip_range            | 0.2         |
|    cost_returns          | 7.1         |
|    cost_value_loss       | 87.4        |
|    cost_values           | 1.33        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.809       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 41.5        |
|    n_updates             | 2330        |
|    policy_gradient_loss  | -0.000645   |
|    std                   | 0.894       |
|    value_loss            | 2.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.064       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.064       |
| reward                   | -0.28563532 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -529        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 43          |
|    time_elapsed          | 10891       |
|    total_timesteps       | 489472      |
| train/                   |             |
|    approx_kl             | 0.002412969 |
|    clip_fraction         | 0.00713     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.3         |
|    cost_value_loss       | 37.9        |
|    cost_values           | 0.554       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00189     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 2380        |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.933       |
|    value_loss            | 16.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.19         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.19         |
| reward                   | -0.47028983  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 31           |
|    time_elapsed          | 8526         |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0061870436 |
|    clip_fraction         | 0.0294       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 9.32         |
|    cost_values           | 1.44         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.583        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.24         |
|    n_updates             | 2260         |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 0.951        |
|    value_loss            | 1            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.63785475  |
| rollout/                 |              |
|    ep_len_mean           | 868          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 42           |
|    time_elapsed          | 11500        |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0072986586 |
|    clip_fraction         | 0.0898       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.79         |
|    cost_value_loss       | 6.59         |
|    cost_values           | 2.62         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.0889       |
|    lagrangian_multiplier | 0.000968     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.05         |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00761     |
|    std                   | 0.748        |
|    value_loss            | 8.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0341       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0341       |
| reward                   | -0.42612493  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 7            |
|    time_elapsed          | 1972         |
|    total_timesteps       | 516096       |
| train/                   |              |
|    approx_kl             | 0.0046547484 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.11         |
|    cost_value_loss       | 22.9         |
|    cost_values           | 0.717        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.901        |
|    lagrangian_multiplier | 0.00124      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.62         |
|    n_updates             | 2510         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.857        |
|    value_loss            | 2.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.167        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.167        |
| reward                   | -0.63996196  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 35           |
|    time_elapsed          | 9686         |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0038661994 |
|    clip_fraction         | 0.0204       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.42         |
|    cost_value_loss       | 46.2         |
|    cost_values           | 2.29         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.578        |
|    lagrangian_multiplier | 0.00444      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00328     |
|    std                   | 0.895        |
|    value_loss            | 2.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0191      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0191      |
| reward                   | -0.35731798 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -507        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 39          |
|    time_elapsed          | 10594       |
|    total_timesteps       | 481280      |
| train/                   |             |
|    approx_kl             | 0.005571406 |
|    clip_fraction         | 0.0427      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.3         |
|    cost_value_loss       | 19.1        |
|    cost_values           | 1.21        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -2.73       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 2340        |
|    policy_gradient_loss  | -0.0041     |
|    std                   | 0.895       |
|    value_loss            | 3.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.156       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.156       |
| reward                   | -0.57339036 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -518        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 44          |
|    time_elapsed          | 11172       |
|    total_timesteps       | 491520      |
| train/                   |             |
|    approx_kl             | 0.005071882 |
|    clip_fraction         | 0.0309      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 28.2        |
|    cost_values           | 0.775       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0.00163     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.39        |
|    n_updates             | 2390        |
|    policy_gradient_loss  | -0.00517    |
|    std                   | 0.934       |
|    value_loss            | 2.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.102       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.102       |
| reward                   | -0.59139395 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 32          |
|    time_elapsed          | 8828        |
|    total_timesteps       | 466944      |
| train/                   |             |
|    approx_kl             | 0.002104472 |
|    clip_fraction         | 0.018       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.72        |
|    cost_value_loss       | 49.7        |
|    cost_values           | 1.91        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.446       |
|    lagrangian_multiplier | 0.00544     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.14        |
|    n_updates             | 2270        |
|    policy_gradient_loss  | -0.00122    |
|    std                   | 0.95        |
|    value_loss            | 2.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5458448  |
| rollout/                 |             |
|    ep_len_mean           | 869         |
|    ep_rew_mean           | -473        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 43          |
|    time_elapsed          | 11798       |
|    total_timesteps       | 489472      |
| train/                   |             |
|    approx_kl             | 0.007247486 |
|    clip_fraction         | 0.049       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.03        |
|    cost_value_loss       | 8.31        |
|    cost_values           | 2.61        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0.00278     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.56        |
|    n_updates             | 2380        |
|    policy_gradient_loss  | -0.00621    |
|    std                   | 0.747       |
|    value_loss            | 1.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.269       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.269       |
| reward                   | -0.42101148 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 8           |
|    time_elapsed          | 2259        |
|    total_timesteps       | 518144      |
| train/                   |             |
|    approx_kl             | 0.00263889  |
|    clip_fraction         | 0.0875      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 3.45        |
|    cost_values           | 0.698       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0.000362    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.86        |
|    n_updates             | 2520        |
|    policy_gradient_loss  | -0.000136   |
|    std                   | 0.858       |
|    value_loss            | 8.62        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00477      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00477      |
| reward                   | -0.3981121   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -481         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 40           |
|    time_elapsed          | 10888        |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0032161872 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.27         |
|    cost_value_loss       | 43.3         |
|    cost_values           | 1.44         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.301        |
|    lagrangian_multiplier | 0.00362      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.894        |
|    value_loss            | 12           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.309       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.309       |
| reward                   | -0.26956233 |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -466        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 36          |
|    time_elapsed          | 9983        |
|    total_timesteps       | 475136      |
| train/                   |             |
|    approx_kl             | 0.003951032 |
|    clip_fraction         | 0.0298      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.32        |
|    cost_value_loss       | 59.1        |
|    cost_values           | 2.53        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.578       |
|    lagrangian_multiplier | 0.00464     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.8        |
|    n_updates             | 2310        |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.892       |
|    value_loss            | 9.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.622       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.622       |
| reward                   | -0.48335928 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -522        |
| time/                    |             |
|    fps                   | 8           |
|    iterations            | 45          |
|    time_elapsed          | 11454       |
|    total_timesteps       | 493568      |
| train/                   |             |
|    approx_kl             | 0.007328704 |
|    clip_fraction         | 0.0176      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.895       |
|    cost_value_loss       | 2.37        |
|    cost_values           | 0.519       |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 2400        |
|    policy_gradient_loss  | -0.00168    |
|    std                   | 0.934       |
|    value_loss            | 11.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.214        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.214        |
| reward                   | -0.49123788  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 33           |
|    time_elapsed          | 9117         |
|    total_timesteps       | 468992       |
| train/                   |              |
|    approx_kl             | 0.0056543415 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.52         |
|    cost_value_loss       | 48.7         |
|    cost_values           | 2.06         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.615        |
|    lagrangian_multiplier | 0.00552      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.74         |
|    n_updates             | 2280         |
|    policy_gradient_loss  | -0.00381     |
|    std                   | 0.95         |
|    value_loss            | 1.79         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6097948  |
| rollout/                 |             |
|    ep_len_mean           | 869         |
|    ep_rew_mean           | -473        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 44          |
|    time_elapsed          | 12100       |
|    total_timesteps       | 491520      |
| train/                   |             |
|    approx_kl             | 0.007829504 |
|    clip_fraction         | 0.055       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.31        |
|    cost_value_loss       | 7.46        |
|    cost_values           | 2.4         |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.825       |
|    lagrangian_multiplier | 0.000836    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 2390        |
|    policy_gradient_loss  | -0.00491    |
|    std                   | 0.746       |
|    value_loss            | 2.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.235       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.235       |
| reward                   | -0.54016834 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 9           |
|    time_elapsed          | 2546        |
|    total_timesteps       | 520192      |
| train/                   |             |
|    approx_kl             | 0.005240225 |
|    clip_fraction         | 0.0288      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 6.61        |
|    cost_values           | 0.715       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.623       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.39        |
|    n_updates             | 2530        |
|    policy_gradient_loss  | -0.00307    |
|    std                   | 0.858       |
|    value_loss            | 1.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.5625516  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 41          |
|    time_elapsed          | 11178       |
|    total_timesteps       | 485376      |
| train/                   |             |
|    approx_kl             | 0.002215268 |
|    clip_fraction         | 0.00425     |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 118         |
|    cost_values           | 1.87        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.571       |
|    lagrangian_multiplier | 0.000101    |
|    learning_rate         | 0.0003      |
|    loss                  | 53.8        |
|    n_updates             | 2360        |
|    policy_gradient_loss  | -0.000778   |
|    std                   | 0.894       |
|    value_loss            | 0.456       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.22        |
| reward                   | -0.44691846 |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -469        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 37          |
|    time_elapsed          | 10284       |
|    total_timesteps       | 477184      |
| train/                   |             |
|    approx_kl             | 0.011310153 |
|    clip_fraction         | 0.0882      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.97        |
|    cost_value_loss       | 70.5        |
|    cost_values           | 2.74        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0.00969     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.43        |
|    n_updates             | 2320        |
|    policy_gradient_loss  | -0.00759    |
|    std                   | 0.89        |
|    value_loss            | 1.97        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.5167457   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -524         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 46           |
|    time_elapsed          | 11742        |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0034603945 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 1.9          |
|    cost_values           | 0.699        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.53         |
|    n_updates             | 2410         |
|    policy_gradient_loss  | -0.00633     |
|    std                   | 0.934        |
|    value_loss            | 3.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0379       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0379       |
| reward                   | -0.27653587  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 34           |
|    time_elapsed          | 9410         |
|    total_timesteps       | 471040       |
| train/                   |              |
|    approx_kl             | 0.0035766512 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.07         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.453        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.44         |
|    n_updates             | 2290         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.948        |
|    value_loss            | 1.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.4160462  |
| rollout/                 |             |
|    ep_len_mean           | 878         |
|    ep_rew_mean           | -478        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 45          |
|    time_elapsed          | 12405       |
|    total_timesteps       | 493568      |
| train/                   |             |
|    approx_kl             | 0.009171126 |
|    clip_fraction         | 0.0722      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.72        |
|    cost_value_loss       | 7.08        |
|    cost_values           | 2.46        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.296       |
|    lagrangian_multiplier | 0.00252     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.67        |
|    n_updates             | 2400        |
|    policy_gradient_loss  | -0.00761    |
|    std                   | 0.745       |
|    value_loss            | 3.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0812       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0812       |
| reward                   | -0.43603125  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 10           |
|    time_elapsed          | 2834         |
|    total_timesteps       | 522240       |
| train/                   |              |
|    approx_kl             | 0.0024732328 |
|    clip_fraction         | 0.00693      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.751        |
|    cost_value_loss       | 1.98         |
|    cost_values           | 0.59         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.07         |
|    n_updates             | 2540         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.856        |
|    value_loss            | 1.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0516       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0516       |
| reward                   | -0.2737423   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 42           |
|    time_elapsed          | 11478        |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0035575246 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.76         |
|    cost_value_loss       | 91.7         |
|    cost_values           | 2.15         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.82         |
|    lagrangian_multiplier | 0.0145       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.22         |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.894        |
|    value_loss            | 0.765        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0599       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0599       |
| reward                   | -0.48980895  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -507         |
| time/                    |              |
|    fps                   | 8            |
|    iterations            | 47           |
|    time_elapsed          | 12026        |
|    total_timesteps       | 497664       |
| train/                   |              |
|    approx_kl             | 0.0064115985 |
|    clip_fraction         | 0.0377       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.56         |
|    cost_value_loss       | 20.1         |
|    cost_values           | 0.787        |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0.00224      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.16         |
|    n_updates             | 2420         |
|    policy_gradient_loss  | -0.00636     |
|    std                   | 0.933        |
|    value_loss            | 4.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0931       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0931       |
| reward                   | -0.4740749   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 38           |
|    time_elapsed          | 10588        |
|    total_timesteps       | 479232       |
| train/                   |              |
|    approx_kl             | 0.0036739598 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.34         |
|    cost_value_loss       | 35.9         |
|    cost_values           | 2.84         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.6         |
|    explained_variance    | -0.178       |
|    lagrangian_multiplier | 0.00461      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.8          |
|    n_updates             | 2330         |
|    policy_gradient_loss  | 0.00103      |
|    std                   | 0.893        |
|    value_loss            | 6.15         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.387      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.387      |
| reward                   | -0.5854631 |
| rollout/                 |            |
|    ep_len_mean           | 988        |
|    ep_rew_mean           | -442       |
| time/                    |            |
|    fps                   | 7          |
|    iterations            | 35         |
|    time_elapsed          | 9705       |
|    total_timesteps       | 473088     |
| train/                   |            |
|    approx_kl             | 0.00421377 |
|    clip_fraction         | 0.015      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.84       |
|    cost_value_loss       | 33.2       |
|    cost_values           | 1.93       |
|    entropy               | -2.72      |
|    entropy_loss          | -2.72      |
|    explained_variance    | 0.96       |
|    lagrangian_multiplier | 0.00302    |
|    learning_rate         | 0.0003     |
|    loss                  | 8.42       |
|    n_updates             | 2300       |
|    policy_gradient_loss  | -0.00274   |
|    std                   | 0.945      |
|    value_loss            | 1.79       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.43566713  |
| rollout/                 |              |
|    ep_len_mean           | 888          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 46           |
|    time_elapsed          | 12709        |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0049893693 |
|    clip_fraction         | 0.157        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.79         |
|    cost_value_loss       | 7.4          |
|    cost_values           | 2.52         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.562        |
|    lagrangian_multiplier | 0.00108      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.1          |
|    n_updates             | 2410         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.746        |
|    value_loss            | 3.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.381        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.381        |
| reward                   | -0.48451382  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 11           |
|    time_elapsed          | 3127         |
|    total_timesteps       | 524288       |
| train/                   |              |
|    approx_kl             | 0.0026381416 |
|    clip_fraction         | 0.00225      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.598        |
|    cost_value_loss       | 0.0187       |
|    cost_values           | 0.701        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.832        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.43         |
|    n_updates             | 2550         |
|    policy_gradient_loss  | -0.000297    |
|    std                   | 0.857        |
|    value_loss            | 3.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.115        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.115        |
| reward                   | -0.31462577  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -509         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 48           |
|    time_elapsed          | 12309        |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0019191504 |
|    clip_fraction         | 0.00229      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.77         |
|    cost_value_loss       | 100          |
|    cost_values           | 1.26         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -0.327       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52           |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.000965    |
|    std                   | 0.932        |
|    value_loss            | 5.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.325       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.325       |
| reward                   | -0.2191691  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -460        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 43          |
|    time_elapsed          | 11773       |
|    total_timesteps       | 489472      |
| train/                   |             |
|    approx_kl             | 0.006590195 |
|    clip_fraction         | 0.0451      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.8        |
|    cost_value_loss       | 153         |
|    cost_values           | 2.2         |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.461       |
|    lagrangian_multiplier | 0.0163      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 2380        |
|    policy_gradient_loss  | -0.00528    |
|    std                   | 0.892       |
|    value_loss            | 2.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.18         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.18         |
| reward                   | -0.4880934   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 39           |
|    time_elapsed          | 10894        |
|    total_timesteps       | 481280       |
| train/                   |              |
|    approx_kl             | 0.0064134193 |
|    clip_fraction         | 0.068        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.15         |
|    cost_value_loss       | 29.6         |
|    cost_values           | 2.58         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.158        |
|    lagrangian_multiplier | 0.00333      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.08         |
|    n_updates             | 2340         |
|    policy_gradient_loss  | -0.00667     |
|    std                   | 0.891        |
|    value_loss            | 4.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0449       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0449       |
| reward                   | -0.3643608   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 36           |
|    time_elapsed          | 10005        |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0036781807 |
|    clip_fraction         | 0.0275       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 1.89         |
|    cost_values           | 1.47         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.281        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.16         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.0018      |
|    std                   | 0.944        |
|    value_loss            | 4.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.5697603  |
| rollout/                 |             |
|    ep_len_mean           | 886         |
|    ep_rew_mean           | -478        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 47          |
|    time_elapsed          | 13017       |
|    total_timesteps       | 497664      |
| train/                   |             |
|    approx_kl             | 0.009378839 |
|    clip_fraction         | 0.0582      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.72        |
|    cost_value_loss       | 6.55        |
|    cost_values           | 2.62        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.00139     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.34        |
|    n_updates             | 2420        |
|    policy_gradient_loss  | -0.00748    |
|    std                   | 0.746       |
|    value_loss            | 1.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0537       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0537       |
| reward                   | -0.5559815   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 12           |
|    time_elapsed          | 3418         |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 0.0034275784 |
|    clip_fraction         | 0.00918      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.3          |
|    cost_value_loss       | 18.8         |
|    cost_values           | 0.609        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.797        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.858        |
|    value_loss            | 3.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0852       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0852       |
| reward                   | -0.27422237  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 49           |
|    time_elapsed          | 12596        |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0042523555 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.53         |
|    cost_value_loss       | 31.2         |
|    cost_values           | 1.65         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -0.467       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.931        |
|    value_loss            | 5.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.31        |
| reward                   | -0.19453841 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -451        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 44          |
|    time_elapsed          | 12075       |
|    total_timesteps       | 491520      |
| train/                   |             |
|    approx_kl             | 0.004683934 |
|    clip_fraction         | 0.0199      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.54        |
|    cost_value_loss       | 95.1        |
|    cost_values           | 2.41        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | -0.137      |
|    lagrangian_multiplier | 0.0118      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.01        |
|    n_updates             | 2390        |
|    policy_gradient_loss  | -0.00135    |
|    std                   | 0.894       |
|    value_loss            | 1.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.259        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.259        |
| reward                   | -0.4914099   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 40           |
|    time_elapsed          | 11201        |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0037277802 |
|    clip_fraction         | 0.00981      |
|    clip_range            | 0.2          |
|    cost_returns          | 7            |
|    cost_value_loss       | 60.8         |
|    cost_values           | 2.41         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0.00459      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.89         |
|    value_loss            | 4.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00815      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00815      |
| reward                   | -0.43656793  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 37           |
|    time_elapsed          | 10302        |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0047760746 |
|    clip_fraction         | 0.074        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 9.73         |
|    cost_values           | 1.54         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.838        |
|    lagrangian_multiplier | 2.89e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.71         |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.000249    |
|    std                   | 0.945        |
|    value_loss            | 0.892        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.6898559  |
| rollout/                 |             |
|    ep_len_mean           | 886         |
|    ep_rew_mean           | -471        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 48          |
|    time_elapsed          | 13317       |
|    total_timesteps       | 499712      |
| train/                   |             |
|    approx_kl             | 0.008048294 |
|    clip_fraction         | 0.0838      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.15        |
|    cost_value_loss       | 7.68        |
|    cost_values           | 2.79        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.707       |
|    lagrangian_multiplier | 0.00521     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.37        |
|    n_updates             | 2430        |
|    policy_gradient_loss  | -0.00848    |
|    std                   | 0.74        |
|    value_loss            | 12.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.40661427  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 13           |
|    time_elapsed          | 3712         |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0054891123 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 0.532        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0.000404     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.11         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 0.858        |
|    value_loss            | 7.65         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/uhktx3ql
------------------------------------
| avg_speed          | 0.0428      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0428      |
| reward             | -0.43643695 |
| rollout/           |             |
|    ep_len_mean     | 986         |
|    ep_rew_mean     | -512        |
| time/              |             |
|    fps             | 7           |
|    iterations      | 1           |
|    time_elapsed    | 286         |
|    total_timesteps | 503808      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.218        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.218        |
| reward                   | -0.31084722  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 45           |
|    time_elapsed          | 12370        |
|    total_timesteps       | 493568       |
| train/                   |              |
|    approx_kl             | 0.0024498703 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 7            |
|    cost_value_loss       | 75.8         |
|    cost_values           | 2.14         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.88         |
|    lagrangian_multiplier | 0.0647       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.12         |
|    n_updates             | 2400         |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 0.894        |
|    value_loss            | 7.78         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.76        |
| reward                   | -0.6240199  |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 41          |
|    time_elapsed          | 11507       |
|    total_timesteps       | 485376      |
| train/                   |             |
|    approx_kl             | 0.010065875 |
|    clip_fraction         | 0.0708      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.14        |
|    cost_value_loss       | 29.8        |
|    cost_values           | 2.31        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.768       |
|    lagrangian_multiplier | 0.00613     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 2360        |
|    policy_gradient_loss  | -0.00726    |
|    std                   | 0.886       |
|    value_loss            | 1.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.367        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.367        |
| reward                   | -0.5022309   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 38           |
|    time_elapsed          | 10609        |
|    total_timesteps       | 479232       |
| train/                   |              |
|    approx_kl             | 0.0030694671 |
|    clip_fraction         | 0.00244      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.6          |
|    cost_value_loss       | 33.6         |
|    cost_values           | 1.76         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.542        |
|    lagrangian_multiplier | 0.00406      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.28         |
|    n_updates             | 2330         |
|    policy_gradient_loss  | -0.000479    |
|    std                   | 0.946        |
|    value_loss            | 9.1          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.98       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.98       |
| reward                   | -0.3624741 |
| rollout/                 |            |
|    ep_len_mean           | 882        |
|    ep_rew_mean           | -464       |
| time/                    |            |
|    fps                   | 7          |
|    iterations            | 49         |
|    time_elapsed          | 13620      |
|    total_timesteps       | 501760     |
| train/                   |            |
|    approx_kl             | 0.00829445 |
|    clip_fraction         | 0.0472     |
|    clip_range            | 0.2        |
|    cost_returns          | 4.14       |
|    cost_value_loss       | 5.57       |
|    cost_values           | 2.49       |
|    entropy               | -2.22      |
|    entropy_loss          | -2.22      |
|    explained_variance    | 0.889      |
|    lagrangian_multiplier | 0.00264    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.18       |
|    n_updates             | 2440       |
|    policy_gradient_loss  | -0.00286   |
|    std                   | 0.737      |
|    value_loss            | 3.44       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.369        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.369        |
| reward                   | -0.4941409   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 14           |
|    time_elapsed          | 4003         |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0048796656 |
|    clip_fraction         | 0.0192       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 8.53         |
|    cost_values           | 0.542        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.08         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.858        |
|    value_loss            | 1.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.22631244  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -509         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 2            |
|    time_elapsed          | 576          |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0033041732 |
|    clip_fraction         | 0.00693      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.03         |
|    cost_value_loss       | 45.1         |
|    cost_values           | 1.34         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.155        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22           |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.929        |
|    value_loss            | 1.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.123        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.123        |
| reward                   | -0.5465669   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 46           |
|    time_elapsed          | 12661        |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0007225737 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 10.1         |
|    cost_value_loss       | 126          |
|    cost_values           | 1.77         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.421        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.2         |
|    n_updates             | 2410         |
|    policy_gradient_loss  | -0.000636    |
|    std                   | 0.894        |
|    value_loss            | 1.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.232        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.232        |
| reward                   | -0.2882995   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 42           |
|    time_elapsed          | 11815        |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0069977483 |
|    clip_fraction         | 0.057        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.68         |
|    cost_value_loss       | 33.9         |
|    cost_values           | 2.11         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.344        |
|    lagrangian_multiplier | 0.00927      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.03         |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 0.886        |
|    value_loss            | 21           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.197       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.197       |
| reward                   | -0.5196132  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 39          |
|    time_elapsed          | 10908       |
|    total_timesteps       | 481280      |
| train/                   |             |
|    approx_kl             | 0.003038835 |
|    clip_fraction         | 0.00991     |
|    clip_range            | 0.2         |
|    cost_returns          | 7.92        |
|    cost_value_loss       | 89          |
|    cost_values           | 1.83        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.799       |
|    lagrangian_multiplier | 0.00696     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 2340        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.944       |
|    value_loss            | 1.08        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/pe6a45mq
------------------------------------
| avg_speed          | 7.82        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.82        |
| reward             | -0.61576396 |
| rollout/           |             |
|    ep_len_mean     | 881         |
|    ep_rew_mean     | -460        |
| time/              |             |
|    fps             | 6           |
|    iterations      | 1           |
|    time_elapsed    | 306         |
|    total_timesteps | 503808      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.561        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.561        |
| reward                   | -0.25037858  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 15           |
|    time_elapsed          | 4297         |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 0.0065766093 |
|    clip_fraction         | 0.046        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 9.21         |
|    cost_values           | 0.609        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.756        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.18         |
|    n_updates             | 2590         |
|    policy_gradient_loss  | -0.00445     |
|    std                   | 0.858        |
|    value_loss            | 1.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.214        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.214        |
| reward                   | -0.54808897  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 3            |
|    time_elapsed          | 868          |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0044311075 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.23         |
|    cost_value_loss       | 18.1         |
|    cost_values           | 1.77         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.233        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.26         |
|    n_updates             | 2470         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.929        |
|    value_loss            | 0.552        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.091       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.091       |
| reward                   | -0.4820881  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 47          |
|    time_elapsed          | 12955       |
|    total_timesteps       | 497664      |
| train/                   |             |
|    approx_kl             | 0.005116458 |
|    clip_fraction         | 0.00942     |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 133         |
|    cost_values           | 2.14        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.459       |
|    lagrangian_multiplier | 0.0112      |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 2420        |
|    policy_gradient_loss  | -0.0033     |
|    std                   | 0.895       |
|    value_loss            | 2.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.133        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.133        |
| reward                   | -0.39514685  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 43           |
|    time_elapsed          | 12128        |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0073608137 |
|    clip_fraction         | 0.0758       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.67         |
|    cost_value_loss       | 60           |
|    cost_values           | 2.09         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.727        |
|    lagrangian_multiplier | 0.0109       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.03         |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.00651     |
|    std                   | 0.885        |
|    value_loss            | 11.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.234        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.234        |
| reward                   | -0.47281843  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 40           |
|    time_elapsed          | 11213        |
|    total_timesteps       | 483328       |
| train/                   |              |
|    approx_kl             | 0.0031215088 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.6         |
|    cost_value_loss       | 146          |
|    cost_values           | 2.18         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.675        |
|    lagrangian_multiplier | 0.0174       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.13         |
|    n_updates             | 2350         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.942        |
|    value_loss            | 2.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5887497  |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 2           |
|    time_elapsed          | 616         |
|    total_timesteps       | 505856      |
| train/                   |             |
|    approx_kl             | 0.009143774 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.1         |
|    cost_value_loss       | 7.58        |
|    cost_values           | 2.7         |
|    entropy               | -2.21       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.624       |
|    lagrangian_multiplier | 0.00333     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 2460        |
|    policy_gradient_loss  | -0.00625    |
|    std                   | 0.734       |
|    value_loss            | 11          |
------------------------------------------
------------------------------------------
| avg_speed                | 0.351       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.351       |
| reward                   | -0.40383267 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 16          |
|    time_elapsed          | 4593        |
|    total_timesteps       | 534528      |
| train/                   |             |
|    approx_kl             | 0.004956325 |
|    clip_fraction         | 0.0154      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 6.29        |
|    cost_values           | 0.741       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.92        |
|    n_updates             | 2600        |
|    policy_gradient_loss  | -0.0034     |
|    std                   | 0.859       |
|    value_loss            | 15.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00308     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00308     |
| reward                   | -0.3969969  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -508        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 4           |
|    time_elapsed          | 1159        |
|    total_timesteps       | 509952      |
| train/                   |             |
|    approx_kl             | 0.003503655 |
|    clip_fraction         | 0.0162      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.45        |
|    cost_value_loss       | 23.5        |
|    cost_values           | 2.2         |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | -0.213      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 2480        |
|    policy_gradient_loss  | -0.00218    |
|    std                   | 0.929       |
|    value_loss            | 4.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.349        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.349        |
| reward                   | -0.44288298  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 48           |
|    time_elapsed          | 13252        |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0011234086 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | 8.01         |
|    cost_value_loss       | 93.3         |
|    cost_values           | 1.9          |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.929        |
|    lagrangian_multiplier | 0.111        |
|    learning_rate         | 0.0003       |
|    loss                  | 2.77         |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.894        |
|    value_loss            | 37.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.158       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.158       |
| reward                   | -0.47916588 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -467        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 44          |
|    time_elapsed          | 12440       |
|    total_timesteps       | 491520      |
| train/                   |             |
|    approx_kl             | 0.007953737 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.21        |
|    cost_value_loss       | 86.6        |
|    cost_values           | 1.89        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0.00637     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.2        |
|    n_updates             | 2390        |
|    policy_gradient_loss  | -0.00254    |
|    std                   | 0.884       |
|    value_loss            | 4.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.403        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.403        |
| reward                   | -0.48726848  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 41           |
|    time_elapsed          | 11521        |
|    total_timesteps       | 485376       |
| train/                   |              |
|    approx_kl             | 0.0020126388 |
|    clip_fraction         | 0.0322       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 1.88         |
|    cost_values           | 1.69         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.72        |
|    explained_variance    | -1.37        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.24         |
|    n_updates             | 2360         |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 0.951        |
|    value_loss            | 0.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -0.6640011  |
| rollout/                 |             |
|    ep_len_mean           | 900         |
|    ep_rew_mean           | -470        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 3           |
|    time_elapsed          | 924         |
|    total_timesteps       | 507904      |
| train/                   |             |
|    approx_kl             | 0.008889994 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.53        |
|    cost_value_loss       | 9.23        |
|    cost_values           | 2.89        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.117       |
|    lagrangian_multiplier | 0.00408     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.67        |
|    n_updates             | 2470        |
|    policy_gradient_loss  | -0.00882    |
|    std                   | 0.732       |
|    value_loss            | 1.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.3942627   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 17           |
|    time_elapsed          | 4892         |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0025792536 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 0.791        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.6         |
|    n_updates             | 2610         |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.859        |
|    value_loss            | 33.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.13         |
| reward                   | -0.6080622   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -503         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 5            |
|    time_elapsed          | 1451         |
|    total_timesteps       | 512000       |
| train/                   |              |
|    approx_kl             | 0.0008909955 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.45         |
|    cost_value_loss       | 28.3         |
|    cost_values           | 2.61         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.0719       |
|    lagrangian_multiplier | 7.73e-08     |
|    learning_rate         | 0.0003       |
|    loss                  | 16.4         |
|    n_updates             | 2490         |
|    policy_gradient_loss  | -0.000146    |
|    std                   | 0.928        |
|    value_loss            | 4.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0889       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0889       |
| reward                   | -0.29636994  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 49           |
|    time_elapsed          | 13550        |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0028485488 |
|    clip_fraction         | 0.00703      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.54         |
|    cost_value_loss       | 88.8         |
|    cost_values           | 1.62         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.134        |
|    lagrangian_multiplier | 0.000924     |
|    learning_rate         | 0.0003       |
|    loss                  | 32.7         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.894        |
|    value_loss            | 8.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.819        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.819        |
| reward                   | -0.4175393   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 45           |
|    time_elapsed          | 12748        |
|    total_timesteps       | 493568       |
| train/                   |              |
|    approx_kl             | 0.0049789166 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.55         |
|    cost_value_loss       | 106          |
|    cost_values           | 1.88         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.604        |
|    lagrangian_multiplier | 0.000662     |
|    learning_rate         | 0.0003       |
|    loss                  | 41.3         |
|    n_updates             | 2400         |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.884        |
|    value_loss            | 5.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.77379006 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 42          |
|    time_elapsed          | 11821       |
|    total_timesteps       | 487424      |
| train/                   |             |
|    approx_kl             | 0.004587823 |
|    clip_fraction         | 0.0276      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.38        |
|    cost_value_loss       | 20.3        |
|    cost_values           | 1.71        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.448       |
|    lagrangian_multiplier | 0.00378     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.73        |
|    n_updates             | 2370        |
|    policy_gradient_loss  | -0.00302    |
|    std                   | 0.954       |
|    value_loss            | 3.92        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.47         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.47         |
| reward                   | -0.3670375   |
| rollout/                 |              |
|    ep_len_mean           | 900          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 4            |
|    time_elapsed          | 1233         |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0075860787 |
|    clip_fraction         | 0.0886       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.25         |
|    cost_value_loss       | 7.68         |
|    cost_values           | 2.9          |
|    entropy               | -2.2         |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.734        |
|    lagrangian_multiplier | 0.00273      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.67         |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.0054      |
|    std                   | 0.73         |
|    value_loss            | 2.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.156        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.156        |
| reward                   | -0.39184773  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 18           |
|    time_elapsed          | 5192         |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0065816697 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 0.718        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.09         |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.00573     |
|    std                   | 0.859        |
|    value_loss            | 3.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.279        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.279        |
| reward                   | -0.5200027   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 6            |
|    time_elapsed          | 1746         |
|    total_timesteps       | 514048       |
| train/                   |              |
|    approx_kl             | 0.0052211955 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.16         |
|    cost_value_loss       | 42.5         |
|    cost_values           | 2.95         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.0615       |
|    lagrangian_multiplier | 0.00434      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.23         |
|    n_updates             | 2500         |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 0.928        |
|    value_loss            | 3.94         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/4ts77xgw
------------------------------------
| avg_speed          | 0.0668      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0668      |
| reward             | -0.36909726 |
| rollout/           |             |
|    ep_len_mean     | 983         |
|    ep_rew_mean     | -439        |
| time/              |             |
|    fps             | 6           |
|    iterations      | 1           |
|    time_elapsed    | 296         |
|    total_timesteps | 503808      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.126        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.126        |
| reward                   | -0.38310406  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 46           |
|    time_elapsed          | 13063        |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0059786146 |
|    clip_fraction         | 0.0676       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.83         |
|    cost_value_loss       | 28.7         |
|    cost_values           | 1.95         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.764        |
|    lagrangian_multiplier | 0.00293      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.32         |
|    n_updates             | 2410         |
|    policy_gradient_loss  | -0.0045      |
|    std                   | 0.881        |
|    value_loss            | 3.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.418        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.418        |
| reward                   | -0.42381582  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 43           |
|    time_elapsed          | 12127        |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0035954532 |
|    clip_fraction         | 0.00386      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.21         |
|    cost_value_loss       | 67           |
|    cost_values           | 1.79         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.805        |
|    lagrangian_multiplier | 0.00828      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.51         |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.954        |
|    value_loss            | 1.84         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.84        |
| reward                   | -0.62630993 |
| rollout/                 |             |
|    ep_len_mean           | 900         |
|    ep_rew_mean           | -468        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 5           |
|    time_elapsed          | 1545        |
|    total_timesteps       | 512000      |
| train/                   |             |
|    approx_kl             | 0.008622247 |
|    clip_fraction         | 0.0615      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 9.03        |
|    cost_values           | 2.94        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.481       |
|    lagrangian_multiplier | 0.00382     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.64        |
|    n_updates             | 2490        |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 0.734       |
|    value_loss            | 1.29        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.178        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.178        |
| reward                   | -0.47020632  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 19           |
|    time_elapsed          | 5493         |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0043815277 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.95         |
|    cost_value_loss       | 46.1         |
|    cost_values           | 0.819        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.536        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.4         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.859        |
|    value_loss            | 2.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.9519008   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 7            |
|    time_elapsed          | 2042         |
|    total_timesteps       | 516096       |
| train/                   |              |
|    approx_kl             | 0.0060771303 |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.37         |
|    cost_value_loss       | 55.9         |
|    cost_values           | 2.95         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.584        |
|    lagrangian_multiplier | 0.00764      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.55         |
|    n_updates             | 2510         |
|    policy_gradient_loss  | -0.00475     |
|    std                   | 0.929        |
|    value_loss            | 2.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.13         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.13         |
| reward                   | -0.5317139   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 2            |
|    time_elapsed          | 594          |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0075706835 |
|    clip_fraction         | 0.109        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.87         |
|    cost_value_loss       | 72.1         |
|    cost_values           | 1.18         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.514        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37           |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.0114      |
|    std                   | 0.895        |
|    value_loss            | 0.331        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.195       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.195       |
| reward                   | -0.42838946 |
| rollout/                 |             |
|    ep_len_mean           | 947         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 47          |
|    time_elapsed          | 13378       |
|    total_timesteps       | 497664      |
| train/                   |             |
|    approx_kl             | 0.003471443 |
|    clip_fraction         | 0.0632      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.12        |
|    cost_value_loss       | 79.2        |
|    cost_values           | 2.27        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.38        |
|    lagrangian_multiplier | 0.014       |
|    learning_rate         | 0.0003      |
|    loss                  | 7.82        |
|    n_updates             | 2420        |
|    policy_gradient_loss  | -0.00155    |
|    std                   | 0.878       |
|    value_loss            | 10.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.039       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.039       |
| reward                   | -0.41056198 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 44          |
|    time_elapsed          | 12438       |
|    total_timesteps       | 491520      |
| train/                   |             |
|    approx_kl             | 0.004393374 |
|    clip_fraction         | 0.0114      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.24        |
|    cost_value_loss       | 40.4        |
|    cost_values           | 1.5         |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0.00325     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.88        |
|    n_updates             | 2390        |
|    policy_gradient_loss  | -0.00201    |
|    std                   | 0.954       |
|    value_loss            | 2.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.1747613   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 20           |
|    time_elapsed          | 5797         |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0063208025 |
|    clip_fraction         | 0.014        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 18.3         |
|    cost_values           | 0.912        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.618        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.36         |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.000828    |
|    std                   | 0.859        |
|    value_loss            | 1.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0354      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0354      |
| reward                   | -0.32118988 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -514        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 8           |
|    time_elapsed          | 2337        |
|    total_timesteps       | 518144      |
| train/                   |             |
|    approx_kl             | 0.011018086 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.87        |
|    cost_value_loss       | 56.3        |
|    cost_values           | 2.43        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.72        |
|    lagrangian_multiplier | 0.0903      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.02        |
|    n_updates             | 2520        |
|    policy_gradient_loss  | 0.00319     |
|    std                   | 0.929       |
|    value_loss            | 20          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -0.57284003 |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -473        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 6           |
|    time_elapsed          | 1860        |
|    total_timesteps       | 514048      |
| train/                   |             |
|    approx_kl             | 0.015868835 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 9.74        |
|    cost_values           | 2.96        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0.00486     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 2500        |
|    policy_gradient_loss  | -0.0063     |
|    std                   | 0.731       |
|    value_loss            | 1.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0299      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0299      |
| reward                   | -0.39840525 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 3           |
|    time_elapsed          | 895         |
|    total_timesteps       | 507904      |
| train/                   |             |
|    approx_kl             | 0.00329293  |
|    clip_fraction         | 0.00513     |
|    clip_range            | 0.2         |
|    cost_returns          | 12.8        |
|    cost_value_loss       | 165         |
|    cost_values           | 1.68        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.169       |
|    lagrangian_multiplier | 0.000258    |
|    learning_rate         | 0.0003      |
|    loss                  | 72.7        |
|    n_updates             | 2470        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.895       |
|    value_loss            | 1.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.38        |
| reward                   | -0.62175035 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 45          |
|    time_elapsed          | 12746       |
|    total_timesteps       | 493568      |
| train/                   |             |
|    approx_kl             | 0.005516354 |
|    clip_fraction         | 0.019       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.75        |
|    cost_value_loss       | 68.2        |
|    cost_values           | 1.66        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.781       |
|    lagrangian_multiplier | 0.00758     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.84        |
|    n_updates             | 2400        |
|    policy_gradient_loss  | -0.00362    |
|    std                   | 0.954       |
|    value_loss            | 1.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.49         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.49         |
| reward                   | -0.28334194  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 48           |
|    time_elapsed          | 13693        |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0044392543 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 13.2         |
|    cost_value_loss       | 151          |
|    cost_values           | 2.47         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.735        |
|    lagrangian_multiplier | 0.0242       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.11         |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 0.873        |
|    value_loss            | 1.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -1.0008416   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -510         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 9            |
|    time_elapsed          | 2635         |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0001699363 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 2.93         |
|    cost_value_loss       | 19.6         |
|    cost_values           | 0.977        |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0.0183       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.65         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -0.000409    |
|    std                   | 0.929        |
|    value_loss            | 13.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.362        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.362        |
| reward                   | -0.6034353   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 21           |
|    time_elapsed          | 6102         |
|    total_timesteps       | 544768       |
| train/                   |              |
|    approx_kl             | 0.0034317905 |
|    clip_fraction         | 0.00742      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 6.95         |
|    cost_values           | 0.88         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 2650         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.86         |
|    value_loss            | 28.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6146343  |
| rollout/                 |             |
|    ep_len_mean           | 908         |
|    ep_rew_mean           | -473        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 7           |
|    time_elapsed          | 2173        |
|    total_timesteps       | 516096      |
| train/                   |             |
|    approx_kl             | 0.007159983 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.45        |
|    cost_value_loss       | 9.89        |
|    cost_values           | 2.74        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0.547       |
|    lagrangian_multiplier | 0.00486     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.62        |
|    n_updates             | 2510        |
|    policy_gradient_loss  | 0.000481    |
|    std                   | 0.728       |
|    value_loss            | 1.65        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00662      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00662      |
| reward                   | -0.5222514   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 4            |
|    time_elapsed          | 1201         |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0069606653 |
|    clip_fraction         | 0.032        |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 195          |
|    cost_values           | 2.17         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.212        |
|    lagrangian_multiplier | 0.0187       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.00439     |
|    std                   | 0.894        |
|    value_loss            | 1.75         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.162        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.162        |
| reward                   | -0.3318033   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 46           |
|    time_elapsed          | 13049        |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0036202676 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.97         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 1.68         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.753        |
|    lagrangian_multiplier | 0.00291      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.98         |
|    n_updates             | 2410         |
|    policy_gradient_loss  | -0.00311     |
|    std                   | 0.955        |
|    value_loss            | 1.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.02         |
| reward                   | -0.3813018   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 49           |
|    time_elapsed          | 14011        |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0049170367 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 12.6         |
|    cost_value_loss       | 138          |
|    cost_values           | 2.48         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.77         |
|    lagrangian_multiplier | 0.0131       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.872        |
|    value_loss            | 1.61         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.79        |
| reward                   | -0.6470765  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -509        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 10          |
|    time_elapsed          | 2933        |
|    total_timesteps       | 522240      |
| train/                   |             |
|    approx_kl             | 0.002692673 |
|    clip_fraction         | 0.00928     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.26        |
|    cost_value_loss       | 61.9        |
|    cost_values           | 0.797       |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0.00493     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.8         |
|    n_updates             | 2540        |
|    policy_gradient_loss  | -0.00314    |
|    std                   | 0.928       |
|    value_loss            | 3.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0554      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0554      |
| reward                   | -0.7794507  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 22          |
|    time_elapsed          | 6407        |
|    total_timesteps       | 546816      |
| train/                   |             |
|    approx_kl             | 0.003286598 |
|    clip_fraction         | 0.00239     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 6.61        |
|    cost_values           | 0.819       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.4        |
|    n_updates             | 2660        |
|    policy_gradient_loss  | -0.000839   |
|    std                   | 0.861       |
|    value_loss            | 34          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5494244  |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -475        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 8           |
|    time_elapsed          | 2488        |
|    total_timesteps       | 518144      |
| train/                   |             |
|    approx_kl             | 0.009028793 |
|    clip_fraction         | 0.0913      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 7.83        |
|    cost_values           | 2.83        |
|    entropy               | -2.18       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.292       |
|    lagrangian_multiplier | 0.00373     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.43        |
|    n_updates             | 2520        |
|    policy_gradient_loss  | -0.00546    |
|    std                   | 0.723       |
|    value_loss            | 2.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.25         |
| reward                   | -0.22482611  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 5            |
|    time_elapsed          | 1508         |
|    total_timesteps       | 512000       |
| train/                   |              |
|    approx_kl             | 0.0058094277 |
|    clip_fraction         | 0.0534       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.4         |
|    cost_value_loss       | 156          |
|    cost_values           | 2.39         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.802        |
|    lagrangian_multiplier | 0.0202       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.82         |
|    n_updates             | 2490         |
|    policy_gradient_loss  | -0.00424     |
|    std                   | 0.895        |
|    value_loss            | 0.918        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.17        |
| reward                   | -0.3655049  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 47          |
|    time_elapsed          | 13356       |
|    total_timesteps       | 497664      |
| train/                   |             |
|    approx_kl             | 0.004277619 |
|    clip_fraction         | 0.0417      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 0.575       |
|    cost_values           | 1.3         |
|    entropy               | -2.75       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.829       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.378       |
|    n_updates             | 2420        |
|    policy_gradient_loss  | -0.00457    |
|    std                   | 0.956       |
|    value_loss            | 0.776       |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/mtgakx2v
------------------------------------
| avg_speed          | 0.257       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.257       |
| reward             | -0.12673672 |
| rollout/           |             |
|    ep_len_mean     | 951         |
|    ep_rew_mean     | -454        |
| time/              |             |
|    fps             | 6           |
|    iterations      | 1           |
|    time_elapsed    | 312         |
|    total_timesteps | 503808      |
------------------------------------
------------------------------------------
| avg_speed                | 0.199       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.199       |
| reward                   | -0.48799485 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -514        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 11          |
|    time_elapsed          | 3235        |
|    total_timesteps       | 524288      |
| train/                   |             |
|    approx_kl             | 0.005343793 |
|    clip_fraction         | 0.0248      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 22.8        |
|    cost_values           | 0.812       |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.00562     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.82        |
|    n_updates             | 2550        |
|    policy_gradient_loss  | -0.0053     |
|    std                   | 0.928       |
|    value_loss            | 15.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.328        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.328        |
| reward                   | -0.27638185  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 23           |
|    time_elapsed          | 6712         |
|    total_timesteps       | 548864       |
| train/                   |              |
|    approx_kl             | 0.0079923915 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 0.762        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.88         |
|    n_updates             | 2670         |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 0.86         |
|    value_loss            | 2.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.51220256  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 9            |
|    time_elapsed          | 2803         |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0070681702 |
|    clip_fraction         | 0.119        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.88         |
|    cost_value_loss       | 11.5         |
|    cost_values           | 2.96         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | -0.0245      |
|    lagrangian_multiplier | 0.00522      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.97         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.723        |
|    value_loss            | 1.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.177        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.177        |
| reward                   | -0.27345484  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 6            |
|    time_elapsed          | 1816         |
|    total_timesteps       | 514048       |
| train/                   |              |
|    approx_kl             | 0.0039680763 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 134          |
|    cost_values           | 2.5          |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.804        |
|    lagrangian_multiplier | 0.0134       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 2500         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.898        |
|    value_loss            | 1.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.271        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.271        |
| reward                   | -0.4240908   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 48           |
|    time_elapsed          | 13667        |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0059323227 |
|    clip_fraction         | 0.0565       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.1          |
|    cost_value_loss       | 3.31         |
|    cost_values           | 1.43         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.856        |
|    lagrangian_multiplier | 0.00017      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.31         |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.957        |
|    value_loss            | 2.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0134       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0134       |
| reward                   | -0.3231112   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 2            |
|    time_elapsed          | 633          |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0041886014 |
|    clip_fraction         | 0.0466       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 138          |
|    cost_values           | 2.76         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.339        |
|    lagrangian_multiplier | 0.0206       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.91         |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.00288     |
|    std                   | 0.873        |
|    value_loss            | 2.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.07         |
| reward                   | -0.43126184  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -513         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 12           |
|    time_elapsed          | 3534         |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 0.0070260353 |
|    clip_fraction         | 0.0509       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 3.62         |
|    cost_values           | 0.468        |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.66         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -0.00869     |
|    std                   | 0.929        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.206       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.206       |
| reward                   | -0.46141064 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 24          |
|    time_elapsed          | 7017        |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.005781414 |
|    clip_fraction         | 0.0331      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.62        |
|    cost_value_loss       | 10.4        |
|    cost_values           | 0.843       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.00294    |
|    std                   | 0.861       |
|    value_loss            | 0.611       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.23931015 |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -481        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 10          |
|    time_elapsed          | 3118        |
|    total_timesteps       | 522240      |
| train/                   |             |
|    approx_kl             | 0.009564175 |
|    clip_fraction         | 0.0758      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 9.96        |
|    cost_values           | 2.94        |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0.003       |
|    learning_rate         | 0.0003      |
|    loss                  | 4.02        |
|    n_updates             | 2540        |
|    policy_gradient_loss  | -0.00191    |
|    std                   | 0.724       |
|    value_loss            | 0.958       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0628      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0628      |
| reward                   | -0.34072435 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 7           |
|    time_elapsed          | 2123        |
|    total_timesteps       | 516096      |
| train/                   |             |
|    approx_kl             | 0.00374575  |
|    clip_fraction         | 0.0207      |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 37.5        |
|    cost_values           | 2.36        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | -0.465      |
|    lagrangian_multiplier | 0.00401     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.16        |
|    n_updates             | 2510        |
|    policy_gradient_loss  | -0.00219    |
|    std                   | 0.899       |
|    value_loss            | 7.29        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.68         |
| reward                   | -0.47469875  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 49           |
|    time_elapsed          | 13977        |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0029681674 |
|    clip_fraction         | 0.00576      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.57         |
|    cost_value_loss       | 36.4         |
|    cost_values           | 1.58         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.309        |
|    lagrangian_multiplier | 9.89e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.958        |
|    value_loss            | 1.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.279       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.279       |
| reward                   | -0.46215612 |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 3           |
|    time_elapsed          | 954         |
|    total_timesteps       | 507904      |
| train/                   |             |
|    approx_kl             | 0.009662238 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.56        |
|    cost_value_loss       | 91.5        |
|    cost_values           | 2.77        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.647       |
|    lagrangian_multiplier | 0.0125      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.33        |
|    n_updates             | 2470        |
|    policy_gradient_loss  | -0.00806    |
|    std                   | 0.877       |
|    value_loss            | 1.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00652      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00652      |
| reward                   | -0.5477998   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -513         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 13           |
|    time_elapsed          | 3831         |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0042808373 |
|    clip_fraction         | 0.0408       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.03         |
|    cost_value_loss       | 35.6         |
|    cost_values           | 1.12         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.33         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.00321     |
|    std                   | 0.93         |
|    value_loss            | 1.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.014        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.014        |
| reward                   | -0.30011967  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 25           |
|    time_elapsed          | 7324         |
|    total_timesteps       | 552960       |
| train/                   |              |
|    approx_kl             | 0.0047189863 |
|    clip_fraction         | 0.044        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.706        |
|    cost_value_loss       | 0.0241       |
|    cost_values           | 0.833        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.861        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0988       |
|    n_updates             | 2690         |
|    policy_gradient_loss  | -0.00402     |
|    std                   | 0.858        |
|    value_loss            | 0.394        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.46303424  |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -477         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 11           |
|    time_elapsed          | 3439         |
|    total_timesteps       | 524288       |
| train/                   |              |
|    approx_kl             | 0.0054156687 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.75         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 2.95         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.532        |
|    lagrangian_multiplier | 0.00517      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.89         |
|    n_updates             | 2550         |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 0.725        |
|    value_loss            | 2.67         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -2.3509798 |
| rollout/                 |            |
|    ep_len_mean           | 983        |
|    ep_rew_mean           | -430       |
| time/                    |            |
|    fps                   | 6          |
|    iterations            | 8          |
|    time_elapsed          | 2428       |
|    total_timesteps       | 518144     |
| train/                   |            |
|    approx_kl             | 0.01205177 |
|    clip_fraction         | 0.0908     |
|    clip_range            | 0.2        |
|    cost_returns          | 7.4        |
|    cost_value_loss       | 69.2       |
|    cost_values           | 2.4        |
|    entropy               | -2.59      |
|    entropy_loss          | -2.61      |
|    explained_variance    | 0.452      |
|    lagrangian_multiplier | 0.00983    |
|    learning_rate         | 0.0003     |
|    loss                  | 7.59       |
|    n_updates             | 2520       |
|    policy_gradient_loss  | -0.00622   |
|    std                   | 0.882      |
|    value_loss            | 1.06       |
-----------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/p13vkfbg
------------------------------------
| avg_speed          | 0.552       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.552       |
| reward             | -0.24603158 |
| rollout/           |             |
|    ep_len_mean     | 992         |
|    ep_rew_mean     | -444        |
| time/              |             |
|    fps             | 6           |
|    iterations      | 1           |
|    time_elapsed    | 305         |
|    total_timesteps | 503808      |
------------------------------------
-----------------------------------------
| avg_speed                | 0.279      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.279      |
| reward                   | -0.2679441 |
| rollout/                 |            |
|    ep_len_mean           | 981        |
|    ep_rew_mean           | -514       |
| time/                    |            |
|    fps                   | 6          |
|    iterations            | 14         |
|    time_elapsed          | 4133       |
|    total_timesteps       | 530432     |
| train/                   |            |
|    approx_kl             | 0.00225844 |
|    clip_fraction         | 0.00107    |
|    clip_range            | 0.2        |
|    cost_returns          | 8.52       |
|    cost_value_loss       | 95.7       |
|    cost_values           | 1.52       |
|    entropy               | -2.69      |
|    entropy_loss          | -2.69      |
|    explained_variance    | 0.631      |
|    lagrangian_multiplier | 6.76e-05   |
|    learning_rate         | 0.0003     |
|    loss                  | 44         |
|    n_updates             | 2580       |
|    policy_gradient_loss  | -0.00177   |
|    std                   | 0.93       |
|    value_loss            | 3.42       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 1.11       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.11       |
| reward                   | -0.4282705 |
| rollout/                 |            |
|    ep_len_mean           | 953        |
|    ep_rew_mean           | -446       |
| time/                    |            |
|    fps                   | 6          |
|    iterations            | 4          |
|    time_elapsed          | 1274       |
|    total_timesteps       | 509952     |
| train/                   |            |
|    approx_kl             | 0.00546703 |
|    clip_fraction         | 0.0223     |
|    clip_range            | 0.2        |
|    cost_returns          | 9.15       |
|    cost_value_loss       | 82.5       |
|    cost_values           | 2.74       |
|    entropy               | -2.58      |
|    entropy_loss          | -2.58      |
|    explained_variance    | 0.509      |
|    lagrangian_multiplier | 0.00945    |
|    learning_rate         | 0.0003     |
|    loss                  | 9.29       |
|    n_updates             | 2480       |
|    policy_gradient_loss  | -0.00227   |
|    std                   | 0.88       |
|    value_loss            | 1.12       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.287       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.287       |
| reward                   | -0.28739706 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -451        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 26          |
|    time_elapsed          | 7632        |
|    total_timesteps       | 555008      |
| train/                   |             |
|    approx_kl             | 0.003624292 |
|    clip_fraction         | 0.0042      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.47        |
|    cost_value_loss       | 9.63        |
|    cost_values           | 0.763       |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | -1.45       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.04        |
|    n_updates             | 2700        |
|    policy_gradient_loss  | -0.00104    |
|    std                   | 0.855       |
|    value_loss            | 2.96        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.225      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.225      |
| reward                   | -0.5601849 |
| rollout/                 |            |
|    ep_len_mean           | 983        |
|    ep_rew_mean           | -449       |
| time/                    |            |
|    fps                   | 6          |
|    iterations            | 9          |
|    time_elapsed          | 2733       |
|    total_timesteps       | 520192     |
| train/                   |            |
|    approx_kl             | 0.05859372 |
|    clip_fraction         | 0.277      |
|    clip_range            | 0.2        |
|    cost_returns          | 9.86       |
|    cost_value_loss       | 117        |
|    cost_values           | 2          |
|    entropy               | -2.58      |
|    entropy_loss          | -2.58      |
|    explained_variance    | 0.961      |
|    lagrangian_multiplier | 0.166      |
|    learning_rate         | 0.0003     |
|    loss                  | 2.63       |
|    n_updates             | 2530       |
|    policy_gradient_loss  | 0.0324     |
|    std                   | 0.878      |
|    value_loss            | 27.5       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8.05       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.05       |
| reward                   | -0.5837569 |
| rollout/                 |            |
|    ep_len_mean           | 917        |
|    ep_rew_mean           | -475       |
| time/                    |            |
|    fps                   | 6          |
|    iterations            | 12         |
|    time_elapsed          | 3757       |
|    total_timesteps       | 526336     |
| train/                   |            |
|    approx_kl             | 0.00793717 |
|    clip_fraction         | 0.109      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.42       |
|    cost_value_loss       | 8.69       |
|    cost_values           | 2.97       |
|    entropy               | -2.18      |
|    entropy_loss          | -2.18      |
|    explained_variance    | 0.172      |
|    lagrangian_multiplier | 0.00373    |
|    learning_rate         | 0.0003     |
|    loss                  | 7.04       |
|    n_updates             | 2560       |
|    policy_gradient_loss  | -0.00392   |
|    std                   | 0.724      |
|    value_loss            | 20.6       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.284       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.284       |
| reward                   | -0.44775134 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 2           |
|    time_elapsed          | 618         |
|    total_timesteps       | 505856      |
| train/                   |             |
|    approx_kl             | 0.002252914 |
|    clip_fraction         | 0.00474     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 23.6        |
|    cost_values           | 2.11        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.615       |
|    lagrangian_multiplier | 0.00271     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.82        |
|    n_updates             | 2460        |
|    policy_gradient_loss  | -0.000778   |
|    std                   | 0.958       |
|    value_loss            | 1.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.136        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.136        |
| reward                   | -0.37333727  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -509         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 15           |
|    time_elapsed          | 4440         |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 0.0027652853 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 2.71         |
|    cost_values           | 1.28         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.846        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.53         |
|    n_updates             | 2590         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.929        |
|    value_loss            | 9.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.6216512  |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 5           |
|    time_elapsed          | 1599        |
|    total_timesteps       | 512000      |
| train/                   |             |
|    approx_kl             | 0.010055574 |
|    clip_fraction         | 0.0857      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.83        |
|    cost_value_loss       | 107         |
|    cost_values           | 2.64        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.407       |
|    lagrangian_multiplier | 0.0131      |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 2490        |
|    policy_gradient_loss  | -0.000849   |
|    std                   | 0.879       |
|    value_loss            | 9.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.248        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.248        |
| reward                   | -0.420618    |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 27           |
|    time_elapsed          | 7942         |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0012084176 |
|    clip_fraction         | 0.0324       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 8.82         |
|    cost_values           | 0.977        |
|    entropy               | -2.5         |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.575        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.97         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 0.851        |
|    value_loss            | 1.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.44305193 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 10          |
|    time_elapsed          | 3036        |
|    total_timesteps       | 522240      |
| train/                   |             |
|    approx_kl             | 0.003055277 |
|    clip_fraction         | 0.0166      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 22.5        |
|    cost_values           | 0.918       |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0.000323    |
|    learning_rate         | 0.0003      |
|    loss                  | 93.8        |
|    n_updates             | 2540        |
|    policy_gradient_loss  | -0.000824   |
|    std                   | 0.878       |
|    value_loss            | 223         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.32999033  |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 13           |
|    time_elapsed          | 4080         |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0073211044 |
|    clip_fraction         | 0.0716       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.09         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 2.97         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.747        |
|    lagrangian_multiplier | 0.006        |
|    learning_rate         | 0.0003       |
|    loss                  | 3.92         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.00581     |
|    std                   | 0.721        |
|    value_loss            | 1.81         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.16        |
| reward                   | -0.6485609  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 3           |
|    time_elapsed          | 929         |
|    total_timesteps       | 507904      |
| train/                   |             |
|    approx_kl             | 0.004118163 |
|    clip_fraction         | 0.0149      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.6         |
|    cost_value_loss       | 24.9        |
|    cost_values           | 2.08        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.0587      |
|    lagrangian_multiplier | 0.000672    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 2470        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.958       |
|    value_loss            | 3.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0769       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0769       |
| reward                   | -0.3514697   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -506         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 16           |
|    time_elapsed          | 4751         |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0050629834 |
|    clip_fraction         | 0.0106       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.36         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 1.56         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -1.01        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.43         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.929        |
|    value_loss            | 2.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.28        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.28        |
| reward                   | -0.346127   |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 6           |
|    time_elapsed          | 1921        |
|    total_timesteps       | 514048      |
| train/                   |             |
|    approx_kl             | 0.005466423 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 112         |
|    cost_values           | 2.65        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.7         |
|    lagrangian_multiplier | 0.0114      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 2500        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.876       |
|    value_loss            | 4.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.411        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.411        |
| reward                   | -0.53892064  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 28           |
|    time_elapsed          | 8253         |
|    total_timesteps       | 559104       |
| train/                   |              |
|    approx_kl             | 0.0046134293 |
|    clip_fraction         | 0.0292       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 6.61         |
|    cost_values           | 0.967        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.5         |
|    explained_variance    | -0.143       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.57         |
|    n_updates             | 2720         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.846        |
|    value_loss            | 1.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0364       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0364       |
| reward                   | -0.36942542  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 11           |
|    time_elapsed          | 3348         |
|    total_timesteps       | 524288       |
| train/                   |              |
|    approx_kl             | 0.0032891524 |
|    clip_fraction         | 0.018        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.72         |
|    cost_value_loss       | 90           |
|    cost_values           | 0.753        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0.00074      |
|    learning_rate         | 0.0003       |
|    loss                  | 76.1         |
|    n_updates             | 2550         |
|    policy_gradient_loss  | -0.000535    |
|    std                   | 0.879        |
|    value_loss            | 126          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.5988549  |
| rollout/                 |             |
|    ep_len_mean           | 900         |
|    ep_rew_mean           | -467        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 14          |
|    time_elapsed          | 4405        |
|    total_timesteps       | 530432      |
| train/                   |             |
|    approx_kl             | 0.006468367 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.71        |
|    cost_value_loss       | 10.3        |
|    cost_values           | 2.98        |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.321       |
|    lagrangian_multiplier | 0.00354     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.81        |
|    n_updates             | 2580        |
|    policy_gradient_loss  | -0.00155    |
|    std                   | 0.72        |
|    value_loss            | 20.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.735        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.735        |
| reward                   | -0.43563235  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 4            |
|    time_elapsed          | 1244         |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0065608127 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.12         |
|    cost_value_loss       | 23.7         |
|    cost_values           | 1.96         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.555        |
|    lagrangian_multiplier | 0.00326      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.78         |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.00442     |
|    std                   | 0.958        |
|    value_loss            | 1.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0969       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0969       |
| reward                   | -0.5929077   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -507         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 17           |
|    time_elapsed          | 5059         |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0035474966 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.56         |
|    cost_value_loss       | 71           |
|    cost_values           | 1.65         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.595        |
|    lagrangian_multiplier | 0.00873      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.38         |
|    n_updates             | 2610         |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 0.929        |
|    value_loss            | 15.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.303       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.303       |
| reward                   | -0.3983564  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 29          |
|    time_elapsed          | 8568        |
|    total_timesteps       | 561152      |
| train/                   |             |
|    approx_kl             | 0.008378488 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.21        |
|    cost_value_loss       | 15.6        |
|    cost_values           | 1.06        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.864       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.12        |
|    n_updates             | 2730        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.844       |
|    value_loss            | 0.955       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0809      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0809      |
| reward                   | -0.46357116 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 7           |
|    time_elapsed          | 2245        |
|    total_timesteps       | 516096      |
| train/                   |             |
|    approx_kl             | 0.005193201 |
|    clip_fraction         | 0.0268      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.06        |
|    cost_value_loss       | 63.2        |
|    cost_values           | 2.9         |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.359       |
|    lagrangian_multiplier | 0.0128      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.51        |
|    n_updates             | 2510        |
|    policy_gradient_loss  | -0.00241    |
|    std                   | 0.877       |
|    value_loss            | 2.02        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.84148     |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 12           |
|    time_elapsed          | 3660         |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 0.0022436609 |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.53         |
|    cost_value_loss       | 80.1         |
|    cost_values           | 0.756        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0.00639      |
|    learning_rate         | 0.0003       |
|    loss                  | 17.7         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -0.000188    |
|    std                   | 0.879        |
|    value_loss            | 68.6         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.81       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.81       |
| reward                   | -0.5431328 |
| rollout/                 |            |
|    ep_len_mean           | 900        |
|    ep_rew_mean           | -466       |
| time/                    |            |
|    fps                   | 6          |
|    iterations            | 15         |
|    time_elapsed          | 4726       |
|    total_timesteps       | 532480     |
| train/                   |            |
|    approx_kl             | 0.01131996 |
|    clip_fraction         | 0.0853     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.21       |
|    cost_value_loss       | 9.75       |
|    cost_values           | 2.74       |
|    entropy               | -2.17      |
|    entropy_loss          | -2.17      |
|    explained_variance    | 0.613      |
|    lagrangian_multiplier | 0.00246    |
|    learning_rate         | 0.0003     |
|    loss                  | 6.78       |
|    n_updates             | 2590       |
|    policy_gradient_loss  | -0.00353   |
|    std                   | 0.72       |
|    value_loss            | 17.4       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 4.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.69         |
| reward                   | -0.561973    |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 5            |
|    time_elapsed          | 1558         |
|    total_timesteps       | 512000       |
| train/                   |              |
|    approx_kl             | 0.0048565217 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.61         |
|    cost_value_loss       | 7.68         |
|    cost_values           | 1.87         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.675        |
|    lagrangian_multiplier | 0.000195     |
|    learning_rate         | 0.0003       |
|    loss                  | 3.34         |
|    n_updates             | 2490         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 0.964        |
|    value_loss            | 1.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.5567427   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -504         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 18           |
|    time_elapsed          | 5369         |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0032409353 |
|    clip_fraction         | 0.00449      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.8         |
|    cost_value_loss       | 134          |
|    cost_values           | 1.91         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.418        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 68.7         |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.93         |
|    value_loss            | 2.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0414       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0414       |
| reward                   | -0.3508706   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 30           |
|    time_elapsed          | 8882         |
|    total_timesteps       | 563200       |
| train/                   |              |
|    approx_kl             | 0.0023786866 |
|    clip_fraction         | 0.00986      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 11           |
|    cost_values           | 1.05         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | -0.583       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.73         |
|    n_updates             | 2740         |
|    policy_gradient_loss  | 9.72e-06     |
|    std                   | 0.843        |
|    value_loss            | 1.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0416       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0416       |
| reward                   | -0.33779672  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 8            |
|    time_elapsed          | 2567         |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0050676037 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 165          |
|    cost_values           | 2.94         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | -1.09        |
|    lagrangian_multiplier | 0.02         |
|    learning_rate         | 0.0003       |
|    loss                  | 9.99         |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 0.873        |
|    value_loss            | 0.812        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0468       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0468       |
| reward                   | -0.5274673   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -503         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 13           |
|    time_elapsed          | 3974         |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0037351113 |
|    clip_fraction         | 0.039        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.01         |
|    cost_value_loss       | 70.6         |
|    cost_values           | 0.775        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0.00439      |
|    learning_rate         | 0.0003       |
|    loss                  | 25.1         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 0.879        |
|    value_loss            | 102          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.42027274  |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 16           |
|    time_elapsed          | 5054         |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0067762462 |
|    clip_fraction         | 0.0658       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.64         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 2.75         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.879        |
|    lagrangian_multiplier | 0.0048       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.77         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.00675     |
|    std                   | 0.72         |
|    value_loss            | 1.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.206        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.206        |
| reward                   | -0.46454132  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 6            |
|    time_elapsed          | 1870         |
|    total_timesteps       | 514048       |
| train/                   |              |
|    approx_kl             | 0.0051902295 |
|    clip_fraction         | 0.0418       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 1.51         |
|    cost_values           | 1.82         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.719        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.26         |
|    n_updates             | 2500         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.966        |
|    value_loss            | 3.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.266       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.266       |
| reward                   | -0.4298598  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -506        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 19          |
|    time_elapsed          | 5683        |
|    total_timesteps       | 540672      |
| train/                   |             |
|    approx_kl             | 0.006129162 |
|    clip_fraction         | 0.0351      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.38        |
|    cost_value_loss       | 70.2        |
|    cost_values           | 2.35        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.232       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 33.6        |
|    n_updates             | 2630        |
|    policy_gradient_loss  | -0.00352    |
|    std                   | 0.93        |
|    value_loss            | 1.84        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0744       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0744       |
| reward                   | -0.43874216  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 31           |
|    time_elapsed          | 9200         |
|    total_timesteps       | 565248       |
| train/                   |              |
|    approx_kl             | 0.0072593093 |
|    clip_fraction         | 0.0701       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 2.23         |
|    cost_values           | 1.01         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.58         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.27         |
|    n_updates             | 2750         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.839        |
|    value_loss            | 0.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.315       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.315       |
| reward                   | -0.50637454 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 9           |
|    time_elapsed          | 2893        |
|    total_timesteps       | 520192      |
| train/                   |             |
|    approx_kl             | 0.0053317   |
|    clip_fraction         | 0.0383      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 169         |
|    cost_values           | 2.96        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0.0271      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.37        |
|    n_updates             | 2530        |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 0.874       |
|    value_loss            | 1.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -2.4401307   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -512         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 14           |
|    time_elapsed          | 4288         |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0046435483 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.82         |
|    cost_value_loss       | 54.7         |
|    cost_values           | 0.776        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0.00214      |
|    learning_rate         | 0.0003       |
|    loss                  | 44.7         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.879        |
|    value_loss            | 155          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.40103975  |
| rollout/                 |              |
|    ep_len_mean           | 885          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 17           |
|    time_elapsed          | 5383         |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0040756674 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.1          |
|    cost_value_loss       | 12.3         |
|    cost_values           | 2.93         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.55         |
|    lagrangian_multiplier | 0.00587      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.33         |
|    n_updates             | 2610         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.722        |
|    value_loss            | 12.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.204        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.204        |
| reward                   | -0.4816055   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 7            |
|    time_elapsed          | 2188         |
|    total_timesteps       | 516096       |
| train/                   |              |
|    approx_kl             | 0.0040415013 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 3.33         |
|    cost_values           | 1.68         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.832        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2            |
|    n_updates             | 2510         |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.966        |
|    value_loss            | 2.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.308        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.308        |
| reward                   | -0.5218138   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 20           |
|    time_elapsed          | 5997         |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0044544325 |
|    clip_fraction         | 0.00571      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 4.16         |
|    cost_values           | 2.22         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.69        |
|    explained_variance    | -1.25        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.26         |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.000441    |
|    std                   | 0.928        |
|    value_loss            | 1.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0696      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0696      |
| reward                   | -0.5379501  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 32          |
|    time_elapsed          | 9513        |
|    total_timesteps       | 567296      |
| train/                   |             |
|    approx_kl             | 0.008138226 |
|    clip_fraction         | 0.0848      |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 13.1        |
|    cost_values           | 1.14        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.204       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.49        |
|    n_updates             | 2760        |
|    policy_gradient_loss  | -0.00416    |
|    std                   | 0.838       |
|    value_loss            | 0.406       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.614       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.614       |
| reward                   | -0.53446513 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 10          |
|    time_elapsed          | 3220        |
|    total_timesteps       | 522240      |
| train/                   |             |
|    approx_kl             | 0.008733966 |
|    clip_fraction         | 0.0397      |
|    clip_range            | 0.2         |
|    cost_returns          | 16.2        |
|    cost_value_loss       | 197         |
|    cost_values           | 2.99        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0.0325      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.44        |
|    n_updates             | 2540        |
|    policy_gradient_loss  | -0.00306    |
|    std                   | 0.873       |
|    value_loss            | 1.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.286        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.286        |
| reward                   | -0.44551772  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -515         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 15           |
|    time_elapsed          | 4606         |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 0.0041965907 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.96         |
|    cost_value_loss       | 94.5         |
|    cost_values           | 0.78         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.961        |
|    lagrangian_multiplier | 0.00929      |
|    learning_rate         | 0.0003       |
|    loss                  | 16           |
|    n_updates             | 2590         |
|    policy_gradient_loss  | -0.00368     |
|    std                   | 0.881        |
|    value_loss            | 88.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.49629065 |
| rollout/                 |             |
|    ep_len_mean           | 885         |
|    ep_rew_mean           | -455        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 18          |
|    time_elapsed          | 5715        |
|    total_timesteps       | 538624      |
| train/                   |             |
|    approx_kl             | 0.004597998 |
|    clip_fraction         | 0.029       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 9.08        |
|    cost_values           | 2.68        |
|    entropy               | -2.17       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.605       |
|    lagrangian_multiplier | 0.00174     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.96        |
|    n_updates             | 2620        |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.721       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.336        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.336        |
| reward                   | -0.43025896  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 8            |
|    time_elapsed          | 2509         |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0013761023 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 2.22         |
|    cost_values           | 1.27         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | -9.02        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.81         |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -5.71e-05    |
|    std                   | 0.965        |
|    value_loss            | 8.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.47192603 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -501        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 21          |
|    time_elapsed          | 6313        |
|    total_timesteps       | 544768      |
| train/                   |             |
|    approx_kl             | 0.001855605 |
|    clip_fraction         | 0.0043      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.66        |
|    cost_value_loss       | 92.9        |
|    cost_values           | 2.26        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | -0.587      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 45.4        |
|    n_updates             | 2650        |
|    policy_gradient_loss  | 0.000132    |
|    std                   | 0.927       |
|    value_loss            | 1.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.266        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.266        |
| reward                   | -0.52733725  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 33           |
|    time_elapsed          | 9828         |
|    total_timesteps       | 569344       |
| train/                   |              |
|    approx_kl             | 0.0027385058 |
|    clip_fraction         | 0.04         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 1.37         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.671        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.98         |
|    n_updates             | 2770         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.839        |
|    value_loss            | 1.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.26        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.26        |
| reward                   | -0.4182777  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 11          |
|    time_elapsed          | 3549        |
|    total_timesteps       | 524288      |
| train/                   |             |
|    approx_kl             | 0.005219461 |
|    clip_fraction         | 0.0545      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 180         |
|    cost_values           | 2.95        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.0165      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.9        |
|    n_updates             | 2550        |
|    policy_gradient_loss  | -0.00639    |
|    std                   | 0.871       |
|    value_loss            | 0.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0136      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0136      |
| reward                   | -0.5499209  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -513        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 16          |
|    time_elapsed          | 4921        |
|    total_timesteps       | 534528      |
| train/                   |             |
|    approx_kl             | 0.014193044 |
|    clip_fraction         | 0.0171      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.4        |
|    cost_value_loss       | 201         |
|    cost_values           | 1.3         |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0.0135      |
|    learning_rate         | 0.0003      |
|    loss                  | 14.5        |
|    n_updates             | 2600        |
|    policy_gradient_loss  | -0.00622    |
|    std                   | 0.881       |
|    value_loss            | 9.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.42         |
| reward                   | -0.5216904   |
| rollout/                 |              |
|    ep_len_mean           | 891          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 19           |
|    time_elapsed          | 6045         |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0053046523 |
|    clip_fraction         | 0.0475       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.65         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 2.65         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.94         |
|    lagrangian_multiplier | 0.00319      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.01         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.0053      |
|    std                   | 0.72         |
|    value_loss            | 1.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.319       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.319       |
| reward                   | -0.32067168 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 9           |
|    time_elapsed          | 2830        |
|    total_timesteps       | 520192      |
| train/                   |             |
|    approx_kl             | 0.009461236 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 2.01        |
|    cost_values           | 1.08        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.733       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.722       |
|    n_updates             | 2530        |
|    policy_gradient_loss  | -0.0102     |
|    std                   | 0.962       |
|    value_loss            | 0.464       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.167        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.167        |
| reward                   | -0.3391425   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -498         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 22           |
|    time_elapsed          | 6626         |
|    total_timesteps       | 546816       |
| train/                   |              |
|    approx_kl             | 0.0036198776 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.72         |
|    cost_value_loss       | 25           |
|    cost_values           | 2.11         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.736        |
|    lagrangian_multiplier | 0.00336      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.73         |
|    n_updates             | 2660         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.927        |
|    value_loss            | 4.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.175       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.175       |
| reward                   | -0.32831585 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 34          |
|    time_elapsed          | 10147       |
|    total_timesteps       | 571392      |
| train/                   |             |
|    approx_kl             | 0.005182968 |
|    clip_fraction         | 0.0583      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 7.24        |
|    cost_values           | 1.22        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.12        |
|    n_updates             | 2780        |
|    policy_gradient_loss  | -0.00617    |
|    std                   | 0.837       |
|    value_loss            | 0.981       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.07        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.07        |
| reward                   | -0.50310224 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -515        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 17          |
|    time_elapsed          | 5241        |
|    total_timesteps       | 536576      |
| train/                   |             |
|    approx_kl             | 0.002624577 |
|    clip_fraction         | 0.00425     |
|    clip_range            | 0.2         |
|    cost_returns          | 7.95        |
|    cost_value_loss       | 73.6        |
|    cost_values           | 1.68        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.565       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 35.3        |
|    n_updates             | 2610        |
|    policy_gradient_loss  | -0.00151    |
|    std                   | 0.88        |
|    value_loss            | 1.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.119        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.119        |
| reward                   | -0.6507612   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 12           |
|    time_elapsed          | 3882         |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 0.0062283063 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.6         |
|    cost_value_loss       | 206          |
|    cost_values           | 2.98         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.905        |
|    lagrangian_multiplier | 0.0324       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.77         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 0.867        |
|    value_loss            | 0.299        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.5526697   |
| rollout/                 |              |
|    ep_len_mean           | 891          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 20           |
|    time_elapsed          | 6377         |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0076444023 |
|    clip_fraction         | 0.106        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.57         |
|    cost_value_loss       | 9.95         |
|    cost_values           | 2.93         |
|    entropy               | -2.16        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.681        |
|    lagrangian_multiplier | 0.00264      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.6          |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.00349     |
|    std                   | 0.717        |
|    value_loss            | 9.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.27        |
| reward                   | -0.5160504  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 10          |
|    time_elapsed          | 3144        |
|    total_timesteps       | 522240      |
| train/                   |             |
|    approx_kl             | 0.001348895 |
|    clip_fraction         | 0.0885      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.75        |
|    cost_value_loss       | 9.56        |
|    cost_values           | 0.929       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.865       |
|    lagrangian_multiplier | 0.00013     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.23        |
|    n_updates             | 2540        |
|    policy_gradient_loss  | 0.0056      |
|    std                   | 0.961       |
|    value_loss            | 6.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.7          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.7          |
| reward                   | -0.7702505   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -499         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 23           |
|    time_elapsed          | 6941         |
|    total_timesteps       | 548864       |
| train/                   |              |
|    approx_kl             | 0.0026494025 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.35         |
|    cost_value_loss       | 38.3         |
|    cost_values           | 1.67         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.3          |
|    lagrangian_multiplier | 0.00355      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 2670         |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.927        |
|    value_loss            | 14.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.181       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.181       |
| reward                   | -0.5510901  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 35          |
|    time_elapsed          | 10464       |
|    total_timesteps       | 573440      |
| train/                   |             |
|    approx_kl             | 0.002555137 |
|    clip_fraction         | 0.00962     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 7.97        |
|    cost_values           | 1.23        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.339       |
|    lagrangian_multiplier | 0.000388    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.88        |
|    n_updates             | 2790        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.834       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0529      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0529      |
| reward                   | -0.34151956 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -528        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 18          |
|    time_elapsed          | 5565        |
|    total_timesteps       | 538624      |
| train/                   |             |
|    approx_kl             | 0.010051791 |
|    clip_fraction         | 0.0671      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.11        |
|    cost_value_loss       | 91.3        |
|    cost_values           | 2.08        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.434       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 41.4        |
|    n_updates             | 2620        |
|    policy_gradient_loss  | -0.0076     |
|    std                   | 0.879       |
|    value_loss            | 3.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0411       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0411       |
| reward                   | -0.37470213  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 13           |
|    time_elapsed          | 4208         |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0050928937 |
|    clip_fraction         | 0.0316       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.8         |
|    cost_value_loss       | 150          |
|    cost_values           | 2.83         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.753        |
|    lagrangian_multiplier | 0.0187       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.91         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.00473     |
|    std                   | 0.866        |
|    value_loss            | 2.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.62232155  |
| rollout/                 |              |
|    ep_len_mean           | 891          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 21           |
|    time_elapsed          | 6710         |
|    total_timesteps       | 544768       |
| train/                   |              |
|    approx_kl             | 0.0054907706 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.53         |
|    cost_value_loss       | 14           |
|    cost_values           | 2.67         |
|    entropy               | -2.16        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0.00425      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.23         |
|    n_updates             | 2650         |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 0.715        |
|    value_loss            | 2.06         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.46408498 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 11          |
|    time_elapsed          | 3435        |
|    total_timesteps       | 524288      |
| train/                   |             |
|    approx_kl             | 0.002022624 |
|    clip_fraction         | 0.00625     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.54        |
|    cost_value_loss       | 3.47        |
|    cost_values           | 0.935       |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.6         |
|    n_updates             | 2550        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.961       |
|    value_loss            | 3.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.206       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.206       |
| reward                   | -0.31115374 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -500        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 24          |
|    time_elapsed          | 7262        |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.008224469 |
|    clip_fraction         | 0.0774      |
|    clip_range            | 0.2         |
|    cost_returns          | 4           |
|    cost_value_loss       | 34.3        |
|    cost_values           | 1.76        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.672       |
|    lagrangian_multiplier | 0.00607     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.75        |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.00626    |
|    std                   | 0.93        |
|    value_loss            | 2.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.224       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.224       |
| reward                   | -0.43910113 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 36          |
|    time_elapsed          | 10784       |
|    total_timesteps       | 575488      |
| train/                   |             |
|    approx_kl             | 0.004222813 |
|    clip_fraction         | 0.027       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 2.44        |
|    cost_values           | 1.14        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | -0.38       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.78        |
|    n_updates             | 2800        |
|    policy_gradient_loss  | -0.00206    |
|    std                   | 0.832       |
|    value_loss            | 2.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.211        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.211        |
| reward                   | -0.53107834  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -554         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 19           |
|    time_elapsed          | 5882         |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0014805386 |
|    clip_fraction         | 0.00659      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.5         |
|    cost_value_loss       | 156          |
|    cost_values           | 1.71         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.865        |
|    lagrangian_multiplier | 0.306        |
|    learning_rate         | 0.0003       |
|    loss                  | 2.46         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.879        |
|    value_loss            | 66.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0186       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0186       |
| reward                   | -0.54047513  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 14           |
|    time_elapsed          | 4545         |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0046706945 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 141          |
|    cost_values           | 2.61         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.887        |
|    lagrangian_multiplier | 0.0194       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.08         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.00535     |
|    std                   | 0.864        |
|    value_loss            | 2.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0803       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0803       |
| reward                   | -0.45825276  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 12           |
|    time_elapsed          | 3723         |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 0.0038872384 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 4.09         |
|    cost_values           | 0.731        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -0.495       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.98         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -0.000546    |
|    std                   | 0.966        |
|    value_loss            | 3.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.656015    |
| rollout/                 |              |
|    ep_len_mean           | 892          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 22           |
|    time_elapsed          | 7047         |
|    total_timesteps       | 546816       |
| train/                   |              |
|    approx_kl             | 0.0057080816 |
|    clip_fraction         | 0.0811       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.69         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 2.63         |
|    entropy               | -2.16        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 0.3          |
|    lagrangian_multiplier | 0.00559      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.77         |
|    n_updates             | 2660         |
|    policy_gradient_loss  | -0.00424     |
|    std                   | 0.716        |
|    value_loss            | 1.91         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.454       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.454       |
| reward                   | -0.47353432 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -497        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 25          |
|    time_elapsed          | 7580        |
|    total_timesteps       | 552960      |
| train/                   |             |
|    approx_kl             | 0.010098711 |
|    clip_fraction         | 0.0479      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 15          |
|    cost_values           | 1.6         |
|    entropy               | -2.7        |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0.00213     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.32        |
|    n_updates             | 2690        |
|    policy_gradient_loss  | -0.00243    |
|    std                   | 0.934       |
|    value_loss            | 3.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0383       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0383       |
| reward                   | -0.456985    |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 37           |
|    time_elapsed          | 11101        |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0031599659 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.24         |
|    cost_value_loss       | 33.5         |
|    cost_values           | 1.1          |
|    entropy               | -2.45        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.803        |
|    lagrangian_multiplier | 0.00446      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.28         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | -0.00013     |
|    std                   | 0.829        |
|    value_loss            | 0.518        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.199        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.199        |
| reward                   | -0.48480475  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -581         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 20           |
|    time_elapsed          | 6207         |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0006992017 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.13         |
|    cost_value_loss       | 49.5         |
|    cost_values           | 0.715        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.913        |
|    lagrangian_multiplier | 0.00297      |
|    learning_rate         | 0.0003       |
|    loss                  | 105          |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.000277    |
|    std                   | 0.879        |
|    value_loss            | 435          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.139        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.139        |
| reward                   | -0.5482994   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 15           |
|    time_elapsed          | 4877         |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 0.0017199524 |
|    clip_fraction         | 0.0062       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.9         |
|    cost_value_loss       | 202          |
|    cost_values           | 2.39         |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.775        |
|    lagrangian_multiplier | 0.000134     |
|    learning_rate         | 0.0003       |
|    loss                  | 91.2         |
|    n_updates             | 2590         |
|    policy_gradient_loss  | 0.000356     |
|    std                   | 0.863        |
|    value_loss            | 0.457        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.126       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.126       |
| reward                   | -0.5066362  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 13          |
|    time_elapsed          | 4012        |
|    total_timesteps       | 528384      |
| train/                   |             |
|    approx_kl             | 0.005800834 |
|    clip_fraction         | 0.0319      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 3.2         |
|    cost_values           | 0.765       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.85        |
|    n_updates             | 2570        |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 0.967       |
|    value_loss            | 6.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.5306889  |
| rollout/                 |             |
|    ep_len_mean           | 892         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 23          |
|    time_elapsed          | 7381        |
|    total_timesteps       | 548864      |
| train/                   |             |
|    approx_kl             | 0.008710229 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.56        |
|    cost_value_loss       | 9.6         |
|    cost_values           | 2.81        |
|    entropy               | -2.16       |
|    entropy_loss          | -2.16       |
|    explained_variance    | 0.758       |
|    lagrangian_multiplier | 0.00449     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.66        |
|    n_updates             | 2670        |
|    policy_gradient_loss  | -0.00735    |
|    std                   | 0.715       |
|    value_loss            | 1.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.288        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.288        |
| reward                   | -0.50371814  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -501         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 26           |
|    time_elapsed          | 7899         |
|    total_timesteps       | 555008       |
| train/                   |              |
|    approx_kl             | 0.0046364246 |
|    clip_fraction         | 0.0551       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.48         |
|    cost_value_loss       | 22           |
|    cost_values           | 1.51         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.874        |
|    lagrangian_multiplier | 0.00391      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.27         |
|    n_updates             | 2700         |
|    policy_gradient_loss  | -0.00426     |
|    std                   | 0.937        |
|    value_loss            | 1.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0381       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0381       |
| reward                   | -0.3849287   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 38           |
|    time_elapsed          | 11423        |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0042967936 |
|    clip_fraction         | 0.0386       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 20.1         |
|    cost_values           | 1.21         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.793        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.23         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.002       |
|    std                   | 0.827        |
|    value_loss            | 0.556        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.226        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.226        |
| reward                   | -0.38621485  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -601         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 21           |
|    time_elapsed          | 6533         |
|    total_timesteps       | 544768       |
| train/                   |              |
|    approx_kl             | 0.0035703443 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.85         |
|    cost_value_loss       | 47.1         |
|    cost_values           | 0.53         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.922        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 220          |
|    n_updates             | 2650         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.879        |
|    value_loss            | 399          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.192        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.192        |
| reward                   | -0.36622804  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 16           |
|    time_elapsed          | 5207         |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0027758335 |
|    clip_fraction         | 0.00703      |
|    clip_range            | 0.2          |
|    cost_returns          | 17.1         |
|    cost_value_loss       | 216          |
|    cost_values           | 2.78         |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.782        |
|    lagrangian_multiplier | 0.0196       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.863        |
|    value_loss            | 1.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.4          |
| reward                   | -0.39955786  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 14           |
|    time_elapsed          | 4303         |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0055059628 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 0.78         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.835        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.37         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.966        |
|    value_loss            | 0.697        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.7         |
| reward                   | -0.5661961  |
| rollout/                 |             |
|    ep_len_mean           | 887         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 24          |
|    time_elapsed          | 7717        |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.011973031 |
|    clip_fraction         | 0.0895      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.34        |
|    cost_value_loss       | 14.1        |
|    cost_values           | 2.97        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.35        |
|    lagrangian_multiplier | 0.0062      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.06        |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.00379    |
|    std                   | 0.708       |
|    value_loss            | 1.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.163       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.163       |
| reward                   | -0.38858747 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -496        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 27          |
|    time_elapsed          | 8220        |
|    total_timesteps       | 557056      |
| train/                   |             |
|    approx_kl             | 0.006494268 |
|    clip_fraction         | 0.0529      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 0.491       |
|    cost_values           | 1.25        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.282       |
|    n_updates             | 2710        |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.931       |
|    value_loss            | 0.436       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.299       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.299       |
| reward                   | -0.42975405 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 39          |
|    time_elapsed          | 11745       |
|    total_timesteps       | 581632      |
| train/                   |             |
|    approx_kl             | 0.003087134 |
|    clip_fraction         | 0.0142      |
|    clip_range            | 0.2         |
|    cost_returns          | 4           |
|    cost_value_loss       | 40.9        |
|    cost_values           | 1.47        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.226       |
|    lagrangian_multiplier | 0.00489     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.5         |
|    n_updates             | 2830        |
|    policy_gradient_loss  | -0.00103    |
|    std                   | 0.826       |
|    value_loss            | 8.92        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.18         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.18         |
| reward                   | -0.41264725  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -613         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 22           |
|    time_elapsed          | 6864         |
|    total_timesteps       | 546816       |
| train/                   |              |
|    approx_kl             | 0.0030512172 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.49         |
|    cost_value_loss       | 77.8         |
|    cost_values           | 0.733        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0.00212      |
|    learning_rate         | 0.0003       |
|    loss                  | 80.1         |
|    n_updates             | 2660         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.88         |
|    value_loss            | 290          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.45         |
| reward                   | -0.44008046  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 15           |
|    time_elapsed          | 4593         |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 0.0041603157 |
|    clip_fraction         | 0.0426       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 2.35         |
|    cost_values           | 1.02         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.658        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.56         |
|    n_updates             | 2590         |
|    policy_gradient_loss  | -0.00508     |
|    std                   | 0.967        |
|    value_loss            | 1.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.198       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.198       |
| reward                   | -0.4443103  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 17          |
|    time_elapsed          | 5539        |
|    total_timesteps       | 536576      |
| train/                   |             |
|    approx_kl             | 0.004493258 |
|    clip_fraction         | 0.0454      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.3        |
|    cost_value_loss       | 218         |
|    cost_values           | 2.98        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.0301      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.34        |
|    n_updates             | 2610        |
|    policy_gradient_loss  | -0.00587    |
|    std                   | 0.864       |
|    value_loss            | 0.282       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.69         |
| reward                   | -0.6398392   |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 25           |
|    time_elapsed          | 8056         |
|    total_timesteps       | 552960       |
| train/                   |              |
|    approx_kl             | 0.0096214395 |
|    clip_fraction         | 0.358        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.87         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 2.59         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0.363        |
|    lagrangian_multiplier | 0.0054       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.69         |
|    n_updates             | 2690         |
|    policy_gradient_loss  | 0.0328       |
|    std                   | 0.706        |
|    value_loss            | 23.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.81        |
| reward                   | -0.99550915 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -494        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 28          |
|    time_elapsed          | 8541        |
|    total_timesteps       | 559104      |
| train/                   |             |
|    approx_kl             | 0.001747953 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.74        |
|    cost_value_loss       | 101         |
|    cost_values           | 1.38        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.00434     |
|    learning_rate         | 0.0003      |
|    loss                  | 16.1        |
|    n_updates             | 2720        |
|    policy_gradient_loss  | 0.00974     |
|    std                   | 0.926       |
|    value_loss            | 1.03        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0161       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0161       |
| reward                   | -0.26979655  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 40           |
|    time_elapsed          | 12070        |
|    total_timesteps       | 583680       |
| train/                   |              |
|    approx_kl             | 0.0049240254 |
|    clip_fraction         | 0.0604       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.922        |
|    cost_value_loss       | 0.0173       |
|    cost_values           | 0.931        |
|    entropy               | -2.45        |
|    entropy_loss          | -2.44        |
|    explained_variance    | -0.363       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0849       |
|    n_updates             | 2840         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.827        |
|    value_loss            | 0.251        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.469        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.469        |
| reward                   | -0.26306185  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 16           |
|    time_elapsed          | 4882         |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0027277402 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.11         |
|    cost_value_loss       | 3.54         |
|    cost_values           | 1.17         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.757        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.94         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 0.968        |
|    value_loss            | 3.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0788       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0788       |
| reward                   | -0.36280096  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -613         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 23           |
|    time_elapsed          | 7197         |
|    total_timesteps       | 548864       |
| train/                   |              |
|    approx_kl             | 0.0051314095 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.5          |
|    cost_value_loss       | 91.8         |
|    cost_values           | 0.839        |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0.00736      |
|    learning_rate         | 0.0003       |
|    loss                  | 25.4         |
|    n_updates             | 2670         |
|    policy_gradient_loss  | -0.000497    |
|    std                   | 0.88         |
|    value_loss            | 177          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.123      |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 0.123      |
| reward                   | -0.466658  |
| rollout/                 |            |
|    ep_len_mean           | 972        |
|    ep_rew_mean           | -444       |
| time/                    |            |
|    fps                   | 6          |
|    iterations            | 18         |
|    time_elapsed          | 5871       |
|    total_timesteps       | 538624     |
| train/                   |            |
|    approx_kl             | 0.00400373 |
|    clip_fraction         | 0.0113     |
|    clip_range            | 0.2        |
|    cost_returns          | 17         |
|    cost_value_loss       | 211        |
|    cost_values           | 2.99       |
|    entropy               | -2.54      |
|    entropy_loss          | -2.54      |
|    explained_variance    | 0.864      |
|    lagrangian_multiplier | 0.0392     |
|    learning_rate         | 0.0003     |
|    loss                  | 8.03       |
|    n_updates             | 2620       |
|    policy_gradient_loss  | -0.00301   |
|    std                   | 0.862      |
|    value_loss            | 0.404      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.266        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.266        |
| reward                   | -0.30941427  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -491         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 29           |
|    time_elapsed          | 8866         |
|    total_timesteps       | 561152       |
| train/                   |              |
|    approx_kl             | 0.0029254344 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 5.95         |
|    cost_values           | 1.42         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.497        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.86         |
|    n_updates             | 2730         |
|    policy_gradient_loss  | -0.00494     |
|    std                   | 0.927        |
|    value_loss            | 3            |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.5555457  |
| rollout/                 |             |
|    ep_len_mean           | 889         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 26          |
|    time_elapsed          | 8396        |
|    total_timesteps       | 555008      |
| train/                   |             |
|    approx_kl             | 0.003866227 |
|    clip_fraction         | 0.0367      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.78        |
|    cost_value_loss       | 14.1        |
|    cost_values           | 2.4         |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.0663      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.79        |
|    n_updates             | 2700        |
|    policy_gradient_loss  | -0.00342    |
|    std                   | 0.707       |
|    value_loss            | 0.596       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0729       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0729       |
| reward                   | -0.40330178  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 41           |
|    time_elapsed          | 12393        |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0058894735 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.685        |
|    cost_value_loss       | 0.0134       |
|    cost_values           | 0.76         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | -5.52        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0829       |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.827        |
|    value_loss            | 0.965        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.59         |
| reward                   | -0.45037305  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 17           |
|    time_elapsed          | 5180         |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0039967815 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 1.4          |
|    cost_values           | 1.26         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.261        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.41         |
|    n_updates             | 2610         |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.97         |
|    value_loss            | 2.56         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0459      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0459      |
| reward                   | -0.45232317 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -610        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 24          |
|    time_elapsed          | 7523        |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.010273354 |
|    clip_fraction         | 0.0806      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.87        |
|    cost_value_loss       | 70.5        |
|    cost_values           | 1.12        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.0116      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.34        |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.00596    |
|    std                   | 0.879       |
|    value_loss            | 4.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.295        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.295        |
| reward                   | -0.29018182  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 19           |
|    time_elapsed          | 6205         |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0055885473 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 16.3         |
|    cost_value_loss       | 203          |
|    cost_values           | 2.96         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.841        |
|    lagrangian_multiplier | 0.0174       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.858        |
|    value_loss            | 0.469        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.315        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.315        |
| reward                   | -0.50251     |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -490         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 30           |
|    time_elapsed          | 9185         |
|    total_timesteps       | 563200       |
| train/                   |              |
|    approx_kl             | 0.0044531007 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.37         |
|    cost_value_loss       | 20.9         |
|    cost_values           | 1.51         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0.00551      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.74         |
|    n_updates             | 2740         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.928        |
|    value_loss            | 4.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.35178304 |
| rollout/                 |             |
|    ep_len_mean           | 889         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 27          |
|    time_elapsed          | 8737        |
|    total_timesteps       | 557056      |
| train/                   |             |
|    approx_kl             | 0.006926809 |
|    clip_fraction         | 0.0756      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.58        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.46        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0.685       |
|    lagrangian_multiplier | 0.000483    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.62        |
|    n_updates             | 2710        |
|    policy_gradient_loss  | -0.00705    |
|    std                   | 0.708       |
|    value_loss            | 3.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.343        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.343        |
| reward                   | -0.5078848   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 18           |
|    time_elapsed          | 5477         |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0063977176 |
|    clip_fraction         | 0.0547       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 0.883        |
|    cost_values           | 1.13         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.858        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.733        |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.00365     |
|    std                   | 0.97         |
|    value_loss            | 1.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.262        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.262        |
| reward                   | -0.42404518  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 42           |
|    time_elapsed          | 12718        |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0047691367 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.544        |
|    cost_value_loss       | 0.00804      |
|    cost_values           | 0.604        |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.16         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.363        |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.000954    |
|    std                   | 0.824        |
|    value_loss            | 1.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0169      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0169      |
| reward                   | -0.38596272 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -610        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 25          |
|    time_elapsed          | 7849        |
|    total_timesteps       | 552960      |
| train/                   |             |
|    approx_kl             | 0.015250088 |
|    clip_fraction         | 0.0417      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 160         |
|    cost_values           | 1.11        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.0117      |
|    learning_rate         | 0.0003      |
|    loss                  | 13.5        |
|    n_updates             | 2690        |
|    policy_gradient_loss  | -0.00596    |
|    std                   | 0.881       |
|    value_loss            | 15.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.311        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.311        |
| reward                   | -0.5645642   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 20           |
|    time_elapsed          | 6540         |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0035016253 |
|    clip_fraction         | 0.00459      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.4         |
|    cost_value_loss       | 109          |
|    cost_values           | 2.67         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0.0118       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.000893    |
|    std                   | 0.857        |
|    value_loss            | 0.996        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0157      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0157      |
| reward                   | -0.48394164 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 31          |
|    time_elapsed          | 9507        |
|    total_timesteps       | 565248      |
| train/                   |             |
|    approx_kl             | 0.005846086 |
|    clip_fraction         | 0.0495      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 40.4        |
|    cost_values           | 1.29        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.00425     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.86        |
|    n_updates             | 2750        |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 0.929       |
|    value_loss            | 1.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.244        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.244        |
| reward                   | -0.5674078   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 19           |
|    time_elapsed          | 5772         |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0052457377 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 2.51         |
|    cost_values           | 0.913        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.733        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.34         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.967        |
|    value_loss            | 3.72         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.41634735 |
| rollout/                 |             |
|    ep_len_mean           | 884         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 28          |
|    time_elapsed          | 9079        |
|    total_timesteps       | 559104      |
| train/                   |             |
|    approx_kl             | 0.004850722 |
|    clip_fraction         | 0.0589      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.33        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.67        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | -0.154      |
|    lagrangian_multiplier | 0.000386    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.18        |
|    n_updates             | 2720        |
|    policy_gradient_loss  | -0.00448    |
|    std                   | 0.708       |
|    value_loss            | 2.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.147        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.147        |
| reward                   | -0.44141164  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 43           |
|    time_elapsed          | 13047        |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0017423709 |
|    clip_fraction         | 0.0265       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.467        |
|    cost_value_loss       | 0.00465      |
|    cost_values           | 0.488        |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.342        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.242        |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.000424    |
|    std                   | 0.82         |
|    value_loss            | 1.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0703      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0703      |
| reward                   | -0.3922053  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -610        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 26          |
|    time_elapsed          | 8181        |
|    total_timesteps       | 555008      |
| train/                   |             |
|    approx_kl             | 0.008770732 |
|    clip_fraction         | 0.0532      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 143         |
|    cost_values           | 1.38        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.403       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 75.7        |
|    n_updates             | 2700        |
|    policy_gradient_loss  | -0.00692    |
|    std                   | 0.882       |
|    value_loss            | 0.723       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.238        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.238        |
| reward                   | -0.22640188  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 21           |
|    time_elapsed          | 6879         |
|    total_timesteps       | 544768       |
| train/                   |              |
|    approx_kl             | 0.0018071902 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 158          |
|    cost_values           | 2.03         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0.0146       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 2650         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.856        |
|    value_loss            | 3.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.166        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.166        |
| reward                   | -0.64636695  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 32           |
|    time_elapsed          | 9834         |
|    total_timesteps       | 567296       |
| train/                   |              |
|    approx_kl             | 0.0024974383 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 3.59         |
|    cost_values           | 1.2          |
|    entropy               | -2.66        |
|    entropy_loss          | -2.68        |
|    explained_variance    | -0.227       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.83         |
|    n_updates             | 2760         |
|    policy_gradient_loss  | -0.000519    |
|    std                   | 0.916        |
|    value_loss            | 1.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.436       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.436       |
| reward                   | -0.53738725 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 20          |
|    time_elapsed          | 6066        |
|    total_timesteps       | 542720      |
| train/                   |             |
|    approx_kl             | 0.002559086 |
|    clip_fraction         | 0.0354      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.38        |
|    cost_value_loss       | 5.9         |
|    cost_values           | 0.976       |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.752       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 2640        |
|    policy_gradient_loss  | -0.00341    |
|    std                   | 0.966       |
|    value_loss            | 2.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.54        |
| reward                   | -0.41937295 |
| rollout/                 |             |
|    ep_len_mean           | 884         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 29          |
|    time_elapsed          | 9421        |
|    total_timesteps       | 561152      |
| train/                   |             |
|    approx_kl             | 0.011916467 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.07        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 2.97        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.27        |
|    lagrangian_multiplier | 0.00887     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.89        |
|    n_updates             | 2730        |
|    policy_gradient_loss  | -0.00659    |
|    std                   | 0.703       |
|    value_loss            | 19.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0963       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0963       |
| reward                   | -0.33505934  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 44           |
|    time_elapsed          | 13379        |
|    total_timesteps       | 591872       |
| train/                   |              |
|    approx_kl             | 0.0021985997 |
|    clip_fraction         | 0.0609       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.744        |
|    cost_value_loss       | 4.06         |
|    cost_values           | 0.502        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.2          |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.07         |
|    n_updates             | 2880         |
|    policy_gradient_loss  | 0.000168     |
|    std                   | 0.816        |
|    value_loss            | 1.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.21         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.21         |
| reward                   | -0.5005438   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -608         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 27           |
|    time_elapsed          | 8511         |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0015140609 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 12.4         |
|    cost_value_loss       | 147          |
|    cost_values           | 1.89         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | -0.216       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 70.5         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.882        |
|    value_loss            | 0.357        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.178       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.178       |
| reward                   | -0.49521726 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 22          |
|    time_elapsed          | 7211        |
|    total_timesteps       | 546816      |
| train/                   |             |
|    approx_kl             | 0.004763527 |
|    clip_fraction         | 0.0464      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 124         |
|    cost_values           | 1.91        |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.814       |
|    lagrangian_multiplier | 0.0146      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.19        |
|    n_updates             | 2660        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.855       |
|    value_loss            | 4.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0688       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0688       |
| reward                   | -0.31098542  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 21           |
|    time_elapsed          | 6364         |
|    total_timesteps       | 544768       |
| train/                   |              |
|    approx_kl             | 0.0027445666 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 3.24         |
|    cost_values           | 0.824        |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.0458       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.55         |
|    n_updates             | 2650         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.969        |
|    value_loss            | 1.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.146       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.146       |
| reward                   | -0.41027075 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -487        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 33          |
|    time_elapsed          | 10162       |
|    total_timesteps       | 569344      |
| train/                   |             |
|    approx_kl             | 0.005021362 |
|    clip_fraction         | 0.0565      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 36.4        |
|    cost_values           | 1.54        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | -23.3       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.6        |
|    n_updates             | 2770        |
|    policy_gradient_loss  | 0.00308     |
|    std                   | 0.91        |
|    value_loss            | 3.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.328       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.328       |
| reward                   | -0.5085489  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 45          |
|    time_elapsed          | 13707       |
|    total_timesteps       | 593920      |
| train/                   |             |
|    approx_kl             | 0.008874425 |
|    clip_fraction         | 0.0791      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.594       |
|    cost_value_loss       | 0.0692      |
|    cost_values           | 0.641       |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.108       |
|    n_updates             | 2890        |
|    policy_gradient_loss  | -0.00455    |
|    std                   | 0.818       |
|    value_loss            | 0.272       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.7391071  |
| rollout/                 |             |
|    ep_len_mean           | 893         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 30          |
|    time_elapsed          | 9767        |
|    total_timesteps       | 563200      |
| train/                   |             |
|    approx_kl             | 0.006444904 |
|    clip_fraction         | 0.0875      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.47        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 2.97        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.745       |
|    lagrangian_multiplier | 0.00853     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.9         |
|    n_updates             | 2740        |
|    policy_gradient_loss  | -0.00628    |
|    std                   | 0.703       |
|    value_loss            | 1.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0479       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0479       |
| reward                   | -0.5070782   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -612         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 28           |
|    time_elapsed          | 8843         |
|    total_timesteps       | 559104       |
| train/                   |              |
|    approx_kl             | 0.0022286582 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 16.6         |
|    cost_value_loss       | 218          |
|    cost_values           | 2.43         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.363        |
|    lagrangian_multiplier | 0.00211      |
|    learning_rate         | 0.0003       |
|    loss                  | 53           |
|    n_updates             | 2720         |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.881        |
|    value_loss            | 0.544        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0533       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0533       |
| reward                   | -0.48991743  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 23           |
|    time_elapsed          | 7546         |
|    total_timesteps       | 548864       |
| train/                   |              |
|    approx_kl             | 0.0038673682 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.78         |
|    cost_value_loss       | 93.7         |
|    cost_values           | 2.11         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | -3.79        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.2         |
|    n_updates             | 2670         |
|    policy_gradient_loss  | -0.00211     |
|    std                   | 0.855        |
|    value_loss            | 4.01         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.11        |
| reward                   | -0.5437936  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 22          |
|    time_elapsed          | 6666        |
|    total_timesteps       | 546816      |
| train/                   |             |
|    approx_kl             | 0.004956942 |
|    clip_fraction         | 0.0447      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 1.06        |
|    cost_values           | 0.857       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.682       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.08        |
|    n_updates             | 2660        |
|    policy_gradient_loss  | -0.00508    |
|    std                   | 0.972       |
|    value_loss            | 1.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.147       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.147       |
| reward                   | -0.39820945 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -485        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 34          |
|    time_elapsed          | 10491       |
|    total_timesteps       | 571392      |
| train/                   |             |
|    approx_kl             | 0.001977195 |
|    clip_fraction         | 0.00386     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.41        |
|    cost_value_loss       | 25.1        |
|    cost_values           | 1.54        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0.0058      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 2780        |
|    policy_gradient_loss  | -0.000987   |
|    std                   | 0.91        |
|    value_loss            | 9.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.201       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.201       |
| reward                   | -0.462298   |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 46          |
|    time_elapsed          | 14034       |
|    total_timesteps       | 595968      |
| train/                   |             |
|    approx_kl             | 0.005107193 |
|    clip_fraction         | 0.0741      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.56        |
|    cost_value_loss       | 36.1        |
|    cost_values           | 0.95        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.171       |
|    lagrangian_multiplier | 0.00274     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.8         |
|    n_updates             | 2900        |
|    policy_gradient_loss  | 0.000372    |
|    std                   | 0.82        |
|    value_loss            | 1.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.51         |
| reward                   | -0.29817218  |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 31           |
|    time_elapsed          | 10112        |
|    total_timesteps       | 565248       |
| train/                   |              |
|    approx_kl             | 0.0079246275 |
|    clip_fraction         | 0.0746       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.24         |
|    cost_value_loss       | 17.3         |
|    cost_values           | 2.63         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0.765        |
|    lagrangian_multiplier | 0.00516      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.55         |
|    n_updates             | 2750         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.704        |
|    value_loss            | 1.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.394        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.394        |
| reward                   | -0.5279022   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -610         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 29           |
|    time_elapsed          | 9179         |
|    total_timesteps       | 561152       |
| train/                   |              |
|    approx_kl             | 0.0062082447 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.8         |
|    cost_value_loss       | 144          |
|    cost_values           | 2.9          |
|    entropy               | -2.59        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.497        |
|    lagrangian_multiplier | 0.0191       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.81         |
|    n_updates             | 2730         |
|    policy_gradient_loss  | -0.00354     |
|    std                   | 0.882        |
|    value_loss            | 0.226        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.179        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.179        |
| reward                   | -0.43193185  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 23           |
|    time_elapsed          | 6969         |
|    total_timesteps       | 548864       |
| train/                   |              |
|    approx_kl             | 0.0045217862 |
|    clip_fraction         | 0.0515       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.862        |
|    cost_value_loss       | 0.412        |
|    cost_values           | 0.747        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.504        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.736        |
|    n_updates             | 2670         |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 0.97         |
|    value_loss            | 1.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.515        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.515        |
| reward                   | -0.61219007  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 24           |
|    time_elapsed          | 7885         |
|    total_timesteps       | 550912       |
| train/                   |              |
|    approx_kl             | 0.0039041983 |
|    clip_fraction         | 0.0353       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.63         |
|    cost_value_loss       | 95.2         |
|    cost_values           | 2.52         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.304        |
|    lagrangian_multiplier | 0.00187      |
|    learning_rate         | 0.0003       |
|    loss                  | 25.2         |
|    n_updates             | 2680         |
|    policy_gradient_loss  | -0.00414     |
|    std                   | 0.854        |
|    value_loss            | 5.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.237        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.237        |
| reward                   | -0.3215794   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 35           |
|    time_elapsed          | 10820        |
|    total_timesteps       | 573440       |
| train/                   |              |
|    approx_kl             | 0.0031493963 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.04         |
|    cost_value_loss       | 68.6         |
|    cost_values           | 1.37         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | -5.96        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.9         |
|    n_updates             | 2790         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.91         |
|    value_loss            | 4.7          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0775      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0775      |
| reward                   | -0.4569739  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 47          |
|    time_elapsed          | 14366       |
|    total_timesteps       | 598016      |
| train/                   |             |
|    approx_kl             | 0.008055105 |
|    clip_fraction         | 0.0867      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.904       |
|    cost_value_loss       | 0.0265      |
|    cost_values           | 0.958       |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | -0.449      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0977      |
|    n_updates             | 2910        |
|    policy_gradient_loss  | -0.00514    |
|    std                   | 0.82        |
|    value_loss            | 0.522       |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.20330255 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 32          |
|    time_elapsed          | 10457       |
|    total_timesteps       | 567296      |
| train/                   |             |
|    approx_kl             | 0.007516704 |
|    clip_fraction         | 0.0744      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.3         |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.666       |
|    lagrangian_multiplier | 0.00376     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.1         |
|    n_updates             | 2760        |
|    policy_gradient_loss  | -0.00558    |
|    std                   | 0.701       |
|    value_loss            | 9.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0179      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0179      |
| reward                   | -0.40718618 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -611        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 30          |
|    time_elapsed          | 9517        |
|    total_timesteps       | 563200      |
| train/                   |             |
|    approx_kl             | 0.004849901 |
|    clip_fraction         | 0.0214      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.3        |
|    cost_value_loss       | 103         |
|    cost_values           | 2.98        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.58       |
|    explained_variance    | -0.391      |
|    lagrangian_multiplier | 0.0143      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.73        |
|    n_updates             | 2740        |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.876       |
|    value_loss            | 0.903       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.114       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.114       |
| reward                   | -0.23446745 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 24          |
|    time_elapsed          | 7271        |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.00424173  |
|    clip_fraction         | 0.0337      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.969       |
|    cost_value_loss       | 1.21        |
|    cost_values           | 0.812       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.408       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.19        |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.00511    |
|    std                   | 0.974       |
|    value_loss            | 2.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.468        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.468        |
| reward                   | -0.47606963  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 25           |
|    time_elapsed          | 8227         |
|    total_timesteps       | 552960       |
| train/                   |              |
|    approx_kl             | 0.0042273058 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.6         |
|    cost_value_loss       | 186          |
|    cost_values           | 2.91         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.853        |
|    lagrangian_multiplier | 0.0238       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.65         |
|    n_updates             | 2690         |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 0.853        |
|    value_loss            | 1.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0139      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0139      |
| reward                   | -0.517702   |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -484        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 36          |
|    time_elapsed          | 11151       |
|    total_timesteps       | 575488      |
| train/                   |             |
|    approx_kl             | 0.002470239 |
|    clip_fraction         | 0.0294      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 2.44        |
|    cost_values           | 1.47        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.613       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.61        |
|    n_updates             | 2800        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.912       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.347       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.347       |
| reward                   | -0.5690787  |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 48          |
|    time_elapsed          | 14699       |
|    total_timesteps       | 600064      |
| train/                   |             |
|    approx_kl             | 0.010415578 |
|    clip_fraction         | 0.0963      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.97        |
|    cost_value_loss       | 3.07        |
|    cost_values           | 0.82        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.42       |
|    explained_variance    | -0.0655     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.13        |
|    n_updates             | 2920        |
|    policy_gradient_loss  | -0.00536    |
|    std                   | 0.823       |
|    value_loss            | 0.204       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.55        |
| reward                   | -0.49907145 |
| rollout/                 |             |
|    ep_len_mean           | 893         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 33          |
|    time_elapsed          | 10804       |
|    total_timesteps       | 569344      |
| train/                   |             |
|    approx_kl             | 0.005047653 |
|    clip_fraction         | 0.0793      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.81        |
|    cost_value_loss       | 13.6        |
|    cost_values           | 2.52        |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.44        |
|    n_updates             | 2770        |
|    policy_gradient_loss  | -0.00726    |
|    std                   | 0.699       |
|    value_loss            | 1.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0428      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0428      |
| reward                   | -0.43956757 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 25          |
|    time_elapsed          | 7574        |
|    total_timesteps       | 552960      |
| train/                   |             |
|    approx_kl             | 0.007220567 |
|    clip_fraction         | 0.0361      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.946       |
|    cost_value_loss       | 1.19        |
|    cost_values           | 0.882       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.0861      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.26        |
|    n_updates             | 2690        |
|    policy_gradient_loss  | -0.00176    |
|    std                   | 0.97        |
|    value_loss            | 1.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.192       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.192       |
| reward                   | -0.32485873 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -610        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 31          |
|    time_elapsed          | 9852        |
|    total_timesteps       | 565248      |
| train/                   |             |
|    approx_kl             | 0.008660359 |
|    clip_fraction         | 0.0564      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.37        |
|    cost_value_loss       | 85          |
|    cost_values           | 2.96        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.867       |
|    lagrangian_multiplier | 0.0122      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.26        |
|    n_updates             | 2750        |
|    policy_gradient_loss  | -0.00486    |
|    std                   | 0.874       |
|    value_loss            | 0.435       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.277       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.277       |
| reward                   | -0.5851618  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 26          |
|    time_elapsed          | 8568        |
|    total_timesteps       | 555008      |
| train/                   |             |
|    approx_kl             | 0.005228206 |
|    clip_fraction         | 0.0291      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 172         |
|    cost_values           | 2.78        |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0.0237      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.35        |
|    n_updates             | 2700        |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.852       |
|    value_loss            | 0.555       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.721       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.721       |
| reward                   | -0.32506087 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -485        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 37          |
|    time_elapsed          | 11486       |
|    total_timesteps       | 577536      |
| train/                   |             |
|    approx_kl             | 0.005493134 |
|    clip_fraction         | 0.0612      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.99        |
|    cost_value_loss       | 65.9        |
|    cost_values           | 1.8         |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.471       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.6        |
|    n_updates             | 2810        |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 0.913       |
|    value_loss            | 2.68        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0166       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0166       |
| reward                   | -0.4214725   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 49           |
|    time_elapsed          | 15035        |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0034787823 |
|    clip_fraction         | 0.00981      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.714        |
|    cost_value_loss       | 0.0178       |
|    cost_values           | 0.801        |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.951        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0922       |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.000276    |
|    std                   | 0.824        |
|    value_loss            | 0.686        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.21        |
| reward                   | -0.38527963 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 34          |
|    time_elapsed          | 11153       |
|    total_timesteps       | 571392      |
| train/                   |             |
|    approx_kl             | 0.006976475 |
|    clip_fraction         | 0.0833      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.39        |
|    cost_value_loss       | 16.9        |
|    cost_values           | 2.75        |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.578       |
|    lagrangian_multiplier | 0.00615     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 2780        |
|    policy_gradient_loss  | -0.00757    |
|    std                   | 0.697       |
|    value_loss            | 8.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.321        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.321        |
| reward                   | -0.5263834   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 26           |
|    time_elapsed          | 7880         |
|    total_timesteps       | 555008       |
| train/                   |              |
|    approx_kl             | 0.0060473746 |
|    clip_fraction         | 0.0543       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.16         |
|    cost_values           | 0.943        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -0.289       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.873        |
|    n_updates             | 2700         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.972        |
|    value_loss            | 1.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.112       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.112       |
| reward                   | -0.2300495  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -609        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 32          |
|    time_elapsed          | 10196       |
|    total_timesteps       | 567296      |
| train/                   |             |
|    approx_kl             | 0.001965403 |
|    clip_fraction         | 0.0183      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 79.7        |
|    cost_values           | 2.98        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.57       |
|    explained_variance    | -0.483      |
|    lagrangian_multiplier | 0.0158      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.2         |
|    n_updates             | 2760        |
|    policy_gradient_loss  | -0.000338   |
|    std                   | 0.872       |
|    value_loss            | 2.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.587        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.587        |
| reward                   | -0.35656455  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 27           |
|    time_elapsed          | 8908         |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0054500718 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 149          |
|    cost_values           | 2.69         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.948        |
|    lagrangian_multiplier | 0.0176       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.4          |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.851        |
|    value_loss            | 0.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0492       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0492       |
| reward                   | -0.55499536  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -477         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 38           |
|    time_elapsed          | 11822        |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0037264316 |
|    clip_fraction         | 0.0041       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.39         |
|    cost_value_loss       | 80           |
|    cost_values           | 2.33         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.802        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 39.8         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.00211     |
|    std                   | 0.912        |
|    value_loss            | 1.65         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.395      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.395      |
| reward             | -0.5616501 |
| rollout/           |            |
|    ep_len_mean     | 984        |
|    ep_rew_mean     | -455       |
| time/              |            |
|    fps             | 6          |
|    iterations      | 1          |
|    time_elapsed    | 337        |
|    total_timesteps | 604160     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.318        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.318        |
| reward                   | -0.36162612  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 27           |
|    time_elapsed          | 8186         |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0024066279 |
|    clip_fraction         | 0.0822       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 12.4         |
|    cost_values           | 0.941        |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -0.895       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.84         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | 0.00117      |
|    std                   | 0.974        |
|    value_loss            | 1.88         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.5271603  |
| rollout/                 |             |
|    ep_len_mean           | 893         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 35          |
|    time_elapsed          | 11505       |
|    total_timesteps       | 573440      |
| train/                   |             |
|    approx_kl             | 0.009547927 |
|    clip_fraction         | 0.0712      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.45        |
|    cost_value_loss       | 15.2        |
|    cost_values           | 2.87        |
|    entropy               | -2.1        |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.798       |
|    lagrangian_multiplier | 0.00766     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 2790        |
|    policy_gradient_loss  | -0.00418    |
|    std                   | 0.696       |
|    value_loss            | 7.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0308      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0308      |
| reward                   | -0.4926102  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -607        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 33          |
|    time_elapsed          | 10531       |
|    total_timesteps       | 569344      |
| train/                   |             |
|    approx_kl             | 0.004200885 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.59        |
|    cost_value_loss       | 72.7        |
|    cost_values           | 2.98        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0.0166      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.49        |
|    n_updates             | 2770        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 0.868       |
|    value_loss            | 1.32        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.143        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.143        |
| reward                   | -0.21605265  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 28           |
|    time_elapsed          | 9248         |
|    total_timesteps       | 559104       |
| train/                   |              |
|    approx_kl             | 0.0049603265 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.9         |
|    cost_value_loss       | 236          |
|    cost_values           | 2.87         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0.0204       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.7         |
|    n_updates             | 2720         |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.849        |
|    value_loss            | 0.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.486        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.486        |
| reward                   | -0.45590693  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -480         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 39           |
|    time_elapsed          | 12155        |
|    total_timesteps       | 581632       |
| train/                   |              |
|    approx_kl             | 0.0023623966 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.7          |
|    cost_value_loss       | 91.9         |
|    cost_values           | 2.62         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.202        |
|    lagrangian_multiplier | 0.0136       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.06         |
|    n_updates             | 2830         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.911        |
|    value_loss            | 2.94         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.254       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.254       |
| reward                   | -0.36938623 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -457        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 2           |
|    time_elapsed          | 674         |
|    total_timesteps       | 606208      |
| train/                   |             |
|    approx_kl             | 0.004631162 |
|    clip_fraction         | 0.0201      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.57        |
|    cost_value_loss       | 0.0328      |
|    cost_values           | 0.732       |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | -0.056      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.155       |
|    n_updates             | 2950        |
|    policy_gradient_loss  | -0.000301   |
|    std                   | 0.821       |
|    value_loss            | 1.83        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.247        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.247        |
| reward                   | -0.47081786  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 28           |
|    time_elapsed          | 8494         |
|    total_timesteps       | 559104       |
| train/                   |              |
|    approx_kl             | 0.0031137222 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.15         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 1.26         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.35         |
|    lagrangian_multiplier | 0.00188      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.37         |
|    n_updates             | 2720         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.976        |
|    value_loss            | 1.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.24884374 |
| rollout/                 |             |
|    ep_len_mean           | 900         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 36          |
|    time_elapsed          | 11856       |
|    total_timesteps       | 575488      |
| train/                   |             |
|    approx_kl             | 0.007093484 |
|    clip_fraction         | 0.0489      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.06        |
|    cost_value_loss       | 15.3        |
|    cost_values           | 2.67        |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0.712       |
|    lagrangian_multiplier | 0.00359     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.7         |
|    n_updates             | 2800        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.696       |
|    value_loss            | 8.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.131       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.131       |
| reward                   | -0.41532403 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -608        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 34          |
|    time_elapsed          | 10871       |
|    total_timesteps       | 571392      |
| train/                   |             |
|    approx_kl             | 0.005811097 |
|    clip_fraction         | 0.0345      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.64        |
|    cost_value_loss       | 69.9        |
|    cost_values           | 2.94        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0.00803     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.9         |
|    n_updates             | 2780        |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.865       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.616       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.616       |
| reward                   | -0.52014035 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -438        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 29          |
|    time_elapsed          | 9589        |
|    total_timesteps       | 561152      |
| train/                   |             |
|    approx_kl             | 0.004900597 |
|    clip_fraction         | 0.0177      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 129         |
|    cost_values           | 2.8         |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.166       |
|    lagrangian_multiplier | 0.0158      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 2730        |
|    policy_gradient_loss  | -0.00197    |
|    std                   | 0.849       |
|    value_loss            | 10.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0532       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0532       |
| reward                   | -0.5091511   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 40           |
|    time_elapsed          | 12487        |
|    total_timesteps       | 583680       |
| train/                   |              |
|    approx_kl             | 0.0052145044 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.93         |
|    cost_value_loss       | 39.5         |
|    cost_values           | 2.14         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.363        |
|    lagrangian_multiplier | 0.0064       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.49         |
|    n_updates             | 2840         |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 0.907        |
|    value_loss            | 1.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.492        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.492        |
| reward                   | -0.46861124  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 29           |
|    time_elapsed          | 8803         |
|    total_timesteps       | 561152       |
| train/                   |              |
|    approx_kl             | 0.0038845884 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 9.47         |
|    cost_values           | 1.21         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.454        |
|    lagrangian_multiplier | 0.000368     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.7          |
|    n_updates             | 2730         |
|    policy_gradient_loss  | -0.000694    |
|    std                   | 0.982        |
|    value_loss            | 2.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.007        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.007        |
| reward                   | -0.5120101   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 3            |
|    time_elapsed          | 1014         |
|    total_timesteps       | 608256       |
| train/                   |              |
|    approx_kl             | 0.0021706594 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 9.08         |
|    cost_values           | 0.676        |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -0.493       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.68         |
|    n_updates             | 2960         |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.82         |
|    value_loss            | 3.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.77         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.77         |
| reward                   | -0.33404836  |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 37           |
|    time_elapsed          | 12210        |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0047556153 |
|    clip_fraction         | 0.0336       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.28         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 2.65         |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.881        |
|    lagrangian_multiplier | 0.000133     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.63         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 0.697        |
|    value_loss            | 2.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.053        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.053        |
| reward                   | -0.20380923  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -606         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 35           |
|    time_elapsed          | 11216        |
|    total_timesteps       | 573440       |
| train/                   |              |
|    approx_kl             | 0.0082155885 |
|    clip_fraction         | 0.0583       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.6         |
|    cost_value_loss       | 130          |
|    cost_values           | 2.99         |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0.00603      |
|    learning_rate         | 0.0003       |
|    loss                  | 18.5         |
|    n_updates             | 2790         |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 0.864        |
|    value_loss            | 0.257        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.26         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.26         |
| reward                   | -0.50937927  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 30           |
|    time_elapsed          | 9932         |
|    total_timesteps       | 563200       |
| train/                   |              |
|    approx_kl             | 0.0028711776 |
|    clip_fraction         | 0.0404       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.86         |
|    cost_value_loss       | 93.4         |
|    cost_values           | 2.62         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0.0102       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.82         |
|    n_updates             | 2740         |
|    policy_gradient_loss  | -0.00456     |
|    std                   | 0.848        |
|    value_loss            | 2.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.121       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.121       |
| reward                   | -0.5515458  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -474        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 41          |
|    time_elapsed          | 12824       |
|    total_timesteps       | 585728      |
| train/                   |             |
|    approx_kl             | 0.004552817 |
|    clip_fraction         | 0.0152      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.03        |
|    cost_value_loss       | 2.65        |
|    cost_values           | 1.8         |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0.000283    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.73        |
|    n_updates             | 2850        |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 0.905       |
|    value_loss            | 3.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0201      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0201      |
| reward                   | -0.46095163 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 30          |
|    time_elapsed          | 9111        |
|    total_timesteps       | 563200      |
| train/                   |             |
|    approx_kl             | 0.002285236 |
|    clip_fraction         | 0.0334      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 0.256       |
|    cost_values           | 1.1         |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.708       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.221       |
|    n_updates             | 2740        |
|    policy_gradient_loss  | -0.000782   |
|    std                   | 0.98        |
|    value_loss            | 0.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.179       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.179       |
| reward                   | -0.3214429  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 4           |
|    time_elapsed          | 1355        |
|    total_timesteps       | 610304      |
| train/                   |             |
|    approx_kl             | 0.008476188 |
|    clip_fraction         | 0.0545      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.56        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 0.909       |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.429       |
|    lagrangian_multiplier | 0.000544    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.44        |
|    n_updates             | 2970        |
|    policy_gradient_loss  | -0.00442    |
|    std                   | 0.819       |
|    value_loss            | 0.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5298079  |
| rollout/                 |             |
|    ep_len_mean           | 894         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 38          |
|    time_elapsed          | 12564       |
|    total_timesteps       | 579584      |
| train/                   |             |
|    approx_kl             | 0.012831101 |
|    clip_fraction         | 0.0903      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.08        |
|    cost_value_loss       | 15.2        |
|    cost_values           | 2.71        |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0.541       |
|    lagrangian_multiplier | 0.00399     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 2820        |
|    policy_gradient_loss  | -0.00648    |
|    std                   | 0.695       |
|    value_loss            | 4.88        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.363        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.363        |
| reward                   | -0.4823541   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -604         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 36           |
|    time_elapsed          | 11562        |
|    total_timesteps       | 575488       |
| train/                   |              |
|    approx_kl             | 0.0021376861 |
|    clip_fraction         | 0.0305       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.32         |
|    cost_value_loss       | 47.2         |
|    cost_values           | 3            |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.09         |
|    lagrangian_multiplier | 0.00982      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.2          |
|    n_updates             | 2800         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.86         |
|    value_loss            | 2.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0139       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0139       |
| reward                   | -0.41617128  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 31           |
|    time_elapsed          | 10276        |
|    total_timesteps       | 565248       |
| train/                   |              |
|    approx_kl             | 0.0032939848 |
|    clip_fraction         | 0.0397       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.58         |
|    cost_value_loss       | 100          |
|    cost_values           | 2.69         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.672        |
|    lagrangian_multiplier | 0.00962      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 2750         |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 0.846        |
|    value_loss            | 1.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.146        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.146        |
| reward                   | -0.4734517   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 42           |
|    time_elapsed          | 13164        |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0027296345 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.18         |
|    cost_value_loss       | 61.7         |
|    cost_values           | 1.99         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.285        |
|    lagrangian_multiplier | 0.00588      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.66         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.903        |
|    value_loss            | 10.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0587       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0587       |
| reward                   | -0.35632667  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 31           |
|    time_elapsed          | 9424         |
|    total_timesteps       | 565248       |
| train/                   |              |
|    approx_kl             | 0.0080496855 |
|    clip_fraction         | 0.0896       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 6.11         |
|    cost_values           | 0.98         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.127        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.85         |
|    n_updates             | 2750         |
|    policy_gradient_loss  | -0.00333     |
|    std                   | 0.979        |
|    value_loss            | 1.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0425       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0425       |
| reward                   | -0.4006183   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 5            |
|    time_elapsed          | 1698         |
|    total_timesteps       | 612352       |
| train/                   |              |
|    approx_kl             | 0.0044352887 |
|    clip_fraction         | 0.0352       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.688        |
|    cost_value_loss       | 0.00986      |
|    cost_values           | 0.731        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.191        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0995       |
|    n_updates             | 2980         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.818        |
|    value_loss            | 1.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.29        |
| reward                   | -0.39759272 |
| rollout/                 |             |
|    ep_len_mean           | 878         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 39          |
|    time_elapsed          | 12922       |
|    total_timesteps       | 581632      |
| train/                   |             |
|    approx_kl             | 0.00909877  |
|    clip_fraction         | 0.0819      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.71        |
|    cost_value_loss       | 17.9        |
|    cost_values           | 2.78        |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0.836       |
|    lagrangian_multiplier | 0.00902     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 2830        |
|    policy_gradient_loss  | -0.00395    |
|    std                   | 0.694       |
|    value_loss            | 6.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.517        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.517        |
| reward                   | -0.42000043  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -605         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 37           |
|    time_elapsed          | 11908        |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0039044986 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 102          |
|    cost_values           | 2.99         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.889        |
|    lagrangian_multiplier | 0.02         |
|    learning_rate         | 0.0003       |
|    loss                  | 7.17         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | -0.00337     |
|    std                   | 0.858        |
|    value_loss            | 0.589        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.319       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.319       |
| reward                   | -0.4443819  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 32          |
|    time_elapsed          | 10623       |
|    total_timesteps       | 567296      |
| train/                   |             |
|    approx_kl             | 0.011861491 |
|    clip_fraction         | 0.0596      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.9        |
|    cost_value_loss       | 237         |
|    cost_values           | 2.88        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0.0224      |
|    learning_rate         | 0.0003      |
|    loss                  | 12.2        |
|    n_updates             | 2760        |
|    policy_gradient_loss  | -0.004      |
|    std                   | 0.846       |
|    value_loss            | 0.448       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.207        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.207        |
| reward                   | -0.45214647  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 43           |
|    time_elapsed          | 13507        |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0038959405 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 0.051        |
|    cost_values           | 1.52         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.127        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.26         |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.898        |
|    value_loss            | 5.27         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0944      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0944      |
| reward                   | -0.3342232  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 32          |
|    time_elapsed          | 9741        |
|    total_timesteps       | 567296      |
| train/                   |             |
|    approx_kl             | 0.003137222 |
|    clip_fraction         | 0.00605     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.7         |
|    cost_value_loss       | 48.8        |
|    cost_values           | 1.33        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.443       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.8        |
|    n_updates             | 2760        |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.979       |
|    value_loss            | 0.371       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0545       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0545       |
| reward                   | -0.40512043  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 6            |
|    time_elapsed          | 2035         |
|    total_timesteps       | 614400       |
| train/                   |              |
|    approx_kl             | 0.0059997453 |
|    clip_fraction         | 0.0426       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.545        |
|    cost_value_loss       | 0.00655      |
|    cost_values           | 0.534        |
|    entropy               | -2.43        |
|    entropy_loss          | -2.42        |
|    explained_variance    | -0.137       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.992        |
|    n_updates             | 2990         |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.82         |
|    value_loss            | 2.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.194        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.194        |
| reward                   | -0.57598096  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -611         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 38           |
|    time_elapsed          | 12255        |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0052681775 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.51         |
|    cost_value_loss       | 55.8         |
|    cost_values           | 2.95         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.613        |
|    lagrangian_multiplier | 0.00703      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.16         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.856        |
|    value_loss            | 0.844        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.46899873 |
| rollout/                 |             |
|    ep_len_mean           | 878         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 40          |
|    time_elapsed          | 13280       |
|    total_timesteps       | 583680      |
| train/                   |             |
|    approx_kl             | 0.013561055 |
|    clip_fraction         | 0.0884      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.88        |
|    cost_value_loss       | 19          |
|    cost_values           | 2.89        |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0.784       |
|    lagrangian_multiplier | 0.0054      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.64        |
|    n_updates             | 2840        |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.695       |
|    value_loss            | 10.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.285        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.285        |
| reward                   | -0.5084576   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 33           |
|    time_elapsed          | 10057        |
|    total_timesteps       | 569344       |
| train/                   |              |
|    approx_kl             | 0.0038589716 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 1.84         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | -0.224       |
|    lagrangian_multiplier | 0.00226      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.4          |
|    n_updates             | 2770         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.976        |
|    value_loss            | 0.658        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.29         |
| reward                   | -0.72018737  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 33           |
|    time_elapsed          | 10976        |
|    total_timesteps       | 569344       |
| train/                   |              |
|    approx_kl             | 0.0041660164 |
|    clip_fraction         | 0.0475       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.1         |
|    cost_value_loss       | 218          |
|    cost_values           | 3            |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0.0487       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.12         |
|    n_updates             | 2770         |
|    policy_gradient_loss  | -0.00536     |
|    std                   | 0.846        |
|    value_loss            | 0.308        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.292        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.292        |
| reward                   | -0.51819366  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 44           |
|    time_elapsed          | 13849        |
|    total_timesteps       | 591872       |
| train/                   |              |
|    approx_kl             | 0.0054818867 |
|    clip_fraction         | 0.0648       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.74         |
|    cost_value_loss       | 83           |
|    cost_values           | 1.91         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.726        |
|    lagrangian_multiplier | 0.00514      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 2880         |
|    policy_gradient_loss  | -0.000489    |
|    std                   | 0.896        |
|    value_loss            | 3.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0706       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0706       |
| reward                   | -0.25286806  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 7            |
|    time_elapsed          | 2375         |
|    total_timesteps       | 616448       |
| train/                   |              |
|    approx_kl             | 0.0027379205 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.412        |
|    cost_value_loss       | 0.00498      |
|    cost_values           | 0.458        |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -0.0441      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0533       |
|    n_updates             | 3000         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.82         |
|    value_loss            | 0.215        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.192       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.192       |
| reward                   | -0.35892504 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -613        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 39          |
|    time_elapsed          | 12602       |
|    total_timesteps       | 581632      |
| train/                   |             |
|    approx_kl             | 0.00690206  |
|    clip_fraction         | 0.076       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.86        |
|    cost_value_loss       | 58.3        |
|    cost_values           | 2.97        |
|    entropy               | -2.52       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0.0114      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.54        |
|    n_updates             | 2830        |
|    policy_gradient_loss  | -0.00659    |
|    std                   | 0.855       |
|    value_loss            | 0.223       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.72        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.72        |
| reward                   | -0.4988981  |
| rollout/                 |             |
|    ep_len_mean           | 880         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 41          |
|    time_elapsed          | 13638       |
|    total_timesteps       | 585728      |
| train/                   |             |
|    approx_kl             | 0.006122148 |
|    clip_fraction         | 0.0651      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.29        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.95        |
|    entropy               | -2.09       |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0.00595     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.03        |
|    n_updates             | 2850        |
|    policy_gradient_loss  | -0.00428    |
|    std                   | 0.69        |
|    value_loss            | 0.907       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.43         |
| reward                   | -0.51869094  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 34           |
|    time_elapsed          | 10369        |
|    total_timesteps       | 571392       |
| train/                   |              |
|    approx_kl             | 0.0027823234 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.16         |
|    cost_value_loss       | 23.6         |
|    cost_values           | 2.26         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.479        |
|    lagrangian_multiplier | 0.0025       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.22         |
|    n_updates             | 2780         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.979        |
|    value_loss            | 1.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.169        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.169        |
| reward                   | -0.23089245  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 34           |
|    time_elapsed          | 11328        |
|    total_timesteps       | 571392       |
| train/                   |              |
|    approx_kl             | 0.0072455243 |
|    clip_fraction         | 0.0674       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.8         |
|    cost_value_loss       | 199          |
|    cost_values           | 2.84         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.93         |
|    lagrangian_multiplier | 0.0242       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.89         |
|    n_updates             | 2780         |
|    policy_gradient_loss  | -0.00695     |
|    std                   | 0.848        |
|    value_loss            | 0.378        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.54979     |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 45           |
|    time_elapsed          | 14195        |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0051699774 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.24         |
|    cost_value_loss       | 69.6         |
|    cost_values           | 1.8          |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.856        |
|    lagrangian_multiplier | 0.00666      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.64         |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.00353     |
|    std                   | 0.895        |
|    value_loss            | 1.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.146        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.146        |
| reward                   | -0.2771315   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 8            |
|    time_elapsed          | 2720         |
|    total_timesteps       | 618496       |
| train/                   |              |
|    approx_kl             | 0.0017919639 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.327        |
|    cost_value_loss       | 0.00401      |
|    cost_values           | 0.366        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.363        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.87         |
|    n_updates             | 3010         |
|    policy_gradient_loss  | -0.000656    |
|    std                   | 0.818        |
|    value_loss            | 2.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0688       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0688       |
| reward                   | -0.2522736   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -634         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 40           |
|    time_elapsed          | 12953        |
|    total_timesteps       | 583680       |
| train/                   |              |
|    approx_kl             | 0.0054819654 |
|    clip_fraction         | 0.0891       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.41         |
|    cost_value_loss       | 55.9         |
|    cost_values           | 2.86         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0.0102       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.11         |
|    n_updates             | 2840         |
|    policy_gradient_loss  | -0.000251    |
|    std                   | 0.854        |
|    value_loss            | 1.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.21         |
| reward                   | -0.27870238  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 35           |
|    time_elapsed          | 10686        |
|    total_timesteps       | 573440       |
| train/                   |              |
|    approx_kl             | 0.0035024018 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.21         |
|    cost_value_loss       | 81.8         |
|    cost_values           | 2.46         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0.0113       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.27         |
|    n_updates             | 2790         |
|    policy_gradient_loss  | -0.0033      |
|    std                   | 0.981        |
|    value_loss            | 0.865        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.47892806 |
| rollout/                 |             |
|    ep_len_mean           | 876         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 42          |
|    time_elapsed          | 13999       |
|    total_timesteps       | 587776      |
| train/                   |             |
|    approx_kl             | 0.0126441   |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.83        |
|    cost_value_loss       | 10.4        |
|    cost_values           | 2.97        |
|    entropy               | -2.09       |
|    entropy_loss          | -2.09       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0.00485     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.82        |
|    n_updates             | 2860        |
|    policy_gradient_loss  | -0.00503    |
|    std                   | 0.69        |
|    value_loss            | 1.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0193      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0193      |
| reward                   | -0.59746206 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -464        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 46          |
|    time_elapsed          | 14544       |
|    total_timesteps       | 595968      |
| train/                   |             |
|    approx_kl             | 0.005559352 |
|    clip_fraction         | 0.0454      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 40          |
|    cost_values           | 1.67        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.551       |
|    lagrangian_multiplier | 0.00631     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.67        |
|    n_updates             | 2900        |
|    policy_gradient_loss  | -0.0043     |
|    std                   | 0.893       |
|    value_loss            | 3.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.242        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.242        |
| reward                   | -0.33159232  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 35           |
|    time_elapsed          | 11680        |
|    total_timesteps       | 573440       |
| train/                   |              |
|    approx_kl             | 0.0034101158 |
|    clip_fraction         | 0.0485       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 132          |
|    cost_values           | 2.57         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.881        |
|    lagrangian_multiplier | 0.0698       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.06         |
|    n_updates             | 2790         |
|    policy_gradient_loss  | 0.00121      |
|    std                   | 0.847        |
|    value_loss            | 5.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0486      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0486      |
| reward                   | -0.419461   |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -456        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 9           |
|    time_elapsed          | 3069        |
|    total_timesteps       | 620544      |
| train/                   |             |
|    approx_kl             | 0.004465523 |
|    clip_fraction         | 0.0275      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.297       |
|    cost_value_loss       | 0.00357     |
|    cost_values           | 0.329       |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | -1.58       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.819       |
|    n_updates             | 3020        |
|    policy_gradient_loss  | -0.00178    |
|    std                   | 0.816       |
|    value_loss            | 3.02        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.125        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.125        |
| reward                   | -0.3094201   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 36           |
|    time_elapsed          | 11004        |
|    total_timesteps       | 575488       |
| train/                   |              |
|    approx_kl             | 0.0058235764 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 0.195        |
|    cost_values           | 2.16         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.339        |
|    lagrangian_multiplier | 9.45e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 0.766        |
|    n_updates             | 2800         |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 0.981        |
|    value_loss            | 2.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0448      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0448      |
| reward                   | -0.34101683 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -632        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 41          |
|    time_elapsed          | 13305       |
|    total_timesteps       | 585728      |
| train/                   |             |
|    approx_kl             | 0.003499732 |
|    clip_fraction         | 0.0305      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.92        |
|    cost_value_loss       | 75.8        |
|    cost_values           | 2.04        |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | -17.7       |
|    lagrangian_multiplier | 0.624       |
|    learning_rate         | 0.0003      |
|    loss                  | 2.65        |
|    n_updates             | 2850        |
|    policy_gradient_loss  | 0.00309     |
|    std                   | 0.854       |
|    value_loss            | 102         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.46044573  |
| rollout/                 |              |
|    ep_len_mean           | 870          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 43           |
|    time_elapsed          | 14359        |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0073113106 |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.01         |
|    cost_value_loss       | 18.3         |
|    cost_values           | 2.99         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0.774        |
|    lagrangian_multiplier | 0.00728      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.16         |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 0.689        |
|    value_loss            | 6.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.17         |
| reward                   | -0.3741213   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 47           |
|    time_elapsed          | 14892        |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0040291734 |
|    clip_fraction         | 0.0392       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.11         |
|    cost_value_loss       | 31.4         |
|    cost_values           | 1.75         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.464        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.00447     |
|    std                   | 0.891        |
|    value_loss            | 1.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.000606     |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.000606     |
| reward                   | -0.32435712  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 36           |
|    time_elapsed          | 12031        |
|    total_timesteps       | 575488       |
| train/                   |              |
|    approx_kl             | 0.0026524588 |
|    clip_fraction         | 0.00684      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.88         |
|    cost_value_loss       | 114          |
|    cost_values           | 2.19         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.874        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.7         |
|    n_updates             | 2800         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.848        |
|    value_loss            | 2.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.353       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.353       |
| reward                   | -0.44369757 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 10          |
|    time_elapsed          | 3416        |
|    total_timesteps       | 622592      |
| train/                   |             |
|    approx_kl             | 0.002466768 |
|    clip_fraction         | 0.000488    |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 23.1        |
|    cost_values           | 0.628       |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | -1.81       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.7        |
|    n_updates             | 3030        |
|    policy_gradient_loss  | -0.000781   |
|    std                   | 0.815       |
|    value_loss            | 3.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.242        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.242        |
| reward                   | -0.48865178  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 37           |
|    time_elapsed          | 11324        |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0029284926 |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.62         |
|    cost_value_loss       | 25.3         |
|    cost_values           | 1.55         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.878        |
|    lagrangian_multiplier | 0.0062       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.88         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | -0.00518     |
|    std                   | 0.981        |
|    value_loss            | 3.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0801       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0801       |
| reward                   | -0.22012751  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -635         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 42           |
|    time_elapsed          | 13657        |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0069004195 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.7         |
|    cost_value_loss       | 132          |
|    cost_values           | 2.4          |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0.000234     |
|    learning_rate         | 0.0003       |
|    loss                  | 60.2         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 0.853        |
|    value_loss            | 0.661        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.65962625 |
| rollout/                 |             |
|    ep_len_mean           | 853         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 44          |
|    time_elapsed          | 14723       |
|    total_timesteps       | 591872      |
| train/                   |             |
|    approx_kl             | 0.011380059 |
|    clip_fraction         | 0.0979      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.56        |
|    cost_value_loss       | 15.9        |
|    cost_values           | 2.98        |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.768       |
|    lagrangian_multiplier | 0.00587     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.67        |
|    n_updates             | 2880        |
|    policy_gradient_loss  | -0.00301    |
|    std                   | 0.687       |
|    value_loss            | 12.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.285       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.285       |
| reward                   | -0.47573686 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -462        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 48          |
|    time_elapsed          | 15239       |
|    total_timesteps       | 600064      |
| train/                   |             |
|    approx_kl             | 0.00400196  |
|    clip_fraction         | 0.00479     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.81        |
|    cost_value_loss       | 63.6        |
|    cost_values           | 1.97        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | -0.81       |
|    lagrangian_multiplier | 0.00903     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.05        |
|    n_updates             | 2920        |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.889       |
|    value_loss            | 2.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.361       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.361       |
| reward                   | -0.3047183  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 37          |
|    time_elapsed          | 12386       |
|    total_timesteps       | 577536      |
| train/                   |             |
|    approx_kl             | 0.006790175 |
|    clip_fraction         | 0.0214      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 173         |
|    cost_values           | 2.57        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | -0.0193     |
|    lagrangian_multiplier | 0.00112     |
|    learning_rate         | 0.0003      |
|    loss                  | 56.4        |
|    n_updates             | 2810        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.848       |
|    value_loss            | 1.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0104      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0104      |
| reward                   | -0.28603742 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 11          |
|    time_elapsed          | 3763        |
|    total_timesteps       | 624640      |
| train/                   |             |
|    approx_kl             | 0.004275596 |
|    clip_fraction         | 0.038       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.75        |
|    cost_value_loss       | 0.352       |
|    cost_values           | 0.733       |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.752       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.124       |
|    n_updates             | 3040        |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.818       |
|    value_loss            | 0.102       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.039        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.039        |
| reward                   | -0.43438035  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 38           |
|    time_elapsed          | 11645        |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0045245686 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.0219       |
|    cost_values           | 1.12         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.505        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.856        |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.981        |
|    value_loss            | 2.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.094        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.094        |
| reward                   | -0.46865195  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -633         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 43           |
|    time_elapsed          | 14005        |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0012198744 |
|    clip_fraction         | 0.0019       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.7          |
|    cost_value_loss       | 80.3         |
|    cost_values           | 2.32         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.676        |
|    lagrangian_multiplier | 0.0897       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.89         |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.853        |
|    value_loss            | 2.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.62         |
| reward                   | -0.5043167   |
| rollout/                 |              |
|    ep_len_mean           | 853          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 45           |
|    time_elapsed          | 15089        |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0064257663 |
|    clip_fraction         | 0.0449       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.63         |
|    cost_value_loss       | 17.6         |
|    cost_values           | 2.97         |
|    entropy               | -2.07        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.78         |
|    lagrangian_multiplier | 0.00611      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.79         |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.0052      |
|    std                   | 0.685        |
|    value_loss            | 15.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0558       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0558       |
| reward                   | -0.3383375   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 49           |
|    time_elapsed          | 15586        |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0033874281 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.74         |
|    cost_value_loss       | 83.9         |
|    cost_values           | 2.19         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.372        |
|    lagrangian_multiplier | 0.0122       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.24         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 0.887        |
|    value_loss            | 1.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00515      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00515      |
| reward                   | -0.563725    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 38           |
|    time_elapsed          | 12741        |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0058704736 |
|    clip_fraction         | 0.0581       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.3         |
|    cost_value_loss       | 204          |
|    cost_values           | 2.93         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | -1.08        |
|    lagrangian_multiplier | 0.0303       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.77         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.00444     |
|    std                   | 0.849        |
|    value_loss            | 0.631        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.02         |
| reward                   | -0.46205568  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 12           |
|    time_elapsed          | 4108         |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0025460355 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.564        |
|    cost_value_loss       | 0.0445       |
|    cost_values           | 0.741        |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.412        |
|    lagrangian_multiplier | 4.43e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 0.404        |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.000983    |
|    std                   | 0.819        |
|    value_loss            | 1.89         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.335        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.335        |
| reward                   | -0.27011508  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 39           |
|    time_elapsed          | 11966        |
|    total_timesteps       | 581632       |
| train/                   |              |
|    approx_kl             | 0.0005967552 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 9.69         |
|    cost_value_loss       | 108          |
|    cost_values           | 1.44         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.89         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.7         |
|    n_updates             | 2830         |
|    policy_gradient_loss  | -0.00035     |
|    std                   | 0.98         |
|    value_loss            | 0.587        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.165        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.165        |
| reward                   | -0.30141503  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -648         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 44           |
|    time_elapsed          | 14356        |
|    total_timesteps       | 591872       |
| train/                   |              |
|    approx_kl             | 0.0070778774 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.64         |
|    cost_value_loss       | 56.5         |
|    cost_values           | 1.87         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.871        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.6         |
|    n_updates             | 2880         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.852        |
|    value_loss            | 3.32         |
-------------------------------------------
------------------------------------
| avg_speed          | 0.313       |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.313       |
| reward             | -0.59833133 |
| rollout/           |             |
|    ep_len_mean     | 982         |
|    ep_rew_mean     | -466        |
| time/              |             |
|    fps             | 5           |
|    iterations      | 1           |
|    time_elapsed    | 345         |
|    total_timesteps | 604160      |
------------------------------------
-------------------------------------------
| avg_speed                | 7.59         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.59         |
| reward                   | -0.48686504  |
| rollout/                 |              |
|    ep_len_mean           | 853          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 46           |
|    time_elapsed          | 15455        |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0050902893 |
|    clip_fraction         | 0.0561       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.27         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 2.86         |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0.901        |
|    lagrangian_multiplier | 0.00554      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.36         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.00682     |
|    std                   | 0.684        |
|    value_loss            | 3.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.456        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.456        |
| reward                   | -0.49949577  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 39           |
|    time_elapsed          | 13098        |
|    total_timesteps       | 581632       |
| train/                   |              |
|    approx_kl             | 0.0043182457 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.1         |
|    cost_value_loss       | 118          |
|    cost_values           | 2.81         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.846        |
|    lagrangian_multiplier | 0.0195       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.36         |
|    n_updates             | 2830         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.847        |
|    value_loss            | 3.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.242       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.242       |
| reward                   | -0.36010423 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -445        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 13          |
|    time_elapsed          | 4458        |
|    total_timesteps       | 628736      |
| train/                   |             |
|    approx_kl             | 0.010633712 |
|    clip_fraction         | 0.0927      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.64        |
|    cost_value_loss       | 0.0116      |
|    cost_values           | 0.627       |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | -6.09       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.118       |
|    n_updates             | 3060        |
|    policy_gradient_loss  | -0.00568    |
|    std                   | 0.818       |
|    value_loss            | 1.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.01         |
| reward                   | -0.51828516  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 40           |
|    time_elapsed          | 12290        |
|    total_timesteps       | 583680       |
| train/                   |              |
|    approx_kl             | 0.0030628832 |
|    clip_fraction         | 0.00166      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.3          |
|    cost_value_loss       | 86.6         |
|    cost_values           | 1.85         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.461        |
|    lagrangian_multiplier | 0.015        |
|    learning_rate         | 0.0003       |
|    loss                  | 7.1          |
|    n_updates             | 2840         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.98         |
|    value_loss            | 1.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0957       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0957       |
| reward                   | -0.33823785  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -665         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 45           |
|    time_elapsed          | 14710        |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0017312949 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.19         |
|    cost_value_loss       | 113          |
|    cost_values           | 1.32         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | -0.628       |
|    lagrangian_multiplier | 0.205        |
|    learning_rate         | 0.0003       |
|    loss                  | 2.17         |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.852        |
|    value_loss            | 101          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.043        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.043        |
| reward                   | -0.3478166   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 2            |
|    time_elapsed          | 697          |
|    total_timesteps       | 606208       |
| train/                   |              |
|    approx_kl             | 0.0067121154 |
|    clip_fraction         | 0.0371       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.97         |
|    cost_value_loss       | 50.7         |
|    cost_values           | 2.22         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.752        |
|    lagrangian_multiplier | 0.00684      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.57         |
|    n_updates             | 2950         |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 0.881        |
|    value_loss            | 1.52         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.91       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.91       |
| reward                   | -0.5286336 |
| rollout/                 |            |
|    ep_len_mean           | 853        |
|    ep_rew_mean           | -413       |
| time/                    |            |
|    fps                   | 6          |
|    iterations            | 47         |
|    time_elapsed          | 15818      |
|    total_timesteps       | 598016     |
| train/                   |            |
|    approx_kl             | 0.01622905 |
|    clip_fraction         | 0.0866     |
|    clip_range            | 0.2        |
|    cost_returns          | 6.73       |
|    cost_value_loss       | 16.1       |
|    cost_values           | 2.94       |
|    entropy               | -2.06      |
|    entropy_loss          | -2.07      |
|    explained_variance    | 0.901      |
|    lagrangian_multiplier | 0.0069     |
|    learning_rate         | 0.0003     |
|    loss                  | 4.18       |
|    n_updates             | 2910       |
|    policy_gradient_loss  | -0.00416   |
|    std                   | 0.682      |
|    value_loss            | 1.15       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.025        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.025        |
| reward                   | -0.5431946   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 40           |
|    time_elapsed          | 13457        |
|    total_timesteps       | 583680       |
| train/                   |              |
|    approx_kl             | 0.0044566225 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 149          |
|    cost_values           | 2.59         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0.00907      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 2840         |
|    policy_gradient_loss  | -0.00479     |
|    std                   | 0.846        |
|    value_loss            | 2.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0808       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0808       |
| reward                   | -0.45683822  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 14           |
|    time_elapsed          | 4808         |
|    total_timesteps       | 630784       |
| train/                   |              |
|    approx_kl             | 0.0056175194 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.497        |
|    cost_value_loss       | 0.0149       |
|    cost_values           | 0.572        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.0174       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.533        |
|    n_updates             | 3070         |
|    policy_gradient_loss  | -0.000587    |
|    std                   | 0.818        |
|    value_loss            | 1.21         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.77         |
| reward                   | -0.5700202   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 41           |
|    time_elapsed          | 12615        |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0023612212 |
|    clip_fraction         | 0.00117      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.35         |
|    cost_value_loss       | 85.7         |
|    cost_values           | 1.67         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.947        |
|    lagrangian_multiplier | 0.0117       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.72         |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.979        |
|    value_loss            | 2.72         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.245         |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.245         |
| reward                   | -0.53516006   |
| rollout/                 |               |
|    ep_len_mean           | 994           |
|    ep_rew_mean           | -659          |
| time/                    |               |
|    fps                   | 6             |
|    iterations            | 46            |
|    time_elapsed          | 15066         |
|    total_timesteps       | 595968        |
| train/                   |               |
|    approx_kl             | 0.00069055654 |
|    clip_fraction         | 0.00542       |
|    clip_range            | 0.2           |
|    cost_returns          | 1.89          |
|    cost_value_loss       | 14.4          |
|    cost_values           | 0.671         |
|    entropy               | -2.52         |
|    entropy_loss          | -2.52         |
|    explained_variance    | 0.636         |
|    lagrangian_multiplier | 0.0858        |
|    learning_rate         | 0.0003        |
|    loss                  | 1.52          |
|    n_updates             | 2900          |
|    policy_gradient_loss  | -0.000984     |
|    std                   | 0.852         |
|    value_loss            | 155           |
--------------------------------------------
------------------------------------------
| avg_speed                | 0.561       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.561       |
| reward                   | -0.52441263 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -473        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 3           |
|    time_elapsed          | 1052        |
|    total_timesteps       | 608256      |
| train/                   |             |
|    approx_kl             | 0.005746235 |
|    clip_fraction         | 0.0266      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.3         |
|    cost_value_loss       | 78.3        |
|    cost_values           | 2.17        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.592       |
|    lagrangian_multiplier | 0.0123      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.28        |
|    n_updates             | 2960        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.878       |
|    value_loss            | 3.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.37329897 |
| rollout/                 |             |
|    ep_len_mean           | 853         |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 48          |
|    time_elapsed          | 16184       |
|    total_timesteps       | 600064      |
| train/                   |             |
|    approx_kl             | 0.016609529 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.27        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 2.99        |
|    entropy               | -2.05       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0.0065      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.96        |
|    n_updates             | 2920        |
|    policy_gradient_loss  | -0.0088     |
|    std                   | 0.679       |
|    value_loss            | 1.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.148        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.148        |
| reward                   | -0.6036719   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 41           |
|    time_elapsed          | 13814        |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0054394756 |
|    clip_fraction         | 0.0294       |
|    clip_range            | 0.2          |
|    cost_returns          | 10           |
|    cost_value_loss       | 99.2         |
|    cost_values           | 2.62         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.721        |
|    lagrangian_multiplier | 0.00748      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 0.841        |
|    value_loss            | 4.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.266        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.266        |
| reward                   | -0.33531052  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 42           |
|    time_elapsed          | 12942        |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0049751606 |
|    clip_fraction         | 0.0462       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.88         |
|    cost_value_loss       | 37.9         |
|    cost_values           | 1.05         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0.00466      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.43         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.00626     |
|    std                   | 0.978        |
|    value_loss            | 2.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.219        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.219        |
| reward                   | -0.4800757   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 15           |
|    time_elapsed          | 5158         |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0056351675 |
|    clip_fraction         | 0.0424       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.289        |
|    cost_value_loss       | 0.00264      |
|    cost_values           | 0.315        |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -0.188       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.149        |
|    n_updates             | 3080         |
|    policy_gradient_loss  | -0.000203    |
|    std                   | 0.823        |
|    value_loss            | 0.352        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.131        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.131        |
| reward                   | -0.5650563   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -666         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 47           |
|    time_elapsed          | 15424        |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0007773683 |
|    clip_fraction         | 0.00146      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.79         |
|    cost_value_loss       | 144          |
|    cost_values           | 0.851        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.894        |
|    lagrangian_multiplier | 0.0268       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.98         |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.852        |
|    value_loss            | 12.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00198     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00198     |
| reward                   | -0.5175269  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -475        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 4           |
|    time_elapsed          | 1403        |
|    total_timesteps       | 610304      |
| train/                   |             |
|    approx_kl             | 0.006966767 |
|    clip_fraction         | 0.0156      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.74        |
|    cost_value_loss       | 80.4        |
|    cost_values           | 2.17        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.592       |
|    lagrangian_multiplier | 0.0122      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.74        |
|    n_updates             | 2970        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.878       |
|    value_loss            | 0.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.4451704  |
| rollout/                 |             |
|    ep_len_mean           | 853         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 49          |
|    time_elapsed          | 16552       |
|    total_timesteps       | 602112      |
| train/                   |             |
|    approx_kl             | 0.007964272 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.39        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.98        |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0.867       |
|    lagrangian_multiplier | 0.00574     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 2930        |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 0.677       |
|    value_loss            | 2.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.7545081  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 43          |
|    time_elapsed          | 13265       |
|    total_timesteps       | 589824      |
| train/                   |             |
|    approx_kl             | 0.004184898 |
|    clip_fraction         | 0.0113      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 59.4        |
|    cost_values           | 1.26        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0.00719     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.15        |
|    n_updates             | 2870        |
|    policy_gradient_loss  | -0.00197    |
|    std                   | 0.977       |
|    value_loss            | 1.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.512113    |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 42           |
|    time_elapsed          | 14173        |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0055468595 |
|    clip_fraction         | 0.0599       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.17         |
|    cost_value_loss       | 75.1         |
|    cost_values           | 2.57         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.775        |
|    lagrangian_multiplier | 0.0117       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.4          |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.00487     |
|    std                   | 0.835        |
|    value_loss            | 1.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.164        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.164        |
| reward                   | -0.38448265  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 5508         |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0017096949 |
|    clip_fraction         | 0.084        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.249        |
|    cost_value_loss       | 0.00231      |
|    cost_values           | 0.238        |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -0.243       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.171        |
|    n_updates             | 3090         |
|    policy_gradient_loss  | 0.000321     |
|    std                   | 0.82         |
|    value_loss            | 0.529        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -1.6721438  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -686        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 48          |
|    time_elapsed          | 15783       |
|    total_timesteps       | 600064      |
| train/                   |             |
|    approx_kl             | 0.008453813 |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.31        |
|    cost_value_loss       | 140         |
|    cost_values           | 0.629       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0.0128      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.4        |
|    n_updates             | 2920        |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.852       |
|    value_loss            | 51.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.275       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.275       |
| reward                   | -0.53395647 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -473        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 5           |
|    time_elapsed          | 1760        |
|    total_timesteps       | 612352      |
| train/                   |             |
|    approx_kl             | 0.006683842 |
|    clip_fraction         | 0.062       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.68        |
|    cost_value_loss       | 0.0663      |
|    cost_values           | 1.82        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.57       |
|    explained_variance    | -0.081      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.472       |
|    n_updates             | 2980        |
|    policy_gradient_loss  | -0.000658   |
|    std                   | 0.88        |
|    value_loss            | 1.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.64         |
| reward                   | -0.30049857  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -439         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 44           |
|    time_elapsed          | 13591        |
|    total_timesteps       | 591872       |
| train/                   |              |
|    approx_kl             | 0.0023762744 |
|    clip_fraction         | 0.00537      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.21         |
|    cost_value_loss       | 47.4         |
|    cost_values           | 1.63         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.678        |
|    lagrangian_multiplier | 0.00472      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.54         |
|    n_updates             | 2880         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.977        |
|    value_loss            | 2.93         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.206        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.206        |
| reward                   | -0.44718987  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 43           |
|    time_elapsed          | 14534        |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0047572413 |
|    clip_fraction         | 0.0605       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.62         |
|    cost_value_loss       | 91.4         |
|    cost_values           | 2.5          |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.892        |
|    lagrangian_multiplier | 0.00817      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.834        |
|    value_loss            | 1.13         |
-------------------------------------------
------------------------------------
| avg_speed          | 5.78        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 5.78        |
| reward             | -0.40958774 |
| rollout/           |             |
|    ep_len_mean     | 851         |
|    ep_rew_mean     | -409        |
| time/              |             |
|    fps             | 5           |
|    iterations      | 1           |
|    time_elapsed    | 365         |
|    total_timesteps | 604160      |
------------------------------------
------------------------------------------
| avg_speed                | 0.0283      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0283      |
| reward                   | -0.45442292 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 17          |
|    time_elapsed          | 5862        |
|    total_timesteps       | 636928      |
| train/                   |             |
|    approx_kl             | 0.008344322 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.486       |
|    cost_value_loss       | 1.7         |
|    cost_values           | 0.44        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.315       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.27        |
|    n_updates             | 3100        |
|    policy_gradient_loss  | 0.000593    |
|    std                   | 0.819       |
|    value_loss            | 1.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.3541713   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 49           |
|    time_elapsed          | 16140        |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0023819497 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.63         |
|    cost_value_loss       | 65           |
|    cost_values           | 0.476        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0.00184      |
|    learning_rate         | 0.0003       |
|    loss                  | 64.9         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | 0.000341     |
|    std                   | 0.853        |
|    value_loss            | 238          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0736       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0736       |
| reward                   | -0.3907746   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 45           |
|    time_elapsed          | 13921        |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0012991683 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.37         |
|    cost_value_loss       | 69           |
|    cost_values           | 1.49         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0.0094       |
|    learning_rate         | 0.0003       |
|    loss                  | 7            |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 0.976        |
|    value_loss            | 3.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0831       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0831       |
| reward                   | -0.57511663  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 6            |
|    time_elapsed          | 2116         |
|    total_timesteps       | 614400       |
| train/                   |              |
|    approx_kl             | 0.0045746723 |
|    clip_fraction         | 0.153        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.09         |
|    cost_value_loss       | 67.1         |
|    cost_values           | 1.85         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 0.0113       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.83         |
|    n_updates             | 2990         |
|    policy_gradient_loss  | -0.000659    |
|    std                   | 0.881        |
|    value_loss            | 0.964        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.218        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.218        |
| reward                   | -0.5051319   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 44           |
|    time_elapsed          | 14896        |
|    total_timesteps       | 591872       |
| train/                   |              |
|    approx_kl             | 0.0071988404 |
|    clip_fraction         | 0.0683       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.9         |
|    cost_value_loss       | 203          |
|    cost_values           | 2.57         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0.0195       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 2880         |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.834        |
|    value_loss            | 0.843        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.64        |
| reward                   | -0.40332988 |
| rollout/                 |             |
|    ep_len_mean           | 848         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 2           |
|    time_elapsed          | 729         |
|    total_timesteps       | 606208      |
| train/                   |             |
|    approx_kl             | 0.008138311 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.8         |
|    cost_value_loss       | 17.2        |
|    cost_values           | 2.99        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.613       |
|    lagrangian_multiplier | 0.00512     |
|    learning_rate         | 0.0003      |
|    loss                  | 6           |
|    n_updates             | 2950        |
|    policy_gradient_loss  | -0.00459    |
|    std                   | 0.674       |
|    value_loss            | 9.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.045        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.045        |
| reward                   | -0.54619926  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 18           |
|    time_elapsed          | 6215         |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0038744346 |
|    clip_fraction         | 0.022        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.311        |
|    cost_value_loss       | 0.00581      |
|    cost_values           | 0.275        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.544        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.248        |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.000784    |
|    std                   | 0.819        |
|    value_loss            | 1.25         |
-------------------------------------------
------------------------------------
| avg_speed          | 0.252       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.252       |
| reward             | -0.27864173 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -702        |
| time/              |             |
|    fps             | 5           |
|    iterations      | 1           |
|    time_elapsed    | 361         |
|    total_timesteps | 604160      |
------------------------------------
------------------------------------------
| avg_speed                | 7.61        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.61        |
| reward                   | -0.6452708  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 46          |
|    time_elapsed          | 14250       |
|    total_timesteps       | 595968      |
| train/                   |             |
|    approx_kl             | 0.006631518 |
|    clip_fraction         | 0.0358      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.34        |
|    cost_value_loss       | 30.7        |
|    cost_values           | 0.988       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.766       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.3        |
|    n_updates             | 2900        |
|    policy_gradient_loss  | -0.00418    |
|    std                   | 0.976       |
|    value_loss            | 1.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0715       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0715       |
| reward                   | -0.54141045  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -465         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 7            |
|    time_elapsed          | 2473         |
|    total_timesteps       | 616448       |
| train/                   |              |
|    approx_kl             | 0.0043273154 |
|    clip_fraction         | 0.0759       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.2          |
|    cost_value_loss       | 14.9         |
|    cost_values           | 1.83         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.0285       |
|    lagrangian_multiplier | 0.0031       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.95         |
|    n_updates             | 3000         |
|    policy_gradient_loss  | -0.00608     |
|    std                   | 0.881        |
|    value_loss            | 0.247        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.111        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.111        |
| reward                   | -0.19177294  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 45           |
|    time_elapsed          | 15257        |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0041282303 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.3         |
|    cost_value_loss       | 121          |
|    cost_values           | 2.67         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0.0159       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.79         |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.833        |
|    value_loss            | 2.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.85        |
| reward                   | -0.3834865  |
| rollout/                 |             |
|    ep_len_mean           | 842         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 3           |
|    time_elapsed          | 1098        |
|    total_timesteps       | 608256      |
| train/                   |             |
|    approx_kl             | 0.008416833 |
|    clip_fraction         | 0.0564      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.49        |
|    cost_value_loss       | 15          |
|    cost_values           | 2.99        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.591       |
|    lagrangian_multiplier | 0.00598     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.15        |
|    n_updates             | 2960        |
|    policy_gradient_loss  | -0.00358    |
|    std                   | 0.671       |
|    value_loss            | 9.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0542       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0542       |
| reward                   | -0.2849986   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 19           |
|    time_elapsed          | 6573         |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0016755257 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 16.2         |
|    cost_values           | 0.626        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.578        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.06         |
|    n_updates             | 3120         |
|    policy_gradient_loss  | 0.000197     |
|    std                   | 0.818        |
|    value_loss            | 1.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0632      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0632      |
| reward                   | -0.5094009  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 47          |
|    time_elapsed          | 14584       |
|    total_timesteps       | 598016      |
| train/                   |             |
|    approx_kl             | 0.004450399 |
|    clip_fraction         | 0.0197      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.902       |
|    cost_value_loss       | 1.68        |
|    cost_values           | 0.57        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.84        |
|    n_updates             | 2910        |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.975       |
|    value_loss            | 4.37        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.102        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.102        |
| reward                   | -0.5169367   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 2            |
|    time_elapsed          | 719          |
|    total_timesteps       | 606208       |
| train/                   |              |
|    approx_kl             | 0.0045909053 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.74         |
|    cost_value_loss       | 87.7         |
|    cost_values           | 0.862        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0.00861      |
|    learning_rate         | 0.0003       |
|    loss                  | 25.7         |
|    n_updates             | 2950         |
|    policy_gradient_loss  | -0.000579    |
|    std                   | 0.854        |
|    value_loss            | 163          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.39        |
| reward                   | -0.4780384  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -468        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 8           |
|    time_elapsed          | 2830        |
|    total_timesteps       | 618496      |
| train/                   |             |
|    approx_kl             | 0.012585358 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.39        |
|    cost_value_loss       | 0.0447      |
|    cost_values           | 1.51        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.553       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0154      |
|    n_updates             | 3010        |
|    policy_gradient_loss  | -0.0123     |
|    std                   | 0.879       |
|    value_loss            | 0.191       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.258        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.258        |
| reward                   | -0.48374772  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 46           |
|    time_elapsed          | 15619        |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0067035276 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 123          |
|    cost_values           | 2.72         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.848        |
|    lagrangian_multiplier | 0.0173       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.78         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.833        |
|    value_loss            | 1.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.204        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.204        |
| reward                   | -0.49798578  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 20           |
|    time_elapsed          | 6930         |
|    total_timesteps       | 643072       |
| train/                   |              |
|    approx_kl             | 0.0038897612 |
|    clip_fraction         | 0.00967      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.5          |
|    cost_value_loss       | 10.6         |
|    cost_values           | 0.871        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.345        |
|    lagrangian_multiplier | 0.000624     |
|    learning_rate         | 0.0003       |
|    loss                  | 9.65         |
|    n_updates             | 3130         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.818        |
|    value_loss            | 9.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.5664259  |
| rollout/                 |             |
|    ep_len_mean           | 830         |
|    ep_rew_mean           | -396        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 4           |
|    time_elapsed          | 1474        |
|    total_timesteps       | 610304      |
| train/                   |             |
|    approx_kl             | 0.005999896 |
|    clip_fraction         | 0.083       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.58        |
|    cost_value_loss       | 18.6        |
|    cost_values           | 2.92        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0.255       |
|    lagrangian_multiplier | 0.0039      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.06        |
|    n_updates             | 2970        |
|    policy_gradient_loss  | -0.00369    |
|    std                   | 0.671       |
|    value_loss            | 20          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.42         |
| reward                   | -0.3000691   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 48           |
|    time_elapsed          | 14916        |
|    total_timesteps       | 600064       |
| train/                   |              |
|    approx_kl             | 0.0067587397 |
|    clip_fraction         | 0.101        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.804        |
|    cost_value_loss       | 1.58         |
|    cost_values           | 0.625        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.926        |
|    n_updates             | 2920         |
|    policy_gradient_loss  | -0.00775     |
|    std                   | 0.976        |
|    value_loss            | 0.899        |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.14e-05    |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.14e-05    |
| reward                   | -0.46738058 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -711        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 3           |
|    time_elapsed          | 1083        |
|    total_timesteps       | 608256      |
| train/                   |             |
|    approx_kl             | 0.005011659 |
|    clip_fraction         | 0.0303      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.74        |
|    cost_value_loss       | 40.6        |
|    cost_values           | 0.787       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0.00283     |
|    learning_rate         | 0.0003      |
|    loss                  | 35.6        |
|    n_updates             | 2960        |
|    policy_gradient_loss  | -0.000908   |
|    std                   | 0.855       |
|    value_loss            | 143         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00949     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00949     |
| reward                   | -0.54982156 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -462        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 9           |
|    time_elapsed          | 3188        |
|    total_timesteps       | 620544      |
| train/                   |             |
|    approx_kl             | 0.020877326 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 3.35        |
|    cost_values           | 1.5         |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | -0.37       |
|    lagrangian_multiplier | 0.000191    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.76        |
|    n_updates             | 3020        |
|    policy_gradient_loss  | -0.00474    |
|    std                   | 0.876       |
|    value_loss            | 0.129       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.183        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.183        |
| reward                   | -0.5096998   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 47           |
|    time_elapsed          | 15985        |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0031460747 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.18         |
|    cost_value_loss       | 88.3         |
|    cost_values           | 2.68         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | -0.251       |
|    lagrangian_multiplier | 0.0105       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.26         |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.00037     |
|    std                   | 0.833        |
|    value_loss            | 3.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.167       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.167       |
| reward                   | -0.33193588 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 21          |
|    time_elapsed          | 7288        |
|    total_timesteps       | 645120      |
| train/                   |             |
|    approx_kl             | 0.0036131   |
|    clip_fraction         | 0.0192      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.85        |
|    cost_value_loss       | 32.9        |
|    cost_values           | 0.801       |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.629       |
|    lagrangian_multiplier | 0.00119     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 3140        |
|    policy_gradient_loss  | -0.00247    |
|    std                   | 0.818       |
|    value_loss            | 2.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.29        |
| reward                   | -0.6002031  |
| rollout/                 |             |
|    ep_len_mean           | 837         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 5           |
|    time_elapsed          | 1850        |
|    total_timesteps       | 612352      |
| train/                   |             |
|    approx_kl             | 0.008718883 |
|    clip_fraction         | 0.072       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.65        |
|    cost_value_loss       | 17          |
|    cost_values           | 2.96        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0.00865     |
|    lagrangian_multiplier | 0.00791     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 2980        |
|    policy_gradient_loss  | -0.00396    |
|    std                   | 0.671       |
|    value_loss            | 17          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0174       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0174       |
| reward                   | -0.483417    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -444         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 49           |
|    time_elapsed          | 15251        |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0016035099 |
|    clip_fraction         | 0.00937      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.07         |
|    cost_value_loss       | 16.5         |
|    cost_values           | 0.973        |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.87         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.977        |
|    value_loss            | 1.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.22         |
| reward                   | -0.3627491   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 4            |
|    time_elapsed          | 1446         |
|    total_timesteps       | 610304       |
| train/                   |              |
|    approx_kl             | 0.0053416863 |
|    clip_fraction         | 0.0331       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 4.97         |
|    cost_values           | 0.99         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.853        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.63         |
|    n_updates             | 2970         |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.855        |
|    value_loss            | 1.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -1.174741    |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 10           |
|    time_elapsed          | 3546         |
|    total_timesteps       | 622592       |
| train/                   |              |
|    approx_kl             | 0.0037745624 |
|    clip_fraction         | 0.111        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 3.51         |
|    cost_values           | 1.79         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.642        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.67         |
|    n_updates             | 3030         |
|    policy_gradient_loss  | 0.00684      |
|    std                   | 0.878        |
|    value_loss            | 3.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0977      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0977      |
| reward                   | -0.46947664 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 48          |
|    time_elapsed          | 16354       |
|    total_timesteps       | 600064      |
| train/                   |             |
|    approx_kl             | 0.005888748 |
|    clip_fraction         | 0.0523      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 171         |
|    cost_values           | 2.79        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0.0183      |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 2920        |
|    policy_gradient_loss  | -0.00538    |
|    std                   | 0.828       |
|    value_loss            | 1.7         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0561       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0561       |
| reward                   | -0.45158023  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 22           |
|    time_elapsed          | 7649         |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0039749024 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.87         |
|    cost_value_loss       | 43.1         |
|    cost_values           | 1.12         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.192        |
|    lagrangian_multiplier | 0.00275      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.817        |
|    value_loss            | 4.27         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.44090986 |
| rollout/                 |             |
|    ep_len_mean           | 836         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 6           |
|    time_elapsed          | 2229        |
|    total_timesteps       | 614400      |
| train/                   |             |
|    approx_kl             | 0.010158406 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.99        |
|    cost_value_loss       | 18.7        |
|    cost_values           | 2.99        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0.248       |
|    lagrangian_multiplier | 0.00724     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.58        |
|    n_updates             | 2990        |
|    policy_gradient_loss  | -0.00809    |
|    std                   | 0.669       |
|    value_loss            | 16.6        |
------------------------------------------
-----------------------------------
| avg_speed          | 0.165      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.165      |
| reward             | -0.3307647 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -450       |
| time/              |            |
|    fps             | 6          |
|    iterations      | 1          |
|    time_elapsed    | 334        |
|    total_timesteps | 604160     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.026        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.026        |
| reward                   | -0.5264172   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 5            |
|    time_elapsed          | 1816         |
|    total_timesteps       | 612352       |
| train/                   |              |
|    approx_kl             | 0.0061102677 |
|    clip_fraction         | 0.089        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 4.78         |
|    cost_values           | 1.06         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | -0.232       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.04         |
|    n_updates             | 2980         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.854        |
|    value_loss            | 0.613        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.21          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.21          |
| reward                   | -0.5041369    |
| rollout/                 |               |
|    ep_len_mean           | 987           |
|    ep_rew_mean           | -464          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 11            |
|    time_elapsed          | 3907          |
|    total_timesteps       | 624640        |
| train/                   |               |
|    approx_kl             | 0.00045041434 |
|    clip_fraction         | 0.000146      |
|    clip_range            | 0.2           |
|    cost_returns          | 2.16          |
|    cost_value_loss       | 6.36          |
|    cost_values           | 1.26          |
|    entropy               | -2.57         |
|    entropy_loss          | -2.57         |
|    explained_variance    | 0.877         |
|    lagrangian_multiplier | 0.00104       |
|    learning_rate         | 0.0003        |
|    loss                  | 3.12          |
|    n_updates             | 3040          |
|    policy_gradient_loss  | -0.000786     |
|    std                   | 0.877         |
|    value_loss            | 3.99          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.139        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.139        |
| reward                   | -0.50958633  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 49           |
|    time_elapsed          | 16723        |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0020859125 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.1         |
|    cost_value_loss       | 206          |
|    cost_values           | 2.93         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.614        |
|    lagrangian_multiplier | 0.0225       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.826        |
|    value_loss            | 0.795        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0165       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0165       |
| reward                   | -0.25245768  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 23           |
|    time_elapsed          | 8013         |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0012589123 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 1.07         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.751        |
|    lagrangian_multiplier | 0.000346     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.99         |
|    n_updates             | 3160         |
|    policy_gradient_loss  | -0.000615    |
|    std                   | 0.816        |
|    value_loss            | 1.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.5507441  |
| rollout/                 |             |
|    ep_len_mean           | 846         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 7           |
|    time_elapsed          | 2607        |
|    total_timesteps       | 616448      |
| train/                   |             |
|    approx_kl             | 0.008732512 |
|    clip_fraction         | 0.0546      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.42        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 2.78        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0.577       |
|    lagrangian_multiplier | 0.000677    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.59        |
|    n_updates             | 3000        |
|    policy_gradient_loss  | -0.00511    |
|    std                   | 0.668       |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.267        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.267        |
| reward                   | -0.5868041   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -448         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 2            |
|    time_elapsed          | 672          |
|    total_timesteps       | 606208       |
| train/                   |              |
|    approx_kl             | 0.0018321795 |
|    clip_fraction         | 0.215        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.67         |
|    cost_value_loss       | 24.3         |
|    cost_values           | 0.763        |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0.000299     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.26         |
|    n_updates             | 2950         |
|    policy_gradient_loss  | 0.0152       |
|    std                   | 0.98         |
|    value_loss            | 2.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00691      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00691      |
| reward                   | -0.47173154  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -721         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 6            |
|    time_elapsed          | 2181         |
|    total_timesteps       | 614400       |
| train/                   |              |
|    approx_kl             | 0.0060083624 |
|    clip_fraction         | 0.0507       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.21         |
|    cost_value_loss       | 52.2         |
|    cost_values           | 1.19         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.9         |
|    n_updates             | 2990         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.854        |
|    value_loss            | 0.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.177        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.177        |
| reward                   | -0.25203976  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 12           |
|    time_elapsed          | 4270         |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0016992467 |
|    clip_fraction         | 0.00498      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 1.82         |
|    cost_values           | 0.817        |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.942        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.65         |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.877        |
|    value_loss            | 3.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0284      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0284      |
| reward                   | -0.23649418 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 24          |
|    time_elapsed          | 8373        |
|    total_timesteps       | 651264      |
| train/                   |             |
|    approx_kl             | 0.005015537 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.67        |
|    cost_value_loss       | 39.3        |
|    cost_values           | 1.29        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.825       |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 3170        |
|    policy_gradient_loss  | -0.00148    |
|    std                   | 0.816       |
|    value_loss            | 2.19        |
------------------------------------------
-----------------------------------
| avg_speed          | 0.297      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.297      |
| reward             | -0.5742204 |
| rollout/           |            |
|    ep_len_mean     | 993        |
|    ep_rew_mean     | -449       |
| time/              |            |
|    fps             | 5          |
|    iterations      | 1          |
|    time_elapsed    | 367        |
|    total_timesteps | 604160     |
-----------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.38835558 |
| rollout/                 |             |
|    ep_len_mean           | 834         |
|    ep_rew_mean           | -394        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 8           |
|    time_elapsed          | 2987        |
|    total_timesteps       | 618496      |
| train/                   |             |
|    approx_kl             | 0.012605398 |
|    clip_fraction         | 0.0938      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.11        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.63        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | -0.74       |
|    lagrangian_multiplier | 0.00516     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.05        |
|    n_updates             | 3010        |
|    policy_gradient_loss  | -0.00599    |
|    std                   | 0.668       |
|    value_loss            | 2.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.282        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.282        |
| reward                   | -0.56836945  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 3            |
|    time_elapsed          | 1008         |
|    total_timesteps       | 608256       |
| train/                   |              |
|    approx_kl             | 0.0036065453 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.658        |
|    cost_value_loss       | 0.0218       |
|    cost_values           | 0.77         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.485        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.199        |
|    n_updates             | 2960         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.979        |
|    value_loss            | 1.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.183        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.183        |
| reward                   | -0.51759285  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -723         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 7            |
|    time_elapsed          | 2542         |
|    total_timesteps       | 616448       |
| train/                   |              |
|    approx_kl             | 0.0032805924 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.17         |
|    cost_value_loss       | 47.8         |
|    cost_values           | 1.01         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0.00242      |
|    learning_rate         | 0.0003       |
|    loss                  | 24.9         |
|    n_updates             | 3000         |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 0.854        |
|    value_loss            | 52.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.34491658  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -465         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 13           |
|    time_elapsed          | 4630         |
|    total_timesteps       | 628736       |
| train/                   |              |
|    approx_kl             | 0.0049507055 |
|    clip_fraction         | 0.035        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 6.94         |
|    cost_values           | 0.765        |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.98         |
|    n_updates             | 3060         |
|    policy_gradient_loss  | -0.00537     |
|    std                   | 0.876        |
|    value_loss            | 1.9          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.271       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.271       |
| reward                   | -0.39918804 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 25          |
|    time_elapsed          | 8737        |
|    total_timesteps       | 653312      |
| train/                   |             |
|    approx_kl             | 0.005572388 |
|    clip_fraction         | 0.00596     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 0.0359      |
|    cost_values           | 1.14        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | -0.196      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.69        |
|    n_updates             | 3180        |
|    policy_gradient_loss  | -1.57e-05   |
|    std                   | 0.818       |
|    value_loss            | 6.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.22        |
| reward                   | -0.38597295 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -449        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 2           |
|    time_elapsed          | 736         |
|    total_timesteps       | 606208      |
| train/                   |             |
|    approx_kl             | 0.004665705 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 189         |
|    cost_values           | 2.77        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.224       |
|    lagrangian_multiplier | 0.0253      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.3         |
|    n_updates             | 2950        |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.824       |
|    value_loss            | 1.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.355       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.355       |
| reward                   | -0.5143266  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 4           |
|    time_elapsed          | 1342        |
|    total_timesteps       | 610304      |
| train/                   |             |
|    approx_kl             | 0.006564807 |
|    clip_fraction         | 0.0756      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.623       |
|    cost_value_loss       | 0.835       |
|    cost_values           | 0.473       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.535       |
|    n_updates             | 2970        |
|    policy_gradient_loss  | -0.00671    |
|    std                   | 0.979       |
|    value_loss            | 1.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.62583095 |
| rollout/                 |             |
|    ep_len_mean           | 840         |
|    ep_rew_mean           | -396        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 9           |
|    time_elapsed          | 3364        |
|    total_timesteps       | 620544      |
| train/                   |             |
|    approx_kl             | 0.00563398  |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.83        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 2.7         |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0.093       |
|    lagrangian_multiplier | 0.00968     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 3020        |
|    policy_gradient_loss  | 0.00312     |
|    std                   | 0.667       |
|    value_loss            | 20.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.101        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.101        |
| reward                   | -0.44296232  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 8            |
|    time_elapsed          | 2914         |
|    total_timesteps       | 618496       |
| train/                   |              |
|    approx_kl             | 0.0048884456 |
|    clip_fraction         | 0.0265       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.78         |
|    cost_value_loss       | 66.1         |
|    cost_values           | 1.07         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.71         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33           |
|    n_updates             | 3010         |
|    policy_gradient_loss  | -0.0037      |
|    std                   | 0.853        |
|    value_loss            | 0.968        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0215      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0215      |
| reward                   | -0.49001074 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -466        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 14          |
|    time_elapsed          | 4993        |
|    total_timesteps       | 630784      |
| train/                   |             |
|    approx_kl             | 0.007125452 |
|    clip_fraction         | 0.0466      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.85        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 0.922       |
|    entropy               | -2.56       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.88        |
|    n_updates             | 3070        |
|    policy_gradient_loss  | -0.00507    |
|    std                   | 0.874       |
|    value_loss            | 0.362       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.11         |
| reward                   | -0.37637743  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 26           |
|    time_elapsed          | 9104         |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0024918912 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 1.14         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.696        |
|    lagrangian_multiplier | 0.00135      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.16         |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -8.36e-05    |
|    std                   | 0.818        |
|    value_loss            | 2.79         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.632       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.632       |
| reward                   | -0.51073027 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 3           |
|    time_elapsed          | 1107        |
|    total_timesteps       | 608256      |
| train/                   |             |
|    approx_kl             | 0.009771885 |
|    clip_fraction         | 0.0722      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.5         |
|    cost_value_loss       | 89.8        |
|    cost_values           | 2.73        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.815       |
|    lagrangian_multiplier | 0.0122      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.1         |
|    n_updates             | 2960        |
|    policy_gradient_loss  | -0.00624    |
|    std                   | 0.819       |
|    value_loss            | 1.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.55        |
| reward                   | -0.4244091  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 5           |
|    time_elapsed          | 1681        |
|    total_timesteps       | 612352      |
| train/                   |             |
|    approx_kl             | 0.001559768 |
|    clip_fraction         | 0.00869     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.56        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 0.652       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.526       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 2980        |
|    policy_gradient_loss  | -0.000312   |
|    std                   | 0.977       |
|    value_loss            | 10.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.5459092  |
| rollout/                 |             |
|    ep_len_mean           | 831         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 10          |
|    time_elapsed          | 3749        |
|    total_timesteps       | 622592      |
| train/                   |             |
|    approx_kl             | 0.007094375 |
|    clip_fraction         | 0.0909      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.3         |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.48        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0.319       |
|    lagrangian_multiplier | 0.00472     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 3030        |
|    policy_gradient_loss  | -0.0068     |
|    std                   | 0.667       |
|    value_loss            | 19.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0524       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0524       |
| reward                   | -0.5095586   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 9            |
|    time_elapsed          | 3286         |
|    total_timesteps       | 620544       |
| train/                   |              |
|    approx_kl             | 0.0052958997 |
|    clip_fraction         | 0.0771       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.82         |
|    cost_value_loss       | 4.87         |
|    cost_values           | 1.41         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.763        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.32         |
|    n_updates             | 3020         |
|    policy_gradient_loss  | -0.00625     |
|    std                   | 0.853        |
|    value_loss            | 0.109        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00101      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00101      |
| reward                   | -0.30977586  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 15           |
|    time_elapsed          | 5359         |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0036928619 |
|    clip_fraction         | 0.0247       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.4          |
|    cost_value_loss       | 1.46         |
|    cost_values           | 1.33         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | -1.98        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.43         |
|    n_updates             | 3080         |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.875        |
|    value_loss            | 2.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.039       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.039       |
| reward                   | -0.36123738 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 27          |
|    time_elapsed          | 9470        |
|    total_timesteps       | 657408      |
| train/                   |             |
|    approx_kl             | 0.005973622 |
|    clip_fraction         | 0.0659      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.6         |
|    cost_value_loss       | 50.3        |
|    cost_values           | 1.23        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.389       |
|    lagrangian_multiplier | 0.00368     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 3200        |
|    policy_gradient_loss  | -0.00337    |
|    std                   | 0.817       |
|    value_loss            | 7.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00353     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00353     |
| reward                   | -0.4675684  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 6           |
|    time_elapsed          | 2026        |
|    total_timesteps       | 614400      |
| train/                   |             |
|    approx_kl             | 0.005289986 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.07        |
|    cost_value_loss       | 16.4        |
|    cost_values           | 0.8         |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.696       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 2990        |
|    policy_gradient_loss  | -0.0051     |
|    std                   | 0.976       |
|    value_loss            | 3.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.222       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.222       |
| reward                   | -0.31740585 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 4           |
|    time_elapsed          | 1485        |
|    total_timesteps       | 610304      |
| train/                   |             |
|    approx_kl             | 0.006145963 |
|    clip_fraction         | 0.0411      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.09        |
|    cost_value_loss       | 52.6        |
|    cost_values           | 2.76        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.485       |
|    lagrangian_multiplier | 0.00572     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.19        |
|    n_updates             | 2970        |
|    policy_gradient_loss  | -0.00309    |
|    std                   | 0.818       |
|    value_loss            | 1.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.54016215  |
| rollout/                 |              |
|    ep_len_mean           | 828          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 11           |
|    time_elapsed          | 4136         |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0067024427 |
|    clip_fraction         | 0.0767       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.68         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 2.41         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.02        |
|    explained_variance    | 0.489        |
|    lagrangian_multiplier | 0.00492      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.53         |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -0.00575     |
|    std                   | 0.666        |
|    value_loss            | 9.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.17         |
| reward                   | -0.4823588   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -693         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 10           |
|    time_elapsed          | 3656         |
|    total_timesteps       | 622592       |
| train/                   |              |
|    approx_kl             | 0.0037958976 |
|    clip_fraction         | 0.0357       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.9          |
|    cost_value_loss       | 39.6         |
|    cost_values           | 1.69         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.5         |
|    n_updates             | 3030         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.853        |
|    value_loss            | 0.504        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00288      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00288      |
| reward                   | -0.3878141   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 5726         |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0046724374 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.31         |
|    cost_value_loss       | 53.7         |
|    cost_values           | 1.13         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0.00824      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.45         |
|    n_updates             | 3090         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.875        |
|    value_loss            | 1.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.172       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.172       |
| reward                   | -0.553347   |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 7           |
|    time_elapsed          | 2370        |
|    total_timesteps       | 616448      |
| train/                   |             |
|    approx_kl             | 0.008242385 |
|    clip_fraction         | 0.05        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.897       |
|    cost_value_loss       | 1.51        |
|    cost_values           | 0.727       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.58        |
|    n_updates             | 3000        |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.975       |
|    value_loss            | 1.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0115      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0115      |
| reward                   | -0.40947786 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 28          |
|    time_elapsed          | 9834        |
|    total_timesteps       | 659456      |
| train/                   |             |
|    approx_kl             | 0.00626484  |
|    clip_fraction         | 0.0191      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.31        |
|    cost_value_loss       | 20.5        |
|    cost_values           | 0.999       |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.68        |
|    lagrangian_multiplier | 0.00207     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.46        |
|    n_updates             | 3210        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.816       |
|    value_loss            | 0.451       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.354        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.354        |
| reward                   | -0.40940017  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 5            |
|    time_elapsed          | 1855         |
|    total_timesteps       | 612352       |
| train/                   |              |
|    approx_kl             | 0.0054944195 |
|    clip_fraction         | 0.0454       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.6         |
|    cost_value_loss       | 157          |
|    cost_values           | 2.71         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.894        |
|    lagrangian_multiplier | 0.0228       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.95         |
|    n_updates             | 2980         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.815        |
|    value_loss            | 0.624        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.61236924 |
| rollout/                 |             |
|    ep_len_mean           | 824         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 12          |
|    time_elapsed          | 4523        |
|    total_timesteps       | 626688      |
| train/                   |             |
|    approx_kl             | 0.008913023 |
|    clip_fraction         | 0.0603      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.14        |
|    cost_value_loss       | 15.2        |
|    cost_values           | 2.56        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | -0.00357    |
|    lagrangian_multiplier | 7.08e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 15          |
|    n_updates             | 3050        |
|    policy_gradient_loss  | -0.0018     |
|    std                   | 0.665       |
|    value_loss            | 16.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0549       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0549       |
| reward                   | -0.5689637   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -685         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 11           |
|    time_elapsed          | 4023         |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0017076252 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.62         |
|    cost_value_loss       | 19.5         |
|    cost_values           | 1.93         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.89         |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.851        |
|    value_loss            | 0.522        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0746       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0746       |
| reward                   | -0.54902357  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -465         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 17           |
|    time_elapsed          | 6094         |
|    total_timesteps       | 636928       |
| train/                   |              |
|    approx_kl             | 0.0028006085 |
|    clip_fraction         | 0.00674      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.1          |
|    cost_value_loss       | 35.2         |
|    cost_values           | 1.12         |
|    entropy               | -2.57        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0.000304     |
|    learning_rate         | 0.0003       |
|    loss                  | 14.9         |
|    n_updates             | 3100         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.876        |
|    value_loss            | 3.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.24        |
| reward                   | -0.55419374 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 8           |
|    time_elapsed          | 2710        |
|    total_timesteps       | 618496      |
| train/                   |             |
|    approx_kl             | 0.004218438 |
|    clip_fraction         | 0.0195      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 9.24        |
|    cost_values           | 0.742       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.71        |
|    n_updates             | 3010        |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 0.973       |
|    value_loss            | 0.964       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.137        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.137        |
| reward                   | -0.3305557   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 29           |
|    time_elapsed          | 10200        |
|    total_timesteps       | 661504       |
| train/                   |              |
|    approx_kl             | 0.0020583244 |
|    clip_fraction         | 0.0449       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.709        |
|    cost_value_loss       | 0.0183       |
|    cost_values           | 0.789        |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.349        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.369        |
|    n_updates             | 3220         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.812        |
|    value_loss            | 0.833        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.724       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.724       |
| reward                   | -0.32196537 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 6           |
|    time_elapsed          | 2231        |
|    total_timesteps       | 614400      |
| train/                   |             |
|    approx_kl             | 0.026607305 |
|    clip_fraction         | 0.0757      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.42        |
|    cost_value_loss       | 1.09        |
|    cost_values           | 2.56        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.425       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.733       |
|    n_updates             | 2990        |
|    policy_gradient_loss  | 0.00114     |
|    std                   | 0.808       |
|    value_loss            | 1.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.46        |
| reward                   | -0.50665426 |
| rollout/                 |             |
|    ep_len_mean           | 817         |
|    ep_rew_mean           | -379        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 13          |
|    time_elapsed          | 4911        |
|    total_timesteps       | 628736      |
| train/                   |             |
|    approx_kl             | 0.006161589 |
|    clip_fraction         | 0.041       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.47        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0.288       |
|    lagrangian_multiplier | 0.000281    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.51        |
|    n_updates             | 3060        |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.665       |
|    value_loss            | 9.01        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.175      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.175      |
| reward                   | -0.3922364 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -672       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 12         |
|    time_elapsed          | 4392       |
|    total_timesteps       | 626688     |
| train/                   |            |
|    approx_kl             | 0.01006229 |
|    clip_fraction         | 0.0659     |
|    clip_range            | 0.2        |
|    cost_returns          | 11.8       |
|    cost_value_loss       | 124        |
|    cost_values           | 2.34       |
|    entropy               | -2.51      |
|    entropy_loss          | -2.51      |
|    explained_variance    | 0.914      |
|    lagrangian_multiplier | 0.000428   |
|    learning_rate         | 0.0003     |
|    loss                  | 50.2       |
|    n_updates             | 3050       |
|    policy_gradient_loss  | -0.00581   |
|    std                   | 0.85       |
|    value_loss            | 0.355      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.11         |
| reward                   | -0.46544522  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 18           |
|    time_elapsed          | 6464         |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0062011955 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.91         |
|    cost_value_loss       | 53.5         |
|    cost_values           | 1.23         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0.00652      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.98         |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.875        |
|    value_loss            | 1.06         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0399      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0399      |
| reward                   | -0.47917414 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 9           |
|    time_elapsed          | 3057        |
|    total_timesteps       | 620544      |
| train/                   |             |
|    approx_kl             | 0.005506715 |
|    clip_fraction         | 0.091       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 0.837       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.4         |
|    n_updates             | 3020        |
|    policy_gradient_loss  | -0.00844    |
|    std                   | 0.971       |
|    value_loss            | 0.336       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0349       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0349       |
| reward                   | -0.4452676   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 30           |
|    time_elapsed          | 10567        |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0031050462 |
|    clip_fraction         | 0.00645      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.73         |
|    cost_value_loss       | 68.8         |
|    cost_values           | 1.35         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.823        |
|    lagrangian_multiplier | 0.0104       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.45         |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.0025      |
|    std                   | 0.81         |
|    value_loss            | 0.477        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.16        |
| reward                   | -0.40953153 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 7           |
|    time_elapsed          | 2606        |
|    total_timesteps       | 616448      |
| train/                   |             |
|    approx_kl             | 0.00458875  |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.55        |
|    cost_value_loss       | 82.7        |
|    cost_values           | 2.39        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | -0.312      |
|    lagrangian_multiplier | 3.65e-06    |
|    learning_rate         | 0.0003      |
|    loss                  | 42.7        |
|    n_updates             | 3000        |
|    policy_gradient_loss  | 0.00502     |
|    std                   | 0.807       |
|    value_loss            | 4.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.47        |
| reward                   | -0.48930612 |
| rollout/                 |             |
|    ep_len_mean           | 817         |
|    ep_rew_mean           | -378        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 14          |
|    time_elapsed          | 5300        |
|    total_timesteps       | 630784      |
| train/                   |             |
|    approx_kl             | 0.006275568 |
|    clip_fraction         | 0.0879      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.28        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0.385       |
|    lagrangian_multiplier | 0.00482     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.78        |
|    n_updates             | 3070        |
|    policy_gradient_loss  | -0.00495    |
|    std                   | 0.665       |
|    value_loss            | 7.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.153        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.153        |
| reward                   | -0.5341841   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -656         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 13           |
|    time_elapsed          | 4765         |
|    total_timesteps       | 628736       |
| train/                   |              |
|    approx_kl             | 0.0057902774 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.43         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 2.58         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.476        |
|    lagrangian_multiplier | 0.00137      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.16         |
|    n_updates             | 3060         |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 0.849        |
|    value_loss            | 2.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.123        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.123        |
| reward                   | -0.4215112   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 19           |
|    time_elapsed          | 6836         |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0033839354 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 4            |
|    cost_value_loss       | 32.5         |
|    cost_values           | 1.4          |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0.00528      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.34         |
|    n_updates             | 3120         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.873        |
|    value_loss            | 1.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.584        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.584        |
| reward                   | -0.2496667   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 10           |
|    time_elapsed          | 3404         |
|    total_timesteps       | 622592       |
| train/                   |              |
|    approx_kl             | 0.0030247562 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 11.4         |
|    cost_values           | 1.13         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.653        |
|    lagrangian_multiplier | 0.000752     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.87         |
|    n_updates             | 3030         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.97         |
|    value_loss            | 5.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0996      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0996      |
| reward                   | -0.43978566 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 31          |
|    time_elapsed          | 10941       |
|    total_timesteps       | 665600      |
| train/                   |             |
|    approx_kl             | 0.006491164 |
|    clip_fraction         | 0.0559      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.94        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 1.02        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0.003       |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 3240        |
|    policy_gradient_loss  | -0.00444    |
|    std                   | 0.811       |
|    value_loss            | 0.407       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.129       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.129       |
| reward                   | -0.5811879  |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 8           |
|    time_elapsed          | 2984        |
|    total_timesteps       | 618496      |
| train/                   |             |
|    approx_kl             | 0.013584704 |
|    clip_fraction         | 0.0608      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.38        |
|    cost_value_loss       | 1.98        |
|    cost_values           | 2.46        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.233       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.36        |
|    n_updates             | 3010        |
|    policy_gradient_loss  | -0.0012     |
|    std                   | 0.81        |
|    value_loss            | 1.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.98        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.98        |
| reward                   | -0.4116715  |
| rollout/                 |             |
|    ep_len_mean           | 822         |
|    ep_rew_mean           | -380        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 15          |
|    time_elapsed          | 5697        |
|    total_timesteps       | 632832      |
| train/                   |             |
|    approx_kl             | 0.010076584 |
|    clip_fraction         | 0.0705      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.7         |
|    cost_value_loss       | 12          |
|    cost_values           | 2.32        |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 0.581       |
|    lagrangian_multiplier | 0.00284     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.33        |
|    n_updates             | 3080        |
|    policy_gradient_loss  | -0.00728    |
|    std                   | 0.662       |
|    value_loss            | 2.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0313       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0313       |
| reward                   | -0.5339277   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -646         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 14           |
|    time_elapsed          | 5146         |
|    total_timesteps       | 630784       |
| train/                   |              |
|    approx_kl             | 0.0036374377 |
|    clip_fraction         | 0.0508       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.89         |
|    cost_value_loss       | 23.8         |
|    cost_values           | 2.74         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.791        |
|    lagrangian_multiplier | 0.00502      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.94         |
|    n_updates             | 3070         |
|    policy_gradient_loss  | -0.00156     |
|    std                   | 0.848        |
|    value_loss            | 2.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.088        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.088        |
| reward                   | -0.44731918  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -446         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 11           |
|    time_elapsed          | 3779         |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0035852166 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 1.21         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.0963       |
|    lagrangian_multiplier | 0.00112      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.63         |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.969        |
|    value_loss            | 2.14         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.051         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.051         |
| reward                   | -0.41798      |
| rollout/                 |               |
|    ep_len_mean           | 990           |
|    ep_rew_mean           | -462          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 20            |
|    time_elapsed          | 7219          |
|    total_timesteps       | 643072        |
| train/                   |               |
|    approx_kl             | 0.00011701413 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 7.04          |
|    cost_value_loss       | 72.8          |
|    cost_values           | 1.87          |
|    entropy               | -2.56         |
|    entropy_loss          | -2.56         |
|    explained_variance    | 0.512         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 35.8          |
|    n_updates             | 3130          |
|    policy_gradient_loss  | -0.000703     |
|    std                   | 0.871         |
|    value_loss            | 2.47          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.497        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.497        |
| reward                   | -0.30012155  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 32           |
|    time_elapsed          | 11317        |
|    total_timesteps       | 667648       |
| train/                   |              |
|    approx_kl             | 0.0064777904 |
|    clip_fraction         | 0.0442       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.95         |
|    cost_value_loss       | 85.9         |
|    cost_values           | 1.36         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0.013        |
|    learning_rate         | 0.0003       |
|    loss                  | 7.07         |
|    n_updates             | 3250         |
|    policy_gradient_loss  | -0.00543     |
|    std                   | 0.81         |
|    value_loss            | 0.322        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.198       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.198       |
| reward                   | -0.45598856 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 9           |
|    time_elapsed          | 3360        |
|    total_timesteps       | 620544      |
| train/                   |             |
|    approx_kl             | 0.014440872 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 32.4        |
|    cost_values           | 2.41        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.728       |
|    lagrangian_multiplier | 0.00328     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.97        |
|    n_updates             | 3020        |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.81        |
|    value_loss            | 1.52        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.69         |
| reward                   | -0.5024783   |
| rollout/                 |              |
|    ep_len_mean           | 822          |
|    ep_rew_mean           | -380         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 6089         |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0068433257 |
|    clip_fraction         | 0.125        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.02         |
|    cost_value_loss       | 8.18         |
|    cost_values           | 2.21         |
|    entropy               | -1.99        |
|    entropy_loss          | -2           |
|    explained_variance    | 0.781        |
|    lagrangian_multiplier | 0.000996     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 3090         |
|    policy_gradient_loss  | -0.00396     |
|    std                   | 0.66         |
|    value_loss            | 2.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0394      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0394      |
| reward                   | -0.44424927 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -651        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 15          |
|    time_elapsed          | 5531        |
|    total_timesteps       | 632832      |
| train/                   |             |
|    approx_kl             | 0.004390817 |
|    clip_fraction         | 0.0165      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.5         |
|    cost_value_loss       | 77.9        |
|    cost_values           | 2.87        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0.0129      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.55        |
|    n_updates             | 3080        |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.844       |
|    value_loss            | 0.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0736       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0736       |
| reward                   | -0.29862657  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 12           |
|    time_elapsed          | 4150         |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0044303257 |
|    clip_fraction         | 0.033        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.1          |
|    cost_value_loss       | 26.3         |
|    cost_values           | 1.41         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.752        |
|    lagrangian_multiplier | 0.0022       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.88         |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.000344    |
|    std                   | 0.97         |
|    value_loss            | 2.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.54        |
| reward                   | -0.4364486  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 21          |
|    time_elapsed          | 7602        |
|    total_timesteps       | 645120      |
| train/                   |             |
|    approx_kl             | 0.005991799 |
|    clip_fraction         | 0.013       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.11        |
|    cost_value_loss       | 99.7        |
|    cost_values           | 2.27        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.592       |
|    lagrangian_multiplier | 0.00698     |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 3140        |
|    policy_gradient_loss  | -0.00313    |
|    std                   | 0.871       |
|    value_loss            | 2.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0754       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0754       |
| reward                   | -0.5357438   |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 33           |
|    time_elapsed          | 11684        |
|    total_timesteps       | 669696       |
| train/                   |              |
|    approx_kl             | 0.0053937463 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.3          |
|    cost_value_loss       | 46.2         |
|    cost_values           | 1.46         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.877        |
|    lagrangian_multiplier | 0.0067       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.77         |
|    n_updates             | 3260         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.809        |
|    value_loss            | 1.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0897       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0897       |
| reward                   | -0.45800254  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 10           |
|    time_elapsed          | 3734         |
|    total_timesteps       | 622592       |
| train/                   |              |
|    approx_kl             | 0.0041848305 |
|    clip_fraction         | 0.0605       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.17         |
|    cost_value_loss       | 0.41         |
|    cost_values           | 2.26         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.24         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.578        |
|    n_updates             | 3030         |
|    policy_gradient_loss  | -0.000941    |
|    std                   | 0.803        |
|    value_loss            | 0.986        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.19800137  |
| rollout/                 |              |
|    ep_len_mean           | 822          |
|    ep_rew_mean           | -378         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 17           |
|    time_elapsed          | 6481         |
|    total_timesteps       | 636928       |
| train/                   |              |
|    approx_kl             | 0.0076435977 |
|    clip_fraction         | 0.0831       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.39         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 2.3          |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.0301       |
|    lagrangian_multiplier | 0.0061       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.78         |
|    n_updates             | 3100         |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 0.658        |
|    value_loss            | 1.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.25        |
| reward                   | -0.41725677 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -439        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 13          |
|    time_elapsed          | 4521        |
|    total_timesteps       | 628736      |
| train/                   |             |
|    approx_kl             | 0.004327613 |
|    clip_fraction         | 0.024       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.55        |
|    cost_value_loss       | 16.8        |
|    cost_values           | 1.24        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.603       |
|    lagrangian_multiplier | 0.000612    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.47        |
|    n_updates             | 3060        |
|    policy_gradient_loss  | -0.00271    |
|    std                   | 0.968       |
|    value_loss            | 1.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.308        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.308        |
| reward                   | -0.56844455  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -651         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 5912         |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0057705333 |
|    clip_fraction         | 0.0629       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.79         |
|    cost_value_loss       | 28.1         |
|    cost_values           | 2.78         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0.00365      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.04         |
|    n_updates             | 3090         |
|    policy_gradient_loss  | 0.00082      |
|    std                   | 0.843        |
|    value_loss            | 0.631        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0164        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0164        |
| reward                   | -0.48183772   |
| rollout/                 |               |
|    ep_len_mean           | 995           |
|    ep_rew_mean           | -464          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 22            |
|    time_elapsed          | 7979          |
|    total_timesteps       | 647168        |
| train/                   |               |
|    approx_kl             | 0.00022215003 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 9.48          |
|    cost_value_loss       | 108           |
|    cost_values           | 2.27          |
|    entropy               | -2.55         |
|    entropy_loss          | -2.55         |
|    explained_variance    | 0.947         |
|    lagrangian_multiplier | 0.0302        |
|    learning_rate         | 0.0003        |
|    loss                  | 5.39          |
|    n_updates             | 3150          |
|    policy_gradient_loss  | -0.000357     |
|    std                   | 0.871         |
|    value_loss            | 1.35          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0636       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0636       |
| reward                   | -0.57837594  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 34           |
|    time_elapsed          | 12062        |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0025928016 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.4          |
|    cost_value_loss       | 19.2         |
|    cost_values           | 0.975        |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.926        |
|    lagrangian_multiplier | 0.00174      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.32         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.000485    |
|    std                   | 0.808        |
|    value_loss            | 1.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0278       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0278       |
| reward                   | -0.23092405  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 11           |
|    time_elapsed          | 4114         |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0049096067 |
|    clip_fraction         | 0.0767       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 0.215        |
|    cost_values           | 1.96         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | -0.563       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.683        |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -0.000816    |
|    std                   | 0.805        |
|    value_loss            | 1.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -0.5123542   |
| rollout/                 |              |
|    ep_len_mean           | 805          |
|    ep_rew_mean           | -369         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 18           |
|    time_elapsed          | 6880         |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0058589904 |
|    clip_fraction         | 0.0948       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.5          |
|    cost_value_loss       | 17.9         |
|    cost_values           | 2.61         |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.852        |
|    lagrangian_multiplier | 0.00136      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.33         |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.00525     |
|    std                   | 0.657        |
|    value_loss            | 1.37         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.143       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.143       |
| reward                   | -0.3241607  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -440        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 14          |
|    time_elapsed          | 4894        |
|    total_timesteps       | 630784      |
| train/                   |             |
|    approx_kl             | 0.004783122 |
|    clip_fraction         | 0.0269      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.55        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 1.49        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.762       |
|    lagrangian_multiplier | 0.000642    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.77        |
|    n_updates             | 3070        |
|    policy_gradient_loss  | -0.00388    |
|    std                   | 0.968       |
|    value_loss            | 1.72        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0296       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0296       |
| reward                   | -0.29287705  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -649         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 17           |
|    time_elapsed          | 6293         |
|    total_timesteps       | 636928       |
| train/                   |              |
|    approx_kl             | 0.0012905146 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 130          |
|    cost_values           | 2.86         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.9          |
|    lagrangian_multiplier | 0.0168       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.6          |
|    n_updates             | 3100         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.845        |
|    value_loss            | 1.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.388        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.388        |
| reward                   | -0.45832714  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 23           |
|    time_elapsed          | 8363         |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0027397885 |
|    clip_fraction         | 0.00483      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.24         |
|    cost_value_loss       | 67.1         |
|    cost_values           | 1.61         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0.0103       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.73         |
|    n_updates             | 3160         |
|    policy_gradient_loss  | -0.00123     |
|    std                   | 0.872        |
|    value_loss            | 0.597        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0818       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0818       |
| reward                   | -0.48089033  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 35           |
|    time_elapsed          | 12437        |
|    total_timesteps       | 673792       |
| train/                   |              |
|    approx_kl             | 0.0070662713 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 14.6         |
|    cost_values           | 1.03         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.925        |
|    lagrangian_multiplier | 0.00106      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.35         |
|    n_updates             | 3280         |
|    policy_gradient_loss  | -0.00328     |
|    std                   | 0.808        |
|    value_loss            | 1.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0852       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0852       |
| reward                   | -0.53847355  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 12           |
|    time_elapsed          | 4492         |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0026521753 |
|    clip_fraction         | 0.0514       |
|    clip_range            | 0.2          |
|    cost_returns          | 3            |
|    cost_value_loss       | 12.1         |
|    cost_values           | 1.73         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | -0.368       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.54         |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.000142    |
|    std                   | 0.805        |
|    value_loss            | 3.96         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.21        |
| reward                   | -0.308637   |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 15          |
|    time_elapsed          | 5272        |
|    total_timesteps       | 632832      |
| train/                   |             |
|    approx_kl             | 0.004493979 |
|    clip_fraction         | 0.0352      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.34        |
|    cost_value_loss       | 24.5        |
|    cost_values           | 1.49        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.784       |
|    lagrangian_multiplier | 0.0021      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.66        |
|    n_updates             | 3080        |
|    policy_gradient_loss  | -0.00337    |
|    std                   | 0.967       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -0.499482   |
| rollout/                 |             |
|    ep_len_mean           | 788         |
|    ep_rew_mean           | -360        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 19          |
|    time_elapsed          | 7281        |
|    total_timesteps       | 641024      |
| train/                   |             |
|    approx_kl             | 0.012029159 |
|    clip_fraction         | 0.0989      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.35        |
|    cost_value_loss       | 14.9        |
|    cost_values           | 2.94        |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0.0376      |
|    lagrangian_multiplier | 0.00402     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.75        |
|    n_updates             | 3120        |
|    policy_gradient_loss  | -0.00497    |
|    std                   | 0.656       |
|    value_loss            | 20.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0142      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0142      |
| reward                   | -0.45705995 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -634        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 18          |
|    time_elapsed          | 6682        |
|    total_timesteps       | 638976      |
| train/                   |             |
|    approx_kl             | 0.007825458 |
|    clip_fraction         | 0.0464      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 136         |
|    cost_values           | 2.92        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.859       |
|    lagrangian_multiplier | 0.0177      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.23        |
|    n_updates             | 3110        |
|    policy_gradient_loss  | -0.000687   |
|    std                   | 0.841       |
|    value_loss            | 2.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.227        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.227        |
| reward                   | -0.40951017  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 24           |
|    time_elapsed          | 8748         |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0016929406 |
|    clip_fraction         | 0.000684     |
|    clip_range            | 0.2          |
|    cost_returns          | 10.9         |
|    cost_value_loss       | 136          |
|    cost_values           | 1.98         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.901        |
|    lagrangian_multiplier | 0.00022      |
|    learning_rate         | 0.0003       |
|    loss                  | 62.8         |
|    n_updates             | 3170         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.873        |
|    value_loss            | 1.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0926       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0926       |
| reward                   | -0.43347606  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 36           |
|    time_elapsed          | 12815        |
|    total_timesteps       | 675840       |
| train/                   |              |
|    approx_kl             | 0.0020614567 |
|    clip_fraction         | 0.00708      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.97         |
|    cost_value_loss       | 24.2         |
|    cost_values           | 1.18         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.873        |
|    lagrangian_multiplier | 0.00602      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.71         |
|    n_updates             | 3290         |
|    policy_gradient_loss  | -0.000707    |
|    std                   | 0.809        |
|    value_loss            | 2.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0912       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0912       |
| reward                   | -0.49406067  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 13           |
|    time_elapsed          | 4873         |
|    total_timesteps       | 628736       |
| train/                   |              |
|    approx_kl             | 0.0074384115 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.73         |
|    cost_value_loss       | 0.692        |
|    cost_values           | 1.84         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.255        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.617        |
|    n_updates             | 3060         |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.806        |
|    value_loss            | 1.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.234        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.234        |
| reward                   | -0.37595242  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 5648         |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0065448866 |
|    clip_fraction         | 0.0825       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.28         |
|    cost_value_loss       | 24.7         |
|    cost_values           | 1.51         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.379        |
|    lagrangian_multiplier | 0.0041       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.33         |
|    n_updates             | 3090         |
|    policy_gradient_loss  | -0.0053      |
|    std                   | 0.965        |
|    value_loss            | 6.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0293       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0293       |
| reward                   | -0.5426401   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -606         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 19           |
|    time_elapsed          | 7065         |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0023024923 |
|    clip_fraction         | 0.00962      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.94         |
|    cost_value_loss       | 77.1         |
|    cost_values           | 2.92         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 0.0101       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.02         |
|    n_updates             | 3120         |
|    policy_gradient_loss  | -0.00034     |
|    std                   | 0.842        |
|    value_loss            | 1.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.17263246  |
| rollout/                 |              |
|    ep_len_mean           | 788          |
|    ep_rew_mean           | -360         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 20           |
|    time_elapsed          | 7683         |
|    total_timesteps       | 643072       |
| train/                   |              |
|    approx_kl             | 0.0061726705 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.21         |
|    cost_value_loss       | 18.5         |
|    cost_values           | 2.61         |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.476        |
|    lagrangian_multiplier | 0.00955      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.03         |
|    n_updates             | 3130         |
|    policy_gradient_loss  | -0.00338     |
|    std                   | 0.656        |
|    value_loss            | 22.5         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.265         |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.265         |
| reward                   | -0.35081923   |
| rollout/                 |               |
|    ep_len_mean           | 995           |
|    ep_rew_mean           | -465          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 25            |
|    time_elapsed          | 9132          |
|    total_timesteps       | 653312        |
| train/                   |               |
|    approx_kl             | 0.00014313316 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 9.58          |
|    cost_value_loss       | 106           |
|    cost_values           | 2.46          |
|    entropy               | -2.56         |
|    entropy_loss          | -2.56         |
|    explained_variance    | 0.79          |
|    lagrangian_multiplier | 0.00955       |
|    learning_rate         | 0.0003        |
|    loss                  | 11.4          |
|    n_updates             | 3180          |
|    policy_gradient_loss  | -0.000776     |
|    std                   | 0.873         |
|    value_loss            | 1.78          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.309        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.309        |
| reward                   | -0.5856142   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 37           |
|    time_elapsed          | 13191        |
|    total_timesteps       | 677888       |
| train/                   |              |
|    approx_kl             | 0.0011570081 |
|    clip_fraction         | 0.00757      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.61         |
|    cost_value_loss       | 70.3         |
|    cost_values           | 1.12         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.911        |
|    lagrangian_multiplier | 0.00662      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.97         |
|    n_updates             | 3300         |
|    policy_gradient_loss  | 0.000956     |
|    std                   | 0.809        |
|    value_loss            | 0.861        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.107       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.107       |
| reward                   | -0.41788322 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 14          |
|    time_elapsed          | 5253        |
|    total_timesteps       | 630784      |
| train/                   |             |
|    approx_kl             | 0.005951929 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.27        |
|    cost_value_loss       | 46          |
|    cost_values           | 1.74        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.4        |
|    n_updates             | 3070        |
|    policy_gradient_loss  | -0.00753    |
|    std                   | 0.806       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0849      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0849      |
| reward                   | -0.26298767 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -437        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 17          |
|    time_elapsed          | 5988        |
|    total_timesteps       | 636928      |
| train/                   |             |
|    approx_kl             | 0.009169273 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.73        |
|    cost_value_loss       | 44.3        |
|    cost_values           | 1.71        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.61        |
|    lagrangian_multiplier | 0.00507     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.39        |
|    n_updates             | 3100        |
|    policy_gradient_loss  | -0.00798    |
|    std                   | 0.967       |
|    value_loss            | 0.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.321        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.321        |
| reward                   | -0.35304382  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -582         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 20           |
|    time_elapsed          | 7450         |
|    total_timesteps       | 643072       |
| train/                   |              |
|    approx_kl             | 0.0038525108 |
|    clip_fraction         | 0.0495       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.78         |
|    cost_value_loss       | 13.8         |
|    cost_values           | 2.84         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.485        |
|    lagrangian_multiplier | 0.00202      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.38         |
|    n_updates             | 3130         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.842        |
|    value_loss            | 0.435        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.156        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.156        |
| reward                   | -0.52584475  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 26           |
|    time_elapsed          | 9516         |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0016203704 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 8.58         |
|    cost_value_loss       | 88           |
|    cost_values           | 2.5          |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.793        |
|    lagrangian_multiplier | 0.0114       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.64         |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -0.000869    |
|    std                   | 0.875        |
|    value_loss            | 3.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -0.6605542   |
| rollout/                 |              |
|    ep_len_mean           | 792          |
|    ep_rew_mean           | -360         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 21           |
|    time_elapsed          | 8086         |
|    total_timesteps       | 645120       |
| train/                   |              |
|    approx_kl             | 0.0069030463 |
|    clip_fraction         | 0.0733       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.18         |
|    cost_value_loss       | 18.6         |
|    cost_values           | 2.22         |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.916        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.36         |
|    n_updates             | 3140         |
|    policy_gradient_loss  | -0.0062      |
|    std                   | 0.656        |
|    value_loss            | 1.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.175        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.175        |
| reward                   | -0.46113828  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 38           |
|    time_elapsed          | 13566        |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0040822434 |
|    clip_fraction         | 0.0392       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 9.6          |
|    cost_values           | 1.11         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.922        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.16         |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.81         |
|    value_loss            | 1.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0504       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0504       |
| reward                   | -0.4087858   |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 15           |
|    time_elapsed          | 5629         |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0061531025 |
|    clip_fraction         | 0.116        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.26         |
|    cost_value_loss       | 20.6         |
|    cost_values           | 2.15         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.467        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 3080         |
|    policy_gradient_loss  | -0.013       |
|    std                   | 0.806        |
|    value_loss            | 0.148        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0489       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0489       |
| reward                   | -0.521897    |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 18           |
|    time_elapsed          | 6334         |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0034475764 |
|    clip_fraction         | 0.0372       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.81         |
|    cost_value_loss       | 23.7         |
|    cost_values           | 1.96         |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.189        |
|    lagrangian_multiplier | 0.00272      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.06         |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 0.964        |
|    value_loss            | 2.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.184       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.184       |
| reward                   | -0.57199055 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -562        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 21          |
|    time_elapsed          | 7835        |
|    total_timesteps       | 645120      |
| train/                   |             |
|    approx_kl             | 0.002815626 |
|    clip_fraction         | 0.0424      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.81        |
|    cost_value_loss       | 56.4        |
|    cost_values           | 2.78        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.00845     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.65        |
|    n_updates             | 3140        |
|    policy_gradient_loss  | -0.0017     |
|    std                   | 0.843       |
|    value_loss            | 0.311       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0311      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0311      |
| reward                   | -0.31351987 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 27          |
|    time_elapsed          | 9901        |
|    total_timesteps       | 657408      |
| train/                   |             |
|    approx_kl             | 0.000138273 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 5.42        |
|    cost_value_loss       | 59.6        |
|    cost_values           | 1.86        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0.0217      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.45        |
|    n_updates             | 3200        |
|    policy_gradient_loss  | 4.46e-05    |
|    std                   | 0.876       |
|    value_loss            | 1.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0795      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0795      |
| reward                   | -0.3269076  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 39          |
|    time_elapsed          | 13946       |
|    total_timesteps       | 681984      |
| train/                   |             |
|    approx_kl             | 0.002760304 |
|    clip_fraction         | 0.0257      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.704       |
|    cost_value_loss       | 0.025       |
|    cost_values           | 0.836       |
|    entropy               | -2.39       |
|    entropy_loss          | -2.4        |
|    explained_variance    | -2.59       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0414      |
|    n_updates             | 3320        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.808       |
|    value_loss            | 1.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.65         |
| reward                   | -0.4091953   |
| rollout/                 |              |
|    ep_len_mean           | 789          |
|    ep_rew_mean           | -358         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 22           |
|    time_elapsed          | 8490         |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0054778685 |
|    clip_fraction         | 0.0436       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.32         |
|    cost_value_loss       | 16.7         |
|    cost_values           | 2.66         |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.903        |
|    lagrangian_multiplier | 0.00698      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.11         |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.00417     |
|    std                   | 0.654        |
|    value_loss            | 1.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00763      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00763      |
| reward                   | -0.37991956  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -447         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 6011         |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0033894763 |
|    clip_fraction         | 0.00347      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.73         |
|    cost_value_loss       | 89.4         |
|    cost_values           | 2.64         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.25         |
|    lagrangian_multiplier | 0.0128       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.37         |
|    n_updates             | 3090         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.805        |
|    value_loss            | 0.306        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.342        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.342        |
| reward                   | -0.5465722   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 19           |
|    time_elapsed          | 6683         |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0034814198 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.15         |
|    cost_value_loss       | 43.8         |
|    cost_values           | 1.94         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.43         |
|    lagrangian_multiplier | 0.00432      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.4          |
|    n_updates             | 3120         |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.962        |
|    value_loss            | 2.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.227       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.227       |
| reward                   | -0.5339703  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -551        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 22          |
|    time_elapsed          | 8231        |
|    total_timesteps       | 647168      |
| train/                   |             |
|    approx_kl             | 0.005513571 |
|    clip_fraction         | 0.0496      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 179         |
|    cost_values           | 2.92        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.0174      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 3150        |
|    policy_gradient_loss  | -0.00206    |
|    std                   | 0.842       |
|    value_loss            | 0.646       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.119        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.119        |
| reward                   | -0.28866592  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 28           |
|    time_elapsed          | 10286        |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0040106867 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.91         |
|    cost_value_loss       | 83.4         |
|    cost_values           | 1.54         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.846        |
|    lagrangian_multiplier | 0.0116       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.7          |
|    n_updates             | 3210         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.874        |
|    value_loss            | 1.93         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.134       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.134       |
| reward                   | -0.38019094 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 40          |
|    time_elapsed          | 14326       |
|    total_timesteps       | 684032      |
| train/                   |             |
|    approx_kl             | 0.003321154 |
|    clip_fraction         | 0.0895      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.17        |
|    cost_value_loss       | 6.5         |
|    cost_values           | 0.756       |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.429       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.04        |
|    n_updates             | 3330        |
|    policy_gradient_loss  | 0.00212     |
|    std                   | 0.805       |
|    value_loss            | 1.41        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.97       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.97       |
| reward                   | -0.4601373 |
| rollout/                 |            |
|    ep_len_mean           | 789        |
|    ep_rew_mean           | -356       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 23         |
|    time_elapsed          | 8890       |
|    total_timesteps       | 649216     |
| train/                   |            |
|    approx_kl             | 0.01276368 |
|    clip_fraction         | 0.132      |
|    clip_range            | 0.2        |
|    cost_returns          | 6.5        |
|    cost_value_loss       | 16.3       |
|    cost_values           | 2.95       |
|    entropy               | -1.97      |
|    entropy_loss          | -1.98      |
|    explained_variance    | 0.448      |
|    lagrangian_multiplier | 0.00478    |
|    learning_rate         | 0.0003     |
|    loss                  | 6.22       |
|    n_updates             | 3160       |
|    policy_gradient_loss  | -0.00107   |
|    std                   | 0.653      |
|    value_loss            | 20.8       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.145       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.145       |
| reward                   | -0.53880143 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 17          |
|    time_elapsed          | 6396        |
|    total_timesteps       | 636928      |
| train/                   |             |
|    approx_kl             | 0.008457432 |
|    clip_fraction         | 0.0709      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 168         |
|    cost_values           | 2.91        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.4        |
|    explained_variance    | -1.03       |
|    lagrangian_multiplier | 0.0199      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 3100        |
|    policy_gradient_loss  | -0.00589    |
|    std                   | 0.805       |
|    value_loss            | 0.786       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.151       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.151       |
| reward                   | -0.3107862  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 20          |
|    time_elapsed          | 7036        |
|    total_timesteps       | 643072      |
| train/                   |             |
|    approx_kl             | 0.007827323 |
|    clip_fraction         | 0.0879      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.24        |
|    cost_value_loss       | 90.5        |
|    cost_values           | 1.97        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0.0149      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.14        |
|    n_updates             | 3130        |
|    policy_gradient_loss  | -0.0088     |
|    std                   | 0.961       |
|    value_loss            | 0.823       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.213        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.213        |
| reward                   | -0.26557007  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -560         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 23           |
|    time_elapsed          | 8620         |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0018010115 |
|    clip_fraction         | 0.00234      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.01         |
|    cost_value_loss       | 2.29         |
|    cost_values           | 2.69         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.663        |
|    lagrangian_multiplier | 0.000162     |
|    learning_rate         | 0.0003       |
|    loss                  | 1.37         |
|    n_updates             | 3160         |
|    policy_gradient_loss  | -0.00033     |
|    std                   | 0.84         |
|    value_loss            | 0.998        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0479       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0479       |
| reward                   | -0.29995885  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 29           |
|    time_elapsed          | 10674        |
|    total_timesteps       | 661504       |
| train/                   |              |
|    approx_kl             | 0.0073186643 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.03         |
|    cost_value_loss       | 6.18         |
|    cost_values           | 1.64         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.69         |
|    n_updates             | 3220         |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 0.873        |
|    value_loss            | 1.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.124        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.124        |
| reward                   | -0.57109654  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 41           |
|    time_elapsed          | 14708        |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0018681602 |
|    clip_fraction         | 0.0611       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.649        |
|    cost_value_loss       | 0.0122       |
|    cost_values           | 0.702        |
|    entropy               | -2.38        |
|    entropy_loss          | -2.39        |
|    explained_variance    | -0.162       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.634        |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 0.804        |
|    value_loss            | 1.94         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -0.683566   |
| rollout/                 |             |
|    ep_len_mean           | 782         |
|    ep_rew_mean           | -354        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 24          |
|    time_elapsed          | 9292        |
|    total_timesteps       | 651264      |
| train/                   |             |
|    approx_kl             | 0.005216074 |
|    clip_fraction         | 0.0399      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.83        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.62        |
|    entropy               | -1.97       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.05        |
|    n_updates             | 3170        |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 0.652       |
|    value_loss            | 2.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00644      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00644      |
| reward                   | -0.43074107  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 18           |
|    time_elapsed          | 6786         |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0034490163 |
|    clip_fraction         | 0.0313       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.9         |
|    cost_value_loss       | 132          |
|    cost_values           | 2.89         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.574        |
|    lagrangian_multiplier | 0.0165       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.62         |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.803        |
|    value_loss            | 0.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.204        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.204        |
| reward                   | -0.5175912   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 21           |
|    time_elapsed          | 7392         |
|    total_timesteps       | 645120       |
| train/                   |              |
|    approx_kl             | 0.0066665383 |
|    clip_fraction         | 0.0476       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.53         |
|    cost_value_loss       | 0.182        |
|    cost_values           | 1.63         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.534        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.05         |
|    n_updates             | 3140         |
|    policy_gradient_loss  | -0.00359     |
|    std                   | 0.959        |
|    value_loss            | 6.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0315      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0315      |
| reward                   | -0.28560233 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -561        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 24          |
|    time_elapsed          | 9008        |
|    total_timesteps       | 651264      |
| train/                   |             |
|    approx_kl             | 0.004331765 |
|    clip_fraction         | 0.0375      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 128         |
|    cost_values           | 2.04        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.659       |
|    lagrangian_multiplier | 0.432       |
|    learning_rate         | 0.0003      |
|    loss                  | 2.56        |
|    n_updates             | 3170        |
|    policy_gradient_loss  | 0.00472     |
|    std                   | 0.839       |
|    value_loss            | 59.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.404        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.404        |
| reward                   | -0.3904047   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 30           |
|    time_elapsed          | 11060        |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0031607524 |
|    clip_fraction         | 0.00342      |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 144          |
|    cost_values           | 1.89         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.383        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 68.6         |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.872        |
|    value_loss            | 1            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.000318     |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.000318     |
| reward                   | -0.43144462  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 42           |
|    time_elapsed          | 15091        |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0039062547 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 6.31         |
|    cost_values           | 0.703        |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.571        |
|    lagrangian_multiplier | 1.13e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 3.39         |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.804        |
|    value_loss            | 2.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.39072084 |
| rollout/                 |             |
|    ep_len_mean           | 781         |
|    ep_rew_mean           | -352        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 25          |
|    time_elapsed          | 9696        |
|    total_timesteps       | 653312      |
| train/                   |             |
|    approx_kl             | 0.009910267 |
|    clip_fraction         | 0.0806      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.83        |
|    cost_value_loss       | 19          |
|    cost_values           | 2.21        |
|    entropy               | -1.97       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.59        |
|    lagrangian_multiplier | 0.00344     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.44        |
|    n_updates             | 3180        |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.651       |
|    value_loss            | 15.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0876      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0876      |
| reward                   | -0.36485413 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -444        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 19          |
|    time_elapsed          | 7174        |
|    total_timesteps       | 641024      |
| train/                   |             |
|    approx_kl             | 0.006345911 |
|    clip_fraction         | 0.0264      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.83        |
|    cost_value_loss       | 64.4        |
|    cost_values           | 2.9         |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.475       |
|    lagrangian_multiplier | 0.0107      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.24        |
|    n_updates             | 3120        |
|    policy_gradient_loss  | -0.0017     |
|    std                   | 0.804       |
|    value_loss            | 2.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0462       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0462       |
| reward                   | -0.5593547   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 22           |
|    time_elapsed          | 7746         |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0066775964 |
|    clip_fraction         | 0.0335       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 8.82         |
|    cost_values           | 1.3          |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.345        |
|    lagrangian_multiplier | 0.000837     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.76         |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.00404     |
|    std                   | 0.961        |
|    value_loss            | 9.73         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0794        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0794        |
| reward                   | -0.3853506    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -558          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 25            |
|    time_elapsed          | 9392          |
|    total_timesteps       | 653312        |
| train/                   |               |
|    approx_kl             | 0.00025954228 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 6.76          |
|    cost_value_loss       | 80.8          |
|    cost_values           | 1.56          |
|    entropy               | -2.49         |
|    entropy_loss          | -2.49         |
|    explained_variance    | 0.923         |
|    lagrangian_multiplier | 0.132         |
|    learning_rate         | 0.0003        |
|    loss                  | 2.06          |
|    n_updates             | 3180          |
|    policy_gradient_loss  | -0.000641     |
|    std                   | 0.839         |
|    value_loss            | 14            |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.151        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.151        |
| reward                   | -0.2339894   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 31           |
|    time_elapsed          | 11445        |
|    total_timesteps       | 665600       |
| train/                   |              |
|    approx_kl             | 0.0023662392 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.05         |
|    cost_value_loss       | 117          |
|    cost_values           | 1.72         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.779        |
|    lagrangian_multiplier | 0.01         |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 3240         |
|    policy_gradient_loss  | -0.000342    |
|    std                   | 0.871        |
|    value_loss            | 1.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0239      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0239      |
| reward                   | -0.3982173  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 43          |
|    time_elapsed          | 15475       |
|    total_timesteps       | 690176      |
| train/                   |             |
|    approx_kl             | 0.009269931 |
|    clip_fraction         | 0.0222      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.1         |
|    cost_value_loss       | 20.7        |
|    cost_values           | 0.702       |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.246       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.2        |
|    n_updates             | 3360        |
|    policy_gradient_loss  | -0.000996   |
|    std                   | 0.804       |
|    value_loss            | 4.54        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.0118     |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 0.0118     |
| reward                   | -0.5768661 |
| rollout/                 |            |
|    ep_len_mean           | 982        |
|    ep_rew_mean           | -436       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 23         |
|    time_elapsed          | 8103       |
|    total_timesteps       | 649216     |
| train/                   |            |
|    approx_kl             | 0.01146467 |
|    clip_fraction         | 0.0505     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.38       |
|    cost_value_loss       | 2.12       |
|    cost_values           | 1.02       |
|    entropy               | -2.76      |
|    entropy_loss          | -2.76      |
|    explained_variance    | 0.936      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.38       |
|    n_updates             | 3160       |
|    policy_gradient_loss  | -0.00412   |
|    std                   | 0.961      |
|    value_loss            | 2.21       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.43223682 |
| rollout/                 |             |
|    ep_len_mean           | 782         |
|    ep_rew_mean           | -351        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 26          |
|    time_elapsed          | 10100       |
|    total_timesteps       | 655360      |
| train/                   |             |
|    approx_kl             | 0.007480748 |
|    clip_fraction         | 0.0786      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.18        |
|    cost_value_loss       | 18.3        |
|    cost_values           | 2.27        |
|    entropy               | -1.96       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0.399       |
|    lagrangian_multiplier | 0.000229    |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 3190        |
|    policy_gradient_loss  | -0.00562    |
|    std                   | 0.65        |
|    value_loss            | 9.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0582       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0582       |
| reward                   | -0.28264412  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 20           |
|    time_elapsed          | 7569         |
|    total_timesteps       | 643072       |
| train/                   |              |
|    approx_kl             | 0.0042508114 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 129          |
|    cost_values           | 2.97         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | -2.17        |
|    lagrangian_multiplier | 0.0193       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.61         |
|    n_updates             | 3130         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.805        |
|    value_loss            | 1.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0494       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0494       |
| reward                   | -0.3371324   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 32           |
|    time_elapsed          | 11833        |
|    total_timesteps       | 667648       |
| train/                   |              |
|    approx_kl             | 0.0026025157 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.52         |
|    cost_value_loss       | 71.2         |
|    cost_values           | 1.57         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.0457       |
|    lagrangian_multiplier | 0.0109       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.56         |
|    n_updates             | 3250         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.867        |
|    value_loss            | 1.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.000721     |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.000721     |
| reward                   | -0.39247212  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -557         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 26           |
|    time_elapsed          | 9785         |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0035620215 |
|    clip_fraction         | 0.016        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.74         |
|    cost_value_loss       | 38.1         |
|    cost_values           | 1.16         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.2         |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.837        |
|    value_loss            | 2.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00506      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00506      |
| reward                   | -0.3688253   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 44           |
|    time_elapsed          | 15861        |
|    total_timesteps       | 692224       |
| train/                   |              |
|    approx_kl             | 0.0012625307 |
|    clip_fraction         | 0.00293      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.489        |
|    cost_value_loss       | 0.0426       |
|    cost_values           | 0.685        |
|    entropy               | -2.39        |
|    entropy_loss          | -2.38        |
|    explained_variance    | -0.183       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.574        |
|    n_updates             | 3370         |
|    policy_gradient_loss  | -8.87e-05    |
|    std                   | 0.805        |
|    value_loss            | 2.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.163        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.163        |
| reward                   | -0.48684776  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -441         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 24           |
|    time_elapsed          | 8467         |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0017262108 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.71         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 1.21         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.7          |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.52         |
|    n_updates             | 3170         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.961        |
|    value_loss            | 2.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.28        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.28        |
| reward                   | -0.39241076 |
| rollout/                 |             |
|    ep_len_mean           | 768         |
|    ep_rew_mean           | -344        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 27          |
|    time_elapsed          | 10508       |
|    total_timesteps       | 657408      |
| train/                   |             |
|    approx_kl             | 0.01729996  |
|    clip_fraction         | 0.0995      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.95        |
|    cost_value_loss       | 16.2        |
|    cost_values           | 2.54        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0.372       |
|    lagrangian_multiplier | 0.00411     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.23        |
|    n_updates             | 3200        |
|    policy_gradient_loss  | -0.00612    |
|    std                   | 0.647       |
|    value_loss            | 8.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.455       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.455       |
| reward                   | -0.45348838 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 21          |
|    time_elapsed          | 7966        |
|    total_timesteps       | 645120      |
| train/                   |             |
|    approx_kl             | 0.004925176 |
|    clip_fraction         | 0.0328      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.14        |
|    cost_value_loss       | 23.7        |
|    cost_values           | 2.85        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.557       |
|    lagrangian_multiplier | 0.0033      |
|    learning_rate         | 0.0003      |
|    loss                  | 6           |
|    n_updates             | 3140        |
|    policy_gradient_loss  | -0.00334    |
|    std                   | 0.803       |
|    value_loss            | 1.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.133       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.133       |
| reward                   | -0.3310479  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 33          |
|    time_elapsed          | 12219       |
|    total_timesteps       | 669696      |
| train/                   |             |
|    approx_kl             | 0.005009175 |
|    clip_fraction         | 0.0286      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.56        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 1.51        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.848       |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.1         |
|    n_updates             | 3260        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.863       |
|    value_loss            | 0.684       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0205       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0205       |
| reward                   | -0.43057477  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -569         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 27           |
|    time_elapsed          | 10186        |
|    total_timesteps       | 657408       |
| train/                   |              |
|    approx_kl             | 0.0019647758 |
|    clip_fraction         | 0.00757      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 5.56         |
|    cost_values           | 1.19         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.475        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.21         |
|    n_updates             | 3200         |
|    policy_gradient_loss  | -0.000752    |
|    std                   | 0.838        |
|    value_loss            | 1.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0856       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0856       |
| reward                   | -0.40782145  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 45           |
|    time_elapsed          | 16247        |
|    total_timesteps       | 694272       |
| train/                   |              |
|    approx_kl             | 0.0029831391 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.878        |
|    cost_value_loss       | 3.17         |
|    cost_values           | 0.633        |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.751        |
|    lagrangian_multiplier | 0.000108     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.62         |
|    n_updates             | 3380         |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.802        |
|    value_loss            | 1.25         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.205      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.205      |
| reward                   | -0.5286872 |
| rollout/                 |            |
|    ep_len_mean           | 982        |
|    ep_rew_mean           | -440       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 25         |
|    time_elapsed          | 8826       |
|    total_timesteps       | 653312     |
| train/                   |            |
|    approx_kl             | 0.00728253 |
|    clip_fraction         | 0.0289     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.68       |
|    cost_value_loss       | 62.8       |
|    cost_values           | 1.45       |
|    entropy               | -2.75      |
|    entropy_loss          | -2.76      |
|    explained_variance    | 0.955      |
|    lagrangian_multiplier | 0.00672    |
|    learning_rate         | 0.0003     |
|    loss                  | 8.95       |
|    n_updates             | 3180       |
|    policy_gradient_loss  | -0.00351   |
|    std                   | 0.959      |
|    value_loss            | 1.51       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.0717      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0717      |
| reward                   | -0.4697274  |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 22          |
|    time_elapsed          | 8360        |
|    total_timesteps       | 647168      |
| train/                   |             |
|    approx_kl             | 0.005245623 |
|    clip_fraction         | 0.0117      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 113         |
|    cost_values           | 2.88        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | -0.635      |
|    lagrangian_multiplier | 0.0123      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 3150        |
|    policy_gradient_loss  | -0.000833   |
|    std                   | 0.803       |
|    value_loss            | 1.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.2          |
| reward                   | -0.6233221   |
| rollout/                 |              |
|    ep_len_mean           | 776          |
|    ep_rew_mean           | -348         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 28           |
|    time_elapsed          | 10916        |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0076257633 |
|    clip_fraction         | 0.0897       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.81         |
|    cost_value_loss       | 20.9         |
|    cost_values           | 2.71         |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0.24         |
|    lagrangian_multiplier | 0.00384      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.85         |
|    n_updates             | 3210         |
|    policy_gradient_loss  | -0.0042      |
|    std                   | 0.645        |
|    value_loss            | 20.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0805      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0805      |
| reward                   | -0.37503734 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 34          |
|    time_elapsed          | 12610       |
|    total_timesteps       | 671744      |
| train/                   |             |
|    approx_kl             | 0.010830037 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.03        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 1.28        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0.00175     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.53        |
|    n_updates             | 3270        |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 0.86        |
|    value_loss            | 0.347       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.586       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.586       |
| reward                   | -0.28864184 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 26          |
|    time_elapsed          | 9187        |
|    total_timesteps       | 655360      |
| train/                   |             |
|    approx_kl             | 0.008827827 |
|    clip_fraction         | 0.0213      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.9         |
|    cost_value_loss       | 95.3        |
|    cost_values           | 1.4         |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.881       |
|    lagrangian_multiplier | 0.00725     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 3190        |
|    policy_gradient_loss  | -0.00164    |
|    std                   | 0.958       |
|    value_loss            | 1.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.104       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.104       |
| reward                   | -0.5271379  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 46          |
|    time_elapsed          | 16637       |
|    total_timesteps       | 696320      |
| train/                   |             |
|    approx_kl             | 0.005144392 |
|    clip_fraction         | 0.0429      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.22        |
|    cost_value_loss       | 17.5        |
|    cost_values           | 0.937       |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0.00272     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.86        |
|    n_updates             | 3390        |
|    policy_gradient_loss  | -0.00218    |
|    std                   | 0.802       |
|    value_loss            | 0.379       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -3.1631162   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -569         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 28           |
|    time_elapsed          | 10582        |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0028956328 |
|    clip_fraction         | 0.0241       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.26         |
|    cost_value_loss       | 48.9         |
|    cost_values           | 0.757        |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0.0232       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.63         |
|    n_updates             | 3210         |
|    policy_gradient_loss  | 0.00111      |
|    std                   | 0.838        |
|    value_loss            | 51.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.559        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.559        |
| reward                   | -0.33944768  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 23           |
|    time_elapsed          | 8754         |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0049556475 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.8          |
|    cost_value_loss       | 63.6         |
|    cost_values           | 2.92         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.26         |
|    lagrangian_multiplier | 0.0143       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.54         |
|    n_updates             | 3160         |
|    policy_gradient_loss  | -0.00328     |
|    std                   | 0.804        |
|    value_loss            | 3.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.4903688  |
| rollout/                 |             |
|    ep_len_mean           | 776         |
|    ep_rew_mean           | -350        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 29          |
|    time_elapsed          | 11330       |
|    total_timesteps       | 661504      |
| train/                   |             |
|    approx_kl             | 0.009389564 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.28        |
|    cost_value_loss       | 21.3        |
|    cost_values           | 2.95        |
|    entropy               | -1.94       |
|    entropy_loss          | -1.94       |
|    explained_variance    | -0.0124     |
|    lagrangian_multiplier | 0.0078      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.47        |
|    n_updates             | 3220        |
|    policy_gradient_loss  | -0.00692    |
|    std                   | 0.643       |
|    value_loss            | 18.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.216       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.216       |
| reward                   | -0.3196739  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 27          |
|    time_elapsed          | 9553        |
|    total_timesteps       | 657408      |
| train/                   |             |
|    approx_kl             | 0.004676505 |
|    clip_fraction         | 0.0566      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 1.15        |
|    cost_values           | 1.08        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.815       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.59        |
|    n_updates             | 3200        |
|    policy_gradient_loss  | -0.00548    |
|    std                   | 0.957       |
|    value_loss            | 1.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.318       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.318       |
| reward                   | -0.16363229 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 35          |
|    time_elapsed          | 13002       |
|    total_timesteps       | 673792      |
| train/                   |             |
|    approx_kl             | 0.009718991 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.66        |
|    cost_value_loss       | 37.1        |
|    cost_values           | 1.3         |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | -0.501      |
|    lagrangian_multiplier | 0.00496     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 3280        |
|    policy_gradient_loss  | 0.000792    |
|    std                   | 0.861       |
|    value_loss            | 0.867       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.293        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.293        |
| reward                   | -0.252196    |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 47           |
|    time_elapsed          | 17022        |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0036830963 |
|    clip_fraction         | 0.00732      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.72         |
|    cost_value_loss       | 54.6         |
|    cost_values           | 1.02         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.92         |
|    lagrangian_multiplier | 0.011        |
|    learning_rate         | 0.0003       |
|    loss                  | 5.92         |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.000532    |
|    std                   | 0.802        |
|    value_loss            | 1.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.503       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.503       |
| reward                   | -0.43837532 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -585        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 29          |
|    time_elapsed          | 10972       |
|    total_timesteps       | 661504      |
| train/                   |             |
|    approx_kl             | 0.002530201 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.85        |
|    cost_value_loss       | 27.7        |
|    cost_values           | 0.518       |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.00154     |
|    learning_rate         | 0.0003      |
|    loss                  | 37.2        |
|    n_updates             | 3220        |
|    policy_gradient_loss  | -0.00273    |
|    std                   | 0.838       |
|    value_loss            | 127         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.297       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.297       |
| reward                   | -0.403919   |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 24          |
|    time_elapsed          | 9145        |
|    total_timesteps       | 651264      |
| train/                   |             |
|    approx_kl             | 0.010512875 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.41        |
|    cost_value_loss       | 24.8        |
|    cost_values           | 2.84        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0.0041      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.82        |
|    n_updates             | 3170        |
|    policy_gradient_loss  | -0.00908    |
|    std                   | 0.805       |
|    value_loss            | 0.252       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3282627  |
| rollout/                 |             |
|    ep_len_mean           | 776         |
|    ep_rew_mean           | -352        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 30          |
|    time_elapsed          | 11741       |
|    total_timesteps       | 663552      |
| train/                   |             |
|    approx_kl             | 0.021785576 |
|    clip_fraction         | 0.0842      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.86        |
|    cost_value_loss       | 22.6        |
|    cost_values           | 2.75        |
|    entropy               | -1.93       |
|    entropy_loss          | -1.94       |
|    explained_variance    | 0.588       |
|    lagrangian_multiplier | 0.0128      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.14        |
|    n_updates             | 3230        |
|    policy_gradient_loss  | -0.00568    |
|    std                   | 0.64        |
|    value_loss            | 3.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.138        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.138        |
| reward                   | -0.38645023  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 28           |
|    time_elapsed          | 9918         |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0058301855 |
|    clip_fraction         | 0.0629       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.73         |
|    cost_values           | 1.17         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.75        |
|    explained_variance    | -0.0331      |
|    lagrangian_multiplier | 0.000145     |
|    learning_rate         | 0.0003       |
|    loss                  | 3.01         |
|    n_updates             | 3210         |
|    policy_gradient_loss  | -0.00443     |
|    std                   | 0.953        |
|    value_loss            | 5.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0517       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0517       |
| reward                   | -0.5244563   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -443         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 36           |
|    time_elapsed          | 13394        |
|    total_timesteps       | 675840       |
| train/                   |              |
|    approx_kl             | 0.0072451923 |
|    clip_fraction         | 0.0744       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 3.82         |
|    cost_values           | 1.26         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.412        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.32         |
|    n_updates             | 3290         |
|    policy_gradient_loss  | 0.000381     |
|    std                   | 0.86         |
|    value_loss            | 6.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0963       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0963       |
| reward                   | -0.47351477  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 48           |
|    time_elapsed          | 17417        |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0040125614 |
|    clip_fraction         | 0.0347       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 0.743        |
|    entropy               | -2.39        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.363        |
|    lagrangian_multiplier | 0.00135      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.43         |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.805        |
|    value_loss            | 3.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.352        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.352        |
| reward                   | -0.26412544  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -582         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 30           |
|    time_elapsed          | 11362        |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0034714523 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 2.58         |
|    cost_values           | 0.782        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.923        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.7         |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 0.84         |
|    value_loss            | 64.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.243        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.243        |
| reward                   | -0.36878914  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 25           |
|    time_elapsed          | 9546         |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0056468947 |
|    clip_fraction         | 0.0371       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.81         |
|    cost_value_loss       | 9.57         |
|    cost_values           | 2.86         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.453        |
|    lagrangian_multiplier | 0.00129      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.73         |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.803        |
|    value_loss            | 0.939        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.36        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.36        |
| reward                   | -0.31762677 |
| rollout/                 |             |
|    ep_len_mean           | 773         |
|    ep_rew_mean           | -350        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 31          |
|    time_elapsed          | 12153       |
|    total_timesteps       | 665600      |
| train/                   |             |
|    approx_kl             | 0.007754534 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 2.27        |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 0.382       |
|    lagrangian_multiplier | 0.00607     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.37        |
|    n_updates             | 3240        |
|    policy_gradient_loss  | 0.000786    |
|    std                   | 0.64        |
|    value_loss            | 1.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.17         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.17         |
| reward                   | -0.46501368  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 29           |
|    time_elapsed          | 10280        |
|    total_timesteps       | 661504       |
| train/                   |              |
|    approx_kl             | 0.0032124333 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.95         |
|    cost_value_loss       | 28.5         |
|    cost_values           | 1.04         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.714        |
|    lagrangian_multiplier | 0.000253     |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 3220         |
|    policy_gradient_loss  | -0.00288     |
|    std                   | 0.951        |
|    value_loss            | 3.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.630988    |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -442         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 37           |
|    time_elapsed          | 13785        |
|    total_timesteps       | 677888       |
| train/                   |              |
|    approx_kl             | 0.0060701333 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.67         |
|    cost_value_loss       | 49.3         |
|    cost_values           | 1.36         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.907        |
|    lagrangian_multiplier | 0.00765      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.32         |
|    n_updates             | 3300         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.857        |
|    value_loss            | 1.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0481       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0481       |
| reward                   | -0.5184975   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 49           |
|    time_elapsed          | 17810        |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0031699853 |
|    clip_fraction         | 0.0082       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.89         |
|    cost_value_loss       | 54.5         |
|    cost_values           | 1.31         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | -0.597       |
|    lagrangian_multiplier | 0.00396      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.91         |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.806        |
|    value_loss            | 3.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.146        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.146        |
| reward                   | -0.29601172  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -579         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 31           |
|    time_elapsed          | 11755        |
|    total_timesteps       | 665600       |
| train/                   |              |
|    approx_kl             | 0.0071046883 |
|    clip_fraction         | 0.0687       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 4.26         |
|    cost_values           | 0.98         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.444        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.32         |
|    n_updates             | 3240         |
|    policy_gradient_loss  | -0.00507     |
|    std                   | 0.84         |
|    value_loss            | 1.38         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.175       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.175       |
| reward                   | -0.39283448 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 26          |
|    time_elapsed          | 9944        |
|    total_timesteps       | 655360      |
| train/                   |             |
|    approx_kl             | 0.005467841 |
|    clip_fraction         | 0.0716      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.81        |
|    cost_value_loss       | 55.9        |
|    cost_values           | 2.93        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0.0093      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.89        |
|    n_updates             | 3190        |
|    policy_gradient_loss  | -0.00421    |
|    std                   | 0.797       |
|    value_loss            | 0.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.66        |
| reward                   | -0.7270714  |
| rollout/                 |             |
|    ep_len_mean           | 773         |
|    ep_rew_mean           | -350        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 32          |
|    time_elapsed          | 12573       |
|    total_timesteps       | 667648      |
| train/                   |             |
|    approx_kl             | 0.008650607 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.89        |
|    cost_value_loss       | 15.2        |
|    cost_values           | 2.23        |
|    entropy               | -1.92       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 0.115       |
|    lagrangian_multiplier | 0.00287     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.27        |
|    n_updates             | 3250        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.636       |
|    value_loss            | 10.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.000402    |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.000402    |
| reward                   | -0.38256794 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 30          |
|    time_elapsed          | 10648       |
|    total_timesteps       | 663552      |
| train/                   |             |
|    approx_kl             | 0.00384118  |
|    clip_fraction         | 0.00537     |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 145         |
|    cost_values           | 1.71        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.162       |
|    lagrangian_multiplier | 0.00187     |
|    learning_rate         | 0.0003      |
|    loss                  | 37.6        |
|    n_updates             | 3230        |
|    policy_gradient_loss  | -0.00298    |
|    std                   | 0.951       |
|    value_loss            | 3.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.154        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.154        |
| reward                   | -0.5888301   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 38           |
|    time_elapsed          | 14181        |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0014067347 |
|    clip_fraction         | 0.00083      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.35         |
|    cost_value_loss       | 30.7         |
|    cost_values           | 1.33         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.447        |
|    lagrangian_multiplier | 0.00791      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.24         |
|    n_updates             | 3310         |
|    policy_gradient_loss  | 0.000805     |
|    std                   | 0.856        |
|    value_loss            | 74.9         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/7xavsi5z
-----------------------------------
| avg_speed          | 0.0189     |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.0189     |
| reward             | -0.3163488 |
| rollout/           |            |
|    ep_len_mean     | 985        |
|    ep_rew_mean     | -410       |
| time/              |            |
|    fps             | 5          |
|    iterations      | 1          |
|    time_elapsed    | 395        |
|    total_timesteps | 704512     |
-----------------------------------
-----------------------------------------
| avg_speed                | 0.259      |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 0.259      |
| reward                   | -0.4713488 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -599       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 32         |
|    time_elapsed          | 12152      |
|    total_timesteps       | 667648     |
| train/                   |            |
|    approx_kl             | 0.00801127 |
|    clip_fraction         | 0.0588     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.85       |
|    cost_value_loss       | 19.9       |
|    cost_values           | 1.08       |
|    entropy               | -2.49      |
|    entropy_loss          | -2.49      |
|    explained_variance    | -0.305     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 9.69       |
|    n_updates             | 3250       |
|    policy_gradient_loss  | -0.0048    |
|    std                   | 0.839      |
|    value_loss            | 0.737      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.0154      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0154      |
| reward                   | -0.37655246 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -431        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 27          |
|    time_elapsed          | 10342       |
|    total_timesteps       | 657408      |
| train/                   |             |
|    approx_kl             | 0.008146628 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.88        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0.00276     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 3200        |
|    policy_gradient_loss  | -0.00975    |
|    std                   | 0.789       |
|    value_loss            | 0.105       |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.27         |
| reward                   | -0.2502128   |
| rollout/                 |              |
|    ep_len_mean           | 773          |
|    ep_rew_mean           | -350         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 33           |
|    time_elapsed          | 12991        |
|    total_timesteps       | 669696       |
| train/                   |              |
|    approx_kl             | 0.0043943822 |
|    clip_fraction         | 0.0554       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.64         |
|    cost_value_loss       | 37.6         |
|    cost_values           | 2.47         |
|    entropy               | -1.91        |
|    entropy_loss          | -1.91        |
|    explained_variance    | 0.07         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.5         |
|    n_updates             | 3260         |
|    policy_gradient_loss  | -0.00471     |
|    std                   | 0.634        |
|    value_loss            | 17.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.164       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.164       |
| reward                   | -0.2820342  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 31          |
|    time_elapsed          | 11021       |
|    total_timesteps       | 665600      |
| train/                   |             |
|    approx_kl             | 0.003108223 |
|    clip_fraction         | 0.0125      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.44        |
|    cost_value_loss       | 108         |
|    cost_values           | 1.57        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.755       |
|    lagrangian_multiplier | 0.0113      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.7         |
|    n_updates             | 3240        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.95        |
|    value_loss            | 1.03        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.0723        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0723        |
| reward                   | -0.5548475    |
| rollout/                 |               |
|    ep_len_mean           | 982           |
|    ep_rew_mean           | -452          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 39            |
|    time_elapsed          | 14576         |
|    total_timesteps       | 681984        |
| train/                   |               |
|    approx_kl             | 0.00094954984 |
|    clip_fraction         | 0.00889       |
|    clip_range            | 0.2           |
|    cost_returns          | 5.54          |
|    cost_value_loss       | 67.2          |
|    cost_values           | 1.11          |
|    entropy               | -2.52         |
|    entropy_loss          | -2.52         |
|    explained_variance    | 0.752         |
|    lagrangian_multiplier | 0.0112        |
|    learning_rate         | 0.0003        |
|    loss                  | 7.94          |
|    n_updates             | 3320          |
|    policy_gradient_loss  | -0.00231      |
|    std                   | 0.856         |
|    value_loss            | 89.6          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.127        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.127        |
| reward                   | -0.1573126   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 2            |
|    time_elapsed          | 791          |
|    total_timesteps       | 706560       |
| train/                   |              |
|    approx_kl             | 0.0061161304 |
|    clip_fraction         | 0.0444       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.54         |
|    cost_value_loss       | 17.8         |
|    cost_values           | 1.13         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.527        |
|    lagrangian_multiplier | 0.00089      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.13         |
|    n_updates             | 3440         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 0.806        |
|    value_loss            | 1.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0865      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0865      |
| reward                   | -0.48602638 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -615        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 33          |
|    time_elapsed          | 12556       |
|    total_timesteps       | 669696      |
| train/                   |             |
|    approx_kl             | 0.004052898 |
|    clip_fraction         | 0.00889     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.41        |
|    cost_value_loss       | 24.5        |
|    cost_values           | 0.667       |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0.000443    |
|    learning_rate         | 0.0003      |
|    loss                  | 60.5        |
|    n_updates             | 3260        |
|    policy_gradient_loss  | -0.000575   |
|    std                   | 0.839       |
|    value_loss            | 124         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0582      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0582      |
| reward                   | -0.48542747 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 28          |
|    time_elapsed          | 10742       |
|    total_timesteps       | 659456      |
| train/                   |             |
|    approx_kl             | 0.011918893 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 2.69        |
|    cost_values           | 2.8         |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.814       |
|    lagrangian_multiplier | 0.000102    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.46        |
|    n_updates             | 3210        |
|    policy_gradient_loss  | -0.0089     |
|    std                   | 0.789       |
|    value_loss            | 0.272       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0101       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0101       |
| reward                   | -0.25722152  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -432         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 32           |
|    time_elapsed          | 11394        |
|    total_timesteps       | 667648       |
| train/                   |              |
|    approx_kl             | 0.0020782822 |
|    clip_fraction         | 0.0192       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.27         |
|    cost_value_loss       | 75.5         |
|    cost_values           | 1.57         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.496        |
|    lagrangian_multiplier | 0.00871      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.72         |
|    n_updates             | 3250         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 0.946        |
|    value_loss            | 1.24         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.17618532 |
| rollout/                 |             |
|    ep_len_mean           | 761         |
|    ep_rew_mean           | -342        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 34          |
|    time_elapsed          | 13410       |
|    total_timesteps       | 671744      |
| train/                   |             |
|    approx_kl             | 0.008444265 |
|    clip_fraction         | 0.0609      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.66        |
|    cost_value_loss       | 17.4        |
|    cost_values           | 2.85        |
|    entropy               | -1.91       |
|    entropy_loss          | -1.91       |
|    explained_variance    | 0.157       |
|    lagrangian_multiplier | 0.00617     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.8         |
|    n_updates             | 3270        |
|    policy_gradient_loss  | -0.00586    |
|    std                   | 0.633       |
|    value_loss            | 23.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.151        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.151        |
| reward                   | -0.57881415  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 40           |
|    time_elapsed          | 14974        |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0041777464 |
|    clip_fraction         | 0.00981      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.63         |
|    cost_value_loss       | 84           |
|    cost_values           | 1.16         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.806        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.4         |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.856        |
|    value_loss            | 2.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0525       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0525       |
| reward                   | -0.37386093  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 3            |
|    time_elapsed          | 1195         |
|    total_timesteps       | 708608       |
| train/                   |              |
|    approx_kl             | 0.0053157196 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.8          |
|    cost_value_loss       | 70.5         |
|    cost_values           | 1.81         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.783        |
|    lagrangian_multiplier | 0.00536      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 3450         |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 0.805        |
|    value_loss            | 3.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0163       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0163       |
| reward                   | -0.25921455  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -651         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 34           |
|    time_elapsed          | 12955        |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0035164452 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.85         |
|    cost_value_loss       | 47.5         |
|    cost_values           | 0.559        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0.00797      |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.839        |
|    value_loss            | 161          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0126       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0126       |
| reward                   | -0.33842033  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 29           |
|    time_elapsed          | 11147        |
|    total_timesteps       | 661504       |
| train/                   |              |
|    approx_kl             | 0.0023842524 |
|    clip_fraction         | 0.14         |
|    clip_range            | 0.2          |
|    cost_returns          | 12.3         |
|    cost_value_loss       | 136          |
|    cost_values           | 2.94         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.703        |
|    lagrangian_multiplier | 0.0196       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.78         |
|    n_updates             | 3220         |
|    policy_gradient_loss  | 0.00385      |
|    std                   | 0.792        |
|    value_loss            | 0.723        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0841      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0841      |
| reward                   | -0.20959955 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 33          |
|    time_elapsed          | 11766       |
|    total_timesteps       | 669696      |
| train/                   |             |
|    approx_kl             | 0.006401903 |
|    clip_fraction         | 0.0263      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.7         |
|    cost_value_loss       | 105         |
|    cost_values           | 1.44        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.831       |
|    lagrangian_multiplier | 0.0104      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 3260        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.948       |
|    value_loss            | 1.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.06        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.06        |
| reward                   | -0.30487007 |
| rollout/                 |             |
|    ep_len_mean           | 754         |
|    ep_rew_mean           | -340        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 35          |
|    time_elapsed          | 13833       |
|    total_timesteps       | 673792      |
| train/                   |             |
|    approx_kl             | 0.006188112 |
|    clip_fraction         | 0.0448      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.2         |
|    cost_value_loss       | 17.2        |
|    cost_values           | 2.6         |
|    entropy               | -1.9        |
|    entropy_loss          | -1.9        |
|    explained_variance    | 0.281       |
|    lagrangian_multiplier | 0.00403     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.54        |
|    n_updates             | 3280        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.632       |
|    value_loss            | 22.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.274        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.274        |
| reward                   | -0.55504954  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 41           |
|    time_elapsed          | 15368        |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0025019376 |
|    clip_fraction         | 0.00425      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.87         |
|    cost_value_loss       | 79.1         |
|    cost_values           | 1.4          |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.881        |
|    lagrangian_multiplier | 0.0109       |
|    learning_rate         | 0.0003       |
|    loss                  | 8            |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.854        |
|    value_loss            | 2.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.131       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.131       |
| reward                   | -0.44861913 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 4           |
|    time_elapsed          | 1593        |
|    total_timesteps       | 710656      |
| train/                   |             |
|    approx_kl             | 0.004310115 |
|    clip_fraction         | 0.0242      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.76        |
|    cost_value_loss       | 109         |
|    cost_values           | 2.11        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0.0116      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.81        |
|    n_updates             | 3460        |
|    policy_gradient_loss  | -0.00273    |
|    std                   | 0.803       |
|    value_loss            | 0.737       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0823       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0823       |
| reward                   | -0.26977664  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -688         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 35           |
|    time_elapsed          | 13347        |
|    total_timesteps       | 673792       |
| train/                   |              |
|    approx_kl             | 0.0014623274 |
|    clip_fraction         | 0.0173       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 25.6         |
|    cost_values           | 0.142        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0.00206      |
|    learning_rate         | 0.0003       |
|    loss                  | 73.3         |
|    n_updates             | 3280         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 0.84         |
|    value_loss            | 311          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.352       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.352       |
| reward                   | -0.23353946 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 30          |
|    time_elapsed          | 11549       |
|    total_timesteps       | 663552      |
| train/                   |             |
|    approx_kl             | 0.004662725 |
|    clip_fraction         | 0.0311      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.61        |
|    cost_value_loss       | 92.7        |
|    cost_values           | 2.88        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.676       |
|    lagrangian_multiplier | 0.0111      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.37        |
|    n_updates             | 3230        |
|    policy_gradient_loss  | -0.0023     |
|    std                   | 0.79        |
|    value_loss            | 1.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.036        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.036        |
| reward                   | -0.46007764  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 34           |
|    time_elapsed          | 12140        |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0068979547 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 12.4         |
|    cost_value_loss       | 168          |
|    cost_values           | 1.72         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.852        |
|    lagrangian_multiplier | 0.0199       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.15         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.00559     |
|    std                   | 0.945        |
|    value_loss            | 1.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.36188737  |
| rollout/                 |              |
|    ep_len_mean           | 743          |
|    ep_rew_mean           | -334         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 36           |
|    time_elapsed          | 14260        |
|    total_timesteps       | 675840       |
| train/                   |              |
|    approx_kl             | 0.0087078875 |
|    clip_fraction         | 0.138        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 2.26         |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0.195        |
|    lagrangian_multiplier | 0.00503      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.38         |
|    n_updates             | 3290         |
|    policy_gradient_loss  | -0.00667     |
|    std                   | 0.629        |
|    value_loss            | 9.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.131        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.131        |
| reward                   | -0.4987187   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -463         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 42           |
|    time_elapsed          | 15766        |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0013985129 |
|    clip_fraction         | 0.00298      |
|    clip_range            | 0.2          |
|    cost_returns          | 6            |
|    cost_value_loss       | 66.9         |
|    cost_values           | 1.38         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.7          |
|    lagrangian_multiplier | 0.0066       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.97         |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.854        |
|    value_loss            | 0.981        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0995      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0995      |
| reward                   | -0.56050915 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 5           |
|    time_elapsed          | 1995        |
|    total_timesteps       | 712704      |
| train/                   |             |
|    approx_kl             | 0.005043665 |
|    clip_fraction         | 0.0404      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.83        |
|    cost_value_loss       | 66.2        |
|    cost_values           | 1.8         |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0.00325     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.8        |
|    n_updates             | 3470        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.803       |
|    value_loss            | 1.18        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.27         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.27         |
| reward                   | -0.36486444  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 36           |
|    time_elapsed          | 13746        |
|    total_timesteps       | 675840       |
| train/                   |              |
|    approx_kl             | 0.0024367617 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.57         |
|    cost_value_loss       | 19.1         |
|    cost_values           | 0.155        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0.00273      |
|    learning_rate         | 0.0003       |
|    loss                  | 51           |
|    n_updates             | 3290         |
|    policy_gradient_loss  | -0.00242     |
|    std                   | 0.84         |
|    value_loss            | 258          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0993       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0993       |
| reward                   | -0.31388825  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 35           |
|    time_elapsed          | 12515        |
|    total_timesteps       | 673792       |
| train/                   |              |
|    approx_kl             | 0.0038728584 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.29         |
|    cost_value_loss       | 55.2         |
|    cost_values           | 1.67         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.584        |
|    lagrangian_multiplier | 0.00766      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.85         |
|    n_updates             | 3280         |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.942        |
|    value_loss            | 0.956        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.101        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.101        |
| reward                   | -0.61412007  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 31           |
|    time_elapsed          | 11955        |
|    total_timesteps       | 665600       |
| train/                   |              |
|    approx_kl             | 0.0027217853 |
|    clip_fraction         | 0.00332      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.19         |
|    cost_value_loss       | 23.7         |
|    cost_values           | 2.55         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.924        |
|    lagrangian_multiplier | 0.00144      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.18         |
|    n_updates             | 3240         |
|    policy_gradient_loss  | -0.00044     |
|    std                   | 0.789        |
|    value_loss            | 3.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.419185   |
| rollout/                 |             |
|    ep_len_mean           | 732         |
|    ep_rew_mean           | -327        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 37          |
|    time_elapsed          | 14684       |
|    total_timesteps       | 677888      |
| train/                   |             |
|    approx_kl             | 0.008390007 |
|    clip_fraction         | 0.0907      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 14.8        |
|    cost_values           | 2.24        |
|    entropy               | -1.89       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0.413       |
|    lagrangian_multiplier | 0.00634     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.03        |
|    n_updates             | 3300        |
|    policy_gradient_loss  | -0.00151    |
|    std                   | 0.628       |
|    value_loss            | 15.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.158        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.158        |
| reward                   | -0.4753955   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 43           |
|    time_elapsed          | 16166        |
|    total_timesteps       | 690176       |
| train/                   |              |
|    approx_kl             | 0.0040211026 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 4.37         |
|    cost_values           | 0.81         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22.2         |
|    n_updates             | 3360         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 0.855        |
|    value_loss            | 44.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.138       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.138       |
| reward                   | -0.45652673 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -685        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 37          |
|    time_elapsed          | 14148       |
|    total_timesteps       | 677888      |
| train/                   |             |
|    approx_kl             | 0.004083772 |
|    clip_fraction         | 0.0186      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.32        |
|    cost_value_loss       | 59.3        |
|    cost_values           | 1.12        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.211       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.5        |
|    n_updates             | 3300        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.84        |
|    value_loss            | 5.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.56416935  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 6            |
|    time_elapsed          | 2398         |
|    total_timesteps       | 714752       |
| train/                   |              |
|    approx_kl             | 0.0045800237 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 6.39         |
|    cost_values           | 0.916        |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.755        |
|    lagrangian_multiplier | 0.000929     |
|    learning_rate         | 0.0003       |
|    loss                  | 3.93         |
|    n_updates             | 3480         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.803        |
|    value_loss            | 4.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.5797104   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 36           |
|    time_elapsed          | 12889        |
|    total_timesteps       | 675840       |
| train/                   |              |
|    approx_kl             | 0.0064903274 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.3         |
|    cost_value_loss       | 111          |
|    cost_values           | 2.12         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.89         |
|    lagrangian_multiplier | 0.0155       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.72         |
|    n_updates             | 3290         |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 0.942        |
|    value_loss            | 1.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0186      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0186      |
| reward                   | -0.576829   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 32          |
|    time_elapsed          | 12360       |
|    total_timesteps       | 667648      |
| train/                   |             |
|    approx_kl             | 0.010065652 |
|    clip_fraction         | 0.071       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.8         |
|    cost_value_loss       | 8.29        |
|    cost_values           | 2.31        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0.000121    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.27        |
|    n_updates             | 3250        |
|    policy_gradient_loss  | -0.00374    |
|    std                   | 0.79        |
|    value_loss            | 1.1         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.48919407  |
| rollout/                 |              |
|    ep_len_mean           | 735          |
|    ep_rew_mean           | -329         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 38           |
|    time_elapsed          | 15111        |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0046677724 |
|    clip_fraction         | 0.0679       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.12         |
|    cost_value_loss       | 18.5         |
|    cost_values           | 2.36         |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.319        |
|    lagrangian_multiplier | 0.00428      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.18         |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.00452     |
|    std                   | 0.626        |
|    value_loss            | 20.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -1.183584    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 44           |
|    time_elapsed          | 16567        |
|    total_timesteps       | 692224       |
| train/                   |              |
|    approx_kl             | 0.0026660997 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.05         |
|    cost_value_loss       | 71.6         |
|    cost_values           | 0.588        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.1         |
|    n_updates             | 3370         |
|    policy_gradient_loss  | -0.00124     |
|    std                   | 0.855        |
|    value_loss            | 62.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.256        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.256        |
| reward                   | -0.30636346  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 7            |
|    time_elapsed          | 2795         |
|    total_timesteps       | 716800       |
| train/                   |              |
|    approx_kl             | 0.0025536912 |
|    clip_fraction         | 0.00586      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.79         |
|    cost_value_loss       | 65.4         |
|    cost_values           | 0.818        |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.896        |
|    lagrangian_multiplier | 0.00777      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 3490         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.803        |
|    value_loss            | 1.95         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00381     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00381     |
| reward                   | -0.3195925  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -686        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 38          |
|    time_elapsed          | 14551       |
|    total_timesteps       | 679936      |
| train/                   |             |
|    approx_kl             | 0.006693758 |
|    clip_fraction         | 0.0365      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 92.7        |
|    cost_values           | 1.56        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | -0.102      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 46.2        |
|    n_updates             | 3310        |
|    policy_gradient_loss  | -0.00486    |
|    std                   | 0.839       |
|    value_loss            | 1.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.349       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.349       |
| reward                   | -0.40614685 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 37          |
|    time_elapsed          | 13261       |
|    total_timesteps       | 677888      |
| train/                   |             |
|    approx_kl             | 0.006733141 |
|    clip_fraction         | 0.0366      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 33          |
|    cost_values           | 2.01        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0.00103     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 3300        |
|    policy_gradient_loss  | -0.00298    |
|    std                   | 0.944       |
|    value_loss            | 2.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.513        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.513        |
| reward                   | -0.356538    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 33           |
|    time_elapsed          | 12763        |
|    total_timesteps       | 669696       |
| train/                   |              |
|    approx_kl             | 0.0005431827 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 9.53         |
|    cost_value_loss       | 105          |
|    cost_values           | 1.86         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 0.0247       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.36         |
|    n_updates             | 3260         |
|    policy_gradient_loss  | -0.000481    |
|    std                   | 0.79         |
|    value_loss            | 7.85         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0584      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0584      |
| reward                   | -0.272774   |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -491        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 45          |
|    time_elapsed          | 16967       |
|    total_timesteps       | 694272      |
| train/                   |             |
|    approx_kl             | 0.006785103 |
|    clip_fraction         | 0.0182      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.82        |
|    cost_value_loss       | 47.2        |
|    cost_values           | 0.683       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0.00639     |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 3380        |
|    policy_gradient_loss  | -0.00274    |
|    std                   | 0.856       |
|    value_loss            | 32.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.55        |
| reward                   | -0.31068608 |
| rollout/                 |             |
|    ep_len_mean           | 735         |
|    ep_rew_mean           | -329        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 39          |
|    time_elapsed          | 15534       |
|    total_timesteps       | 681984      |
| train/                   |             |
|    approx_kl             | 0.016533818 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.72        |
|    cost_value_loss       | 21.8        |
|    cost_values           | 2.53        |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.00905     |
|    lagrangian_multiplier | 0.0052      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.2         |
|    n_updates             | 3320        |
|    policy_gradient_loss  | -0.00663    |
|    std                   | 0.624       |
|    value_loss            | 9.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0631       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0631       |
| reward                   | -0.26508883  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 8            |
|    time_elapsed          | 3197         |
|    total_timesteps       | 718848       |
| train/                   |              |
|    approx_kl             | 0.0020323424 |
|    clip_fraction         | 0.00537      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.74         |
|    cost_value_loss       | 133          |
|    cost_values           | 1.32         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.854        |
|    lagrangian_multiplier | 0.018        |
|    learning_rate         | 0.0003       |
|    loss                  | 8.04         |
|    n_updates             | 3500         |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 0.803        |
|    value_loss            | 1.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.414728    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -684         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 39           |
|    time_elapsed          | 14950        |
|    total_timesteps       | 681984       |
| train/                   |              |
|    approx_kl             | 0.0030735848 |
|    clip_fraction         | 0.00244      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.93         |
|    cost_value_loss       | 102          |
|    cost_values           | 2.1          |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.743        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47.3         |
|    n_updates             | 3320         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.839        |
|    value_loss            | 1.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.272       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.272       |
| reward                   | -0.2599882  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 38          |
|    time_elapsed          | 13637       |
|    total_timesteps       | 679936      |
| train/                   |             |
|    approx_kl             | 0.005527299 |
|    clip_fraction         | 0.0168      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.73        |
|    cost_value_loss       | 40.7        |
|    cost_values           | 1.89        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.00282     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.42        |
|    n_updates             | 3310        |
|    policy_gradient_loss  | -0.00474    |
|    std                   | 0.943       |
|    value_loss            | 1           |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0797       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0797       |
| reward                   | -0.56542283  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 34           |
|    time_elapsed          | 13165        |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0021337946 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 9.64         |
|    cost_value_loss       | 104          |
|    cost_values           | 1.6          |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.797        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 50.9         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.79         |
|    value_loss            | 2.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.086        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.086        |
| reward                   | -0.34910065  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -488         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 46           |
|    time_elapsed          | 17373        |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0046051173 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.421        |
|    cost_value_loss       | 0.177        |
|    cost_values           | 0.395        |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 37.6         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | -0.00382     |
|    std                   | 0.857        |
|    value_loss            | 91.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.14        |
| reward                   | -0.5476276  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 9           |
|    time_elapsed          | 3602        |
|    total_timesteps       | 720896      |
| train/                   |             |
|    approx_kl             | 0.006354519 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.26        |
|    cost_value_loss       | 86          |
|    cost_values           | 1.64        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.748       |
|    lagrangian_multiplier | 0.0134      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.12        |
|    n_updates             | 3510        |
|    policy_gradient_loss  | -0.00326    |
|    std                   | 0.803       |
|    value_loss            | 1.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -2.4445462   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -701         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 40           |
|    time_elapsed          | 15355        |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0005136358 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 13.5         |
|    cost_value_loss       | 174          |
|    cost_values           | 1.97         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0.186        |
|    learning_rate         | 0.0003       |
|    loss                  | 2.73         |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.000338    |
|    std                   | 0.839        |
|    value_loss            | 20.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.85         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.85         |
| reward                   | -0.23328829  |
| rollout/                 |              |
|    ep_len_mean           | 735          |
|    ep_rew_mean           | -329         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 40           |
|    time_elapsed          | 15964        |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0069140564 |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.95         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 2.22         |
|    entropy               | -1.87        |
|    entropy_loss          | -1.88        |
|    explained_variance    | 0.237        |
|    lagrangian_multiplier | 0.00461      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.86         |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.622        |
|    value_loss            | 29.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0803      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0803      |
| reward                   | -0.4070112  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 39          |
|    time_elapsed          | 14010       |
|    total_timesteps       | 681984      |
| train/                   |             |
|    approx_kl             | 0.004265394 |
|    clip_fraction         | 0.0707      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.54        |
|    cost_value_loss       | 0.0857      |
|    cost_values           | 1.75        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0922      |
|    n_updates             | 3320        |
|    policy_gradient_loss  | -0.00303    |
|    std                   | 0.942       |
|    value_loss            | 0.327       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.387       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.387       |
| reward                   | -0.19755559 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 35          |
|    time_elapsed          | 13567       |
|    total_timesteps       | 673792      |
| train/                   |             |
|    approx_kl             | 0.005257287 |
|    clip_fraction         | 0.0143      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.08        |
|    cost_value_loss       | 90.3        |
|    cost_values           | 1.92        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 41.8        |
|    n_updates             | 3280        |
|    policy_gradient_loss  | -0.00341    |
|    std                   | 0.79        |
|    value_loss            | 1.75        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.26         |
| reward                   | -0.16798578  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 47           |
|    time_elapsed          | 17782        |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0013138137 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 10.7         |
|    cost_value_loss       | 152          |
|    cost_values           | 1.04         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.876        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 69.5         |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.857        |
|    value_loss            | 2.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0731       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0731       |
| reward                   | -0.3101088   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 10           |
|    time_elapsed          | 4008         |
|    total_timesteps       | 722944       |
| train/                   |              |
|    approx_kl             | 0.0032101898 |
|    clip_fraction         | 0.00527      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.5          |
|    cost_value_loss       | 47.1         |
|    cost_values           | 1.46         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 0.00167      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 3520         |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 0.803        |
|    value_loss            | 4.16         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.231        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.231        |
| reward                   | -0.26460984  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 41           |
|    time_elapsed          | 15760        |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0023036865 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.47         |
|    cost_value_loss       | 17.3         |
|    cost_values           | 0.214        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 158          |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.839        |
|    value_loss            | 321          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.135       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.135       |
| reward                   | -0.41083306 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 40          |
|    time_elapsed          | 14385       |
|    total_timesteps       | 684032      |
| train/                   |             |
|    approx_kl             | 0.006672767 |
|    clip_fraction         | 0.0617      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.45        |
|    cost_value_loss       | 0.877       |
|    cost_values           | 1.24        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0.00022     |
|    learning_rate         | 0.0003      |
|    loss                  | 0.722       |
|    n_updates             | 3330        |
|    policy_gradient_loss  | -0.000818   |
|    std                   | 0.941       |
|    value_loss            | 1.56        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.95       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.95       |
| reward                   | -0.3553944 |
| rollout/                 |            |
|    ep_len_mean           | 727        |
|    ep_rew_mean           | -324       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 41         |
|    time_elapsed          | 16399      |
|    total_timesteps       | 686080     |
| train/                   |            |
|    approx_kl             | 0.00474321 |
|    clip_fraction         | 0.0646     |
|    clip_range            | 0.2        |
|    cost_returns          | 6.69       |
|    cost_value_loss       | 22.7       |
|    cost_values           | 2.18       |
|    entropy               | -1.87      |
|    entropy_loss          | -1.87      |
|    explained_variance    | 0.107      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 18.1       |
|    n_updates             | 3340       |
|    policy_gradient_loss  | -0.00514   |
|    std                   | 0.622      |
|    value_loss            | 14.7       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.40525433  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 36           |
|    time_elapsed          | 13973        |
|    total_timesteps       | 675840       |
| train/                   |              |
|    approx_kl             | 0.0011095777 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 7.51         |
|    cost_value_loss       | 69.3         |
|    cost_values           | 2.26         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.953        |
|    lagrangian_multiplier | 0.00278      |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 3290         |
|    policy_gradient_loss  | -0.000811    |
|    std                   | 0.79         |
|    value_loss            | 1.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.21         |
| reward                   | -0.58054495  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -479         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 48           |
|    time_elapsed          | 18188        |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0044325343 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.66         |
|    cost_value_loss       | 37.2         |
|    cost_values           | 1.26         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0.00378      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.55         |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.856        |
|    value_loss            | 1.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.137        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.137        |
| reward                   | -0.41540873  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 41           |
|    time_elapsed          | 14766        |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0076904465 |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.71         |
|    cost_value_loss       | 54.6         |
|    cost_values           | 1.4          |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0.0024       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.00919     |
|    std                   | 0.941        |
|    value_loss            | 0.335        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.24        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.24        |
| reward                   | -0.40026107 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -735        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 42          |
|    time_elapsed          | 16165       |
|    total_timesteps       | 688128      |
| train/                   |             |
|    approx_kl             | 0.002167216 |
|    clip_fraction         | 0.0241      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.41        |
|    cost_value_loss       | 112         |
|    cost_values           | 0.73        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0.012       |
|    learning_rate         | 0.0003      |
|    loss                  | 17          |
|    n_updates             | 3350        |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 0.84        |
|    value_loss            | 134         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0632      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0632      |
| reward                   | -0.34184885 |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 11          |
|    time_elapsed          | 4417        |
|    total_timesteps       | 724992      |
| train/                   |             |
|    approx_kl             | 0.0030726   |
|    clip_fraction         | 0.0115      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.42        |
|    cost_value_loss       | 87.9        |
|    cost_values           | 1.82        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.00132     |
|    learning_rate         | 0.0003      |
|    loss                  | 27.1        |
|    n_updates             | 3530        |
|    policy_gradient_loss  | -0.00217    |
|    std                   | 0.802       |
|    value_loss            | 1.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.9177213  |
| rollout/                 |             |
|    ep_len_mean           | 704         |
|    ep_rew_mean           | -311        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 42          |
|    time_elapsed          | 16832       |
|    total_timesteps       | 688128      |
| train/                   |             |
|    approx_kl             | 0.008297797 |
|    clip_fraction         | 0.0732      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.23        |
|    entropy               | -1.86       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0.366       |
|    lagrangian_multiplier | 0.00674     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.76        |
|    n_updates             | 3350        |
|    policy_gradient_loss  | -0.00555    |
|    std                   | 0.62        |
|    value_loss            | 10.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.244        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.244        |
| reward                   | -0.2839001   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 37           |
|    time_elapsed          | 14377        |
|    total_timesteps       | 677888       |
| train/                   |              |
|    approx_kl             | 0.0017588737 |
|    clip_fraction         | 0.000781     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.66         |
|    cost_value_loss       | 47.4         |
|    cost_values           | 2.6          |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.93         |
|    lagrangian_multiplier | 0.00662      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.55         |
|    n_updates             | 3300         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.79         |
|    value_loss            | 1.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0241      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0241      |
| reward                   | -0.5372709  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 42          |
|    time_elapsed          | 15151       |
|    total_timesteps       | 688128      |
| train/                   |             |
|    approx_kl             | 0.005688347 |
|    clip_fraction         | 0.0518      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.18        |
|    cost_value_loss       | 73.2        |
|    cost_values           | 1.98        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.548       |
|    lagrangian_multiplier | 0.00465     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 3350        |
|    policy_gradient_loss  | -0.00566    |
|    std                   | 0.94        |
|    value_loss            | 3.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.294        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.294        |
| reward                   | -0.33571562  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -482         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 49           |
|    time_elapsed          | 18591        |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0023934036 |
|    clip_fraction         | 0.00659      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.78         |
|    cost_value_loss       | 64.6         |
|    cost_values           | 1.68         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.927        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.5         |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -0.000146    |
|    std                   | 0.855        |
|    value_loss            | 3.58         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.5294409  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -738        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 43          |
|    time_elapsed          | 16572       |
|    total_timesteps       | 690176      |
| train/                   |             |
|    approx_kl             | 0.005056948 |
|    clip_fraction         | 0.0286      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.63        |
|    cost_value_loss       | 64.3        |
|    cost_values           | 0.588       |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0.00696     |
|    learning_rate         | 0.0003      |
|    loss                  | 23.1        |
|    n_updates             | 3360        |
|    policy_gradient_loss  | -0.00286    |
|    std                   | 0.841       |
|    value_loss            | 161         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.33        |
| reward                   | -0.38038734 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 12          |
|    time_elapsed          | 4825        |
|    total_timesteps       | 727040      |
| train/                   |             |
|    approx_kl             | 0.004283513 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 0.0918      |
|    cost_values           | 1.74        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 9.34e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 0.189       |
|    n_updates             | 3540        |
|    policy_gradient_loss  | -0.0024     |
|    std                   | 0.803       |
|    value_loss            | 1.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.39         |
| reward                   | -0.5250574   |
| rollout/                 |              |
|    ep_len_mean           | 714          |
|    ep_rew_mean           | -318         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 43           |
|    time_elapsed          | 17270        |
|    total_timesteps       | 690176       |
| train/                   |              |
|    approx_kl             | 0.0043077837 |
|    clip_fraction         | 0.108        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.3          |
|    cost_value_loss       | 17.1         |
|    cost_values           | 1.89         |
|    entropy               | -1.86        |
|    entropy_loss          | -1.86        |
|    explained_variance    | 0.43         |
|    lagrangian_multiplier | 0.00295      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.05         |
|    n_updates             | 3360         |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 0.619        |
|    value_loss            | 30.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.95         |
| reward                   | -0.7379719   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 38           |
|    time_elapsed          | 14778        |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0021909918 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.84         |
|    cost_value_loss       | 64           |
|    cost_values           | 2.23         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0.154        |
|    learning_rate         | 0.0003       |
|    loss                  | 2.58         |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.789        |
|    value_loss            | 7.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0578       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0578       |
| reward                   | -0.46688345  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 43           |
|    time_elapsed          | 15529        |
|    total_timesteps       | 690176       |
| train/                   |              |
|    approx_kl             | 0.0039028223 |
|    clip_fraction         | 0.00444      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.24         |
|    cost_value_loss       | 56           |
|    cost_values           | 1.6          |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.823        |
|    lagrangian_multiplier | 0.00187      |
|    learning_rate         | 0.0003       |
|    loss                  | 17.5         |
|    n_updates             | 3360         |
|    policy_gradient_loss  | -0.000366    |
|    std                   | 0.939        |
|    value_loss            | 7.66         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/uhktx3ql
------------------------------------
| avg_speed          | 0.121       |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.121       |
| reward             | -0.57604945 |
| rollout/           |             |
|    ep_len_mean     | 980         |
|    ep_rew_mean     | -478        |
| time/              |             |
|    fps             | 5           |
|    iterations      | 1           |
|    time_elapsed    | 406         |
|    total_timesteps | 704512      |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.233898   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -741        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 44          |
|    time_elapsed          | 16977       |
|    total_timesteps       | 692224      |
| train/                   |             |
|    approx_kl             | 0.005774962 |
|    clip_fraction         | 0.04        |
|    clip_range            | 0.2         |
|    cost_returns          | 9.16        |
|    cost_value_loss       | 104         |
|    cost_values           | 0.82        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.0122      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.81        |
|    n_updates             | 3370        |
|    policy_gradient_loss  | -0.00749    |
|    std                   | 0.841       |
|    value_loss            | 36.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.108        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.108        |
| reward                   | -0.355055    |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 13           |
|    time_elapsed          | 5235         |
|    total_timesteps       | 729088       |
| train/                   |              |
|    approx_kl             | 0.0046236673 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.01         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 1.47         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.765        |
|    lagrangian_multiplier | 0.000296     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.48         |
|    n_updates             | 3550         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.803        |
|    value_loss            | 5.83         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.55462295 |
| rollout/                 |             |
|    ep_len_mean           | 716         |
|    ep_rew_mean           | -320        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 44          |
|    time_elapsed          | 17710       |
|    total_timesteps       | 692224      |
| train/                   |             |
|    approx_kl             | 0.008364346 |
|    clip_fraction         | 0.0647      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.83        |
|    cost_value_loss       | 22.4        |
|    cost_values           | 1.59        |
|    entropy               | -1.86       |
|    entropy_loss          | -1.86       |
|    explained_variance    | 0.682       |
|    lagrangian_multiplier | 0.00695     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.42        |
|    n_updates             | 3370        |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 0.619       |
|    value_loss            | 12.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.368        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.368        |
| reward                   | -0.22777432  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 39           |
|    time_elapsed          | 15187        |
|    total_timesteps       | 681984       |
| train/                   |              |
|    approx_kl             | 0.0012283389 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.43         |
|    cost_value_loss       | 61.5         |
|    cost_values           | 2.02         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.8         |
|    n_updates             | 3320         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.789        |
|    value_loss            | 1.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0282       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0282       |
| reward                   | -0.40606     |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 44           |
|    time_elapsed          | 15918        |
|    total_timesteps       | 692224       |
| train/                   |              |
|    approx_kl             | 0.0073482734 |
|    clip_fraction         | 0.0897       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.96         |
|    cost_value_loss       | 84.7         |
|    cost_values           | 1.42         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0.00773      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 3370         |
|    policy_gradient_loss  | -0.0114      |
|    std                   | 0.937        |
|    value_loss            | 0.619        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0368      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0368      |
| reward                   | -0.25568163 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -480        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 2           |
|    time_elapsed          | 816         |
|    total_timesteps       | 706560      |
| train/                   |             |
|    approx_kl             | 0.004679659 |
|    clip_fraction         | 0.0506      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.26        |
|    cost_value_loss       | 69          |
|    cost_values           | 1.5         |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0.0069      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.2         |
|    n_updates             | 3440        |
|    policy_gradient_loss  | -0.004      |
|    std                   | 0.854       |
|    value_loss            | 1.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.231        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.231        |
| reward                   | -0.5063359   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 45           |
|    time_elapsed          | 17383        |
|    total_timesteps       | 694272       |
| train/                   |              |
|    approx_kl             | 0.0031292657 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.84         |
|    cost_value_loss       | 117          |
|    cost_values           | 0.691        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0.00876      |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 3380         |
|    policy_gradient_loss  | -0.00338     |
|    std                   | 0.841        |
|    value_loss            | 113          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0579       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0579       |
| reward                   | -0.39926118  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 14           |
|    time_elapsed          | 5646         |
|    total_timesteps       | 731136       |
| train/                   |              |
|    approx_kl             | 0.0017118333 |
|    clip_fraction         | 0.00151      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.27         |
|    cost_value_loss       | 116          |
|    cost_values           | 1.86         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.871        |
|    lagrangian_multiplier | 0.000545     |
|    learning_rate         | 0.0003       |
|    loss                  | 45.7         |
|    n_updates             | 3560         |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.803        |
|    value_loss            | 1.41         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.35935795 |
| rollout/                 |             |
|    ep_len_mean           | 716         |
|    ep_rew_mean           | -320        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 45          |
|    time_elapsed          | 18144       |
|    total_timesteps       | 694272      |
| train/                   |             |
|    approx_kl             | 0.00930478  |
|    clip_fraction         | 0.0771      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 21.7        |
|    cost_values           | 1.53        |
|    entropy               | -1.86       |
|    entropy_loss          | -1.86       |
|    explained_variance    | 0.0949      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 3380        |
|    policy_gradient_loss  | -0.00925    |
|    std                   | 0.618       |
|    value_loss            | 2.16        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.198         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.198         |
| reward                   | -0.3238278    |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -430          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 40            |
|    time_elapsed          | 15597         |
|    total_timesteps       | 684032        |
| train/                   |               |
|    approx_kl             | 0.00062320725 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 7.05          |
|    cost_value_loss       | 68.1          |
|    cost_values           | 1.9           |
|    entropy               | -2.36         |
|    entropy_loss          | -2.36         |
|    explained_variance    | 0.978         |
|    lagrangian_multiplier | 0.0252        |
|    learning_rate         | 0.0003        |
|    loss                  | 4.6           |
|    n_updates             | 3330          |
|    policy_gradient_loss  | -0.00123      |
|    std                   | 0.789         |
|    value_loss            | 4             |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0515       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0515       |
| reward                   | -0.3497832   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 45           |
|    time_elapsed          | 16307        |
|    total_timesteps       | 694272       |
| train/                   |              |
|    approx_kl             | 0.0012118807 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 189          |
|    cost_values           | 1.9          |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.872        |
|    lagrangian_multiplier | 0.00337      |
|    learning_rate         | 0.0003       |
|    loss                  | 36.5         |
|    n_updates             | 3380         |
|    policy_gradient_loss  | -0.000369    |
|    std                   | 0.937        |
|    value_loss            | 1.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.082       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.082       |
| reward                   | -0.2729943  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 3           |
|    time_elapsed          | 1232        |
|    total_timesteps       | 708608      |
| train/                   |             |
|    approx_kl             | 0.004670785 |
|    clip_fraction         | 0.0238      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.52        |
|    cost_value_loss       | 26.4        |
|    cost_values           | 0.969       |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.827       |
|    lagrangian_multiplier | 0.00325     |
|    learning_rate         | 0.0003      |
|    loss                  | 6           |
|    n_updates             | 3450        |
|    policy_gradient_loss  | -0.00251    |
|    std                   | 0.854       |
|    value_loss            | 3.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0236       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0236       |
| reward                   | -0.5455641   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -757         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 46           |
|    time_elapsed          | 17803        |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0023658017 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.43         |
|    cost_value_loss       | 83.8         |
|    cost_values           | 0.527        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0.00393      |
|    learning_rate         | 0.0003       |
|    loss                  | 30.4         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.841        |
|    value_loss            | 108          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.133       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.133       |
| reward                   | -0.30717188 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 15          |
|    time_elapsed          | 6062        |
|    total_timesteps       | 733184      |
| train/                   |             |
|    approx_kl             | 0.001569946 |
|    clip_fraction         | 0.0232      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.69        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 1.84        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 1.21e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.89        |
|    n_updates             | 3570        |
|    policy_gradient_loss  | -0.00268    |
|    std                   | 0.802       |
|    value_loss            | 0.174       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.289       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.289       |
| reward                   | -0.61199737 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 41          |
|    time_elapsed          | 16009       |
|    total_timesteps       | 686080      |
| train/                   |             |
|    approx_kl             | 0.002005217 |
|    clip_fraction         | 0.00107     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.44        |
|    cost_value_loss       | 50.5        |
|    cost_values           | 1.69        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.7        |
|    n_updates             | 3340        |
|    policy_gradient_loss  | -0.00158    |
|    std                   | 0.789       |
|    value_loss            | 2.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.45469105 |
| rollout/                 |             |
|    ep_len_mean           | 726         |
|    ep_rew_mean           | -324        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 46          |
|    time_elapsed          | 18584       |
|    total_timesteps       | 696320      |
| train/                   |             |
|    approx_kl             | 0.00666299  |
|    clip_fraction         | 0.0533      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.98        |
|    cost_value_loss       | 19.7        |
|    cost_values           | 1.96        |
|    entropy               | -1.86       |
|    entropy_loss          | -1.86       |
|    explained_variance    | 0.393       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.26        |
|    n_updates             | 3390        |
|    policy_gradient_loss  | -0.00499    |
|    std                   | 0.617       |
|    value_loss            | 0.802       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0959       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0959       |
| reward                   | -0.3329329   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 46           |
|    time_elapsed          | 16694        |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0021450054 |
|    clip_fraction         | 0.00767      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.94         |
|    cost_value_loss       | 77.2         |
|    cost_values           | 1.7          |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.26         |
|    lagrangian_multiplier | 0.0111       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.99         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | -0.000816    |
|    std                   | 0.937        |
|    value_loss            | 4.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0621      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0621      |
| reward                   | -0.64035785 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -477        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 4           |
|    time_elapsed          | 1643        |
|    total_timesteps       | 710656      |
| train/                   |             |
|    approx_kl             | 0.006241967 |
|    clip_fraction         | 0.0398      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.78        |
|    cost_value_loss       | 77.4        |
|    cost_values           | 1.56        |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.00937     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.26        |
|    n_updates             | 3460        |
|    policy_gradient_loss  | -0.00457    |
|    std                   | 0.854       |
|    value_loss            | 2.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.5219946  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -752        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 47          |
|    time_elapsed          | 18224       |
|    total_timesteps       | 698368      |
| train/                   |             |
|    approx_kl             | 0.004473803 |
|    clip_fraction         | 0.0264      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 153         |
|    cost_values           | 0.861       |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.0251      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.66        |
|    n_updates             | 3400        |
|    policy_gradient_loss  | -0.00454    |
|    std                   | 0.842       |
|    value_loss            | 36.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0888       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0888       |
| reward                   | -0.30841568  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 6475         |
|    total_timesteps       | 735232       |
| train/                   |              |
|    approx_kl             | 0.0056146258 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 0.0911       |
|    cost_values           | 1.66         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | -0.166       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.12         |
|    n_updates             | 3580         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.8          |
|    value_loss            | 0.372        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.2620238   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 42           |
|    time_elapsed          | 16414        |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0058584493 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.57         |
|    cost_value_loss       | 96.4         |
|    cost_values           | 2.04         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -2.91        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51           |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.789        |
|    value_loss            | 6.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.54        |
| reward                   | -0.41925538 |
| rollout/                 |             |
|    ep_len_mean           | 732         |
|    ep_rew_mean           | -327        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 47          |
|    time_elapsed          | 19026       |
|    total_timesteps       | 698368      |
| train/                   |             |
|    approx_kl             | 0.011879329 |
|    clip_fraction         | 0.0767      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.27        |
|    cost_value_loss       | 15.8        |
|    cost_values           | 2.29        |
|    entropy               | -1.85       |
|    entropy_loss          | -1.85       |
|    explained_variance    | 0.37        |
|    lagrangian_multiplier | 0.00604     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.15        |
|    n_updates             | 3400        |
|    policy_gradient_loss  | -0.00799    |
|    std                   | 0.616       |
|    value_loss            | 2.3         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.396        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.396        |
| reward                   | -0.42617583  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 47           |
|    time_elapsed          | 17085        |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0052491296 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.21         |
|    cost_value_loss       | 56.3         |
|    cost_values           | 1.39         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.787        |
|    lagrangian_multiplier | 0.00694      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.935        |
|    value_loss            | 0.907        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.161         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.161         |
| reward                   | -0.5325107    |
| rollout/                 |               |
|    ep_len_mean           | 980           |
|    ep_rew_mean           | -477          |
| time/                    |               |
|    fps                   | 4             |
|    iterations            | 5             |
|    time_elapsed          | 2053          |
|    total_timesteps       | 712704        |
| train/                   |               |
|    approx_kl             | 0.00013551721 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 9.4           |
|    cost_value_loss       | 115           |
|    cost_values           | 1.8           |
|    entropy               | -2.51         |
|    entropy_loss          | -2.52         |
|    explained_variance    | 0.973         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 55.2          |
|    n_updates             | 3470          |
|    policy_gradient_loss  | 0.000219      |
|    std                   | 0.854         |
|    value_loss            | 3.67          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0235       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0235       |
| reward                   | -0.49538907  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -399         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 17           |
|    time_elapsed          | 6887         |
|    total_timesteps       | 737280       |
| train/                   |              |
|    approx_kl             | 0.0019246234 |
|    clip_fraction         | 0.0509       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.27         |
|    cost_value_loss       | 83.7         |
|    cost_values           | 1.83         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.863        |
|    lagrangian_multiplier | 0.0104       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.5          |
|    n_updates             | 3590         |
|    policy_gradient_loss  | -0.000121    |
|    std                   | 0.799        |
|    value_loss            | 1.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.247        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.247        |
| reward                   | -0.5563359   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -744         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 48           |
|    time_elapsed          | 18650        |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0043607187 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.1          |
|    cost_value_loss       | 102          |
|    cost_values           | 0.93         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0.0167       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.54         |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.00535     |
|    std                   | 0.84         |
|    value_loss            | 23.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.157        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.157        |
| reward                   | -0.42136762  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 43           |
|    time_elapsed          | 16827        |
|    total_timesteps       | 690176       |
| train/                   |              |
|    approx_kl             | 0.0023413524 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.3          |
|    cost_value_loss       | 37.6         |
|    cost_values           | 2.29         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.558        |
|    lagrangian_multiplier | 0.000569     |
|    learning_rate         | 0.0003       |
|    loss                  | 15.4         |
|    n_updates             | 3360         |
|    policy_gradient_loss  | -0.000603    |
|    std                   | 0.789        |
|    value_loss            | 3.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.191        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.191        |
| reward                   | -0.27638233  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 48           |
|    time_elapsed          | 17474        |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0048012678 |
|    clip_fraction         | 0.0543       |
|    clip_range            | 0.2          |
|    cost_returns          | 6            |
|    cost_value_loss       | 64.6         |
|    cost_values           | 1.52         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0.00597      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.31         |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.000785    |
|    std                   | 0.934        |
|    value_loss            | 0.854        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -0.4804726   |
| rollout/                 |              |
|    ep_len_mean           | 735          |
|    ep_rew_mean           | -330         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 48           |
|    time_elapsed          | 19467        |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0074878456 |
|    clip_fraction         | 0.13         |
|    clip_range            | 0.2          |
|    cost_returns          | 6.81         |
|    cost_value_loss       | 20           |
|    cost_values           | 2.61         |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 0.177        |
|    lagrangian_multiplier | 0.00104      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.42         |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.00513     |
|    std                   | 0.615        |
|    value_loss            | 9.03         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.0167        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0167        |
| reward                   | -0.37836286   |
| rollout/                 |               |
|    ep_len_mean           | 980           |
|    ep_rew_mean           | -473          |
| time/                    |               |
|    fps                   | 4             |
|    iterations            | 6             |
|    time_elapsed          | 2466          |
|    total_timesteps       | 714752        |
| train/                   |               |
|    approx_kl             | 0.00096434413 |
|    clip_fraction         | 0.0169        |
|    clip_range            | 0.2           |
|    cost_returns          | 1.04          |
|    cost_value_loss       | 0.0407        |
|    cost_values           | 1.05          |
|    entropy               | -2.51         |
|    entropy_loss          | -2.51         |
|    explained_variance    | 0.804         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 0.506         |
|    n_updates             | 3480          |
|    policy_gradient_loss  | -0.000759     |
|    std                   | 0.854         |
|    value_loss            | 1.46          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.258        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.258        |
| reward                   | -0.56525064  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 18           |
|    time_elapsed          | 7298         |
|    total_timesteps       | 739328       |
| train/                   |              |
|    approx_kl             | 0.0040350063 |
|    clip_fraction         | 0.0063       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.34         |
|    cost_value_loss       | 66.9         |
|    cost_values           | 2.16         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0.00916      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.67         |
|    n_updates             | 3600         |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 0.799        |
|    value_loss            | 1.27         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0271      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0271      |
| reward                   | -0.4903878  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -735        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 49          |
|    time_elapsed          | 19071       |
|    total_timesteps       | 702464      |
| train/                   |             |
|    approx_kl             | 0.005402881 |
|    clip_fraction         | 0.0562      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.73        |
|    cost_value_loss       | 85.6        |
|    cost_values           | 0.963       |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.0113      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.95        |
|    n_updates             | 3420        |
|    policy_gradient_loss  | -0.00563    |
|    std                   | 0.842       |
|    value_loss            | 35.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0139      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0139      |
| reward                   | -0.51620924 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 44          |
|    time_elapsed          | 17244       |
|    total_timesteps       | 692224      |
| train/                   |             |
|    approx_kl             | 0.005425022 |
|    clip_fraction         | 0.00854     |
|    clip_range            | 0.2         |
|    cost_returns          | 10.7        |
|    cost_value_loss       | 100         |
|    cost_values           | 2.7         |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.785       |
|    lagrangian_multiplier | 0.0177      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.75        |
|    n_updates             | 3370        |
|    policy_gradient_loss  | -0.00286    |
|    std                   | 0.789       |
|    value_loss            | 5.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0262       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0262       |
| reward                   | -0.45579353  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 49           |
|    time_elapsed          | 17865        |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0068365163 |
|    clip_fraction         | 0.0989       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.92         |
|    cost_value_loss       | 80.8         |
|    cost_values           | 1.86         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.801        |
|    lagrangian_multiplier | 0.00495      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -0.00698     |
|    std                   | 0.931        |
|    value_loss            | 0.855        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3614625   |
| rollout/                 |              |
|    ep_len_mean           | 734          |
|    ep_rew_mean           | -329         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 49           |
|    time_elapsed          | 19912        |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0039530047 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.33         |
|    cost_value_loss       | 19.8         |
|    cost_values           | 2.47         |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 0.429        |
|    lagrangian_multiplier | 0.000766     |
|    learning_rate         | 0.0003       |
|    loss                  | 9.61         |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 0.615        |
|    value_loss            | 1.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0479       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0479       |
| reward                   | -0.32622367  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 7            |
|    time_elapsed          | 2879         |
|    total_timesteps       | 716800       |
| train/                   |              |
|    approx_kl             | 0.0044310046 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.24         |
|    cost_value_loss       | 75           |
|    cost_values           | 1.47         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.829        |
|    lagrangian_multiplier | 0.00852      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.39         |
|    n_updates             | 3490         |
|    policy_gradient_loss  | -0.000871    |
|    std                   | 0.853        |
|    value_loss            | 1.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.131       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.131       |
| reward                   | -0.51396775 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 19          |
|    time_elapsed          | 7715        |
|    total_timesteps       | 741376      |
| train/                   |             |
|    approx_kl             | 0.004445605 |
|    clip_fraction         | 0.0156      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 116         |
|    cost_values           | 2.32        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.762       |
|    lagrangian_multiplier | 0.0195      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.56        |
|    n_updates             | 3610        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.8         |
|    value_loss            | 5.16        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/4ts77xgw
-----------------------------------
| avg_speed          | 0.0209     |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.0209     |
| reward             | -0.3450705 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -723       |
| time/              |            |
|    fps             | 4          |
|    iterations      | 1          |
|    time_elapsed    | 423        |
|    total_timesteps | 704512     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.265       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.265       |
| reward                   | -0.37792066 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 45          |
|    time_elapsed          | 17664       |
|    total_timesteps       | 694272      |
| train/                   |             |
|    approx_kl             | 0.002218084 |
|    clip_fraction         | 0.00483     |
|    clip_range            | 0.2         |
|    cost_returns          | 7.17        |
|    cost_value_loss       | 65.2        |
|    cost_values           | 2.7         |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.841       |
|    lagrangian_multiplier | 0.00764     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.64        |
|    n_updates             | 3380        |
|    policy_gradient_loss  | -0.00134    |
|    std                   | 0.79        |
|    value_loss            | 1.43        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/p13vkfbg
------------------------------------
| avg_speed          | 0.0777      |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.0777      |
| reward             | -0.40621686 |
| rollout/           |             |
|    ep_len_mean     | 964         |
|    ep_rew_mean     | -404        |
| time/              |             |
|    fps             | 5           |
|    iterations      | 1           |
|    time_elapsed    | 389         |
|    total_timesteps | 704512      |
------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/pe6a45mq
------------------------------------
| avg_speed          | 7.66        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.66        |
| reward             | -0.58377993 |
| rollout/           |             |
|    ep_len_mean     | 734         |
|    ep_rew_mean     | -329        |
| time/              |             |
|    fps             | 4           |
|    iterations      | 1           |
|    time_elapsed    | 440         |
|    total_timesteps | 704512      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.0151       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0151       |
| reward                   | -0.4756793   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 8            |
|    time_elapsed          | 3296         |
|    total_timesteps       | 718848       |
| train/                   |              |
|    approx_kl             | 0.0022805384 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.7          |
|    cost_value_loss       | 39.6         |
|    cost_values           | 0.952        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.897        |
|    lagrangian_multiplier | 0.00183      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 3500         |
|    policy_gradient_loss  | -0.000868    |
|    std                   | 0.851        |
|    value_loss            | 0.492        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00164     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00164     |
| reward                   | -0.34265095 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 20          |
|    time_elapsed          | 8127        |
|    total_timesteps       | 743424      |
| train/                   |             |
|    approx_kl             | 0.007926503 |
|    clip_fraction         | 0.018       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.15        |
|    cost_value_loss       | 94.4        |
|    cost_values           | 2.22        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0.00938     |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 3620        |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 0.799       |
|    value_loss            | 1.24        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.451        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.451        |
| reward                   | -0.24236533  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 2            |
|    time_elapsed          | 851          |
|    total_timesteps       | 706560       |
| train/                   |              |
|    approx_kl             | 0.0022324687 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 16.2         |
|    cost_value_loss       | 217          |
|    cost_values           | 1.82         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.567        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 3440         |
|    policy_gradient_loss  | -0.00196     |
|    std                   | 0.841        |
|    value_loss            | 1.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.182       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.182       |
| reward                   | -0.31570482 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 2           |
|    time_elapsed          | 779         |
|    total_timesteps       | 706560      |
| train/                   |             |
|    approx_kl             | 0.013904235 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.9         |
|    cost_value_loss       | 115         |
|    cost_values           | 1.67        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.851       |
|    lagrangian_multiplier | 0.0141      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.59        |
|    n_updates             | 3440        |
|    policy_gradient_loss  | -0.0135     |
|    std                   | 0.931       |
|    value_loss            | 0.374       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.185        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.185        |
| reward                   | -0.56885505  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 46           |
|    time_elapsed          | 18083        |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0057073217 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.3         |
|    cost_value_loss       | 141          |
|    cost_values           | 2.67         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.823        |
|    lagrangian_multiplier | 0.0153       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 0.789        |
|    value_loss            | 3.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.55        |
| reward                   | -0.40896514 |
| rollout/                 |             |
|    ep_len_mean           | 729         |
|    ep_rew_mean           | -327        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 2           |
|    time_elapsed          | 888         |
|    total_timesteps       | 706560      |
| train/                   |             |
|    approx_kl             | 0.005318937 |
|    clip_fraction         | 0.0686      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.95        |
|    cost_value_loss       | 25.1        |
|    cost_values           | 2.33        |
|    entropy               | -1.84       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0.631       |
|    lagrangian_multiplier | 0.00237     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.96        |
|    n_updates             | 3440        |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 0.614       |
|    value_loss            | 2.62        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.143        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.143        |
| reward                   | -0.44473824  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 9            |
|    time_elapsed          | 3712         |
|    total_timesteps       | 720896       |
| train/                   |              |
|    approx_kl             | 0.0050446005 |
|    clip_fraction         | 0.0497       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 2.4          |
|    cost_values           | 0.881        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.892        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.64         |
|    n_updates             | 3510         |
|    policy_gradient_loss  | -0.00335     |
|    std                   | 0.851        |
|    value_loss            | 1.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.4          |
| reward                   | -0.32116744  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 21           |
|    time_elapsed          | 8543         |
|    total_timesteps       | 745472       |
| train/                   |              |
|    approx_kl             | 0.0040264837 |
|    clip_fraction         | 0.0382       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 8.76         |
|    cost_values           | 1.68         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.63         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 3630         |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 0.797        |
|    value_loss            | 0.459        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.201        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.201        |
| reward                   | -0.5413592   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 3            |
|    time_elapsed          | 1293         |
|    total_timesteps       | 708608       |
| train/                   |              |
|    approx_kl             | 0.0014681343 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 17.4         |
|    cost_value_loss       | 235          |
|    cost_values           | 2.33         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | -3.94        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 114          |
|    n_updates             | 3450         |
|    policy_gradient_loss  | -0.000321    |
|    std                   | 0.841        |
|    value_loss            | 2.91         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0438      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0438      |
| reward                   | -0.241358   |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 3           |
|    time_elapsed          | 1164        |
|    total_timesteps       | 708608      |
| train/                   |             |
|    approx_kl             | 0.004225558 |
|    clip_fraction         | 0.0421      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.21        |
|    cost_value_loss       | 0.0536      |
|    cost_values           | 1.21        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | -0.264      |
|    lagrangian_multiplier | 0.00237     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.61        |
|    n_updates             | 3450        |
|    policy_gradient_loss  | -0.00306    |
|    std                   | 0.932       |
|    value_loss            | 8.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.361       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.361       |
| reward                   | -0.521427   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 47          |
|    time_elapsed          | 18497       |
|    total_timesteps       | 698368      |
| train/                   |             |
|    approx_kl             | 0.004755785 |
|    clip_fraction         | 0.0468      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.5        |
|    cost_value_loss       | 226         |
|    cost_values           | 2.96        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.476       |
|    lagrangian_multiplier | 0.0307      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.7         |
|    n_updates             | 3400        |
|    policy_gradient_loss  | -0.00425    |
|    std                   | 0.789       |
|    value_loss            | 2.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.45245045 |
| rollout/                 |             |
|    ep_len_mean           | 724         |
|    ep_rew_mean           | -323        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 3           |
|    time_elapsed          | 1336        |
|    total_timesteps       | 708608      |
| train/                   |             |
|    approx_kl             | 0.01340289  |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.59        |
|    cost_value_loss       | 26.3        |
|    cost_values           | 2.73        |
|    entropy               | -1.85       |
|    entropy_loss          | -1.85       |
|    explained_variance    | 0.234       |
|    lagrangian_multiplier | 0.00895     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.71        |
|    n_updates             | 3450        |
|    policy_gradient_loss  | -0.00717    |
|    std                   | 0.615       |
|    value_loss            | 16.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.177        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.177        |
| reward                   | -0.39635232  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 10           |
|    time_elapsed          | 4132         |
|    total_timesteps       | 722944       |
| train/                   |              |
|    approx_kl             | 0.0025897094 |
|    clip_fraction         | 0.0206       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 22.5         |
|    cost_values           | 0.809        |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.761        |
|    lagrangian_multiplier | 0.00149      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.93         |
|    n_updates             | 3520         |
|    policy_gradient_loss  | -0.000508    |
|    std                   | 0.851        |
|    value_loss            | 5.49         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.124      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.124      |
| reward                   | -0.5112079 |
| rollout/                 |            |
|    ep_len_mean           | 989        |
|    ep_rew_mean           | -400       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 22         |
|    time_elapsed          | 8959       |
|    total_timesteps       | 747520     |
| train/                   |            |
|    approx_kl             | 0.00351485 |
|    clip_fraction         | 0.023      |
|    clip_range            | 0.2        |
|    cost_returns          | 6.72       |
|    cost_value_loss       | 78         |
|    cost_values           | 1.58       |
|    entropy               | -2.37      |
|    entropy_loss          | -2.37      |
|    explained_variance    | 0.967      |
|    lagrangian_multiplier | 0.00773    |
|    learning_rate         | 0.0003     |
|    loss                  | 8.88       |
|    n_updates             | 3640       |
|    policy_gradient_loss  | -0.00206   |
|    std                   | 0.796      |
|    value_loss            | 0.637      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.112       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.112       |
| reward                   | -0.2869108  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 4           |
|    time_elapsed          | 1551        |
|    total_timesteps       | 710656      |
| train/                   |             |
|    approx_kl             | 0.006003006 |
|    clip_fraction         | 0.0404      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.32        |
|    cost_value_loss       | 6.61        |
|    cost_values           | 0.92        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.7        |
|    explained_variance    | -0.376      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.74        |
|    n_updates             | 3460        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.929       |
|    value_loss            | 0.897       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.186       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.186       |
| reward                   | -0.53198886 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 4           |
|    time_elapsed          | 1734        |
|    total_timesteps       | 710656      |
| train/                   |             |
|    approx_kl             | 0.008933831 |
|    clip_fraction         | 0.0225      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.4        |
|    cost_value_loss       | 222         |
|    cost_values           | 2.87        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.681       |
|    lagrangian_multiplier | 0.00079     |
|    learning_rate         | 0.0003      |
|    loss                  | 80.1        |
|    n_updates             | 3460        |
|    policy_gradient_loss  | -0.00249    |
|    std                   | 0.841       |
|    value_loss            | 1.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.209        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.209        |
| reward                   | -0.43574408  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 48           |
|    time_elapsed          | 18923        |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0041968427 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.58         |
|    cost_value_loss       | 92.3         |
|    cost_values           | 2.85         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0.0161       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.62         |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.79         |
|    value_loss            | 2.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.4178533  |
| rollout/                 |             |
|    ep_len_mean           | 729         |
|    ep_rew_mean           | -327        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 4           |
|    time_elapsed          | 1785        |
|    total_timesteps       | 710656      |
| train/                   |             |
|    approx_kl             | 0.008400588 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 6           |
|    cost_value_loss       | 16.6        |
|    cost_values           | 2.65        |
|    entropy               | -1.84       |
|    entropy_loss          | -1.85       |
|    explained_variance    | -0.0468     |
|    lagrangian_multiplier | 0.00181     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.85        |
|    n_updates             | 3460        |
|    policy_gradient_loss  | 0.00242     |
|    std                   | 0.614       |
|    value_loss            | 18.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.22229207 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -457        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 11          |
|    time_elapsed          | 4553        |
|    total_timesteps       | 724992      |
| train/                   |             |
|    approx_kl             | 0.004088108 |
|    clip_fraction         | 0.00713     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.22        |
|    cost_value_loss       | 43.7        |
|    cost_values           | 1.28        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0.00314     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 3530        |
|    policy_gradient_loss  | -0.000392   |
|    std                   | 0.852       |
|    value_loss            | 4.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.135        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.135        |
| reward                   | -0.5587533   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 23           |
|    time_elapsed          | 9383         |
|    total_timesteps       | 749568       |
| train/                   |              |
|    approx_kl             | 0.0049316734 |
|    clip_fraction         | 0.0483       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.85         |
|    cost_value_loss       | 85.8         |
|    cost_values           | 1.52         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.859        |
|    lagrangian_multiplier | 0.0133       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 3650         |
|    policy_gradient_loss  | -0.0054      |
|    std                   | 0.793        |
|    value_loss            | 0.882        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0058       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0058       |
| reward                   | -0.5463149   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 5            |
|    time_elapsed          | 1945         |
|    total_timesteps       | 712704       |
| train/                   |              |
|    approx_kl             | 0.0079861805 |
|    clip_fraction         | 0.0957       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.4         |
|    cost_value_loss       | 133          |
|    cost_values           | 1.46         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.7          |
|    lagrangian_multiplier | 0.0103       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 3470         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.925        |
|    value_loss            | 1.19         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.321         |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.321         |
| reward                   | -0.29853335   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -732          |
| time/                    |               |
|    fps                   | 4             |
|    iterations            | 5             |
|    time_elapsed          | 2173          |
|    total_timesteps       | 712704        |
| train/                   |               |
|    approx_kl             | 0.00028219703 |
|    clip_fraction         | 0.000195      |
|    clip_range            | 0.2           |
|    cost_returns          | 13.1          |
|    cost_value_loss       | 169           |
|    cost_values           | 2.15          |
|    entropy               | -2.49         |
|    entropy_loss          | -2.49         |
|    explained_variance    | 0.988         |
|    lagrangian_multiplier | 0.441         |
|    learning_rate         | 0.0003        |
|    loss                  | 2.58          |
|    n_updates             | 3470          |
|    policy_gradient_loss  | -0.000335     |
|    std                   | 0.841         |
|    value_loss            | 34.3          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.161        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.161        |
| reward                   | -0.3302976   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 49           |
|    time_elapsed          | 19345        |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0010177686 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 17.8         |
|    cost_value_loss       | 236          |
|    cost_values           | 2.84         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0.0309       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.69         |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -8.1e-06     |
|    std                   | 0.79         |
|    value_loss            | 2.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0364       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0364       |
| reward                   | -0.38729337  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -456         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 12           |
|    time_elapsed          | 4975         |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0035487167 |
|    clip_fraction         | 0.0419       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.5          |
|    cost_value_loss       | 122          |
|    cost_values           | 1.68         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.878        |
|    lagrangian_multiplier | 0.000413     |
|    learning_rate         | 0.0003       |
|    loss                  | 49.3         |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 0.852        |
|    value_loss            | 0.806        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.18        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.18        |
| reward                   | -0.67214954 |
| rollout/                 |             |
|    ep_len_mean           | 727         |
|    ep_rew_mean           | -327        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 5           |
|    time_elapsed          | 2236        |
|    total_timesteps       | 712704      |
| train/                   |             |
|    approx_kl             | 0.011834909 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.67        |
|    cost_value_loss       | 21          |
|    cost_values           | 2.57        |
|    entropy               | -1.84       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0.526       |
|    lagrangian_multiplier | 0.0033      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.78        |
|    n_updates             | 3470        |
|    policy_gradient_loss  | -0.00754    |
|    std                   | 0.611       |
|    value_loss            | 12.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.312       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.312       |
| reward                   | -0.3523659  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 24          |
|    time_elapsed          | 9806        |
|    total_timesteps       | 751616      |
| train/                   |             |
|    approx_kl             | 0.002392195 |
|    clip_fraction         | 0.00117     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.38        |
|    cost_value_loss       | 74.7        |
|    cost_values           | 1.65        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | -6.77       |
|    lagrangian_multiplier | 0.00713     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 3660        |
|    policy_gradient_loss  | -0.000984   |
|    std                   | 0.792       |
|    value_loss            | 3.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.168        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.168        |
| reward                   | -0.5065649   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 6            |
|    time_elapsed          | 2337         |
|    total_timesteps       | 714752       |
| train/                   |              |
|    approx_kl             | 0.0029319474 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.7          |
|    cost_value_loss       | 34.7         |
|    cost_values           | 1.47         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.279        |
|    lagrangian_multiplier | 0.00453      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.59         |
|    n_updates             | 3480         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 0.921        |
|    value_loss            | 1.47         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.157         |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.157         |
| reward                   | -0.23256744   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -727          |
| time/                    |               |
|    fps                   | 4             |
|    iterations            | 6             |
|    time_elapsed          | 2616          |
|    total_timesteps       | 714752        |
| train/                   |               |
|    approx_kl             | 0.00032681224 |
|    clip_fraction         | 0.000244      |
|    clip_range            | 0.2           |
|    cost_returns          | 5.62          |
|    cost_value_loss       | 64.7          |
|    cost_values           | 1.03          |
|    entropy               | -2.49         |
|    entropy_loss          | -2.49         |
|    explained_variance    | 0.985         |
|    lagrangian_multiplier | 0.00673       |
|    learning_rate         | 0.0003        |
|    loss                  | 14            |
|    n_updates             | 3480          |
|    policy_gradient_loss  | -0.000464     |
|    std                   | 0.841         |
|    value_loss            | 55.6          |
--------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/mtgakx2v
------------------------------------
| avg_speed          | 0.0605      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0605      |
| reward             | -0.33122534 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -424        |
| time/              |             |
|    fps             | 4           |
|    iterations      | 1           |
|    time_elapsed    | 424         |
|    total_timesteps | 704512      |
------------------------------------
------------------------------------------
| avg_speed                | 0.207       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.207       |
| reward                   | -0.51912606 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -457        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 13          |
|    time_elapsed          | 5391        |
|    total_timesteps       | 729088      |
| train/                   |             |
|    approx_kl             | 0.005884451 |
|    clip_fraction         | 0.0143      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.99        |
|    cost_value_loss       | 116         |
|    cost_values           | 2.22        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0.018       |
|    learning_rate         | 0.0003      |
|    loss                  | 7.74        |
|    n_updates             | 3550        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.851       |
|    value_loss            | 1.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.009        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.009        |
| reward                   | -0.55933785  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 25           |
|    time_elapsed          | 10224        |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0048592854 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.31         |
|    cost_value_loss       | 44.8         |
|    cost_values           | 1.54         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.685        |
|    lagrangian_multiplier | 0.00869      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.18         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.000869    |
|    std                   | 0.793        |
|    value_loss            | 3.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.33         |
| reward                   | -0.39792502  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 7            |
|    time_elapsed          | 2734         |
|    total_timesteps       | 716800       |
| train/                   |              |
|    approx_kl             | 0.0070510306 |
|    clip_fraction         | 0.0669       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.36         |
|    cost_value_loss       | 85.7         |
|    cost_values           | 1.73         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.6          |
|    lagrangian_multiplier | 0.0099       |
|    learning_rate         | 0.0003       |
|    loss                  | 9            |
|    n_updates             | 3490         |
|    policy_gradient_loss  | -0.00888     |
|    std                   | 0.919        |
|    value_loss            | 2.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.55         |
| reward                   | -0.33089644  |
| rollout/                 |              |
|    ep_len_mean           | 729          |
|    ep_rew_mean           | -329         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 6            |
|    time_elapsed          | 2688         |
|    total_timesteps       | 714752       |
| train/                   |              |
|    approx_kl             | 0.0060854414 |
|    clip_fraction         | 0.0835       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.99         |
|    cost_value_loss       | 17.5         |
|    cost_values           | 2.5          |
|    entropy               | -1.82        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.575        |
|    lagrangian_multiplier | 0.00444      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.85         |
|    n_updates             | 3480         |
|    policy_gradient_loss  | -0.00459     |
|    std                   | 0.607        |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0532      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0532      |
| reward                   | -0.4914856  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -726        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 7           |
|    time_elapsed          | 3062        |
|    total_timesteps       | 716800      |
| train/                   |             |
|    approx_kl             | 0.004440991 |
|    clip_fraction         | 0.04        |
|    clip_range            | 0.2         |
|    cost_returns          | 14.4        |
|    cost_value_loss       | 207         |
|    cost_values           | 0.963       |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0.0238      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.08        |
|    n_updates             | 3490        |
|    policy_gradient_loss  | -0.00594    |
|    std                   | 0.84        |
|    value_loss            | 7.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.25111467  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 2            |
|    time_elapsed          | 849          |
|    total_timesteps       | 706560       |
| train/                   |              |
|    approx_kl             | 0.0050050598 |
|    clip_fraction         | 0.0242       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 123          |
|    cost_values           | 2.98         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.921        |
|    lagrangian_multiplier | 0.0204       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.65         |
|    n_updates             | 3440         |
|    policy_gradient_loss  | -0.00438     |
|    std                   | 0.786        |
|    value_loss            | 1.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.461        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.461        |
| reward                   | -0.51950055  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 14           |
|    time_elapsed          | 5807         |
|    total_timesteps       | 731136       |
| train/                   |              |
|    approx_kl             | 0.0021205698 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 7.41         |
|    cost_value_loss       | 94.6         |
|    cost_values           | 1.6          |
|    entropy               | -2.5         |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0.00381      |
|    learning_rate         | 0.0003       |
|    loss                  | 17.9         |
|    n_updates             | 3560         |
|    policy_gradient_loss  | -0.000129    |
|    std                   | 0.85         |
|    value_loss            | 2.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0256      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0256      |
| reward                   | -0.2172636  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -395        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 8           |
|    time_elapsed          | 3124        |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.008668441 |
|    clip_fraction         | 0.0552      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.65        |
|    cost_value_loss       | 73.6        |
|    cost_values           | 1.6         |
|    entropy               | -2.66       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.685       |
|    lagrangian_multiplier | 0.0118      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.5         |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.00788    |
|    std                   | 0.917       |
|    value_loss            | 0.915       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.169        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.169        |
| reward                   | -0.2718411   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 26           |
|    time_elapsed          | 10646        |
|    total_timesteps       | 755712       |
| train/                   |              |
|    approx_kl             | 0.0019636971 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.758        |
|    cost_value_loss       | 0.0123       |
|    cost_values           | 0.735        |
|    entropy               | -2.34        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.105        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.478        |
|    n_updates             | 3680         |
|    policy_gradient_loss  | -0.000729    |
|    std                   | 0.784        |
|    value_loss            | 1.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.86        |
| reward                   | -0.49938667 |
| rollout/                 |             |
|    ep_len_mean           | 712         |
|    ep_rew_mean           | -322        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 7           |
|    time_elapsed          | 3138        |
|    total_timesteps       | 716800      |
| train/                   |             |
|    approx_kl             | 0.011248281 |
|    clip_fraction         | 0.0893      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.91        |
|    cost_value_loss       | 21.8        |
|    cost_values           | 2.61        |
|    entropy               | -1.81       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.407       |
|    lagrangian_multiplier | 0.000329    |
|    learning_rate         | 0.0003      |
|    loss                  | 19          |
|    n_updates             | 3490        |
|    policy_gradient_loss  | -0.00808    |
|    std                   | 0.605       |
|    value_loss            | 26.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.51903224  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 3            |
|    time_elapsed          | 1275         |
|    total_timesteps       | 708608       |
| train/                   |              |
|    approx_kl             | 0.0077794185 |
|    clip_fraction         | 0.0805       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.47         |
|    cost_value_loss       | 35.2         |
|    cost_values           | 2.91         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0.00432      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.69         |
|    n_updates             | 3450         |
|    policy_gradient_loss  | -0.00885     |
|    std                   | 0.787        |
|    value_loss            | 1.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0425       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0425       |
| reward                   | -0.5338605   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -725         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 8            |
|    time_elapsed          | 3503         |
|    total_timesteps       | 718848       |
| train/                   |              |
|    approx_kl             | 0.0054332763 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.5         |
|    cost_value_loss       | 154          |
|    cost_values           | 1.26         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.841        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 74.5         |
|    n_updates             | 3500         |
|    policy_gradient_loss  | -0.00418     |
|    std                   | 0.84         |
|    value_loss            | 2.96         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.211       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.211       |
| reward                   | -0.3930821  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -393        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 9           |
|    time_elapsed          | 3521        |
|    total_timesteps       | 720896      |
| train/                   |             |
|    approx_kl             | 0.003397983 |
|    clip_fraction         | 0.0207      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.57        |
|    cost_value_loss       | 6.4         |
|    cost_values           | 1.25        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.694       |
|    lagrangian_multiplier | 1.51e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.43        |
|    n_updates             | 3510        |
|    policy_gradient_loss  | -0.00336    |
|    std                   | 0.916       |
|    value_loss            | 1.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.102        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.102        |
| reward                   | -0.5091575   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 15           |
|    time_elapsed          | 6233         |
|    total_timesteps       | 733184       |
| train/                   |              |
|    approx_kl             | 0.0031347186 |
|    clip_fraction         | 0.00527      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.29         |
|    cost_value_loss       | 45.8         |
|    cost_values           | 1.12         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.164        |
|    lagrangian_multiplier | 0.00447      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.56         |
|    n_updates             | 3570         |
|    policy_gradient_loss  | -0.00474     |
|    std                   | 0.849        |
|    value_loss            | 6.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0713       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0713       |
| reward                   | -0.28037283  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 27           |
|    time_elapsed          | 11070        |
|    total_timesteps       | 757760       |
| train/                   |              |
|    approx_kl             | 0.0026227152 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 15.9         |
|    cost_values           | 0.574        |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.706        |
|    lagrangian_multiplier | 0.000743     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.56         |
|    n_updates             | 3690         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.782        |
|    value_loss            | 3.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.67        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.67        |
| reward                   | -0.43971908 |
| rollout/                 |             |
|    ep_len_mean           | 712         |
|    ep_rew_mean           | -322        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 8           |
|    time_elapsed          | 3595        |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.006818083 |
|    clip_fraction         | 0.0605      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.09        |
|    cost_value_loss       | 20.5        |
|    cost_values           | 2.9         |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.602       |
|    lagrangian_multiplier | 0.00747     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.51        |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 0.603       |
|    value_loss            | 19.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.164        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.164        |
| reward                   | -0.40373182  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 4            |
|    time_elapsed          | 1703         |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0077793887 |
|    clip_fraction         | 0.0491       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.74         |
|    cost_value_loss       | 46.8         |
|    cost_values           | 2.85         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.868        |
|    lagrangian_multiplier | 0.00815      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.15         |
|    n_updates             | 3460         |
|    policy_gradient_loss  | -0.00418     |
|    std                   | 0.786        |
|    value_loss            | 5.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0436       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0436       |
| reward                   | -0.18844828  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -724         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 9            |
|    time_elapsed          | 3937         |
|    total_timesteps       | 720896       |
| train/                   |              |
|    approx_kl             | 0.0027786756 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | 16.2         |
|    cost_value_loss       | 221          |
|    cost_values           | 1.72         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.298        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 3510         |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.84         |
|    value_loss            | 2.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.147       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.147       |
| reward                   | -0.42351046 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -393        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 10          |
|    time_elapsed          | 3920        |
|    total_timesteps       | 722944      |
| train/                   |             |
|    approx_kl             | 0.00362211  |
|    clip_fraction         | 0.0307      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.951       |
|    cost_value_loss       | 0.0274      |
|    cost_values           | 1.02        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.66       |
|    explained_variance    | -2.09       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.251       |
|    n_updates             | 3520        |
|    policy_gradient_loss  | -0.00159    |
|    std                   | 0.918       |
|    value_loss            | 1.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0135       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0135       |
| reward                   | -0.3579381   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -459         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 16           |
|    time_elapsed          | 6656         |
|    total_timesteps       | 735232       |
| train/                   |              |
|    approx_kl             | 0.0027026841 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.37         |
|    cost_value_loss       | 71.2         |
|    cost_values           | 0.931        |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0.00625      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.31         |
|    n_updates             | 3580         |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.847        |
|    value_loss            | 0.611        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.111        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.111        |
| reward                   | -0.41609246  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 28           |
|    time_elapsed          | 11492        |
|    total_timesteps       | 759808       |
| train/                   |              |
|    approx_kl             | 0.0074419826 |
|    clip_fraction         | 0.0442       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.642        |
|    cost_value_loss       | 0.277        |
|    cost_values           | 0.586        |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.27         |
|    n_updates             | 3700         |
|    policy_gradient_loss  | -0.00413     |
|    std                   | 0.782        |
|    value_loss            | 0.534        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.24        |
| reward                   | -0.4000252  |
| rollout/                 |             |
|    ep_len_mean           | 712         |
|    ep_rew_mean           | -324        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 9           |
|    time_elapsed          | 4056        |
|    total_timesteps       | 720896      |
| train/                   |             |
|    approx_kl             | 0.010284083 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.18        |
|    cost_value_loss       | 17.5        |
|    cost_values           | 2.84        |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.661       |
|    lagrangian_multiplier | 0.00513     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.2         |
|    n_updates             | 3510        |
|    policy_gradient_loss  | -0.00957    |
|    std                   | 0.604       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.153       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.153       |
| reward                   | -0.21742521 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 5           |
|    time_elapsed          | 2131        |
|    total_timesteps       | 712704      |
| train/                   |             |
|    approx_kl             | 0.00936245  |
|    clip_fraction         | 0.0397      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 157         |
|    cost_values           | 2.95        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0.0152      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 3470        |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 0.786       |
|    value_loss            | 1.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0384       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0384       |
| reward                   | -0.28128776  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -719         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 10           |
|    time_elapsed          | 4380         |
|    total_timesteps       | 722944       |
| train/                   |              |
|    approx_kl             | 0.0048295334 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.3         |
|    cost_value_loss       | 202          |
|    cost_values           | 2.22         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.858        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 99.5         |
|    n_updates             | 3520         |
|    policy_gradient_loss  | -0.00239     |
|    std                   | 0.84         |
|    value_loss            | 2.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0459      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0459      |
| reward                   | -0.32376036 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 11          |
|    time_elapsed          | 4318        |
|    total_timesteps       | 724992      |
| train/                   |             |
|    approx_kl             | 0.009596588 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.99        |
|    cost_value_loss       | 33          |
|    cost_values           | 1.21        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.378       |
|    lagrangian_multiplier | 0.00311     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.99        |
|    n_updates             | 3530        |
|    policy_gradient_loss  | -0.00235    |
|    std                   | 0.92        |
|    value_loss            | 1.32        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.166        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.166        |
| reward                   | -0.50997865  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -458         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 17           |
|    time_elapsed          | 7081         |
|    total_timesteps       | 737280       |
| train/                   |              |
|    approx_kl             | 0.0035937922 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 2.83         |
|    cost_values           | 1.05         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.02         |
|    n_updates             | 3590         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.848        |
|    value_loss            | 1.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00303      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00303      |
| reward                   | -0.6148834   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 29           |
|    time_elapsed          | 11916        |
|    total_timesteps       | 761856       |
| train/                   |              |
|    approx_kl             | 0.0025268258 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.396        |
|    cost_value_loss       | 0.403        |
|    cost_values           | 0.375        |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | -0.97        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.754        |
|    n_updates             | 3710         |
|    policy_gradient_loss  | 8.87e-05     |
|    std                   | 0.782        |
|    value_loss            | 4.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.77        |
| reward                   | -0.4242653  |
| rollout/                 |             |
|    ep_len_mean           | 702         |
|    ep_rew_mean           | -318        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 10          |
|    time_elapsed          | 4511        |
|    total_timesteps       | 722944      |
| train/                   |             |
|    approx_kl             | 0.004120535 |
|    clip_fraction         | 0.0458      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.27        |
|    cost_value_loss       | 13.2        |
|    cost_values           | 2.67        |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0.0298      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.95        |
|    n_updates             | 3520        |
|    policy_gradient_loss  | 0.000248    |
|    std                   | 0.605       |
|    value_loss            | 8.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00856     |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.00856     |
| reward                   | -0.28643578 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 6           |
|    time_elapsed          | 2567        |
|    total_timesteps       | 714752      |
| train/                   |             |
|    approx_kl             | 0.00575172  |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 162         |
|    cost_values           | 2.98        |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.763       |
|    lagrangian_multiplier | 0.0167      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 3480        |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 0.785       |
|    value_loss            | 1.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.1          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.1          |
| reward                   | -0.40351012  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -717         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 11           |
|    time_elapsed          | 4820         |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0064938627 |
|    clip_fraction         | 0.0422       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.33         |
|    cost_value_loss       | 59.2         |
|    cost_values           | 2.66         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.872        |
|    lagrangian_multiplier | 3.33e-06     |
|    learning_rate         | 0.0003       |
|    loss                  | 30.8         |
|    n_updates             | 3530         |
|    policy_gradient_loss  | -0.00369     |
|    std                   | 0.84         |
|    value_loss            | 1.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.433        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.433        |
| reward                   | -0.41063192  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 12           |
|    time_elapsed          | 4714         |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0022107842 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.29         |
|    cost_value_loss       | 31.2         |
|    cost_values           | 1.1          |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.266        |
|    lagrangian_multiplier | 0.00505      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.06         |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.919        |
|    value_loss            | 1.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0622       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0622       |
| reward                   | -0.39896137  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 18           |
|    time_elapsed          | 7506         |
|    total_timesteps       | 739328       |
| train/                   |              |
|    approx_kl             | 0.0034991503 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 9.29         |
|    cost_value_loss       | 122          |
|    cost_values           | 1.27         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0.0174       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.7          |
|    n_updates             | 3600         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.847        |
|    value_loss            | 0.905        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.172        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.172        |
| reward                   | -0.33247074  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 30           |
|    time_elapsed          | 12337        |
|    total_timesteps       | 763904       |
| train/                   |              |
|    approx_kl             | 0.0010934272 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 6.71         |
|    cost_value_loss       | 83.5         |
|    cost_values           | 0.94         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.792        |
|    lagrangian_multiplier | 0.00439      |
|    learning_rate         | 0.0003       |
|    loss                  | 14.7         |
|    n_updates             | 3720         |
|    policy_gradient_loss  | -0.000721    |
|    std                   | 0.781        |
|    value_loss            | 3.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.12339586  |
| rollout/                 |              |
|    ep_len_mean           | 694          |
|    ep_rew_mean           | -315         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 11           |
|    time_elapsed          | 4976         |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0065838597 |
|    clip_fraction         | 0.041        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.54         |
|    cost_value_loss       | 19.2         |
|    cost_values           | 2.6          |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | -0.146       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20           |
|    n_updates             | 3530         |
|    policy_gradient_loss  | -0.00638     |
|    std                   | 0.603        |
|    value_loss            | 21.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.165        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.165        |
| reward                   | -0.5141479   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 7            |
|    time_elapsed          | 2989         |
|    total_timesteps       | 716800       |
| train/                   |              |
|    approx_kl             | 0.0027098197 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 15           |
|    cost_value_loss       | 176          |
|    cost_values           | 2.99         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.914        |
|    lagrangian_multiplier | 0.00965      |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 3490         |
|    policy_gradient_loss  | -0.00369     |
|    std                   | 0.786        |
|    value_loss            | 1.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0932       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0932       |
| reward                   | -0.52281725  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -716         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 12           |
|    time_elapsed          | 5262         |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0022070236 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | 16.2         |
|    cost_value_loss       | 206          |
|    cost_values           | 2.57         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.935        |
|    lagrangian_multiplier | 0.0513       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.23         |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.841        |
|    value_loss            | 8.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0915      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0915      |
| reward                   | -0.41019374 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 13          |
|    time_elapsed          | 5115        |
|    total_timesteps       | 729088      |
| train/                   |             |
|    approx_kl             | 0.009668343 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 40.8        |
|    cost_values           | 1.23        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.776       |
|    lagrangian_multiplier | 0.00639     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.98        |
|    n_updates             | 3550        |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 0.918       |
|    value_loss            | 0.327       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.488        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.488        |
| reward                   | -0.561746    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 19           |
|    time_elapsed          | 7932         |
|    total_timesteps       | 741376       |
| train/                   |              |
|    approx_kl             | 0.0041005993 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.64         |
|    cost_value_loss       | 42.2         |
|    cost_values           | 0.954        |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0.00466      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.5          |
|    n_updates             | 3610         |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 0.847        |
|    value_loss            | 2.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.106        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.106        |
| reward                   | -0.6459232   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 31           |
|    time_elapsed          | 12760        |
|    total_timesteps       | 765952       |
| train/                   |              |
|    approx_kl             | 0.0024938602 |
|    clip_fraction         | 0.00151      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.03         |
|    cost_value_loss       | 30.3         |
|    cost_values           | 0.912        |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.351        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.4         |
|    n_updates             | 3730         |
|    policy_gradient_loss  | -0.000398    |
|    std                   | 0.781        |
|    value_loss            | 4.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0345       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0345       |
| reward                   | -0.56167746  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 8            |
|    time_elapsed          | 3413         |
|    total_timesteps       | 718848       |
| train/                   |              |
|    approx_kl             | 0.0021396626 |
|    clip_fraction         | 0.00278      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.3         |
|    cost_value_loss       | 109          |
|    cost_values           | 2.88         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0.0151       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.93         |
|    n_updates             | 3500         |
|    policy_gradient_loss  | -0.000599    |
|    std                   | 0.786        |
|    value_loss            | 0.661        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.38721883 |
| rollout/                 |             |
|    ep_len_mean           | 695         |
|    ep_rew_mean           | -314        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 12          |
|    time_elapsed          | 5440        |
|    total_timesteps       | 727040      |
| train/                   |             |
|    approx_kl             | 0.013081306 |
|    clip_fraction         | 0.0992      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.1         |
|    cost_value_loss       | 22.8        |
|    cost_values           | 2.75        |
|    entropy               | -1.8        |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0.476       |
|    lagrangian_multiplier | 0.00613     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.71        |
|    n_updates             | 3540        |
|    policy_gradient_loss  | -0.00507    |
|    std                   | 0.601       |
|    value_loss            | 12.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0406      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0406      |
| reward                   | -0.42860782 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 14          |
|    time_elapsed          | 5515        |
|    total_timesteps       | 731136      |
| train/                   |             |
|    approx_kl             | 0.004423124 |
|    clip_fraction         | 0.0309      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.62        |
|    cost_value_loss       | 63.9        |
|    cost_values           | 1.35        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.458       |
|    lagrangian_multiplier | 0.00963     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.66        |
|    n_updates             | 3560        |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 0.916       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.312       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.312       |
| reward                   | -0.42276576 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -721        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 13          |
|    time_elapsed          | 5701        |
|    total_timesteps       | 729088      |
| train/                   |             |
|    approx_kl             | 0.006614088 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 130         |
|    cost_values           | 2.18        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.82        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 64.2        |
|    n_updates             | 3550        |
|    policy_gradient_loss  | -0.0128     |
|    std                   | 0.841       |
|    value_loss            | 1.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.194        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.194        |
| reward                   | -0.35846332  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -460         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 20           |
|    time_elapsed          | 8360         |
|    total_timesteps       | 743424       |
| train/                   |              |
|    approx_kl             | 0.0059190146 |
|    clip_fraction         | 0.0318       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.79         |
|    cost_value_loss       | 73.4         |
|    cost_values           | 1.01         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0.0068       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.09         |
|    n_updates             | 3620         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.847        |
|    value_loss            | 1.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0766       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0766       |
| reward                   | -0.22614475  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 32           |
|    time_elapsed          | 13189        |
|    total_timesteps       | 768000       |
| train/                   |              |
|    approx_kl             | 0.0031471818 |
|    clip_fraction         | 0.0198       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.33         |
|    cost_value_loss       | 36.8         |
|    cost_values           | 1.01         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.348        |
|    lagrangian_multiplier | 0.00476      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.78         |
|    n_updates             | 3740         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.78         |
|    value_loss            | 2.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.101       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.101       |
| reward                   | -0.5652391  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 9           |
|    time_elapsed          | 3843        |
|    total_timesteps       | 720896      |
| train/                   |             |
|    approx_kl             | 0.007158757 |
|    clip_fraction         | 0.0795      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.5        |
|    cost_value_loss       | 161         |
|    cost_values           | 2.93        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.0212      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.56        |
|    n_updates             | 3510        |
|    policy_gradient_loss  | -0.00676    |
|    std                   | 0.787       |
|    value_loss            | 0.871       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.17         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.17         |
| reward                   | -0.3880283   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 15           |
|    time_elapsed          | 5922         |
|    total_timesteps       | 733184       |
| train/                   |              |
|    approx_kl             | 0.0031215413 |
|    clip_fraction         | 0.0351       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.17         |
|    cost_value_loss       | 39.7         |
|    cost_values           | 1.23         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.222        |
|    lagrangian_multiplier | 0.00578      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.74         |
|    n_updates             | 3570         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 0.914        |
|    value_loss            | 4.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.221        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.221        |
| reward                   | -0.28282252  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 14           |
|    time_elapsed          | 6134         |
|    total_timesteps       | 731136       |
| train/                   |              |
|    approx_kl             | 0.0048437887 |
|    clip_fraction         | 0.039        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.1         |
|    cost_value_loss       | 109          |
|    cost_values           | 2.59         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.874        |
|    lagrangian_multiplier | 0.000271     |
|    learning_rate         | 0.0003       |
|    loss                  | 49.2         |
|    n_updates             | 3560         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.841        |
|    value_loss            | 0.614        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.15        |
| reward                   | -0.38072777 |
| rollout/                 |             |
|    ep_len_mean           | 692         |
|    ep_rew_mean           | -310        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 13          |
|    time_elapsed          | 5902        |
|    total_timesteps       | 729088      |
| train/                   |             |
|    approx_kl             | 0.011212448 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.79        |
|    cost_value_loss       | 15.8        |
|    cost_values           | 2.61        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0.329       |
|    lagrangian_multiplier | 0.00625     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.81        |
|    n_updates             | 3550        |
|    policy_gradient_loss  | -0.00691    |
|    std                   | 0.598       |
|    value_loss            | 17.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.173       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.173       |
| reward                   | -0.3938676  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -461        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 21          |
|    time_elapsed          | 8789        |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.004904913 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.93        |
|    cost_value_loss       | 61.8        |
|    cost_values           | 0.942       |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.00681     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.49        |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.00388    |
|    std                   | 0.843       |
|    value_loss            | 1.3         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0812       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0812       |
| reward                   | -0.19041796  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 33           |
|    time_elapsed          | 13624        |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0021039937 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 10.1         |
|    cost_value_loss       | 131          |
|    cost_values           | 1.65         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.792        |
|    lagrangian_multiplier | 0.0168       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.76         |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.000491    |
|    std                   | 0.778        |
|    value_loss            | 3.86         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.112         |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.112         |
| reward                   | -0.41537642   |
| rollout/                 |               |
|    ep_len_mean           | 991           |
|    ep_rew_mean           | -416          |
| time/                    |               |
|    fps                   | 4             |
|    iterations            | 10            |
|    time_elapsed          | 4276          |
|    total_timesteps       | 722944        |
| train/                   |               |
|    approx_kl             | 0.00063392974 |
|    clip_fraction         | 0.000195      |
|    clip_range            | 0.2           |
|    cost_returns          | 16.8          |
|    cost_value_loss       | 208           |
|    cost_values           | 2.95          |
|    entropy               | -2.36         |
|    entropy_loss          | -2.36         |
|    explained_variance    | 0.854         |
|    lagrangian_multiplier | 0.0165        |
|    learning_rate         | 0.0003        |
|    loss                  | 13.5          |
|    n_updates             | 3520          |
|    policy_gradient_loss  | -0.000376     |
|    std                   | 0.787         |
|    value_loss            | 1.32          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.062        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.062        |
| reward                   | -0.229035    |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 6328         |
|    total_timesteps       | 735232       |
| train/                   |              |
|    approx_kl             | 0.0022508719 |
|    clip_fraction         | 0.0139       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 194          |
|    cost_values           | 1.74         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.371        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 94.1         |
|    n_updates             | 3580         |
|    policy_gradient_loss  | -0.00382     |
|    std                   | 0.913        |
|    value_loss            | 0.317        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0562      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0562      |
| reward                   | -0.3153843  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -714        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 15          |
|    time_elapsed          | 6568        |
|    total_timesteps       | 733184      |
| train/                   |             |
|    approx_kl             | 0.002709637 |
|    clip_fraction         | 0.0161      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 170         |
|    cost_values           | 2.96        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0.02        |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 3570        |
|    policy_gradient_loss  | -0.00191    |
|    std                   | 0.84        |
|    value_loss            | 1.28        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.62       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.62       |
| reward                   | -0.4437665 |
| rollout/                 |            |
|    ep_len_mean           | 692        |
|    ep_rew_mean           | -307       |
| time/                    |            |
|    fps                   | 4          |
|    iterations            | 14         |
|    time_elapsed          | 6368       |
|    total_timesteps       | 731136     |
| train/                   |            |
|    approx_kl             | 0.00839957 |
|    clip_fraction         | 0.0947     |
|    clip_range            | 0.2        |
|    cost_returns          | 6.65       |
|    cost_value_loss       | 19.8       |
|    cost_values           | 2.62       |
|    entropy               | -1.78      |
|    entropy_loss          | -1.78      |
|    explained_variance    | 0.294      |
|    lagrangian_multiplier | 0.0103     |
|    learning_rate         | 0.0003     |
|    loss                  | 4.87       |
|    n_updates             | 3560       |
|    policy_gradient_loss  | -0.00509   |
|    std                   | 0.596      |
|    value_loss            | 10.4       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.167       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.167       |
| reward                   | -0.5658538  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 22          |
|    time_elapsed          | 9217        |
|    total_timesteps       | 747520      |
| train/                   |             |
|    approx_kl             | 0.005788245 |
|    clip_fraction         | 0.0486      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 65.6        |
|    cost_values           | 0.735       |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.008       |
|    learning_rate         | 0.0003      |
|    loss                  | 7.6         |
|    n_updates             | 3640        |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.84        |
|    value_loss            | 1.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.246        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.246        |
| reward                   | -0.2778451   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 34           |
|    time_elapsed          | 14054        |
|    total_timesteps       | 772096       |
| train/                   |              |
|    approx_kl             | 0.0025617206 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.62         |
|    cost_value_loss       | 17.2         |
|    cost_values           | 1.45         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.78         |
|    lagrangian_multiplier | 0.000443     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.58         |
|    n_updates             | 3760         |
|    policy_gradient_loss  | -0.000779    |
|    std                   | 0.777        |
|    value_loss            | 2.83         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0595      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0595      |
| reward                   | -0.612143   |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -394        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 17          |
|    time_elapsed          | 6733        |
|    total_timesteps       | 737280      |
| train/                   |             |
|    approx_kl             | 0.006470698 |
|    clip_fraction         | 0.038       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.32        |
|    cost_value_loss       | 99.7        |
|    cost_values           | 2.02        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.746       |
|    lagrangian_multiplier | 0.0148      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.52        |
|    n_updates             | 3590        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.913       |
|    value_loss            | 0.438       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.146        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.146        |
| reward                   | -0.5453257   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 11           |
|    time_elapsed          | 4708         |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0032420312 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.2         |
|    cost_value_loss       | 148          |
|    cost_values           | 2.83         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.925        |
|    lagrangian_multiplier | 0.0152       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 3530         |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 0.788        |
|    value_loss            | 5.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.187        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.187        |
| reward                   | -0.433834    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -715         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 16           |
|    time_elapsed          | 7008         |
|    total_timesteps       | 735232       |
| train/                   |              |
|    approx_kl             | 0.0061868387 |
|    clip_fraction         | 0.0435       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.5         |
|    cost_value_loss       | 98.2         |
|    cost_values           | 3            |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.853        |
|    lagrangian_multiplier | 0.014        |
|    learning_rate         | 0.0003       |
|    loss                  | 8.76         |
|    n_updates             | 3580         |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.84         |
|    value_loss            | 1.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.6193566  |
| rollout/                 |             |
|    ep_len_mean           | 675         |
|    ep_rew_mean           | -300        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 15          |
|    time_elapsed          | 6837        |
|    total_timesteps       | 733184      |
| train/                   |             |
|    approx_kl             | 0.009462771 |
|    clip_fraction         | 0.068       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.05        |
|    cost_value_loss       | 20.1        |
|    cost_values           | 2.86        |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | -0.447      |
|    lagrangian_multiplier | 0.00661     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.64        |
|    n_updates             | 3570        |
|    policy_gradient_loss  | -0.00218    |
|    std                   | 0.594       |
|    value_loss            | 2.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.111        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.111        |
| reward                   | -0.48303306  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 23           |
|    time_elapsed          | 9638         |
|    total_timesteps       | 749568       |
| train/                   |              |
|    approx_kl             | 0.0044769635 |
|    clip_fraction         | 0.0429       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.62         |
|    cost_value_loss       | 1.73         |
|    cost_values           | 0.502        |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.946        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.42         |
|    n_updates             | 3650         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.838        |
|    value_loss            | 1.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.16788906 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 35          |
|    time_elapsed          | 14488       |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.008924705 |
|    clip_fraction         | 0.0343      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.61        |
|    cost_value_loss       | 19.7        |
|    cost_values           | 1.44        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.705       |
|    lagrangian_multiplier | 0.00283     |
|    learning_rate         | 0.0003      |
|    loss                  | 5           |
|    n_updates             | 3770        |
|    policy_gradient_loss  | -0.00376    |
|    std                   | 0.778       |
|    value_loss            | 2.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.39         |
| reward                   | -0.25528184  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 18           |
|    time_elapsed          | 7145         |
|    total_timesteps       | 739328       |
| train/                   |              |
|    approx_kl             | 0.0039797826 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.23         |
|    cost_value_loss       | 6.91         |
|    cost_values           | 1.44         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.634        |
|    lagrangian_multiplier | 0.00258      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.23         |
|    n_updates             | 3600         |
|    policy_gradient_loss  | -0.000426    |
|    std                   | 0.915        |
|    value_loss            | 3.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0337       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0337       |
| reward                   | -0.5071523   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 12           |
|    time_elapsed          | 5139         |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0046914043 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.3         |
|    cost_value_loss       | 122          |
|    cost_values           | 2.88         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.563        |
|    lagrangian_multiplier | 0.0128       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.00168     |
|    std                   | 0.787        |
|    value_loss            | 3.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.387       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.387       |
| reward                   | -0.29665515 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -714        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 17          |
|    time_elapsed          | 7454        |
|    total_timesteps       | 737280      |
| train/                   |             |
|    approx_kl             | 0.003535858 |
|    clip_fraction         | 0.0397      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.6        |
|    cost_value_loss       | 228         |
|    cost_values           | 3           |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.6         |
|    lagrangian_multiplier | 0.00472     |
|    learning_rate         | 0.0003      |
|    loss                  | 36.2        |
|    n_updates             | 3590        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.84        |
|    value_loss            | 0.879       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.11         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.11         |
| reward                   | -0.39572832  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 24           |
|    time_elapsed          | 10066        |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0051436187 |
|    clip_fraction         | 0.0575       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.258        |
|    cost_value_loss       | 0.00267      |
|    cost_values           | 0.288        |
|    entropy               | -2.49        |
|    entropy_loss          | -2.48        |
|    explained_variance    | -0.725       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.461        |
|    n_updates             | 3660         |
|    policy_gradient_loss  | -0.000732    |
|    std                   | 0.842        |
|    value_loss            | 1.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.62        |
| reward                   | -0.44917303 |
| rollout/                 |             |
|    ep_len_mean           | 669         |
|    ep_rew_mean           | -296        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 16          |
|    time_elapsed          | 7307        |
|    total_timesteps       | 735232      |
| train/                   |             |
|    approx_kl             | 0.010351781 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.92        |
|    cost_value_loss       | 24.6        |
|    cost_values           | 2.58        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.0888      |
|    lagrangian_multiplier | 0.00248     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.3        |
|    n_updates             | 3580        |
|    policy_gradient_loss  | 0.00277     |
|    std                   | 0.592       |
|    value_loss            | 16.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0436       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0436       |
| reward                   | -0.41643336  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 36           |
|    time_elapsed          | 14920        |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0047881277 |
|    clip_fraction         | 0.0412       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.58         |
|    cost_value_loss       | 21           |
|    cost_values           | 1.24         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0.00229      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.28         |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00345     |
|    std                   | 0.778        |
|    value_loss            | 0.568        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.199       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.199       |
| reward                   | -0.4865449  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -396        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 19          |
|    time_elapsed          | 7557        |
|    total_timesteps       | 741376      |
| train/                   |             |
|    approx_kl             | 0.010339613 |
|    clip_fraction         | 0.0533      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.09        |
|    cost_value_loss       | 65.1        |
|    cost_values           | 0.984       |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.697       |
|    lagrangian_multiplier | 0.0052      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 3610        |
|    policy_gradient_loss  | -0.00397    |
|    std                   | 0.914       |
|    value_loss            | 2.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.86         |
| reward                   | -0.43299124  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 13           |
|    time_elapsed          | 5572         |
|    total_timesteps       | 729088       |
| train/                   |              |
|    approx_kl             | 0.0058364496 |
|    clip_fraction         | 0.0334       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.79         |
|    cost_value_loss       | 80.2         |
|    cost_values           | 2.79         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0.011        |
|    learning_rate         | 0.0003       |
|    loss                  | 8.56         |
|    n_updates             | 3550         |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.787        |
|    value_loss            | 2.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0941      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0941      |
| reward                   | -0.25177696 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -715        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 18          |
|    time_elapsed          | 7898        |
|    total_timesteps       | 739328      |
| train/                   |             |
|    approx_kl             | 0.009540997 |
|    clip_fraction         | 0.0648      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 133         |
|    cost_values           | 3           |
|    entropy               | -2.48       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0.00659     |
|    learning_rate         | 0.0003      |
|    loss                  | 16.8        |
|    n_updates             | 3600        |
|    policy_gradient_loss  | -0.00543    |
|    std                   | 0.837       |
|    value_loss            | 1.18        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0481       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0481       |
| reward                   | -0.49150813  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 25           |
|    time_elapsed          | 10498        |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0022678296 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.6         |
|    cost_value_loss       | 165          |
|    cost_values           | 1.05         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.891        |
|    lagrangian_multiplier | 0.0142       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.844        |
|    value_loss            | 0.626        |
-------------------------------------------
-----------------------------------------
| avg_speed                | 6.57       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.57       |
| reward                   | -0.3868981 |
| rollout/                 |            |
|    ep_len_mean           | 665        |
|    ep_rew_mean           | -295       |
| time/                    |            |
|    fps                   | 4          |
|    iterations            | 17         |
|    time_elapsed          | 7780       |
|    total_timesteps       | 737280     |
| train/                   |            |
|    approx_kl             | 0.00973226 |
|    clip_fraction         | 0.0814     |
|    clip_range            | 0.2        |
|    cost_returns          | 6.72       |
|    cost_value_loss       | 24.1       |
|    cost_values           | 2.46       |
|    entropy               | -1.77      |
|    entropy_loss          | -1.77      |
|    explained_variance    | 0.326      |
|    lagrangian_multiplier | 0.00347    |
|    learning_rate         | 0.0003     |
|    loss                  | 8.97       |
|    n_updates             | 3590       |
|    policy_gradient_loss  | -0.00599   |
|    std                   | 0.592      |
|    value_loss            | 19.2       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.168        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.168        |
| reward                   | -0.57372934  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 37           |
|    time_elapsed          | 15360        |
|    total_timesteps       | 778240       |
| train/                   |              |
|    approx_kl             | 0.0077456017 |
|    clip_fraction         | 0.09         |
|    clip_range            | 0.2          |
|    cost_returns          | 3.93         |
|    cost_value_loss       | 41.1         |
|    cost_values           | 1.31         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.84         |
|    lagrangian_multiplier | 0.0105       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.94         |
|    n_updates             | 3790         |
|    policy_gradient_loss  | -0.00402     |
|    std                   | 0.778        |
|    value_loss            | 1.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00227      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00227      |
| reward                   | -0.3482183   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 20           |
|    time_elapsed          | 7969         |
|    total_timesteps       | 743424       |
| train/                   |              |
|    approx_kl             | 0.0023881495 |
|    clip_fraction         | 0.00313      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.36         |
|    cost_value_loss       | 79.9         |
|    cost_values           | 1.16         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.612        |
|    lagrangian_multiplier | 0.000563     |
|    learning_rate         | 0.0003       |
|    loss                  | 31.3         |
|    n_updates             | 3620         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.914        |
|    value_loss            | 3.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.47         |
| reward                   | -0.3522582   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 14           |
|    time_elapsed          | 6006         |
|    total_timesteps       | 731136       |
| train/                   |              |
|    approx_kl             | 0.0062146755 |
|    clip_fraction         | 0.0397       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.55         |
|    cost_value_loss       | 32           |
|    cost_values           | 2.7          |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.916        |
|    lagrangian_multiplier | 0.00534      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.4          |
|    n_updates             | 3560         |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 0.786        |
|    value_loss            | 1.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0646       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0646       |
| reward                   | -0.28809452  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -712         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 19           |
|    time_elapsed          | 8346         |
|    total_timesteps       | 741376       |
| train/                   |              |
|    approx_kl             | 0.0071427315 |
|    clip_fraction         | 0.092        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 166          |
|    cost_values           | 3            |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0.0242       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.94         |
|    n_updates             | 3610         |
|    policy_gradient_loss  | -0.00775     |
|    std                   | 0.837        |
|    value_loss            | 0.546        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0298      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0298      |
| reward                   | -0.4322246  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 26          |
|    time_elapsed          | 10936       |
|    total_timesteps       | 755712      |
| train/                   |             |
|    approx_kl             | 0.004143131 |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 7.99        |
|    cost_values           | 0.531       |
|    entropy               | -2.48       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0.00103     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.93        |
|    n_updates             | 3680        |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.839       |
|    value_loss            | 0.228       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0141       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0141       |
| reward                   | -0.36410964  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 38           |
|    time_elapsed          | 15799        |
|    total_timesteps       | 780288       |
| train/                   |              |
|    approx_kl             | 0.0018448846 |
|    clip_fraction         | 0.0132       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.24         |
|    cost_value_loss       | 56.1         |
|    cost_values           | 1.51         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.874        |
|    lagrangian_multiplier | 0.00638      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.63         |
|    n_updates             | 3800         |
|    policy_gradient_loss  | -0.00211     |
|    std                   | 0.777        |
|    value_loss            | 1.86         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.58        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.58        |
| reward                   | -0.39767113 |
| rollout/                 |             |
|    ep_len_mean           | 666         |
|    ep_rew_mean           | -295        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 18          |
|    time_elapsed          | 8255        |
|    total_timesteps       | 739328      |
| train/                   |             |
|    approx_kl             | 0.00839291  |
|    clip_fraction         | 0.0974      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.76        |
|    cost_value_loss       | 23.7        |
|    cost_values           | 2.49        |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.243       |
|    lagrangian_multiplier | 0.012       |
|    learning_rate         | 0.0003      |
|    loss                  | 5.53        |
|    n_updates             | 3600        |
|    policy_gradient_loss  | -0.0056     |
|    std                   | 0.59        |
|    value_loss            | 25.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0577      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0577      |
| reward                   | -0.43445215 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 21          |
|    time_elapsed          | 8379        |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.006633726 |
|    clip_fraction         | 0.0527      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.95        |
|    cost_value_loss       | 132         |
|    cost_values           | 1.45        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | -0.355      |
|    lagrangian_multiplier | 0.0229      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.88        |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.0054     |
|    std                   | 0.914       |
|    value_loss            | 1.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.122        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.122        |
| reward                   | -0.28768176  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 15           |
|    time_elapsed          | 6443         |
|    total_timesteps       | 733184       |
| train/                   |              |
|    approx_kl             | 0.0041582794 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.71         |
|    cost_value_loss       | 52.7         |
|    cost_values           | 2.48         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.869        |
|    lagrangian_multiplier | 0.00429      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 3570         |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 0.786        |
|    value_loss            | 1.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.125        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.125        |
| reward                   | -0.38310537  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -708         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 20           |
|    time_elapsed          | 8793         |
|    total_timesteps       | 743424       |
| train/                   |              |
|    approx_kl             | 0.0117152175 |
|    clip_fraction         | 0.0805       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.4         |
|    cost_value_loss       | 212          |
|    cost_values           | 3            |
|    entropy               | -2.49        |
|    entropy_loss          | -2.48        |
|    explained_variance    | -0.212       |
|    lagrangian_multiplier | 0.041        |
|    learning_rate         | 0.0003       |
|    loss                  | 7.78         |
|    n_updates             | 3620         |
|    policy_gradient_loss  | -0.00329     |
|    std                   | 0.839        |
|    value_loss            | 0.445        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.125        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.125        |
| reward                   | -0.54336387  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -468         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 27           |
|    time_elapsed          | 11374        |
|    total_timesteps       | 757760       |
| train/                   |              |
|    approx_kl             | 0.0054819556 |
|    clip_fraction         | 0.0402       |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 68.3         |
|    cost_values           | 0.726        |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.852        |
|    lagrangian_multiplier | 0.00784      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.85         |
|    n_updates             | 3690         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.835        |
|    value_loss            | 2.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0791       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0791       |
| reward                   | -0.46878123  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 39           |
|    time_elapsed          | 16234        |
|    total_timesteps       | 782336       |
| train/                   |              |
|    approx_kl             | 0.0025307622 |
|    clip_fraction         | 0.00229      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.4          |
|    cost_value_loss       | 107          |
|    cost_values           | 1.58         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.836        |
|    lagrangian_multiplier | 0.0123       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.96         |
|    n_updates             | 3810         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.777        |
|    value_loss            | 1.88         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30401796 |
| rollout/                 |             |
|    ep_len_mean           | 671         |
|    ep_rew_mean           | -296        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 19          |
|    time_elapsed          | 8732        |
|    total_timesteps       | 741376      |
| train/                   |             |
|    approx_kl             | 0.009375367 |
|    clip_fraction         | 0.0793      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.41        |
|    cost_value_loss       | 24          |
|    cost_values           | 2.41        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.431       |
|    lagrangian_multiplier | 0.00761     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.52        |
|    n_updates             | 3610        |
|    policy_gradient_loss  | -0.00472    |
|    std                   | 0.588       |
|    value_loss            | 12.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0466       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0466       |
| reward                   | -0.4266495   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 22           |
|    time_elapsed          | 8790         |
|    total_timesteps       | 747520       |
| train/                   |              |
|    approx_kl             | 0.0046053547 |
|    clip_fraction         | 0.0371       |
|    clip_range            | 0.2          |
|    cost_returns          | 11           |
|    cost_value_loss       | 146          |
|    cost_values           | 1.37         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.803        |
|    lagrangian_multiplier | 0.0149       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.73         |
|    n_updates             | 3640         |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 0.913        |
|    value_loss            | 0.778        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.123       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.123       |
| reward                   | -0.2264291  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 16          |
|    time_elapsed          | 6874        |
|    total_timesteps       | 735232      |
| train/                   |             |
|    approx_kl             | 0.003969229 |
|    clip_fraction         | 0.0263      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.7         |
|    cost_value_loss       | 34.2        |
|    cost_values           | 2.36        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.744       |
|    lagrangian_multiplier | 0.00133     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 3580        |
|    policy_gradient_loss  | -0.00297    |
|    std                   | 0.788       |
|    value_loss            | 2.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0578      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0578      |
| reward                   | -0.29130414 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -709        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 21          |
|    time_elapsed          | 9246        |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.009628585 |
|    clip_fraction         | 0.08        |
|    clip_range            | 0.2         |
|    cost_returns          | 7.52        |
|    cost_value_loss       | 57          |
|    cost_values           | 2.99        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0.00837     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.89        |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.00692    |
|    std                   | 0.836       |
|    value_loss            | 0.452       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.247        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.247        |
| reward                   | -0.44504586  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -469         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 28           |
|    time_elapsed          | 11813        |
|    total_timesteps       | 759808       |
| train/                   |              |
|    approx_kl             | 0.0041813594 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.78         |
|    cost_value_loss       | 93.8         |
|    cost_values           | 0.919        |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0.01         |
|    learning_rate         | 0.0003       |
|    loss                  | 8.74         |
|    n_updates             | 3700         |
|    policy_gradient_loss  | -0.00421     |
|    std                   | 0.834        |
|    value_loss            | 1.24         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.146        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.146        |
| reward                   | -0.39495358  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 40           |
|    time_elapsed          | 16671        |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0028083469 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.38         |
|    cost_value_loss       | 43.2         |
|    cost_values           | 1.53         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | -1.32        |
|    lagrangian_multiplier | 0.00501      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.78         |
|    n_updates             | 3820         |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.778        |
|    value_loss            | 3.65         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.149       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.149       |
| reward                   | -0.51276547 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 23          |
|    time_elapsed          | 9207        |
|    total_timesteps       | 749568      |
| train/                   |             |
|    approx_kl             | 0.004926627 |
|    clip_fraction         | 0.0106      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 202         |
|    cost_values           | 1.69        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0.0211      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 3650        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.913       |
|    value_loss            | 0.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.08        |
| reward                   | -0.475972   |
| rollout/                 |             |
|    ep_len_mean           | 667         |
|    ep_rew_mean           | -293        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 20          |
|    time_elapsed          | 9211        |
|    total_timesteps       | 743424      |
| train/                   |             |
|    approx_kl             | 0.006114146 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 13.6        |
|    cost_values           | 2.46        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.656       |
|    lagrangian_multiplier | 0.00509     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.43        |
|    n_updates             | 3620        |
|    policy_gradient_loss  | -0.00588    |
|    std                   | 0.588       |
|    value_loss            | 5.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.267       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.267       |
| reward                   | -0.39652094 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 17          |
|    time_elapsed          | 7306        |
|    total_timesteps       | 737280      |
| train/                   |             |
|    approx_kl             | 0.003599244 |
|    clip_fraction         | 0.00479     |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 117         |
|    cost_values           | 2.71        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | -0.155      |
|    lagrangian_multiplier | 0.00258     |
|    learning_rate         | 0.0003      |
|    loss                  | 28.7        |
|    n_updates             | 3590        |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.788       |
|    value_loss            | 4.88        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.232        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.232        |
| reward                   | -0.54572356  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 22           |
|    time_elapsed          | 9698         |
|    total_timesteps       | 747520       |
| train/                   |              |
|    approx_kl             | 0.0059236647 |
|    clip_fraction         | 0.0588       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.19         |
|    cost_value_loss       | 50.6         |
|    cost_values           | 3            |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0.0119       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.13         |
|    n_updates             | 3640         |
|    policy_gradient_loss  | -0.00202     |
|    std                   | 0.838        |
|    value_loss            | 0.528        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0224       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0224       |
| reward                   | -0.35006937  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -470         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 29           |
|    time_elapsed          | 12249        |
|    total_timesteps       | 761856       |
| train/                   |              |
|    approx_kl             | 0.0047970824 |
|    clip_fraction         | 0.0123       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.932        |
|    cost_value_loss       | 0.844        |
|    cost_values           | 0.903        |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.821        |
|    n_updates             | 3710         |
|    policy_gradient_loss  | -0.000342    |
|    std                   | 0.833        |
|    value_loss            | 1.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0321       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0321       |
| reward                   | -0.48982653  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 41           |
|    time_elapsed          | 17106        |
|    total_timesteps       | 786432       |
| train/                   |              |
|    approx_kl             | 0.0061379564 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.9          |
|    cost_value_loss       | 66.9         |
|    cost_values           | 1.68         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0.00841      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.02         |
|    n_updates             | 3830         |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.778        |
|    value_loss            | 0.7          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.384       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.384       |
| reward                   | -0.5739763  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 24          |
|    time_elapsed          | 9622        |
|    total_timesteps       | 751616      |
| train/                   |             |
|    approx_kl             | 0.011000995 |
|    clip_fraction         | 0.0909      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 183         |
|    cost_values           | 1.72        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.799       |
|    lagrangian_multiplier | 0.0152      |
|    learning_rate         | 0.0003      |
|    loss                  | 12.5        |
|    n_updates             | 3660        |
|    policy_gradient_loss  | -0.00845    |
|    std                   | 0.912       |
|    value_loss            | 0.867       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.52        |
| reward                   | -0.6121301  |
| rollout/                 |             |
|    ep_len_mean           | 664         |
|    ep_rew_mean           | -292        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 21          |
|    time_elapsed          | 9685        |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.009390743 |
|    clip_fraction         | 0.0965      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 2.49        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.512       |
|    lagrangian_multiplier | 0.00746     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.63        |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.00621    |
|    std                   | 0.587       |
|    value_loss            | 19.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.109       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.109       |
| reward                   | -0.29642114 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 18          |
|    time_elapsed          | 7743        |
|    total_timesteps       | 739328      |
| train/                   |             |
|    approx_kl             | 0.008453101 |
|    clip_fraction         | 0.0537      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.72        |
|    cost_value_loss       | 97.2        |
|    cost_values           | 2.97        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.333       |
|    lagrangian_multiplier | 0.0137      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.23        |
|    n_updates             | 3600        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.789       |
|    value_loss            | 2.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.418       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.418       |
| reward                   | -0.40946034 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -695        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 23          |
|    time_elapsed          | 10147       |
|    total_timesteps       | 749568      |
| train/                   |             |
|    approx_kl             | 0.004086272 |
|    clip_fraction         | 0.0321      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.27        |
|    cost_value_loss       | 37.2        |
|    cost_values           | 2.99        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0.00917     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.07        |
|    n_updates             | 3650        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.836       |
|    value_loss            | 1.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.114        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.114        |
| reward                   | -0.43345806  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 30           |
|    time_elapsed          | 12690        |
|    total_timesteps       | 763904       |
| train/                   |              |
|    approx_kl             | 0.0018876081 |
|    clip_fraction         | 0.00703      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.14         |
|    cost_value_loss       | 70.2         |
|    cost_values           | 0.807        |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.658        |
|    lagrangian_multiplier | 0.00952      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.21         |
|    n_updates             | 3720         |
|    policy_gradient_loss  | 0.000363     |
|    std                   | 0.832        |
|    value_loss            | 1.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0606       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0606       |
| reward                   | -0.46647385  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 25           |
|    time_elapsed          | 10043        |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0086541455 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 15.8         |
|    cost_value_loss       | 210          |
|    cost_values           | 2.04         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0.00161      |
|    learning_rate         | 0.0003       |
|    loss                  | 57.9         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.00615     |
|    std                   | 0.911        |
|    value_loss            | 0.723        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.036        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.036        |
| reward                   | -0.55202717  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 42           |
|    time_elapsed          | 17547        |
|    total_timesteps       | 788480       |
| train/                   |              |
|    approx_kl             | 0.0038212244 |
|    clip_fraction         | 0.0186       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.1         |
|    cost_value_loss       | 161          |
|    cost_values           | 2.03         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.832        |
|    lagrangian_multiplier | 0.0161       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 3840         |
|    policy_gradient_loss  | -0.00392     |
|    std                   | 0.779        |
|    value_loss            | 0.827        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.48540023 |
| rollout/                 |             |
|    ep_len_mean           | 666         |
|    ep_rew_mean           | -293        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 22          |
|    time_elapsed          | 10167       |
|    total_timesteps       | 747520      |
| train/                   |             |
|    approx_kl             | 0.009458318 |
|    clip_fraction         | 0.0647      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.39        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 2.35        |
|    entropy               | -1.74       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.246       |
|    lagrangian_multiplier | 0.00424     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.04        |
|    n_updates             | 3640        |
|    policy_gradient_loss  | -0.00452    |
|    std                   | 0.586       |
|    value_loss            | 14.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.157       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.157       |
| reward                   | -0.5556602  |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 19          |
|    time_elapsed          | 8180        |
|    total_timesteps       | 741376      |
| train/                   |             |
|    approx_kl             | 0.011144701 |
|    clip_fraction         | 0.0965      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 107         |
|    cost_values           | 2.92        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.345       |
|    lagrangian_multiplier | 0.0131      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.63        |
|    n_updates             | 3610        |
|    policy_gradient_loss  | -0.00597    |
|    std                   | 0.789       |
|    value_loss            | 1.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0906      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0906      |
| reward                   | -0.3218303  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -692        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 24          |
|    time_elapsed          | 10600       |
|    total_timesteps       | 751616      |
| train/                   |             |
|    approx_kl             | 0.009001495 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.7        |
|    cost_value_loss       | 105         |
|    cost_values           | 2.99        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.0251      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.37        |
|    n_updates             | 3660        |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 0.837       |
|    value_loss            | 0.456       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.241        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.241        |
| reward                   | -0.25682378  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -474         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 31           |
|    time_elapsed          | 13131        |
|    total_timesteps       | 765952       |
| train/                   |              |
|    approx_kl             | 0.0037115621 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.2          |
|    cost_value_loss       | 91           |
|    cost_values           | 1.41         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.904        |
|    lagrangian_multiplier | 0.0162       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.28         |
|    n_updates             | 3730         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.832        |
|    value_loss            | 0.878        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.249         |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.249         |
| reward                   | -0.28490245   |
| rollout/                 |               |
|    ep_len_mean           | 983           |
|    ep_rew_mean           | -402          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 26            |
|    time_elapsed          | 10461         |
|    total_timesteps       | 755712        |
| train/                   |               |
|    approx_kl             | 0.00051674456 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 9.19          |
|    cost_value_loss       | 107           |
|    cost_values           | 1.84          |
|    entropy               | -2.65         |
|    entropy_loss          | -2.65         |
|    explained_variance    | 0.872         |
|    lagrangian_multiplier | 0.0322        |
|    learning_rate         | 0.0003        |
|    loss                  | 4.88          |
|    n_updates             | 3680          |
|    policy_gradient_loss  | -0.000917     |
|    std                   | 0.911         |
|    value_loss            | 2.11          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.1          |
| reward                   | -0.51180017  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 43           |
|    time_elapsed          | 17990        |
|    total_timesteps       | 790528       |
| train/                   |              |
|    approx_kl             | 0.0014348647 |
|    clip_fraction         | 0.000244     |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 135          |
|    cost_values           | 1.84         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0.0151       |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 3850         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.779        |
|    value_loss            | 2.1          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0196       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0196       |
| reward                   | -0.48795643  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 20           |
|    time_elapsed          | 8621         |
|    total_timesteps       | 743424       |
| train/                   |              |
|    approx_kl             | 0.0032003247 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.62         |
|    cost_value_loss       | 44.1         |
|    cost_values           | 2.87         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -0.681       |
|    lagrangian_multiplier | 0.00567      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.28         |
|    n_updates             | 3620         |
|    policy_gradient_loss  | -0.000532    |
|    std                   | 0.787        |
|    value_loss            | 4.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.26784608  |
| rollout/                 |              |
|    ep_len_mean           | 677          |
|    ep_rew_mean           | -298         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 23           |
|    time_elapsed          | 10652        |
|    total_timesteps       | 749568       |
| train/                   |              |
|    approx_kl             | 0.0059891776 |
|    clip_fraction         | 0.0789       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.53         |
|    cost_value_loss       | 20.1         |
|    cost_values           | 2.14         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0.369        |
|    lagrangian_multiplier | 0.00795      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.27         |
|    n_updates             | 3650         |
|    policy_gradient_loss  | -0.00743     |
|    std                   | 0.584        |
|    value_loss            | 5.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0908       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0908       |
| reward                   | -0.4617984   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -473         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 32           |
|    time_elapsed          | 13563        |
|    total_timesteps       | 768000       |
| train/                   |              |
|    approx_kl             | 0.0058925566 |
|    clip_fraction         | 0.0825       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.683        |
|    cost_value_loss       | 0.0214       |
|    cost_values           | 0.695        |
|    entropy               | -2.44        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.845        |
|    lagrangian_multiplier | 0.000626     |
|    learning_rate         | 0.0003       |
|    loss                  | 0.364        |
|    n_updates             | 3740         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 0.822        |
|    value_loss            | 0.0719       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.172        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.172        |
| reward                   | -0.36904946  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 27           |
|    time_elapsed          | 10874        |
|    total_timesteps       | 757760       |
| train/                   |              |
|    approx_kl             | 0.0129107665 |
|    clip_fraction         | 0.116        |
|    clip_range            | 0.2          |
|    cost_returns          | 9.36         |
|    cost_value_loss       | 96.8         |
|    cost_values           | 1.6          |
|    entropy               | -2.65        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.9          |
|    lagrangian_multiplier | 2.32e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 47.3         |
|    n_updates             | 3690         |
|    policy_gradient_loss  | -0.01        |
|    std                   | 0.911        |
|    value_loss            | 1.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.257       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.257       |
| reward                   | -0.5010954  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -695        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 25          |
|    time_elapsed          | 11054       |
|    total_timesteps       | 753664      |
| train/                   |             |
|    approx_kl             | 0.013287088 |
|    clip_fraction         | 0.0846      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.68        |
|    cost_value_loss       | 6.11        |
|    cost_values           | 2.94        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.48       |
|    explained_variance    | -0.542      |
|    lagrangian_multiplier | 0.000838    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.33        |
|    n_updates             | 3670        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.834       |
|    value_loss            | 2.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.202        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.202        |
| reward                   | -0.45539615  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 44           |
|    time_elapsed          | 18429        |
|    total_timesteps       | 792576       |
| train/                   |              |
|    approx_kl             | 0.0047365506 |
|    clip_fraction         | 0.00723      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 192          |
|    cost_values           | 2.23         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0.0152       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 3860         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.779        |
|    value_loss            | 0.952        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00355      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00355      |
| reward                   | -0.52308154  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 21           |
|    time_elapsed          | 9063         |
|    total_timesteps       | 745472       |
| train/                   |              |
|    approx_kl             | 0.0044729877 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.73         |
|    cost_value_loss       | 94.4         |
|    cost_values           | 2.78         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.235        |
|    lagrangian_multiplier | 0.0134       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.71         |
|    n_updates             | 3630         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.785        |
|    value_loss            | 3.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -0.5373653  |
| rollout/                 |             |
|    ep_len_mean           | 679         |
|    ep_rew_mean           | -298        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 24          |
|    time_elapsed          | 11137       |
|    total_timesteps       | 751616      |
| train/                   |             |
|    approx_kl             | 0.017077524 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 16.8        |
|    cost_values           | 2.23        |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0.293       |
|    lagrangian_multiplier | 0.00567     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.71        |
|    n_updates             | 3660        |
|    policy_gradient_loss  | -0.00827    |
|    std                   | 0.585       |
|    value_loss            | 7.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.104       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.104       |
| reward                   | -0.5292386  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -472        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 33          |
|    time_elapsed          | 14005       |
|    total_timesteps       | 770048      |
| train/                   |             |
|    approx_kl             | 0.003063601 |
|    clip_fraction         | 0.0392      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.44        |
|    cost_value_loss       | 42.3        |
|    cost_values           | 0.79        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.00507     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.98        |
|    n_updates             | 3750        |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.819       |
|    value_loss            | 0.783       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0101      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0101      |
| reward                   | -0.53559166 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 28          |
|    time_elapsed          | 11296       |
|    total_timesteps       | 759808      |
| train/                   |             |
|    approx_kl             | 0.005541962 |
|    clip_fraction         | 0.0491      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.82        |
|    cost_value_loss       | 62.3        |
|    cost_values           | 1.37        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0.00422     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 3700        |
|    policy_gradient_loss  | -0.00279    |
|    std                   | 0.91        |
|    value_loss            | 0.518       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.03        |
| reward                   | -0.2942642  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -699        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 26          |
|    time_elapsed          | 11506       |
|    total_timesteps       | 755712      |
| train/                   |             |
|    approx_kl             | 0.007829696 |
|    clip_fraction         | 0.264       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.53        |
|    cost_value_loss       | 68.7        |
|    cost_values           | 2.99        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.00901     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.1         |
|    n_updates             | 3680        |
|    policy_gradient_loss  | 0.0239      |
|    std                   | 0.831       |
|    value_loss            | 1.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.203        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.203        |
| reward                   | -0.3161773   |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 45           |
|    time_elapsed          | 18873        |
|    total_timesteps       | 794624       |
| train/                   |              |
|    approx_kl             | 0.0043157227 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.5         |
|    cost_value_loss       | 146          |
|    cost_values           | 2.09         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.512        |
|    lagrangian_multiplier | 0.016        |
|    learning_rate         | 0.0003       |
|    loss                  | 9.9          |
|    n_updates             | 3870         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.778        |
|    value_loss            | 0.744        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0913      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0913      |
| reward                   | -0.39991722 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 22          |
|    time_elapsed          | 9507        |
|    total_timesteps       | 747520      |
| train/                   |             |
|    approx_kl             | 0.007758528 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 5.37        |
|    cost_values           | 2.67        |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.502       |
|    lagrangian_multiplier | 0.000202    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.63        |
|    n_updates             | 3640        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.784       |
|    value_loss            | 6.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.4595488  |
| rollout/                 |             |
|    ep_len_mean           | 673         |
|    ep_rew_mean           | -295        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 25          |
|    time_elapsed          | 11624       |
|    total_timesteps       | 753664      |
| train/                   |             |
|    approx_kl             | 0.007400305 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.7         |
|    cost_value_loss       | 29.2        |
|    cost_values           | 2.56        |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | -0.0598     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.5        |
|    n_updates             | 3670        |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 0.585       |
|    value_loss            | 2.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.083       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.083       |
| reward                   | -0.35434648 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 29          |
|    time_elapsed          | 11717       |
|    total_timesteps       | 761856      |
| train/                   |             |
|    approx_kl             | 0.003164117 |
|    clip_fraction         | 0.0483      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.26        |
|    cost_value_loss       | 84          |
|    cost_values           | 1.61        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.709       |
|    lagrangian_multiplier | 0.00914     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.4         |
|    n_updates             | 3710        |
|    policy_gradient_loss  | -0.0023     |
|    std                   | 0.91        |
|    value_loss            | 1.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0607       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0607       |
| reward                   | -0.44459802  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 34           |
|    time_elapsed          | 14447        |
|    total_timesteps       | 772096       |
| train/                   |              |
|    approx_kl             | 0.0016815781 |
|    clip_fraction         | 0.00732      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.88         |
|    cost_value_loss       | 72.2         |
|    cost_values           | 1.27         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.794        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.3         |
|    n_updates             | 3760         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.818        |
|    value_loss            | 2.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0444       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0444       |
| reward                   | -0.4480147   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -686         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 27           |
|    time_elapsed          | 11958        |
|    total_timesteps       | 757760       |
| train/                   |              |
|    approx_kl             | 0.0011985705 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.9         |
|    cost_value_loss       | 189          |
|    cost_values           | 3            |
|    entropy               | -2.46        |
|    entropy_loss          | -2.47        |
|    explained_variance    | -0.244       |
|    lagrangian_multiplier | 0.0647       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.69         |
|    n_updates             | 3690         |
|    policy_gradient_loss  | -0.000768    |
|    std                   | 0.83         |
|    value_loss            | 2.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0163      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0163      |
| reward                   | -0.18895046 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 46          |
|    time_elapsed          | 19319       |
|    total_timesteps       | 796672      |
| train/                   |             |
|    approx_kl             | 0.00499785  |
|    clip_fraction         | 0.021       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.26        |
|    cost_value_loss       | 90          |
|    cost_values           | 1.77        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0.011       |
|    learning_rate         | 0.0003      |
|    loss                  | 8.88        |
|    n_updates             | 3880        |
|    policy_gradient_loss  | -0.00122    |
|    std                   | 0.778       |
|    value_loss            | 1.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.099        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.099        |
| reward                   | -0.29714322  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 23           |
|    time_elapsed          | 9950         |
|    total_timesteps       | 749568       |
| train/                   |              |
|    approx_kl             | 0.0046301982 |
|    clip_fraction         | 0.0367       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.06         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 2.39         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.434        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.82         |
|    n_updates             | 3650         |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.784        |
|    value_loss            | 1.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.179        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.179        |
| reward                   | -0.43693483  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 30           |
|    time_elapsed          | 12138        |
|    total_timesteps       | 763904       |
| train/                   |              |
|    approx_kl             | 0.0035455357 |
|    clip_fraction         | 0.0346       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.3         |
|    cost_value_loss       | 138          |
|    cost_values           | 1.68         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.308        |
|    lagrangian_multiplier | 0.0131       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 3720         |
|    policy_gradient_loss  | -0.00574     |
|    std                   | 0.907        |
|    value_loss            | 1.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.59         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.59         |
| reward                   | -0.5241421   |
| rollout/                 |              |
|    ep_len_mean           | 687          |
|    ep_rew_mean           | -301         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 26           |
|    time_elapsed          | 12115        |
|    total_timesteps       | 755712       |
| train/                   |              |
|    approx_kl             | 0.0077196583 |
|    clip_fraction         | 0.0687       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.18         |
|    cost_value_loss       | 22.6         |
|    cost_values           | 2.87         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | -0.0142      |
|    lagrangian_multiplier | 0.00699      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.69         |
|    n_updates             | 3680         |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 0.585        |
|    value_loss            | 25.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00282     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00282     |
| reward                   | -0.44233045 |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -478        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 35          |
|    time_elapsed          | 14887       |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.005058464 |
|    clip_fraction         | 0.0187      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.06        |
|    cost_value_loss       | 105         |
|    cost_values           | 1.38        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.0116      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.51        |
|    n_updates             | 3770        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.819       |
|    value_loss            | 1.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.211        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.211        |
| reward                   | -0.3581184   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 28           |
|    time_elapsed          | 12411        |
|    total_timesteps       | 759808       |
| train/                   |              |
|    approx_kl             | 0.0050323466 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.5         |
|    cost_value_loss       | 81.6         |
|    cost_values           | 2.99         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.834        |
|    lagrangian_multiplier | 0.00144      |
|    learning_rate         | 0.0003       |
|    loss                  | 25.2         |
|    n_updates             | 3700         |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.83         |
|    value_loss            | 0.415        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0823       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0823       |
| reward                   | -0.319023    |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -399         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 47           |
|    time_elapsed          | 19769        |
|    total_timesteps       | 798720       |
| train/                   |              |
|    approx_kl             | 0.0059948387 |
|    clip_fraction         | 0.0369       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.3         |
|    cost_value_loss       | 132          |
|    cost_values           | 1.99         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.71         |
|    lagrangian_multiplier | 0.0169       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.75         |
|    n_updates             | 3890         |
|    policy_gradient_loss  | -0.00185     |
|    std                   | 0.778        |
|    value_loss            | 1.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.158       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.158       |
| reward                   | -0.26399168 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 24          |
|    time_elapsed          | 10392       |
|    total_timesteps       | 751616      |
| train/                   |             |
|    approx_kl             | 0.009189477 |
|    clip_fraction         | 0.0773      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.15        |
|    cost_value_loss       | 101         |
|    cost_values           | 2.55        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.00859     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.9        |
|    n_updates             | 3660        |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 0.78        |
|    value_loss            | 0.507       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.136       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.136       |
| reward                   | -0.43339804 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 31          |
|    time_elapsed          | 12559       |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.005787418 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.69        |
|    cost_value_loss       | 64.9        |
|    cost_values           | 1.36        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0.00503     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 0.907       |
|    value_loss            | 1.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0463       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0463       |
| reward                   | -0.55673134  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 36           |
|    time_elapsed          | 15333        |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0013843735 |
|    clip_fraction         | 0.0651       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.701        |
|    cost_value_loss       | 0.898        |
|    cost_values           | 0.55         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.68         |
|    lagrangian_multiplier | 7.45e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 0.81         |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.814        |
|    value_loss            | 0.516        |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.39        |
| reward                   | -0.25718987 |
| rollout/                 |             |
|    ep_len_mean           | 663         |
|    ep_rew_mean           | -286        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 27          |
|    time_elapsed          | 12602       |
|    total_timesteps       | 757760      |
| train/                   |             |
|    approx_kl             | 0.01525669  |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.42        |
|    cost_value_loss       | 23.8        |
|    cost_values           | 2.96        |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0.111       |
|    lagrangian_multiplier | 0.00749     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.71        |
|    n_updates             | 3690        |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 0.585       |
|    value_loss            | 13.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0711      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0711      |
| reward                   | -0.40849304 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -669        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 29          |
|    time_elapsed          | 12870       |
|    total_timesteps       | 761856      |
| train/                   |             |
|    approx_kl             | 0.010375858 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 126         |
|    cost_values           | 2.99        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.0157      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.6         |
|    n_updates             | 3710        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.829       |
|    value_loss            | 0.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0664       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0664       |
| reward                   | -0.50440085  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 48           |
|    time_elapsed          | 20208        |
|    total_timesteps       | 800768       |
| train/                   |              |
|    approx_kl             | 0.0005772627 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 9.05         |
|    cost_value_loss       | 114          |
|    cost_values           | 1.98         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.801        |
|    lagrangian_multiplier | 0.0145       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.23         |
|    n_updates             | 3900         |
|    policy_gradient_loss  | 0.000304     |
|    std                   | 0.778        |
|    value_loss            | 6.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.179        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.179        |
| reward                   | -0.44122064  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 25           |
|    time_elapsed          | 10832        |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0054924563 |
|    clip_fraction         | 0.0675       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.1          |
|    cost_value_loss       | 38.4         |
|    cost_values           | 2.42         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.87         |
|    lagrangian_multiplier | 0.00412      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.17         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.00475     |
|    std                   | 0.779        |
|    value_loss            | 2.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0255      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0255      |
| reward                   | -0.48369756 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 32          |
|    time_elapsed          | 12986       |
|    total_timesteps       | 768000      |
| train/                   |             |
|    approx_kl             | 0.003500082 |
|    clip_fraction         | 0.00342     |
|    clip_range            | 0.2         |
|    cost_returns          | 16.1        |
|    cost_value_loss       | 222         |
|    cost_values           | 1.76        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.549       |
|    lagrangian_multiplier | 0.000645    |
|    learning_rate         | 0.0003      |
|    loss                  | 80.7        |
|    n_updates             | 3740        |
|    policy_gradient_loss  | -0.002      |
|    std                   | 0.907       |
|    value_loss            | 0.842       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0583       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0583       |
| reward                   | -0.432245    |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 37           |
|    time_elapsed          | 15779        |
|    total_timesteps       | 778240       |
| train/                   |              |
|    approx_kl             | 0.0037739498 |
|    clip_fraction         | 0.0679       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.63         |
|    cost_value_loss       | 47.5         |
|    cost_values           | 0.72         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.42        |
|    explained_variance    | -0.367       |
|    lagrangian_multiplier | 0.00486      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.46         |
|    n_updates             | 3790         |
|    policy_gradient_loss  | 0.0024       |
|    std                   | 0.812        |
|    value_loss            | 4.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.42704463 |
| rollout/                 |             |
|    ep_len_mean           | 655         |
|    ep_rew_mean           | -281        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 28          |
|    time_elapsed          | 13091       |
|    total_timesteps       | 759808      |
| train/                   |             |
|    approx_kl             | 0.012894852 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.67        |
|    cost_value_loss       | 28.5        |
|    cost_values           | 2.96        |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0.0903      |
|    lagrangian_multiplier | 0.0103      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.16        |
|    n_updates             | 3700        |
|    policy_gradient_loss  | -0.00251    |
|    std                   | 0.584       |
|    value_loss            | 29.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0853      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0853      |
| reward                   | -0.29429886 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -672        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 30          |
|    time_elapsed          | 13334       |
|    total_timesteps       | 763904      |
| train/                   |             |
|    approx_kl             | 0.003326564 |
|    clip_fraction         | 0.0441      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.94        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 2.88        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.719       |
|    lagrangian_multiplier | 0.0018      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.77        |
|    n_updates             | 3720        |
|    policy_gradient_loss  | -0.000791   |
|    std                   | 0.826       |
|    value_loss            | 1.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00686     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00686     |
| reward                   | -0.30033666 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 49          |
|    time_elapsed          | 20656       |
|    total_timesteps       | 802816      |
| train/                   |             |
|    approx_kl             | 0.003761636 |
|    clip_fraction         | 0.0436      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.53        |
|    cost_value_loss       | 65.3        |
|    cost_values           | 2.09        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.0078      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.42        |
|    n_updates             | 3910        |
|    policy_gradient_loss  | -0.00466    |
|    std                   | 0.781       |
|    value_loss            | 0.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.26833156  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 26           |
|    time_elapsed          | 11280        |
|    total_timesteps       | 755712       |
| train/                   |              |
|    approx_kl             | 0.0048490623 |
|    clip_fraction         | 0.071        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.71         |
|    cost_value_loss       | 8            |
|    cost_values           | 2.45         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.949        |
|    lagrangian_multiplier | 4.64e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.08         |
|    n_updates             | 3680         |
|    policy_gradient_loss  | -0.00475     |
|    std                   | 0.774        |
|    value_loss            | 1.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0244       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0244       |
| reward                   | -0.52414453  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 33           |
|    time_elapsed          | 13411        |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0043879473 |
|    clip_fraction         | 0.00747      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.84         |
|    cost_value_loss       | 114          |
|    cost_values           | 1.57         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0.0142       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.86         |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.908        |
|    value_loss            | 0.816        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0276       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0276       |
| reward                   | -0.34837252  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -466         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 38           |
|    time_elapsed          | 16230        |
|    total_timesteps       | 780288       |
| train/                   |              |
|    approx_kl             | 0.0050985664 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.465        |
|    cost_value_loss       | 0.00634      |
|    cost_values           | 0.473        |
|    entropy               | -2.42        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.685        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.108        |
|    n_updates             | 3800         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.812        |
|    value_loss            | 0.693        |
-------------------------------------------
----------------------------------
| avg_speed          | 0.0514    |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 0.0514    |
| reward             | -0.243418 |
| rollout/           |           |
|    ep_len_mean     | 990       |
|    ep_rew_mean     | -403      |
| time/              |           |
|    fps             | 4         |
|    iterations      | 1         |
|    time_elapsed    | 445       |
|    total_timesteps | 804864    |
----------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.304472    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -673         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 31           |
|    time_elapsed          | 13792        |
|    total_timesteps       | 765952       |
| train/                   |              |
|    approx_kl             | 0.0012776694 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | 18.5         |
|    cost_value_loss       | 248          |
|    cost_values           | 2.94         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | -1.24        |
|    lagrangian_multiplier | 0.0047       |
|    learning_rate         | 0.0003       |
|    loss                  | 38.5         |
|    n_updates             | 3730         |
|    policy_gradient_loss  | 0.000459     |
|    std                   | 0.826        |
|    value_loss            | 1.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.34        |
| reward                   | -0.4626928  |
| rollout/                 |             |
|    ep_len_mean           | 647         |
|    ep_rew_mean           | -278        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 29          |
|    time_elapsed          | 13586       |
|    total_timesteps       | 761856      |
| train/                   |             |
|    approx_kl             | 0.013481846 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.52        |
|    cost_value_loss       | 6.28        |
|    cost_values           | 2.45        |
|    entropy               | -1.73       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 0.041       |
|    lagrangian_multiplier | 0.000836    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.85        |
|    n_updates             | 3710        |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.583       |
|    value_loss            | 6.83        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.207        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.207        |
| reward                   | -0.4660759   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 27           |
|    time_elapsed          | 11731        |
|    total_timesteps       | 757760       |
| train/                   |              |
|    approx_kl             | 0.0067100674 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 7.66         |
|    cost_value_loss       | 80.6         |
|    cost_values           | 2.43         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0.012        |
|    learning_rate         | 0.0003       |
|    loss                  | 8.21         |
|    n_updates             | 3690         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.772        |
|    value_loss            | 1.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.246       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.246       |
| reward                   | -0.3578266  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 34          |
|    time_elapsed          | 13838       |
|    total_timesteps       | 772096      |
| train/                   |             |
|    approx_kl             | 0.007604275 |
|    clip_fraction         | 0.0979      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.92        |
|    cost_value_loss       | 116         |
|    cost_values           | 1.51        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.0116      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.88        |
|    n_updates             | 3760        |
|    policy_gradient_loss  | -0.00966    |
|    std                   | 0.911       |
|    value_loss            | 0.427       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0125      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0125      |
| reward                   | -0.32598016 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -464        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 39          |
|    time_elapsed          | 16680       |
|    total_timesteps       | 782336      |
| train/                   |             |
|    approx_kl             | 0.007060216 |
|    clip_fraction         | 0.0412      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.43        |
|    cost_value_loss       | 73.2        |
|    cost_values           | 0.808       |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0.00755     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.63        |
|    n_updates             | 3810        |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.811       |
|    value_loss            | 0.424       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.259        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.259        |
| reward                   | -0.54880464  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 2            |
|    time_elapsed          | 898          |
|    total_timesteps       | 806912       |
| train/                   |              |
|    approx_kl             | 0.0037795047 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 15.6         |
|    cost_values           | 1.35         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.861        |
|    lagrangian_multiplier | 6.4e-05      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.91         |
|    n_updates             | 3930         |
|    policy_gradient_loss  | -0.00185     |
|    std                   | 0.781        |
|    value_loss            | 2.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.123       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.123       |
| reward                   | -0.5209974  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -653        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 32          |
|    time_elapsed          | 14249       |
|    total_timesteps       | 768000      |
| train/                   |             |
|    approx_kl             | 0.006687372 |
|    clip_fraction         | 0.0586      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.3         |
|    cost_value_loss       | 46.7        |
|    cost_values           | 2.84        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.00531     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.51        |
|    n_updates             | 3740        |
|    policy_gradient_loss  | -0.00543    |
|    std                   | 0.826       |
|    value_loss            | 0.522       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6071051   |
| rollout/                 |              |
|    ep_len_mean           | 634          |
|    ep_rew_mean           | -270         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 30           |
|    time_elapsed          | 14081        |
|    total_timesteps       | 763904       |
| train/                   |              |
|    approx_kl             | 0.0097075645 |
|    clip_fraction         | 0.228        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.89         |
|    cost_value_loss       | 18           |
|    cost_values           | 2.05         |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0.074        |
|    lagrangian_multiplier | 0.000292     |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 3720         |
|    policy_gradient_loss  | 0.00867      |
|    std                   | 0.582        |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.151        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.151        |
| reward                   | -0.5779384   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 28           |
|    time_elapsed          | 12191        |
|    total_timesteps       | 759808       |
| train/                   |              |
|    approx_kl             | 0.0055887555 |
|    clip_fraction         | 0.0634       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.44         |
|    cost_value_loss       | 114          |
|    cost_values           | 2.47         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.935        |
|    lagrangian_multiplier | 0.0115       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 3700         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.772        |
|    value_loss            | 1.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.159        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.159        |
| reward                   | -0.5232145   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 35           |
|    time_elapsed          | 14262        |
|    total_timesteps       | 774144       |
| train/                   |              |
|    approx_kl             | 0.0041835904 |
|    clip_fraction         | 0.0415       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.16         |
|    cost_value_loss       | 29           |
|    cost_values           | 1.29         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.65        |
|    explained_variance    | 0.943        |
|    lagrangian_multiplier | 0.00556      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.93         |
|    n_updates             | 3770         |
|    policy_gradient_loss  | -0.00429     |
|    std                   | 0.914        |
|    value_loss            | 0.431        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.216        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.216        |
| reward                   | -0.51171017  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 40           |
|    time_elapsed          | 17129        |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0050874986 |
|    clip_fraction         | 0.0219       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.67         |
|    cost_value_loss       | 118          |
|    cost_values           | 1.2          |
|    entropy               | -2.4         |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.937        |
|    lagrangian_multiplier | 0.0184       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.79         |
|    n_updates             | 3820         |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 0.808        |
|    value_loss            | 1.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.234       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.234       |
| reward                   | -0.49011576 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 3           |
|    time_elapsed          | 1349        |
|    total_timesteps       | 808960      |
| train/                   |             |
|    approx_kl             | 0.001147238 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 13.1        |
|    cost_value_loss       | 172         |
|    cost_values           | 2.03        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.567       |
|    lagrangian_multiplier | 0.0225      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.03        |
|    n_updates             | 3940        |
|    policy_gradient_loss  | 0.000322    |
|    std                   | 0.781       |
|    value_loss            | 3.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0336      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0336      |
| reward                   | -0.5183696  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -637        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 33          |
|    time_elapsed          | 14713       |
|    total_timesteps       | 770048      |
| train/                   |             |
|    approx_kl             | 0.007488446 |
|    clip_fraction         | 0.0196      |
|    clip_range            | 0.2         |
|    cost_returns          | 16.3        |
|    cost_value_loss       | 201         |
|    cost_values           | 2.96        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | -0.928      |
|    lagrangian_multiplier | 0.0259      |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 3750        |
|    policy_gradient_loss  | -0.000476   |
|    std                   | 0.826       |
|    value_loss            | 1.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.45406008 |
| rollout/                 |             |
|    ep_len_mean           | 635         |
|    ep_rew_mean           | -270        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 31          |
|    time_elapsed          | 14580       |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.010428057 |
|    clip_fraction         | 0.0932      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.71        |
|    cost_value_loss       | 20.6        |
|    cost_values           | 1.97        |
|    entropy               | -1.72       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 0.282       |
|    lagrangian_multiplier | 0.00392     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.53        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 0.581       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0518      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0518      |
| reward                   | -0.49375454 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 29          |
|    time_elapsed          | 12641       |
|    total_timesteps       | 761856      |
| train/                   |             |
|    approx_kl             | 0.008527632 |
|    clip_fraction         | 0.0775      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 0.709       |
|    cost_values           | 2.26        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.744       |
|    n_updates             | 3710        |
|    policy_gradient_loss  | -0.00619    |
|    std                   | 0.77        |
|    value_loss            | 1.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.111        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.111        |
| reward                   | -0.4073669   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 36           |
|    time_elapsed          | 14687        |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0028714847 |
|    clip_fraction         | 0.00518      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.5         |
|    cost_value_loss       | 151          |
|    cost_values           | 1.58         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0.0162       |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.914        |
|    value_loss            | 0.815        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0271      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0271      |
| reward                   | -0.26986614 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 41          |
|    time_elapsed          | 17579       |
|    total_timesteps       | 786432      |
| train/                   |             |
|    approx_kl             | 0.005072644 |
|    clip_fraction         | 0.0104      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.62        |
|    cost_value_loss       | 107         |
|    cost_values           | 1.13        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.304       |
|    lagrangian_multiplier | 0.00993     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 3830        |
|    policy_gradient_loss  | -0.000986   |
|    std                   | 0.806       |
|    value_loss            | 0.973       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.102       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.102       |
| reward                   | -0.44365856 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 4           |
|    time_elapsed          | 1795        |
|    total_timesteps       | 811008      |
| train/                   |             |
|    approx_kl             | 0.007968093 |
|    clip_fraction         | 0.0621      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.39        |
|    cost_value_loss       | 121         |
|    cost_values           | 1.75        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0.016       |
|    learning_rate         | 0.0003      |
|    loss                  | 8.71        |
|    n_updates             | 3950        |
|    policy_gradient_loss  | -0.00503    |
|    std                   | 0.781       |
|    value_loss            | 0.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.134       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.134       |
| reward                   | -0.5148461  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -604        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 34          |
|    time_elapsed          | 15177       |
|    total_timesteps       | 772096      |
| train/                   |             |
|    approx_kl             | 0.012548898 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 133         |
|    cost_values           | 2.86        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.0167      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.41        |
|    n_updates             | 3760        |
|    policy_gradient_loss  | -0.00451    |
|    std                   | 0.825       |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.276       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.276       |
| reward                   | -0.36923248 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 37          |
|    time_elapsed          | 15118       |
|    total_timesteps       | 778240      |
| train/                   |             |
|    approx_kl             | 0.006200018 |
|    clip_fraction         | 0.0521      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.11        |
|    cost_value_loss       | 119         |
|    cost_values           | 1.43        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.011       |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 3790        |
|    policy_gradient_loss  | -0.00489    |
|    std                   | 0.914       |
|    value_loss            | 1.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.21        |
| reward                   | -0.18856834 |
| rollout/                 |             |
|    ep_len_mean           | 622         |
|    ep_rew_mean           | -262        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 32          |
|    time_elapsed          | 15074       |
|    total_timesteps       | 768000      |
| train/                   |             |
|    approx_kl             | 0.010440392 |
|    clip_fraction         | 0.085       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.48        |
|    cost_value_loss       | 5.11        |
|    cost_values           | 1.72        |
|    entropy               | -1.71       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0.325       |
|    lagrangian_multiplier | 4.15e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.09        |
|    n_updates             | 3740        |
|    policy_gradient_loss  | -0.00395    |
|    std                   | 0.578       |
|    value_loss            | 7.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.81        |
| reward                   | -0.6309102  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 30          |
|    time_elapsed          | 13088       |
|    total_timesteps       | 763904      |
| train/                   |             |
|    approx_kl             | 0.009519086 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.9         |
|    cost_value_loss       | 46.5        |
|    cost_values           | 2.21        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0.00843     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.35        |
|    n_updates             | 3720        |
|    policy_gradient_loss  | -0.00761    |
|    std                   | 0.771       |
|    value_loss            | 1.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.175       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.175       |
| reward                   | -0.2736465  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 42          |
|    time_elapsed          | 18028       |
|    total_timesteps       | 788480      |
| train/                   |             |
|    approx_kl             | 0.006305949 |
|    clip_fraction         | 0.0196      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.4         |
|    cost_value_loss       | 124         |
|    cost_values           | 1.54        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 58.1        |
|    n_updates             | 3840        |
|    policy_gradient_loss  | -0.00274    |
|    std                   | 0.806       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0283      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0283      |
| reward                   | -0.27778873 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 5           |
|    time_elapsed          | 2246        |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.008079518 |
|    clip_fraction         | 0.0627      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.52        |
|    cost_value_loss       | 65          |
|    cost_values           | 1.49        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0.00789     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.99        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | -0.00391    |
|    std                   | 0.781       |
|    value_loss            | 0.335       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0138       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0138       |
| reward                   | -0.53727776  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -570         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 35           |
|    time_elapsed          | 15644        |
|    total_timesteps       | 774144       |
| train/                   |              |
|    approx_kl             | 0.0064715855 |
|    clip_fraction         | 0.0196       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.2         |
|    cost_value_loss       | 240          |
|    cost_values           | 2.98         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.789        |
|    lagrangian_multiplier | 0.00795      |
|    learning_rate         | 0.0003       |
|    loss                  | 26.3         |
|    n_updates             | 3770         |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 0.823        |
|    value_loss            | 1.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0697       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0697       |
| reward                   | -0.2862619   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 38           |
|    time_elapsed          | 15552        |
|    total_timesteps       | 780288       |
| train/                   |              |
|    approx_kl             | 0.0064549837 |
|    clip_fraction         | 0.039        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 130          |
|    cost_values           | 1.64         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | -0.186       |
|    lagrangian_multiplier | 0.00752      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 3800         |
|    policy_gradient_loss  | -0.00487     |
|    std                   | 0.914        |
|    value_loss            | 1.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.131       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.131       |
| reward                   | -0.49075183 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 31          |
|    time_elapsed          | 13536       |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.00641179  |
|    clip_fraction         | 0.0784      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.38        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 2.32        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.34        |
|    lagrangian_multiplier | 0.00109     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.52        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00294    |
|    std                   | 0.768       |
|    value_loss            | 1.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.12         |
| reward                   | -0.4937163   |
| rollout/                 |              |
|    ep_len_mean           | 618          |
|    ep_rew_mean           | -260         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 33           |
|    time_elapsed          | 15572        |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0086274855 |
|    clip_fraction         | 0.142        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.65         |
|    cost_value_loss       | 19.2         |
|    cost_values           | 1.97         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0.228        |
|    lagrangian_multiplier | 0.00182      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.89         |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 0.576        |
|    value_loss            | 21.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0135       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0135       |
| reward                   | -0.52385193  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 43           |
|    time_elapsed          | 18482        |
|    total_timesteps       | 790528       |
| train/                   |              |
|    approx_kl             | 0.0008468422 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 5.63         |
|    cost_value_loss       | 69.8         |
|    cost_values           | 1.15         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0.000128     |
|    learning_rate         | 0.0003       |
|    loss                  | 36           |
|    n_updates             | 3850         |
|    policy_gradient_loss  | -0.000449    |
|    std                   | 0.806        |
|    value_loss            | 1.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.149       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.149       |
| reward                   | -0.3935927  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 6           |
|    time_elapsed          | 2703        |
|    total_timesteps       | 815104      |
| train/                   |             |
|    approx_kl             | 0.006595345 |
|    clip_fraction         | 0.0465      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.44        |
|    cost_value_loss       | 92.8        |
|    cost_values           | 1.63        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.0143      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.73        |
|    n_updates             | 3970        |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 0.78        |
|    value_loss            | 0.547       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.181        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.181        |
| reward                   | -0.5204257   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -572         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 36           |
|    time_elapsed          | 16105        |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0026333453 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.2         |
|    cost_value_loss       | 185          |
|    cost_values           | 3            |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.189        |
|    lagrangian_multiplier | 0.0276       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.16         |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 0.824        |
|    value_loss            | 3.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.12         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.12         |
| reward                   | -0.49454778  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 39           |
|    time_elapsed          | 15978        |
|    total_timesteps       | 782336       |
| train/                   |              |
|    approx_kl             | 0.0047469675 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.2         |
|    cost_value_loss       | 186          |
|    cost_values           | 1.92         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0.0217       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.5          |
|    n_updates             | 3810         |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 0.915        |
|    value_loss            | 0.742        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.144       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.144       |
| reward                   | -0.4715688  |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 32          |
|    time_elapsed          | 13993       |
|    total_timesteps       | 768000      |
| train/                   |             |
|    approx_kl             | 0.006064823 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 128         |
|    cost_values           | 2.59        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0.0221      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.78        |
|    n_updates             | 3740        |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.766       |
|    value_loss            | 0.949       |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -0.5059299 |
| rollout/                 |            |
|    ep_len_mean           | 613        |
|    ep_rew_mean           | -257       |
| time/                    |            |
|    fps                   | 4          |
|    iterations            | 34         |
|    time_elapsed          | 16074      |
|    total_timesteps       | 772096     |
| train/                   |            |
|    approx_kl             | 0.0182396  |
|    clip_fraction         | 0.129      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.89       |
|    cost_value_loss       | 11.9       |
|    cost_values           | 1.91       |
|    entropy               | -1.7       |
|    entropy_loss          | -1.7       |
|    explained_variance    | 0.627      |
|    lagrangian_multiplier | 0.00197    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.55       |
|    n_updates             | 3760       |
|    policy_gradient_loss  | -0.00537   |
|    std                   | 0.573      |
|    value_loss            | 3.78       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.043        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.043        |
| reward                   | -0.52391547  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 44           |
|    time_elapsed          | 18938        |
|    total_timesteps       | 792576       |
| train/                   |              |
|    approx_kl             | 0.0011239764 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 11           |
|    cost_value_loss       | 158          |
|    cost_values           | 1.1          |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.895        |
|    lagrangian_multiplier | 0.0162       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 3860         |
|    policy_gradient_loss  | -0.000101    |
|    std                   | 0.806        |
|    value_loss            | 3.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.137        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.137        |
| reward                   | -0.4754743   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 7            |
|    time_elapsed          | 3161         |
|    total_timesteps       | 817152       |
| train/                   |              |
|    approx_kl             | 0.0073789055 |
|    clip_fraction         | 0.0404       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.5         |
|    cost_value_loss       | 151          |
|    cost_values           | 1.85         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | -0.425       |
|    lagrangian_multiplier | 0.0118       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 3980         |
|    policy_gradient_loss  | -0.00435     |
|    std                   | 0.781        |
|    value_loss            | 2.64         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.183       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.183       |
| reward                   | -0.5162471  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -575        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 37          |
|    time_elapsed          | 16560       |
|    total_timesteps       | 778240      |
| train/                   |             |
|    approx_kl             | 0.005775143 |
|    clip_fraction         | 0.0455      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.76        |
|    cost_value_loss       | 75.9        |
|    cost_values           | 2.89        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.585       |
|    lagrangian_multiplier | 0.0079      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.69        |
|    n_updates             | 3790        |
|    policy_gradient_loss  | -0.00293    |
|    std                   | 0.824       |
|    value_loss            | 0.822       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.137       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.137       |
| reward                   | -0.28789318 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 40          |
|    time_elapsed          | 16412       |
|    total_timesteps       | 784384      |
| train/                   |             |
|    approx_kl             | 0.007981557 |
|    clip_fraction         | 0.0464      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.34        |
|    cost_value_loss       | 60          |
|    cost_values           | 1.64        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.202       |
|    lagrangian_multiplier | 0.00901     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.32        |
|    n_updates             | 3820        |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 0.915       |
|    value_loss            | 8.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0636       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0636       |
| reward                   | -0.44036776  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 33           |
|    time_elapsed          | 14452        |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0051935636 |
|    clip_fraction         | 0.0537       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.51         |
|    cost_value_loss       | 105          |
|    cost_values           | 2.69         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.83         |
|    lagrangian_multiplier | 0.0167       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.06         |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.00477     |
|    std                   | 0.766        |
|    value_loss            | 0.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.27        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.27        |
| reward                   | -0.4872305  |
| rollout/                 |             |
|    ep_len_mean           | 605         |
|    ep_rew_mean           | -252        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 35          |
|    time_elapsed          | 16580       |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.016104553 |
|    clip_fraction         | 0.25        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.97        |
|    cost_value_loss       | 8.25        |
|    cost_values           | 1.82        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.184       |
|    lagrangian_multiplier | 0.00217     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.15        |
|    n_updates             | 3770        |
|    policy_gradient_loss  | 0.003       |
|    std                   | 0.572       |
|    value_loss            | 13.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.44672576  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 45           |
|    time_elapsed          | 19394        |
|    total_timesteps       | 794624       |
| train/                   |              |
|    approx_kl             | 0.0046332814 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.421        |
|    cost_value_loss       | 0.0124       |
|    cost_values           | 0.522        |
|    entropy               | -2.39        |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.158        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0582       |
|    n_updates             | 3870         |
|    policy_gradient_loss  | -0.00495     |
|    std                   | 0.803        |
|    value_loss            | 1.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.239       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.239       |
| reward                   | -0.25241902 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 8           |
|    time_elapsed          | 3618        |
|    total_timesteps       | 819200      |
| train/                   |             |
|    approx_kl             | 0.009748297 |
|    clip_fraction         | 0.0642      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 61.9        |
|    cost_values           | 1.44        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0.00796     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.72        |
|    n_updates             | 3990        |
|    policy_gradient_loss  | -0.00548    |
|    std                   | 0.78        |
|    value_loss            | 0.335       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0677      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0677      |
| reward                   | -0.24273348 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 41          |
|    time_elapsed          | 16848       |
|    total_timesteps       | 786432      |
| train/                   |             |
|    approx_kl             | 0.006502666 |
|    clip_fraction         | 0.0426      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.15        |
|    cost_value_loss       | 79.3        |
|    cost_values           | 1.66        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.474       |
|    lagrangian_multiplier | 0.00496     |
|    learning_rate         | 0.0003      |
|    loss                  | 13.2        |
|    n_updates             | 3830        |
|    policy_gradient_loss  | -0.000256   |
|    std                   | 0.914       |
|    value_loss            | 6.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0617      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0617      |
| reward                   | -0.44798633 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -575        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 38          |
|    time_elapsed          | 17031       |
|    total_timesteps       | 780288      |
| train/                   |             |
|    approx_kl             | 0.01219158  |
|    clip_fraction         | 0.0688      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.52        |
|    cost_value_loss       | 0.403       |
|    cost_values           | 2.8         |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.151       |
|    n_updates             | 3800        |
|    policy_gradient_loss  | -0.00346    |
|    std                   | 0.825       |
|    value_loss            | 0.167       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.136        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.136        |
| reward                   | -0.44027528  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 34           |
|    time_elapsed          | 14911        |
|    total_timesteps       | 772096       |
| train/                   |              |
|    approx_kl             | 0.0047021518 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.7         |
|    cost_value_loss       | 195          |
|    cost_values           | 2.85         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0.0225       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 3760         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.767        |
|    value_loss            | 0.589        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0253       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0253       |
| reward                   | -0.3125866   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 46           |
|    time_elapsed          | 19851        |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0020572823 |
|    clip_fraction         | 0.0253       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.486        |
|    cost_value_loss       | 0.0057       |
|    cost_values           | 0.512        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.759        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.181        |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.000163    |
|    std                   | 0.794        |
|    value_loss            | 0.495        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.3030627  |
| rollout/                 |             |
|    ep_len_mean           | 618         |
|    ep_rew_mean           | -257        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 36          |
|    time_elapsed          | 17084       |
|    total_timesteps       | 776192      |
| train/                   |             |
|    approx_kl             | 0.012516916 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 15.4        |
|    cost_values           | 1.84        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.283       |
|    lagrangian_multiplier | 0.00338     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.27        |
|    n_updates             | 3780        |
|    policy_gradient_loss  | -0.00672    |
|    std                   | 0.571       |
|    value_loss            | 18.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0179      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0179      |
| reward                   | -0.19138189 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 9           |
|    time_elapsed          | 4073        |
|    total_timesteps       | 821248      |
| train/                   |             |
|    approx_kl             | 0.010518485 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 13.5        |
|    cost_value_loss       | 180         |
|    cost_values           | 1.88        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.83        |
|    lagrangian_multiplier | 0.0154      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 4000        |
|    policy_gradient_loss  | 0.00507     |
|    std                   | 0.78        |
|    value_loss            | 3.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0159      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0159      |
| reward                   | -0.39601904 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -396        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 42          |
|    time_elapsed          | 17285       |
|    total_timesteps       | 788480      |
| train/                   |             |
|    approx_kl             | 0.011426221 |
|    clip_fraction         | 0.0314      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 19          |
|    cost_values           | 1.66        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.771       |
|    lagrangian_multiplier | 0.00234     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.3         |
|    n_updates             | 3840        |
|    policy_gradient_loss  | -0.00068    |
|    std                   | 0.909       |
|    value_loss            | 0.789       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0872      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0872      |
| reward                   | -0.26365757 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -576        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 39          |
|    time_elapsed          | 17503       |
|    total_timesteps       | 782336      |
| train/                   |             |
|    approx_kl             | 0.007596999 |
|    clip_fraction         | 0.0988      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 181         |
|    cost_values           | 2.7         |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0.0075      |
|    learning_rate         | 0.0003      |
|    loss                  | 21          |
|    n_updates             | 3810        |
|    policy_gradient_loss  | 0.0017      |
|    std                   | 0.825       |
|    value_loss            | 0.677       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.118       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.118       |
| reward                   | -0.48483917 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 35          |
|    time_elapsed          | 15365       |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.008172006 |
|    clip_fraction         | 0.0713      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.1        |
|    cost_value_loss       | 225         |
|    cost_values           | 2.95        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.766       |
|    lagrangian_multiplier | 0.0273      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 3770        |
|    policy_gradient_loss  | -0.00668    |
|    std                   | 0.767       |
|    value_loss            | 0.509       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00787      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00787      |
| reward                   | -0.3314544   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 47           |
|    time_elapsed          | 20312        |
|    total_timesteps       | 798720       |
| train/                   |              |
|    approx_kl             | 0.0024489318 |
|    clip_fraction         | 0.0705       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.52         |
|    cost_value_loss       | 44.2         |
|    cost_values           | 0.728        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.92         |
|    lagrangian_multiplier | 0.00518      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.36         |
|    n_updates             | 3890         |
|    policy_gradient_loss  | 0.00202      |
|    std                   | 0.794        |
|    value_loss            | 0.696        |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.97        |
| reward                   | -0.2653353  |
| rollout/                 |             |
|    ep_len_mean           | 624         |
|    ep_rew_mean           | -259        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 37          |
|    time_elapsed          | 17592       |
|    total_timesteps       | 778240      |
| train/                   |             |
|    approx_kl             | 0.013641128 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 1.97        |
|    entropy               | -1.68       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.652       |
|    lagrangian_multiplier | 0.0011      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.61        |
|    n_updates             | 3790        |
|    policy_gradient_loss  | -0.0111     |
|    std                   | 0.57        |
|    value_loss            | 2.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.42467287  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 10           |
|    time_elapsed          | 4533         |
|    total_timesteps       | 823296       |
| train/                   |              |
|    approx_kl             | 0.0014701794 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.1         |
|    cost_value_loss       | 127          |
|    cost_values           | 2.19         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | -0.618       |
|    lagrangian_multiplier | 0.0147       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.4          |
|    n_updates             | 4010         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.78         |
|    value_loss            | 2.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.106       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.106       |
| reward                   | -0.3910168  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 43          |
|    time_elapsed          | 17722       |
|    total_timesteps       | 790528      |
| train/                   |             |
|    approx_kl             | 0.012406162 |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.33        |
|    cost_value_loss       | 0.0592      |
|    cost_values           | 1.5         |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.504       |
|    n_updates             | 3850        |
|    policy_gradient_loss  | 0.00707     |
|    std                   | 0.909       |
|    value_loss            | 1.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0702       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0702       |
| reward                   | -0.42836547  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -539         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 40           |
|    time_elapsed          | 17978        |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0031173346 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.6         |
|    cost_value_loss       | 249          |
|    cost_values           | 2.99         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | -0.377       |
|    lagrangian_multiplier | 0.00446      |
|    learning_rate         | 0.0003       |
|    loss                  | 40.6         |
|    n_updates             | 3820         |
|    policy_gradient_loss  | -0.000906    |
|    std                   | 0.824        |
|    value_loss            | 3.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0481       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0481       |
| reward                   | -0.51753366  |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 36           |
|    time_elapsed          | 15828        |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0017779218 |
|    clip_fraction         | 0.00381      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.5         |
|    cost_value_loss       | 97.2         |
|    cost_values           | 2.9          |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.929        |
|    lagrangian_multiplier | 0.0138       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.39         |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.768        |
|    value_loss            | 0.564        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0334       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0334       |
| reward                   | -0.18963632  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 48           |
|    time_elapsed          | 20774        |
|    total_timesteps       | 800768       |
| train/                   |              |
|    approx_kl             | 0.0030484297 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.81         |
|    cost_value_loss       | 69.9         |
|    cost_values           | 1.09         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0.012        |
|    learning_rate         | 0.0003       |
|    loss                  | 6.03         |
|    n_updates             | 3900         |
|    policy_gradient_loss  | -0.000846    |
|    std                   | 0.794        |
|    value_loss            | 0.553        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.319       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.319       |
| reward                   | -0.36974987 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 11          |
|    time_elapsed          | 4995        |
|    total_timesteps       | 825344      |
| train/                   |             |
|    approx_kl             | 0.003553152 |
|    clip_fraction         | 0.0186      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 140         |
|    cost_values           | 2.16        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.183       |
|    lagrangian_multiplier | 0.0131      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.8        |
|    n_updates             | 4020        |
|    policy_gradient_loss  | -0.00186    |
|    std                   | 0.781       |
|    value_loss            | 13.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.317       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.317       |
| reward                   | -0.4279214  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 44          |
|    time_elapsed          | 18158       |
|    total_timesteps       | 792576      |
| train/                   |             |
|    approx_kl             | 0.006536944 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.13        |
|    cost_value_loss       | 94.2        |
|    cost_values           | 1.4         |
|    entropy               | -2.66       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0.0126      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.66        |
|    n_updates             | 3860        |
|    policy_gradient_loss  | -0.00314    |
|    std                   | 0.914       |
|    value_loss            | 0.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.97        |
| reward                   | -0.62007046 |
| rollout/                 |             |
|    ep_len_mean           | 626         |
|    ep_rew_mean           | -261        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 38          |
|    time_elapsed          | 18104       |
|    total_timesteps       | 780288      |
| train/                   |             |
|    approx_kl             | 0.003626483 |
|    clip_fraction         | 0.0804      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.95        |
|    cost_value_loss       | 24.6        |
|    cost_values           | 2.4         |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | -0.118      |
|    lagrangian_multiplier | 0.000934    |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 3800        |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.569       |
|    value_loss            | 13.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0513      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0513      |
| reward                   | -0.18605132 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -522        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 41          |
|    time_elapsed          | 18444       |
|    total_timesteps       | 786432      |
| train/                   |             |
|    approx_kl             | 0.005424026 |
|    clip_fraction         | 0.0575      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 128         |
|    cost_values           | 2.95        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.625       |
|    lagrangian_multiplier | 0.0192      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.79        |
|    n_updates             | 3830        |
|    policy_gradient_loss  | -0.003      |
|    std                   | 0.821       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.586       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.586       |
| reward                   | -0.44616336 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 37          |
|    time_elapsed          | 16295       |
|    total_timesteps       | 778240      |
| train/                   |             |
|    approx_kl             | 0.005827609 |
|    clip_fraction         | 0.0604      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.7        |
|    cost_value_loss       | 158         |
|    cost_values           | 2.92        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.344       |
|    lagrangian_multiplier | 0.0219      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.34        |
|    n_updates             | 3790        |
|    policy_gradient_loss  | -0.00316    |
|    std                   | 0.765       |
|    value_loss            | 1.93        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.222        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.222        |
| reward                   | -0.3418894   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 49           |
|    time_elapsed          | 21236        |
|    total_timesteps       | 802816       |
| train/                   |              |
|    approx_kl             | 0.0049696695 |
|    clip_fraction         | 0.0351       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.838        |
|    cost_value_loss       | 0.0129       |
|    cost_values           | 0.856        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0425       |
|    n_updates             | 3910         |
|    policy_gradient_loss  | -0.000736    |
|    std                   | 0.794        |
|    value_loss            | 0.184        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.245       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.245       |
| reward                   | -0.28779516 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 45          |
|    time_elapsed          | 18597       |
|    total_timesteps       | 794624      |
| train/                   |             |
|    approx_kl             | 0.004741053 |
|    clip_fraction         | 0.0196      |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 152         |
|    cost_values           | 1.39        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0.0166      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.38        |
|    n_updates             | 3870        |
|    policy_gradient_loss  | -0.00222    |
|    std                   | 0.915       |
|    value_loss            | 0.621       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0918      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0918      |
| reward                   | -0.34587118 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 12          |
|    time_elapsed          | 5455        |
|    total_timesteps       | 827392      |
| train/                   |             |
|    approx_kl             | 0.005054098 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.93        |
|    cost_value_loss       | 66.7        |
|    cost_values           | 1.41        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.852       |
|    lagrangian_multiplier | 0.00772     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.31        |
|    n_updates             | 4030        |
|    policy_gradient_loss  | -0.00294    |
|    std                   | 0.782       |
|    value_loss            | 0.674       |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.87         |
| reward                   | -0.5051399   |
| rollout/                 |              |
|    ep_len_mean           | 613          |
|    ep_rew_mean           | -253         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 39           |
|    time_elapsed          | 18612        |
|    total_timesteps       | 782336       |
| train/                   |              |
|    approx_kl             | 0.0040030116 |
|    clip_fraction         | 0.0449       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.29         |
|    cost_value_loss       | 34.2         |
|    cost_values           | 2.77         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | -0.084       |
|    lagrangian_multiplier | 0.0109       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.25         |
|    n_updates             | 3810         |
|    policy_gradient_loss  | -0.00474     |
|    std                   | 0.569        |
|    value_loss            | 16.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0509       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0509       |
| reward                   | -0.25652996  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -503         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 42           |
|    time_elapsed          | 18912        |
|    total_timesteps       | 788480       |
| train/                   |              |
|    approx_kl             | 0.0069999546 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.15         |
|    cost_value_loss       | 42.3         |
|    cost_values           | 2.9          |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.78         |
|    lagrangian_multiplier | 0.00429      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.44         |
|    n_updates             | 3840         |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.82         |
|    value_loss            | 4.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0224       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0224       |
| reward                   | -0.312228    |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 38           |
|    time_elapsed          | 16760        |
|    total_timesteps       | 780288       |
| train/                   |              |
|    approx_kl             | 0.0024781039 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.05         |
|    cost_value_loss       | 89.2         |
|    cost_values           | 2.74         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -0.0553      |
|    lagrangian_multiplier | 0.00403      |
|    learning_rate         | 0.0003       |
|    loss                  | 17.8         |
|    n_updates             | 3800         |
|    policy_gradient_loss  | 0.000259     |
|    std                   | 0.763        |
|    value_loss            | 3.95         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.0615     |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.0615     |
| reward             | -0.5573258 |
| rollout/           |            |
|    ep_len_mean     | 992        |
|    ep_rew_mean     | -421       |
| time/              |            |
|    fps             | 4          |
|    iterations      | 1          |
|    time_elapsed    | 460        |
|    total_timesteps | 804864     |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.8959649   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 46           |
|    time_elapsed          | 19039        |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0045265644 |
|    clip_fraction         | 0.0346       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.16         |
|    cost_value_loss       | 66.9         |
|    cost_values           | 1.28         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0.00855      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.55         |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 0.915        |
|    value_loss            | 0.835        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0741      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0741      |
| reward                   | -0.4273981  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 13          |
|    time_elapsed          | 5916        |
|    total_timesteps       | 829440      |
| train/                   |             |
|    approx_kl             | 0.004988799 |
|    clip_fraction         | 0.0571      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.67        |
|    cost_value_loss       | 125         |
|    cost_values           | 1.54        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.0128      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.8         |
|    n_updates             | 4040        |
|    policy_gradient_loss  | -0.00629    |
|    std                   | 0.781       |
|    value_loss            | 0.564       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.40576243  |
| rollout/                 |              |
|    ep_len_mean           | 622          |
|    ep_rew_mean           | -258         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 40           |
|    time_elapsed          | 19125        |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0096713705 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.68         |
|    cost_value_loss       | 21.2         |
|    cost_values           | 2.71         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.0581       |
|    lagrangian_multiplier | 0.00336      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.67         |
|    n_updates             | 3820         |
|    policy_gradient_loss  | -0.00321     |
|    std                   | 0.568        |
|    value_loss            | 18.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.204       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.204       |
| reward                   | -0.4410354  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -502        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 43          |
|    time_elapsed          | 19385       |
|    total_timesteps       | 790528      |
| train/                   |             |
|    approx_kl             | 0.008602484 |
|    clip_fraction         | 0.05        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.39        |
|    cost_value_loss       | 0.352       |
|    cost_values           | 2.73        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.676       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.959       |
|    n_updates             | 3850        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.817       |
|    value_loss            | 2.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0708       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0708       |
| reward                   | -0.2551865   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 39           |
|    time_elapsed          | 17204        |
|    total_timesteps       | 782336       |
| train/                   |              |
|    approx_kl             | 0.0018026226 |
|    clip_fraction         | 0.00967      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.38         |
|    cost_value_loss       | 103          |
|    cost_values           | 2.66         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.543        |
|    lagrangian_multiplier | 0.0161       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.28         |
|    n_updates             | 3810         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.763        |
|    value_loss            | 0.768        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0163       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0163       |
| reward                   | -0.4578698   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 2            |
|    time_elapsed          | 920          |
|    total_timesteps       | 806912       |
| train/                   |              |
|    approx_kl             | 0.0031344043 |
|    clip_fraction         | 0.049        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 18.6         |
|    cost_values           | 0.401        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.967        |
|    lagrangian_multiplier | 0.000987     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 3930         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 0.795        |
|    value_loss            | 1.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0433      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0433      |
| reward                   | -0.40325028 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 47          |
|    time_elapsed          | 19483       |
|    total_timesteps       | 798720      |
| train/                   |             |
|    approx_kl             | 0.007170805 |
|    clip_fraction         | 0.0227      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.42        |
|    cost_value_loss       | 66.1        |
|    cost_values           | 1.11        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0.00537     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 3890        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.914       |
|    value_loss            | 4.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.212        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.212        |
| reward                   | -0.5685355   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 14           |
|    time_elapsed          | 6379         |
|    total_timesteps       | 831488       |
| train/                   |              |
|    approx_kl             | 0.0033512763 |
|    clip_fraction         | 0.0376       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.88         |
|    cost_value_loss       | 26.8         |
|    cost_values           | 1.05         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.506        |
|    lagrangian_multiplier | 0.00111      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 4050         |
|    policy_gradient_loss  | -0.00416     |
|    std                   | 0.78         |
|    value_loss            | 3.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.234       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.234       |
| reward                   | -0.26299068 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -486        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 44          |
|    time_elapsed          | 19861       |
|    total_timesteps       | 792576      |
| train/                   |             |
|    approx_kl             | 0.004729295 |
|    clip_fraction         | 0.0313      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.92        |
|    cost_value_loss       | 38.4        |
|    cost_values           | 2.62        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.403       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16          |
|    n_updates             | 3860        |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.817       |
|    value_loss            | 1.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.39        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.39        |
| reward                   | -0.4774465  |
| rollout/                 |             |
|    ep_len_mean           | 625         |
|    ep_rew_mean           | -260        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 41          |
|    time_elapsed          | 19640       |
|    total_timesteps       | 786432      |
| train/                   |             |
|    approx_kl             | 0.018157888 |
|    clip_fraction         | 0.0823      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.56        |
|    cost_value_loss       | 22.6        |
|    cost_values           | 2.63        |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.533       |
|    lagrangian_multiplier | 0.0138      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.87        |
|    n_updates             | 3830        |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 0.567       |
|    value_loss            | 2.03        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.308        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.308        |
| reward                   | -0.34091285  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 40           |
|    time_elapsed          | 17656        |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0067792637 |
|    clip_fraction         | 0.0287       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 123          |
|    cost_values           | 2.85         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.499        |
|    lagrangian_multiplier | 0.0162       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.28         |
|    n_updates             | 3820         |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 0.762        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.132       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.132       |
| reward                   | -0.43425518 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 3           |
|    time_elapsed          | 1385        |
|    total_timesteps       | 808960      |
| train/                   |             |
|    approx_kl             | 0.005544462 |
|    clip_fraction         | 0.00903     |
|    clip_range            | 0.2         |
|    cost_returns          | 9.89        |
|    cost_value_loss       | 133         |
|    cost_values           | 1.2         |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.018       |
|    learning_rate         | 0.0003      |
|    loss                  | 8.29        |
|    n_updates             | 3940        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.794       |
|    value_loss            | 0.591       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0633      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0633      |
| reward                   | -0.5702618  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 48          |
|    time_elapsed          | 19923       |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.010506637 |
|    clip_fraction         | 0.0386      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.69        |
|    cost_value_loss       | 136         |
|    cost_values           | 1.09        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0.0223      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.05        |
|    n_updates             | 3900        |
|    policy_gradient_loss  | -0.0104     |
|    std                   | 0.914       |
|    value_loss            | 0.839       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.507       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.507       |
| reward                   | -0.4818631  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 15          |
|    time_elapsed          | 6848        |
|    total_timesteps       | 833536      |
| train/                   |             |
|    approx_kl             | 0.007607645 |
|    clip_fraction         | 0.0797      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.53        |
|    cost_value_loss       | 86          |
|    cost_values           | 0.969       |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0.0124      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.16        |
|    n_updates             | 4060        |
|    policy_gradient_loss  | -0.00569    |
|    std                   | 0.78        |
|    value_loss            | 1.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0854       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0854       |
| reward                   | -0.43048877  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 45           |
|    time_elapsed          | 20341        |
|    total_timesteps       | 794624       |
| train/                   |              |
|    approx_kl             | 0.0081852265 |
|    clip_fraction         | 0.0545       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 0.6          |
|    cost_values           | 2.69         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -0.24        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.11         |
|    n_updates             | 3870         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.82         |
|    value_loss            | 4.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.085       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.085       |
| reward                   | -0.37639204 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 41          |
|    time_elapsed          | 18116       |
|    total_timesteps       | 786432      |
| train/                   |             |
|    approx_kl             | 0.008794976 |
|    clip_fraction         | 0.0641      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 195         |
|    cost_values           | 2.95        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0.026       |
|    learning_rate         | 0.0003      |
|    loss                  | 9.62        |
|    n_updates             | 3830        |
|    policy_gradient_loss  | -0.00631    |
|    std                   | 0.761       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.48        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.48        |
| reward                   | -0.45507511 |
| rollout/                 |             |
|    ep_len_mean           | 630         |
|    ep_rew_mean           | -263        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 42          |
|    time_elapsed          | 20152       |
|    total_timesteps       | 788480      |
| train/                   |             |
|    approx_kl             | 0.007738217 |
|    clip_fraction         | 0.0929      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.07        |
|    cost_value_loss       | 16.9        |
|    cost_values           | 2.61        |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.0318      |
|    lagrangian_multiplier | 0.0058      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.04        |
|    n_updates             | 3840        |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 0.567       |
|    value_loss            | 25.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0983      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0983      |
| reward                   | -0.51192427 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 49          |
|    time_elapsed          | 20373       |
|    total_timesteps       | 802816      |
| train/                   |             |
|    approx_kl             | 0.008864414 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.3         |
|    cost_value_loss       | 112         |
|    cost_values           | 1.01        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0.0137      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.68        |
|    n_updates             | 3910        |
|    policy_gradient_loss  | -0.0062     |
|    std                   | 0.916       |
|    value_loss            | 0.321       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.232       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.232       |
| reward                   | -0.5503584  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 4           |
|    time_elapsed          | 1852        |
|    total_timesteps       | 811008      |
| train/                   |             |
|    approx_kl             | 0.003112956 |
|    clip_fraction         | 0.00464     |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 136         |
|    cost_values           | 1.62        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 65.7        |
|    n_updates             | 3950        |
|    policy_gradient_loss  | -0.00361    |
|    std                   | 0.794       |
|    value_loss            | 0.485       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.218        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.218        |
| reward                   | -0.31960502  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 16           |
|    time_elapsed          | 7317         |
|    total_timesteps       | 835584       |
| train/                   |              |
|    approx_kl             | 0.0052815895 |
|    clip_fraction         | 0.0784       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.43         |
|    cost_value_loss       | 34.9         |
|    cost_values           | 1.28         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0.00308      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.86         |
|    n_updates             | 4070         |
|    policy_gradient_loss  | -0.00488     |
|    std                   | 0.779        |
|    value_loss            | 0.187        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.198        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.198        |
| reward                   | -0.49459237  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 42           |
|    time_elapsed          | 18572        |
|    total_timesteps       | 788480       |
| train/                   |              |
|    approx_kl             | 0.0073058857 |
|    clip_fraction         | 0.0771       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.3         |
|    cost_value_loss       | 134          |
|    cost_values           | 2.84         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0.907        |
|    lagrangian_multiplier | 0.0129       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.1         |
|    n_updates             | 3840         |
|    policy_gradient_loss  | -0.00663     |
|    std                   | 0.757        |
|    value_loss            | 0.372        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.26205537  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 46           |
|    time_elapsed          | 20816        |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0031022104 |
|    clip_fraction         | 0.049        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.98         |
|    cost_value_loss       | 61.5         |
|    cost_values           | 2.53         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | -1.73        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 31.6         |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.000578    |
|    std                   | 0.82         |
|    value_loss            | 1.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.6456573  |
| rollout/                 |             |
|    ep_len_mean           | 623         |
|    ep_rew_mean           | -261        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 43          |
|    time_elapsed          | 20673       |
|    total_timesteps       | 790528      |
| train/                   |             |
|    approx_kl             | 0.006675075 |
|    clip_fraction         | 0.0724      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.1         |
|    cost_value_loss       | 20.4        |
|    cost_values           | 2.54        |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.275       |
|    lagrangian_multiplier | 0.0128      |
|    learning_rate         | 0.0003      |
|    loss                  | 4           |
|    n_updates             | 3850        |
|    policy_gradient_loss  | -0.00379    |
|    std                   | 0.566       |
|    value_loss            | 7.37        |
------------------------------------------
------------------------------------
| avg_speed          | 0.0689      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0689      |
| reward             | -0.54395944 |
| rollout/           |             |
|    ep_len_mean     | 972         |
|    ep_rew_mean     | -406        |
| time/              |             |
|    fps             | 4           |
|    iterations      | 1           |
|    time_elapsed    | 447         |
|    total_timesteps | 804864      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.154        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.154        |
| reward                   | -0.3879959   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 5            |
|    time_elapsed          | 2323         |
|    total_timesteps       | 813056       |
| train/                   |              |
|    approx_kl             | 0.0028079336 |
|    clip_fraction         | 0.00122      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.689        |
|    cost_value_loss       | 0.0421       |
|    cost_values           | 0.693        |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.946        |
|    lagrangian_multiplier | 0.000411     |
|    learning_rate         | 0.0003       |
|    loss                  | 0.564        |
|    n_updates             | 3960         |
|    policy_gradient_loss  | -0.000491    |
|    std                   | 0.793        |
|    value_loss            | 1.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.217        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.217        |
| reward                   | -0.26548728  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 17           |
|    time_elapsed          | 7784         |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0015181355 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 1.13         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.583        |
|    lagrangian_multiplier | 0.000838     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.99         |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.777        |
|    value_loss            | 1.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0396       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0396       |
| reward                   | -0.44553813  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 43           |
|    time_elapsed          | 19030        |
|    total_timesteps       | 790528       |
| train/                   |              |
|    approx_kl             | 0.0021056496 |
|    clip_fraction         | 0.00293      |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 158          |
|    cost_values           | 2.9          |
|    entropy               | -2.27        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.0377       |
|    lagrangian_multiplier | 0.0207       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.88         |
|    n_updates             | 3850         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.754        |
|    value_loss            | 15.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0216       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0216       |
| reward                   | -0.33870393  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -450         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 47           |
|    time_elapsed          | 21289        |
|    total_timesteps       | 798720       |
| train/                   |              |
|    approx_kl             | 0.0044830916 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.25         |
|    cost_value_loss       | 0.302        |
|    cost_values           | 2.64         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -0.00144     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.939        |
|    n_updates             | 3890         |
|    policy_gradient_loss  | -0.000671    |
|    std                   | 0.817        |
|    value_loss            | 2.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.98        |
| reward                   | -0.4227499  |
| rollout/                 |             |
|    ep_len_mean           | 625         |
|    ep_rew_mean           | -264        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 44          |
|    time_elapsed          | 21200       |
|    total_timesteps       | 792576      |
| train/                   |             |
|    approx_kl             | 0.011725545 |
|    clip_fraction         | 0.0896      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.72        |
|    cost_value_loss       | 18          |
|    cost_values           | 2.36        |
|    entropy               | -1.66       |
|    entropy_loss          | -1.66       |
|    explained_variance    | -0.169      |
|    lagrangian_multiplier | 0.00139     |
|    learning_rate         | 0.0003      |
|    loss                  | 12          |
|    n_updates             | 3860        |
|    policy_gradient_loss  | -0.0044     |
|    std                   | 0.564       |
|    value_loss            | 20.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.285        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.285        |
| reward                   | -0.34383297  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 2            |
|    time_elapsed          | 893          |
|    total_timesteps       | 806912       |
| train/                   |              |
|    approx_kl             | 0.0032675352 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.09         |
|    cost_value_loss       | 129          |
|    cost_values           | 1.23         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.626        |
|    lagrangian_multiplier | 0.00859      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 3930         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.917        |
|    value_loss            | 1.37         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0776      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0776      |
| reward                   | -0.43910888 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 6           |
|    time_elapsed          | 2780        |
|    total_timesteps       | 815104      |
| train/                   |             |
|    approx_kl             | 0.004634356 |
|    clip_fraction         | 0.0247      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.08        |
|    cost_value_loss       | 85.3        |
|    cost_values           | 0.637       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.0117      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.07        |
|    n_updates             | 3970        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.792       |
|    value_loss            | 0.732       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0581      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0581      |
| reward                   | -0.2954752  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 18          |
|    time_elapsed          | 8256        |
|    total_timesteps       | 839680      |
| train/                   |             |
|    approx_kl             | 0.003611497 |
|    clip_fraction         | 0.054       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.9         |
|    cost_value_loss       | 54.8        |
|    cost_values           | 1.35        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.403       |
|    lagrangian_multiplier | 0.00604     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.79        |
|    n_updates             | 4090        |
|    policy_gradient_loss  | -0.00501    |
|    std                   | 0.773       |
|    value_loss            | 0.687       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.5271765   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 44           |
|    time_elapsed          | 19492        |
|    total_timesteps       | 792576       |
| train/                   |              |
|    approx_kl             | 0.0051210485 |
|    clip_fraction         | 0.0441       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.3         |
|    cost_value_loss       | 98.1         |
|    cost_values           | 2.92         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.869        |
|    lagrangian_multiplier | 0.0109       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 3860         |
|    policy_gradient_loss  | -0.00347     |
|    std                   | 0.754        |
|    value_loss            | 0.787        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.437       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.437       |
| reward                   | -0.43178666 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -438        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 48          |
|    time_elapsed          | 21770       |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.0066577   |
|    clip_fraction         | 0.049       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.75        |
|    cost_value_loss       | 121         |
|    cost_values           | 2.48        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 62.1        |
|    n_updates             | 3900        |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 0.814       |
|    value_loss            | 0.372       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.233        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.233        |
| reward                   | -0.4975544   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 3            |
|    time_elapsed          | 1336         |
|    total_timesteps       | 808960       |
| train/                   |              |
|    approx_kl             | 0.0062442464 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.4         |
|    cost_value_loss       | 159          |
|    cost_values           | 1.36         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0.0167       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.63         |
|    n_updates             | 3940         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.916        |
|    value_loss            | 1.27         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5546188  |
| rollout/                 |             |
|    ep_len_mean           | 615         |
|    ep_rew_mean           | -259        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 45          |
|    time_elapsed          | 21717       |
|    total_timesteps       | 794624      |
| train/                   |             |
|    approx_kl             | 0.005725607 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.23        |
|    cost_value_loss       | 27.8        |
|    cost_values           | 2.49        |
|    entropy               | -1.65       |
|    entropy_loss          | -1.66       |
|    explained_variance    | -0.281      |
|    lagrangian_multiplier | 0.0083      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.98        |
|    n_updates             | 3870        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.562       |
|    value_loss            | 9.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0538      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0538      |
| reward                   | -0.5566859  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 7           |
|    time_elapsed          | 3247        |
|    total_timesteps       | 817152      |
| train/                   |             |
|    approx_kl             | 0.005946556 |
|    clip_fraction         | 0.05        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.253       |
|    cost_value_loss       | 0.0339      |
|    cost_values           | 0.241       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.355       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.168       |
|    n_updates             | 3980        |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.788       |
|    value_loss            | 0.451       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.208       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.208       |
| reward                   | -0.33210942 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 19          |
|    time_elapsed          | 8730        |
|    total_timesteps       | 841728      |
| train/                   |             |
|    approx_kl             | 0.003381265 |
|    clip_fraction         | 0.0205      |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 178         |
|    cost_values           | 1.66        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0.0164      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 4100        |
|    policy_gradient_loss  | -0.00209    |
|    std                   | 0.771       |
|    value_loss            | 1.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.093       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.093       |
| reward                   | -0.31750938 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 45          |
|    time_elapsed          | 19955       |
|    total_timesteps       | 794624      |
| train/                   |             |
|    approx_kl             | 0.004272054 |
|    clip_fraction         | 0.0452      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 165         |
|    cost_values           | 2.94        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0.0258      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.53        |
|    n_updates             | 3870        |
|    policy_gradient_loss  | -0.0054     |
|    std                   | 0.753       |
|    value_loss            | 0.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.12        |
| reward                   | -0.22000355 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 49          |
|    time_elapsed          | 22252       |
|    total_timesteps       | 802816      |
| train/                   |             |
|    approx_kl             | 0.011285062 |
|    clip_fraction         | 0.0676      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.26        |
|    cost_value_loss       | 1.15        |
|    cost_values           | 2.54        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.0867      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 3910        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.808       |
|    value_loss            | 1.6         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.26592565  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 4            |
|    time_elapsed          | 1779         |
|    total_timesteps       | 811008       |
| train/                   |              |
|    approx_kl             | 0.0047117793 |
|    clip_fraction         | 0.0258       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.6         |
|    cost_value_loss       | 217          |
|    cost_values           | 1.74         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0.03         |
|    learning_rate         | 0.0003       |
|    loss                  | 8.17         |
|    n_updates             | 3950         |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 0.913        |
|    value_loss            | 0.267        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.129        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.129        |
| reward                   | -0.38778812  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 8            |
|    time_elapsed          | 3718         |
|    total_timesteps       | 819200       |
| train/                   |              |
|    approx_kl             | 0.0067209983 |
|    clip_fraction         | 0.11         |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 160          |
|    cost_values           | 1.07         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0.0107       |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 3990         |
|    policy_gradient_loss  | 0.0109       |
|    std                   | 0.787        |
|    value_loss            | 1.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.36411133 |
| rollout/                 |             |
|    ep_len_mean           | 613         |
|    ep_rew_mean           | -259        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 46          |
|    time_elapsed          | 22243       |
|    total_timesteps       | 796672      |
| train/                   |             |
|    approx_kl             | 0.007858278 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.18        |
|    cost_value_loss       | 20.1        |
|    cost_values           | 2.41        |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 0.0583      |
|    lagrangian_multiplier | 0.00417     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.62        |
|    n_updates             | 3880        |
|    policy_gradient_loss  | -0.003      |
|    std                   | 0.561       |
|    value_loss            | 24.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0223       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0223       |
| reward                   | -0.5799124   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 20           |
|    time_elapsed          | 9205         |
|    total_timesteps       | 843776       |
| train/                   |              |
|    approx_kl             | 0.0052078636 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 8.31         |
|    cost_value_loss       | 112          |
|    cost_values           | 1.33         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.636        |
|    lagrangian_multiplier | 0.0135       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.63         |
|    n_updates             | 4110         |
|    policy_gradient_loss  | -0.00592     |
|    std                   | 0.77         |
|    value_loss            | 1.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0395       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0395       |
| reward                   | -0.35964826  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 46           |
|    time_elapsed          | 20416        |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0021388463 |
|    clip_fraction         | 0.00376      |
|    clip_range            | 0.2          |
|    cost_returns          | 17.6         |
|    cost_value_loss       | 225          |
|    cost_values           | 2.99         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.609        |
|    lagrangian_multiplier | 0.0314       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.47         |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.000721    |
|    std                   | 0.751        |
|    value_loss            | 1.21         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.0945     |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.0945     |
| reward             | -0.4319405 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -431       |
| time/              |            |
|    fps             | 4          |
|    iterations      | 1          |
|    time_elapsed    | 472        |
|    total_timesteps | 804864     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.0188      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0188      |
| reward                   | -0.4435181  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 5           |
|    time_elapsed          | 2225        |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.005800931 |
|    clip_fraction         | 0.0239      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.42        |
|    cost_value_loss       | 84.6        |
|    cost_values           | 1.12        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.00832     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.55        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.911       |
|    value_loss            | 0.642       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0764       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0764       |
| reward                   | -0.27152666  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 9            |
|    time_elapsed          | 4186         |
|    total_timesteps       | 821248       |
| train/                   |              |
|    approx_kl             | 0.0034613034 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.51         |
|    cost_value_loss       | 91.2         |
|    cost_values           | 0.851        |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0.0071       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.9         |
|    n_updates             | 4000         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.786        |
|    value_loss            | 1.41         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.82        |
| reward                   | -0.19900106 |
| rollout/                 |             |
|    ep_len_mean           | 628         |
|    ep_rew_mean           | -266        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 47          |
|    time_elapsed          | 22769       |
|    total_timesteps       | 798720      |
| train/                   |             |
|    approx_kl             | 0.007596189 |
|    clip_fraction         | 0.0796      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.32        |
|    cost_value_loss       | 28.1        |
|    cost_values           | 2.39        |
|    entropy               | -1.64       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 0.0597      |
|    lagrangian_multiplier | 0.00427     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.29        |
|    n_updates             | 3890        |
|    policy_gradient_loss  | -0.00697    |
|    std                   | 0.56        |
|    value_loss            | 19.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.177       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.177       |
| reward                   | -0.3866503  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 21          |
|    time_elapsed          | 9673        |
|    total_timesteps       | 845824      |
| train/                   |             |
|    approx_kl             | 0.006547099 |
|    clip_fraction         | 0.0896      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.68        |
|    cost_value_loss       | 120         |
|    cost_values           | 1.25        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.0123      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.17        |
|    n_updates             | 4120        |
|    policy_gradient_loss  | -0.00453    |
|    std                   | 0.771       |
|    value_loss            | 1.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.211        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.211        |
| reward                   | -0.460649    |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 47           |
|    time_elapsed          | 20877        |
|    total_timesteps       | 798720       |
| train/                   |              |
|    approx_kl             | 0.0056700185 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.65         |
|    cost_value_loss       | 98.3         |
|    cost_values           | 2.92         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.519        |
|    lagrangian_multiplier | 0.0123       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 3890         |
|    policy_gradient_loss  | -0.00556     |
|    std                   | 0.749        |
|    value_loss            | 13.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0307      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0307      |
| reward                   | -0.38055825 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -433        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 2           |
|    time_elapsed          | 942         |
|    total_timesteps       | 806912      |
| train/                   |             |
|    approx_kl             | 0.002626098 |
|    clip_fraction         | 0.0522      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 1           |
|    cost_values           | 1.82        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.699       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.335       |
|    n_updates             | 3930        |
|    policy_gradient_loss  | 0.00775     |
|    std                   | 0.805       |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.214       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.214       |
| reward                   | -0.548021   |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 6           |
|    time_elapsed          | 2680        |
|    total_timesteps       | 815104      |
| train/                   |             |
|    approx_kl             | 0.008828407 |
|    clip_fraction         | 0.0947      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.95        |
|    cost_value_loss       | 133         |
|    cost_values           | 1.46        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0.0167      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.28        |
|    n_updates             | 3970        |
|    policy_gradient_loss  | -0.0054     |
|    std                   | 0.916       |
|    value_loss            | 0.832       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0911      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0911      |
| reward                   | -0.62661535 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 10          |
|    time_elapsed          | 4650        |
|    total_timesteps       | 823296      |
| train/                   |             |
|    approx_kl             | 0.008023341 |
|    clip_fraction         | 0.0265      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.489       |
|    cost_value_loss       | 0.0133      |
|    cost_values           | 0.491       |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.834       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.68        |
|    n_updates             | 4010        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.786       |
|    value_loss            | 7.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.038        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.038        |
| reward                   | -0.5294157   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 22           |
|    time_elapsed          | 10144        |
|    total_timesteps       | 847872       |
| train/                   |              |
|    approx_kl             | 0.0075511076 |
|    clip_fraction         | 0.0561       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.8         |
|    cost_value_loss       | 148          |
|    cost_values           | 1.63         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.916        |
|    lagrangian_multiplier | 0.0151       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 4130         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.771        |
|    value_loss            | 1.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.3115758  |
| rollout/                 |             |
|    ep_len_mean           | 625         |
|    ep_rew_mean           | -264        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 48          |
|    time_elapsed          | 23296       |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.014173342 |
|    clip_fraction         | 0.0993      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.04        |
|    cost_value_loss       | 21.4        |
|    cost_values           | 2.81        |
|    entropy               | -1.64       |
|    entropy_loss          | -1.64       |
|    explained_variance    | 0.159       |
|    lagrangian_multiplier | 0.00612     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.42        |
|    n_updates             | 3900        |
|    policy_gradient_loss  | -0.00217    |
|    std                   | 0.56        |
|    value_loss            | 7.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0404      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0404      |
| reward                   | -0.51295453 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 48          |
|    time_elapsed          | 21331       |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.006694878 |
|    clip_fraction         | 0.0267      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.56        |
|    cost_value_loss       | 62.7        |
|    cost_values           | 2.65        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.666       |
|    lagrangian_multiplier | 0.0108      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.11        |
|    n_updates             | 3900        |
|    policy_gradient_loss  | -0.00372    |
|    std                   | 0.749       |
|    value_loss            | 0.532       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.163       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.163       |
| reward                   | -0.5768835  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 3           |
|    time_elapsed          | 1418        |
|    total_timesteps       | 808960      |
| train/                   |             |
|    approx_kl             | 0.009513786 |
|    clip_fraction         | 0.0797      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 0.0404      |
|    cost_values           | 1.42        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.262       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0311      |
|    n_updates             | 3940        |
|    policy_gradient_loss  | -8.14e-05   |
|    std                   | 0.804       |
|    value_loss            | 0.0995      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.159        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.159        |
| reward                   | -0.44094792  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 7            |
|    time_elapsed          | 3133         |
|    total_timesteps       | 817152       |
| train/                   |              |
|    approx_kl             | 0.0050242282 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.5         |
|    cost_value_loss       | 204          |
|    cost_values           | 1.8          |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.933        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 102          |
|    n_updates             | 3980         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.918        |
|    value_loss            | 1.37         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.172       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.172       |
| reward                   | -0.5143917  |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 11          |
|    time_elapsed          | 5117        |
|    total_timesteps       | 825344      |
| train/                   |             |
|    approx_kl             | 0.005140745 |
|    clip_fraction         | 0.0349      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.41        |
|    cost_value_loss       | 43.1        |
|    cost_values           | 0.542       |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.339       |
|    lagrangian_multiplier | 0.00021     |
|    learning_rate         | 0.0003      |
|    loss                  | 21          |
|    n_updates             | 4020        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.786       |
|    value_loss            | 2.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0875      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0875      |
| reward                   | -0.21892536 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 23          |
|    time_elapsed          | 10617       |
|    total_timesteps       | 849920      |
| train/                   |             |
|    approx_kl             | 0.011359639 |
|    clip_fraction         | 0.0848      |
|    clip_range            | 0.2         |
|    cost_returns          | 8           |
|    cost_value_loss       | 94.2        |
|    cost_values           | 1.45        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00844     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 4140        |
|    policy_gradient_loss  | -0.00601    |
|    std                   | 0.771       |
|    value_loss            | 0.967       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.309        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.309        |
| reward                   | -0.36135793  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 49           |
|    time_elapsed          | 21789        |
|    total_timesteps       | 802816       |
| train/                   |              |
|    approx_kl             | 0.0052763107 |
|    clip_fraction         | 0.0317       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.1          |
|    cost_value_loss       | 80.1         |
|    cost_values           | 2.71         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0.0139       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.03         |
|    n_updates             | 3910         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.748        |
|    value_loss            | 2.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.943       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.943       |
| reward                   | -0.54110247 |
| rollout/                 |             |
|    ep_len_mean           | 621         |
|    ep_rew_mean           | -263        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 49          |
|    time_elapsed          | 23827       |
|    total_timesteps       | 802816      |
| train/                   |             |
|    approx_kl             | 0.01305941  |
|    clip_fraction         | 0.25        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.86        |
|    cost_value_loss       | 6.95        |
|    cost_values           | 2.39        |
|    entropy               | -1.64       |
|    entropy_loss          | -1.64       |
|    explained_variance    | 0.206       |
|    lagrangian_multiplier | 0.0171      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.04        |
|    n_updates             | 3910        |
|    policy_gradient_loss  | 0.0118      |
|    std                   | 0.56        |
|    value_loss            | 13.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.301       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.301       |
| reward                   | -0.43761262 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 8           |
|    time_elapsed          | 3588        |
|    total_timesteps       | 819200      |
| train/                   |             |
|    approx_kl             | 0.005731984 |
|    clip_fraction         | 0.0311      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 166         |
|    cost_values           | 1.75        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0.0205      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.48        |
|    n_updates             | 3990        |
|    policy_gradient_loss  | -0.00497    |
|    std                   | 0.92        |
|    value_loss            | 0.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.254       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.254       |
| reward                   | -0.39153838 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 4           |
|    time_elapsed          | 1904        |
|    total_timesteps       | 811008      |
| train/                   |             |
|    approx_kl             | 0.012347596 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.0201      |
|    cost_values           | 1.06        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.0863      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.304       |
|    n_updates             | 3950        |
|    policy_gradient_loss  | -0.000267   |
|    std                   | 0.807       |
|    value_loss            | 0.78        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0849       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0849       |
| reward                   | -0.39857185  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 12           |
|    time_elapsed          | 5589         |
|    total_timesteps       | 827392       |
| train/                   |              |
|    approx_kl             | 0.0026942044 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.15         |
|    cost_value_loss       | 63.8         |
|    cost_values           | 0.889        |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | -0.339       |
|    lagrangian_multiplier | 0.00662      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.84         |
|    n_updates             | 4030         |
|    policy_gradient_loss  | -0.00188     |
|    std                   | 0.786        |
|    value_loss            | 1.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0171       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0171       |
| reward                   | -0.39814118  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 24           |
|    time_elapsed          | 11095        |
|    total_timesteps       | 851968       |
| train/                   |              |
|    approx_kl             | 0.0012365329 |
|    clip_fraction         | 9.77e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 203          |
|    cost_values           | 1.91         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.831        |
|    lagrangian_multiplier | 0.00742      |
|    learning_rate         | 0.0003       |
|    loss                  | 22           |
|    n_updates             | 4150         |
|    policy_gradient_loss  | -0.000457    |
|    std                   | 0.77         |
|    value_loss            | 2.75         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.053      |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.053      |
| reward             | -0.2541826 |
| rollout/           |            |
|    ep_len_mean     | 958        |
|    ep_rew_mean     | -388       |
| time/              |            |
|    fps             | 4          |
|    iterations      | 1          |
|    time_elapsed    | 461        |
|    total_timesteps | 804864     |
-----------------------------------
------------------------------------
| avg_speed          | 7.35        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.35        |
| reward             | -0.55035233 |
| rollout/           |             |
|    ep_len_mean     | 617         |
|    ep_rew_mean     | -261        |
| time/              |             |
|    fps             | 3           |
|    iterations      | 1           |
|    time_elapsed    | 520         |
|    total_timesteps | 804864      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.0155       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0155       |
| reward                   | -0.23757938  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 9            |
|    time_elapsed          | 4045         |
|    total_timesteps       | 821248       |
| train/                   |              |
|    approx_kl             | 0.0019995281 |
|    clip_fraction         | 0.000293     |
|    clip_range            | 0.2          |
|    cost_returns          | 17.7         |
|    cost_value_loss       | 252          |
|    cost_values           | 1.96         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | -0.763       |
|    lagrangian_multiplier | 0.000949     |
|    learning_rate         | 0.0003       |
|    loss                  | 82.5         |
|    n_updates             | 4000         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.92         |
|    value_loss            | 1.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0761      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0761      |
| reward                   | -0.45231396 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 5           |
|    time_elapsed          | 2395        |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.027813803 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 157         |
|    cost_values           | 1.17        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 74.7        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | 0.00888     |
|    std                   | 0.809       |
|    value_loss            | 2.61        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0451       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0451       |
| reward                   | -0.4928846   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 13           |
|    time_elapsed          | 6064         |
|    total_timesteps       | 829440       |
| train/                   |              |
|    approx_kl             | 0.0053072684 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.651        |
|    cost_value_loss       | 0.569        |
|    cost_values           | 0.601        |
|    entropy               | -2.33        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.763        |
|    lagrangian_multiplier | 0.00015      |
|    learning_rate         | 0.0003       |
|    loss                  | 0.512        |
|    n_updates             | 4040         |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.778        |
|    value_loss            | 0.0994       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.222        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.222        |
| reward                   | -0.26401457  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 25           |
|    time_elapsed          | 11571        |
|    total_timesteps       | 854016       |
| train/                   |              |
|    approx_kl             | 0.0007319009 |
|    clip_fraction         | 0.00215      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.54         |
|    cost_value_loss       | 108          |
|    cost_values           | 2.11         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0.0109       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 4160         |
|    policy_gradient_loss  | -0.000481    |
|    std                   | 0.771        |
|    value_loss            | 2.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0189      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0189      |
| reward                   | -0.5222283  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 2           |
|    time_elapsed          | 925         |
|    total_timesteps       | 806912      |
| train/                   |             |
|    approx_kl             | 0.009296745 |
|    clip_fraction         | 0.0571      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 116         |
|    cost_values           | 2.96        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0.0172      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.81        |
|    n_updates             | 3930        |
|    policy_gradient_loss  | -0.00302    |
|    std                   | 0.75        |
|    value_loss            | 1.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.155        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.155        |
| reward                   | -0.35564312  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 10           |
|    time_elapsed          | 4502         |
|    total_timesteps       | 823296       |
| train/                   |              |
|    approx_kl             | 0.0031868017 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 17.8         |
|    cost_value_loss       | 242          |
|    cost_values           | 2.4          |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.0986       |
|    lagrangian_multiplier | 0.00378      |
|    learning_rate         | 0.0003       |
|    loss                  | 42.3         |
|    n_updates             | 4010         |
|    policy_gradient_loss  | -0.000937    |
|    std                   | 0.92         |
|    value_loss            | 2.37         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.51        |
| reward                   | -0.524171   |
| rollout/                 |             |
|    ep_len_mean           | 626         |
|    ep_rew_mean           | -265        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 2           |
|    time_elapsed          | 1053        |
|    total_timesteps       | 806912      |
| train/                   |             |
|    approx_kl             | 0.011163856 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 16.1        |
|    cost_values           | 1.95        |
|    entropy               | -1.64       |
|    entropy_loss          | -1.64       |
|    explained_variance    | 0.0194      |
|    lagrangian_multiplier | 0.00331     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.12        |
|    n_updates             | 3930        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.559       |
|    value_loss            | 7.88        |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.0881        |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.0881        |
| reward                   | -0.27789524   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -411          |
| time/                    |               |
|    fps                   | 4             |
|    iterations            | 6             |
|    time_elapsed          | 2883          |
|    total_timesteps       | 815104        |
| train/                   |               |
|    approx_kl             | 0.00030276994 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 16.3          |
|    cost_value_loss       | 230           |
|    cost_values           | 1.64          |
|    entropy               | -2.41         |
|    entropy_loss          | -2.41         |
|    explained_variance    | -1.24         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 112           |
|    n_updates             | 3970          |
|    policy_gradient_loss  | -0.00017      |
|    std                   | 0.809         |
|    value_loss            | 0.718         |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.195        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.195        |
| reward                   | -0.56010437  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 14           |
|    time_elapsed          | 6543         |
|    total_timesteps       | 831488       |
| train/                   |              |
|    approx_kl             | 0.0058246767 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.22         |
|    cost_value_loss       | 124          |
|    cost_values           | 1.35         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0.0147       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.81         |
|    n_updates             | 4050         |
|    policy_gradient_loss  | 0.0003       |
|    std                   | 0.775        |
|    value_loss            | 1.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.208        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.208        |
| reward                   | -0.256437    |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 26           |
|    time_elapsed          | 12041        |
|    total_timesteps       | 856064       |
| train/                   |              |
|    approx_kl             | 0.0020034036 |
|    clip_fraction         | 0.00859      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.54         |
|    cost_value_loss       | 57.2         |
|    cost_values           | 1.7          |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.862        |
|    lagrangian_multiplier | 0.00793      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.27         |
|    n_updates             | 4170         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.771        |
|    value_loss            | 0.838        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.288        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.288        |
| reward                   | -0.51005954  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 3            |
|    time_elapsed          | 1386         |
|    total_timesteps       | 808960       |
| train/                   |              |
|    approx_kl             | 0.0053862603 |
|    clip_fraction         | 0.0295       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.21         |
|    cost_value_loss       | 36.6         |
|    cost_values           | 2.65         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.72         |
|    lagrangian_multiplier | 0.00245      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.91         |
|    n_updates             | 3940         |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 0.748        |
|    value_loss            | 3.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.385       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.385       |
| reward                   | -0.4547069  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 11          |
|    time_elapsed          | 4962        |
|    total_timesteps       | 825344      |
| train/                   |             |
|    approx_kl             | 0.005386104 |
|    clip_fraction         | 0.0129      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.9        |
|    cost_value_loss       | 236         |
|    cost_values           | 2.85        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.327       |
|    lagrangian_multiplier | 0.0364      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.68        |
|    n_updates             | 4020        |
|    policy_gradient_loss  | -0.00204    |
|    std                   | 0.92        |
|    value_loss            | 1.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0377       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0377       |
| reward                   | -0.26913577  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 7            |
|    time_elapsed          | 3374         |
|    total_timesteps       | 817152       |
| train/                   |              |
|    approx_kl             | 0.0019946361 |
|    clip_fraction         | 0.000635     |
|    clip_range            | 0.2          |
|    cost_returns          | 7.12         |
|    cost_value_loss       | 88.4         |
|    cost_values           | 1.97         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.0535       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 43.9         |
|    n_updates             | 3980         |
|    policy_gradient_loss  | -0.000891    |
|    std                   | 0.809        |
|    value_loss            | 1.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.05        |
| reward                   | -0.56408906 |
| rollout/                 |             |
|    ep_len_mean           | 603         |
|    ep_rew_mean           | -253        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 3           |
|    time_elapsed          | 1587        |
|    total_timesteps       | 808960      |
| train/                   |             |
|    approx_kl             | 0.008720835 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.89        |
|    cost_value_loss       | 23.5        |
|    cost_values           | 2.34        |
|    entropy               | -1.64       |
|    entropy_loss          | -1.64       |
|    explained_variance    | -0.0259     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.3        |
|    n_updates             | 3940        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.559       |
|    value_loss            | 11          |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0409      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0409      |
| reward                   | -0.46951026 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 15          |
|    time_elapsed          | 7014        |
|    total_timesteps       | 833536      |
| train/                   |             |
|    approx_kl             | 0.004835157 |
|    clip_fraction         | 0.0195      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.51        |
|    cost_value_loss       | 122         |
|    cost_values           | 1.06        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0.0158      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.17        |
|    n_updates             | 4060        |
|    policy_gradient_loss  | -0.00314    |
|    std                   | 0.775       |
|    value_loss            | 0.572       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0207       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0207       |
| reward                   | -0.25481454  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 27           |
|    time_elapsed          | 12516        |
|    total_timesteps       | 858112       |
| train/                   |              |
|    approx_kl             | 0.0035075657 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.9         |
|    cost_value_loss       | 144          |
|    cost_values           | 1.97         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.491        |
|    lagrangian_multiplier | 0.00513      |
|    learning_rate         | 0.0003       |
|    loss                  | 20.9         |
|    n_updates             | 4180         |
|    policy_gradient_loss  | -0.000685    |
|    std                   | 0.771        |
|    value_loss            | 1.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.25        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.25        |
| reward                   | -0.3480878  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -388        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 4           |
|    time_elapsed          | 1848        |
|    total_timesteps       | 811008      |
| train/                   |             |
|    approx_kl             | 0.006008476 |
|    clip_fraction         | 0.0257      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 111         |
|    cost_values           | 2.72        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0.0144      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.27        |
|    n_updates             | 3950        |
|    policy_gradient_loss  | -0.00222    |
|    std                   | 0.746       |
|    value_loss            | 0.497       |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.118         |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.118         |
| reward                   | -0.292059     |
| rollout/                 |               |
|    ep_len_mean           | 972           |
|    ep_rew_mean           | -410          |
| time/                    |               |
|    fps                   | 4             |
|    iterations            | 12            |
|    time_elapsed          | 5419          |
|    total_timesteps       | 827392        |
| train/                   |               |
|    approx_kl             | 0.00022572392 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 14.6          |
|    cost_value_loss       | 199           |
|    cost_values           | 2.46          |
|    entropy               | -2.67         |
|    entropy_loss          | -2.67         |
|    explained_variance    | 0.976         |
|    lagrangian_multiplier | 0.154         |
|    learning_rate         | 0.0003        |
|    loss                  | 3.55          |
|    n_updates             | 4030          |
|    policy_gradient_loss  | -0.000683     |
|    std                   | 0.92          |
|    value_loss            | 0.471         |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0216       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0216       |
| reward                   | -0.35409072  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 8            |
|    time_elapsed          | 3867         |
|    total_timesteps       | 819200       |
| train/                   |              |
|    approx_kl             | 0.0017895097 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 0.165        |
|    cost_values           | 2.12         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.0986       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.482        |
|    n_updates             | 3990         |
|    policy_gradient_loss  | -0.000905    |
|    std                   | 0.81         |
|    value_loss            | 1.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -0.48740673 |
| rollout/                 |             |
|    ep_len_mean           | 584         |
|    ep_rew_mean           | -244        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 4           |
|    time_elapsed          | 2128        |
|    total_timesteps       | 811008      |
| train/                   |             |
|    approx_kl             | 0.008710269 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.85        |
|    cost_value_loss       | 21.2        |
|    cost_values           | 2.68        |
|    entropy               | -1.63       |
|    entropy_loss          | -1.64       |
|    explained_variance    | 0.0483      |
|    lagrangian_multiplier | 0.00509     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.11        |
|    n_updates             | 3950        |
|    policy_gradient_loss  | -0.00799    |
|    std                   | 0.557       |
|    value_loss            | 19.6        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.123      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.123      |
| reward                   | -0.3377469 |
| rollout/                 |            |
|    ep_len_mean           | 996        |
|    ep_rew_mean           | -435       |
| time/                    |            |
|    fps                   | 4          |
|    iterations            | 16         |
|    time_elapsed          | 7491       |
|    total_timesteps       | 835584     |
| train/                   |            |
|    approx_kl             | 0.00577543 |
|    clip_fraction         | 0.0152     |
|    clip_range            | 0.2        |
|    cost_returns          | 7.76       |
|    cost_value_loss       | 90.3       |
|    cost_values           | 1.51       |
|    entropy               | -2.32      |
|    entropy_loss          | -2.32      |
|    explained_variance    | 0.943      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 45.4       |
|    n_updates             | 4070       |
|    policy_gradient_loss  | -0.00211   |
|    std                   | 0.775      |
|    value_loss            | 0.132      |
-----------------------------------------
-----------------------------------------
| avg_speed                | 0.135      |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 0.135      |
| reward                   | -0.2606508 |
| rollout/                 |            |
|    ep_len_mean           | 980        |
|    ep_rew_mean           | -399       |
| time/                    |            |
|    fps                   | 4          |
|    iterations            | 28         |
|    time_elapsed          | 12993      |
|    total_timesteps       | 860160     |
| train/                   |            |
|    approx_kl             | 0.00471811 |
|    clip_fraction         | 0.0122     |
|    clip_range            | 0.2        |
|    cost_returns          | 12.3       |
|    cost_value_loss       | 153        |
|    cost_values           | 2.41       |
|    entropy               | -2.3       |
|    entropy_loss          | -2.3       |
|    explained_variance    | 0.726      |
|    lagrangian_multiplier | 0.0149     |
|    learning_rate         | 0.0003     |
|    loss                  | 11         |
|    n_updates             | 4190       |
|    policy_gradient_loss  | -0.00387   |
|    std                   | 0.77       |
|    value_loss            | 0.402      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.189       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.189       |
| reward                   | -0.45178154 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -388        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 5           |
|    time_elapsed          | 2316        |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.004022026 |
|    clip_fraction         | 0.0188      |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 174         |
|    cost_values           | 2.92        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0.0221      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.84        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.743       |
|    value_loss            | 0.202       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.172        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.172        |
| reward                   | -0.5062789   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 13           |
|    time_elapsed          | 5873         |
|    total_timesteps       | 829440       |
| train/                   |              |
|    approx_kl             | 0.0062102363 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.3         |
|    cost_value_loss       | 224          |
|    cost_values           | 2.16         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.663        |
|    lagrangian_multiplier | 0.0156       |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 4040         |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 0.921        |
|    value_loss            | 1.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.151        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.151        |
| reward                   | -0.4797854   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 9            |
|    time_elapsed          | 4355         |
|    total_timesteps       | 821248       |
| train/                   |              |
|    approx_kl             | 0.0018046859 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.84         |
|    cost_value_loss       | 30           |
|    cost_values           | 1.97         |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.151        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17           |
|    n_updates             | 4000         |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.808        |
|    value_loss            | 4.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0453       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0453       |
| reward                   | -0.32683778  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 17           |
|    time_elapsed          | 7972         |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0056866696 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.96         |
|    cost_value_loss       | 40.6         |
|    cost_values           | 1.1          |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | -0.697       |
|    lagrangian_multiplier | 0.00205      |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 0.775        |
|    value_loss            | 2.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.6622547  |
| rollout/                 |             |
|    ep_len_mean           | 595         |
|    ep_rew_mean           | -249        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 5           |
|    time_elapsed          | 2670        |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.010311844 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.7         |
|    cost_value_loss       | 23.9        |
|    cost_values           | 2.56        |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.248       |
|    lagrangian_multiplier | 0.00207     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | 0.00115     |
|    std                   | 0.556       |
|    value_loss            | 20.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.34         |
| reward                   | -0.49621388  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -387         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 6            |
|    time_elapsed          | 2780         |
|    total_timesteps       | 815104       |
| train/                   |              |
|    approx_kl             | 0.0033412683 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 16           |
|    cost_value_loss       | 194          |
|    cost_values           | 2.94         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0.023        |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 3970         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.741        |
|    value_loss            | 1.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.129        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.129        |
| reward                   | -0.32255033  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 29           |
|    time_elapsed          | 13473        |
|    total_timesteps       | 862208       |
| train/                   |              |
|    approx_kl             | 0.0007157086 |
|    clip_fraction         | 0.00229      |
|    clip_range            | 0.2          |
|    cost_returns          | 16           |
|    cost_value_loss       | 205          |
|    cost_values           | 2.66         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.292        |
|    lagrangian_multiplier | 0.021        |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 4200         |
|    policy_gradient_loss  | 9.72e-05     |
|    std                   | 0.77         |
|    value_loss            | 2.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.217        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.217        |
| reward                   | -0.5879459   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 14           |
|    time_elapsed          | 6335         |
|    total_timesteps       | 831488       |
| train/                   |              |
|    approx_kl             | 0.0002655717 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 9.68         |
|    cost_value_loss       | 116          |
|    cost_values           | 1.94         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0.0287       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.55         |
|    n_updates             | 4050         |
|    policy_gradient_loss  | -9.36e-05    |
|    std                   | 0.921        |
|    value_loss            | 0.857        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0624       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0624       |
| reward                   | -0.35455534  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 10           |
|    time_elapsed          | 4846         |
|    total_timesteps       | 823296       |
| train/                   |              |
|    approx_kl             | 0.0041084182 |
|    clip_fraction         | 0.00674      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.79         |
|    cost_value_loss       | 85.4         |
|    cost_values           | 2.4          |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.846        |
|    lagrangian_multiplier | 0.00599      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 4010         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.807        |
|    value_loss            | 0.571        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0534       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0534       |
| reward                   | -0.54959315  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 18           |
|    time_elapsed          | 8455         |
|    total_timesteps       | 839680       |
| train/                   |              |
|    approx_kl             | 0.0026246996 |
|    clip_fraction         | 0.00454      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 3.84         |
|    cost_values           | 0.844        |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.863        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.76         |
|    n_updates             | 4090         |
|    policy_gradient_loss  | -0.00085     |
|    std                   | 0.773        |
|    value_loss            | 1.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.24         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.24         |
| reward                   | -0.45809835  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 7            |
|    time_elapsed          | 3241         |
|    total_timesteps       | 817152       |
| train/                   |              |
|    approx_kl             | 0.0057661254 |
|    clip_fraction         | 0.0935       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.03         |
|    cost_value_loss       | 35.4         |
|    cost_values           | 2.85         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0.00457      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.06         |
|    n_updates             | 3980         |
|    policy_gradient_loss  | -0.00459     |
|    std                   | 0.741        |
|    value_loss            | 0.294        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.59        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.59        |
| reward                   | -0.5327556  |
| rollout/                 |             |
|    ep_len_mean           | 588         |
|    ep_rew_mean           | -247        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 6           |
|    time_elapsed          | 3215        |
|    total_timesteps       | 815104      |
| train/                   |             |
|    approx_kl             | 0.006862016 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 16.1        |
|    cost_values           | 2.25        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.445       |
|    lagrangian_multiplier | 0.00525     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.05        |
|    n_updates             | 3970        |
|    policy_gradient_loss  | -0.00792    |
|    std                   | 0.553       |
|    value_loss            | 2.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.101       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.101       |
| reward                   | -0.55201143 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 30          |
|    time_elapsed          | 13955       |
|    total_timesteps       | 864256      |
| train/                   |             |
|    approx_kl             | 0.003397921 |
|    clip_fraction         | 0.00576     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.99        |
|    cost_value_loss       | 9.77        |
|    cost_values           | 2.2         |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.629       |
|    lagrangian_multiplier | 0.0318      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 4210        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.77        |
|    value_loss            | 1.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.231       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.231       |
| reward                   | -0.24088308 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 15          |
|    time_elapsed          | 6797        |
|    total_timesteps       | 833536      |
| train/                   |             |
|    approx_kl             | 0.004387803 |
|    clip_fraction         | 0.0259      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.21        |
|    cost_value_loss       | 81.8        |
|    cost_values           | 1.24        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.77        |
|    lagrangian_multiplier | 0.0108      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.34        |
|    n_updates             | 4060        |
|    policy_gradient_loss  | -0.00331    |
|    std                   | 0.922       |
|    value_loss            | 0.467       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.253        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.253        |
| reward                   | -0.47957188  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 11           |
|    time_elapsed          | 5336         |
|    total_timesteps       | 825344       |
| train/                   |              |
|    approx_kl             | 0.0058782743 |
|    clip_fraction         | 0.0267       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.42         |
|    cost_value_loss       | 9.8          |
|    cost_values           | 2.48         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.87         |
|    lagrangian_multiplier | 0.00238      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.98         |
|    n_updates             | 4020         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.802        |
|    value_loss            | 0.482        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.11         |
| reward                   | -0.2534734   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -430         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 19           |
|    time_elapsed          | 8933         |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0049146395 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.25         |
|    cost_value_loss       | 1.68         |
|    cost_values           | 1.1          |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.808        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.868        |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.771        |
|    value_loss            | 1.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.214       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.214       |
| reward                   | -0.22516024 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -395        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 8           |
|    time_elapsed          | 3702        |
|    total_timesteps       | 819200      |
| train/                   |             |
|    approx_kl             | 0.009070509 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 186         |
|    cost_values           | 2.89        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.759       |
|    lagrangian_multiplier | 0.0238      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.76        |
|    n_updates             | 3990        |
|    policy_gradient_loss  | -0.00834    |
|    std                   | 0.741       |
|    value_loss            | 0.144       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.112        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.112        |
| reward                   | -0.45372018  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 31           |
|    time_elapsed          | 14439        |
|    total_timesteps       | 866304       |
| train/                   |              |
|    approx_kl             | 0.0049063032 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.01         |
|    cost_value_loss       | 4.37         |
|    cost_values           | 1.52         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.886        |
|    lagrangian_multiplier | 0.000529     |
|    learning_rate         | 0.0003       |
|    loss                  | 1.89         |
|    n_updates             | 4220         |
|    policy_gradient_loss  | -0.0024      |
|    std                   | 0.769        |
|    value_loss            | 1.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.184        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.184        |
| reward                   | -0.3095293   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 16           |
|    time_elapsed          | 7259         |
|    total_timesteps       | 835584       |
| train/                   |              |
|    approx_kl             | 0.0075408784 |
|    clip_fraction         | 0.0787       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.26         |
|    cost_value_loss       | 130          |
|    cost_values           | 1.33         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0.0127       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.87         |
|    n_updates             | 4070         |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 0.922        |
|    value_loss            | 0.512        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.46275365 |
| rollout/                 |             |
|    ep_len_mean           | 589         |
|    ep_rew_mean           | -247        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 7           |
|    time_elapsed          | 3760        |
|    total_timesteps       | 817152      |
| train/                   |             |
|    approx_kl             | 0.008851583 |
|    clip_fraction         | 0.251       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.44        |
|    cost_value_loss       | 20.4        |
|    cost_values           | 2.54        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.0469      |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 20.8        |
|    n_updates             | 3980        |
|    policy_gradient_loss  | 0.00741     |
|    std                   | 0.552       |
|    value_loss            | 37.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00617      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00617      |
| reward                   | -0.53152627  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 12           |
|    time_elapsed          | 5828         |
|    total_timesteps       | 827392       |
| train/                   |              |
|    approx_kl             | 0.0034427352 |
|    clip_fraction         | 0.0555       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 138          |
|    cost_values           | 2.55         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.864        |
|    lagrangian_multiplier | 0.0164       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.63         |
|    n_updates             | 4030         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 0.802        |
|    value_loss            | 0.741        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.008        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.008        |
| reward                   | -0.42972177  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 20           |
|    time_elapsed          | 9413         |
|    total_timesteps       | 843776       |
| train/                   |              |
|    approx_kl             | 0.0047942586 |
|    clip_fraction         | 0.0043       |
|    clip_range            | 0.2          |
|    cost_returns          | 2            |
|    cost_value_loss       | 12.4         |
|    cost_values           | 1.06         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.871        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.04         |
|    n_updates             | 4110         |
|    policy_gradient_loss  | -0.000207    |
|    std                   | 0.772        |
|    value_loss            | 0.964        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.2903336   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 9            |
|    time_elapsed          | 4176         |
|    total_timesteps       | 821248       |
| train/                   |              |
|    approx_kl             | 0.0037341719 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.1         |
|    cost_value_loss       | 113          |
|    cost_values           | 2.71         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.737        |
|    lagrangian_multiplier | 0.0125       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 4000         |
|    policy_gradient_loss  | -0.000291    |
|    std                   | 0.742        |
|    value_loss            | 2.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.189        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.189        |
| reward                   | -0.6196168   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 32           |
|    time_elapsed          | 14923        |
|    total_timesteps       | 868352       |
| train/                   |              |
|    approx_kl             | 0.0035041324 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.32         |
|    cost_value_loss       | 85.2         |
|    cost_values           | 1.75         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0.923        |
|    lagrangian_multiplier | 0.00811      |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 4230         |
|    policy_gradient_loss  | -0.000741    |
|    std                   | 0.769        |
|    value_loss            | 1.81         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.233         |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 0.233         |
| reward                   | -0.33308724   |
| rollout/                 |               |
|    ep_len_mean           | 972           |
|    ep_rew_mean           | -416          |
| time/                    |               |
|    fps                   | 4             |
|    iterations            | 17            |
|    time_elapsed          | 7718          |
|    total_timesteps       | 837632        |
| train/                   |               |
|    approx_kl             | 0.00029899826 |
|    clip_fraction         | 0.000146      |
|    clip_range            | 0.2           |
|    cost_returns          | 17.5          |
|    cost_value_loss       | 253           |
|    cost_values           | 1.78          |
|    entropy               | -2.67         |
|    entropy_loss          | -2.67         |
|    explained_variance    | 0.957         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 124           |
|    n_updates             | 4080          |
|    policy_gradient_loss  | -9.58e-05     |
|    std                   | 0.921         |
|    value_loss            | 0.815         |
--------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.8258323  |
| rollout/                 |             |
|    ep_len_mean           | 585         |
|    ep_rew_mean           | -245        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 8           |
|    time_elapsed          | 4307        |
|    total_timesteps       | 819200      |
| train/                   |             |
|    approx_kl             | 0.005418711 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.69        |
|    cost_value_loss       | 18.2        |
|    cost_values           | 2.86        |
|    entropy               | -1.61       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.113       |
|    lagrangian_multiplier | 0.00597     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.51        |
|    n_updates             | 3990        |
|    policy_gradient_loss  | -0.00373    |
|    std                   | 0.551       |
|    value_loss            | 18.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.236       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.236       |
| reward                   | -0.48356476 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 13          |
|    time_elapsed          | 6323        |
|    total_timesteps       | 829440      |
| train/                   |             |
|    approx_kl             | 0.002575159 |
|    clip_fraction         | 0.0211      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.88        |
|    cost_value_loss       | 84.1        |
|    cost_values           | 2.52        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.478       |
|    lagrangian_multiplier | 0.013       |
|    learning_rate         | 0.0003      |
|    loss                  | 7.92        |
|    n_updates             | 4040        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.802       |
|    value_loss            | 2.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.149       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.149       |
| reward                   | -0.55412114 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 21          |
|    time_elapsed          | 9898        |
|    total_timesteps       | 845824      |
| train/                   |             |
|    approx_kl             | 0.010917158 |
|    clip_fraction         | 0.0636      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.579       |
|    cost_value_loss       | 0.0198      |
|    cost_values           | 0.682       |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.119       |
|    n_updates             | 4120        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.771       |
|    value_loss            | 0.864       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0253      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0253      |
| reward                   | -0.3784365  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 10          |
|    time_elapsed          | 4653        |
|    total_timesteps       | 823296      |
| train/                   |             |
|    approx_kl             | 0.005261183 |
|    clip_fraction         | 0.0256      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.79        |
|    cost_value_loss       | 39.9        |
|    cost_values           | 2.75        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0.00771     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.42        |
|    n_updates             | 4010        |
|    policy_gradient_loss  | -0.00359    |
|    std                   | 0.741       |
|    value_loss            | 1.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0564      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0564      |
| reward                   | -0.4949904  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 18          |
|    time_elapsed          | 8183        |
|    total_timesteps       | 839680      |
| train/                   |             |
|    approx_kl             | 0.014877357 |
|    clip_fraction         | 0.0431      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.4        |
|    cost_value_loss       | 151         |
|    cost_values           | 1.57        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0.0133      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 4090        |
|    policy_gradient_loss  | -0.00384    |
|    std                   | 0.921       |
|    value_loss            | 0.402       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.231        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.231        |
| reward                   | -0.5375083   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 33           |
|    time_elapsed          | 15408        |
|    total_timesteps       | 870400       |
| train/                   |              |
|    approx_kl             | 0.0079446575 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 1.37         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0.949        |
|    lagrangian_multiplier | 0.00167      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.21         |
|    n_updates             | 4240         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.77         |
|    value_loss            | 2.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.53        |
| reward                   | -0.48390603 |
| rollout/                 |             |
|    ep_len_mean           | 581         |
|    ep_rew_mean           | -244        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 9           |
|    time_elapsed          | 4861        |
|    total_timesteps       | 821248      |
| train/                   |             |
|    approx_kl             | 0.006537201 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.08        |
|    cost_value_loss       | 16          |
|    cost_values           | 2.83        |
|    entropy               | -1.61       |
|    entropy_loss          | -1.61       |
|    explained_variance    | 0.212       |
|    lagrangian_multiplier | 0.00306     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.92        |
|    n_updates             | 4000        |
|    policy_gradient_loss  | 0.000812    |
|    std                   | 0.549       |
|    value_loss            | 9.03        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0572       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0572       |
| reward                   | -0.3434135   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 14           |
|    time_elapsed          | 6812         |
|    total_timesteps       | 831488       |
| train/                   |              |
|    approx_kl             | 0.0039720656 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 171          |
|    cost_values           | 2.33         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.788        |
|    lagrangian_multiplier | 0.0237       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.73         |
|    n_updates             | 4050         |
|    policy_gradient_loss  | -0.000809    |
|    std                   | 0.8          |
|    value_loss            | 2.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.237        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.237        |
| reward                   | -0.35491693  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 22           |
|    time_elapsed          | 10385        |
|    total_timesteps       | 847872       |
| train/                   |              |
|    approx_kl             | 0.0060241567 |
|    clip_fraction         | 0.0377       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.97         |
|    cost_value_loss       | 18.1         |
|    cost_values           | 0.455        |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | -2.8         |
|    lagrangian_multiplier | 0.00341      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.36         |
|    n_updates             | 4130         |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.77         |
|    value_loss            | 0.776        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.269        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.269        |
| reward                   | -0.28465095  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 11           |
|    time_elapsed          | 5131         |
|    total_timesteps       | 825344       |
| train/                   |              |
|    approx_kl             | 0.0070041786 |
|    clip_fraction         | 0.0623       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.5         |
|    cost_value_loss       | 138          |
|    cost_values           | 2.92         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.921        |
|    lagrangian_multiplier | 0.018        |
|    learning_rate         | 0.0003       |
|    loss                  | 9.9          |
|    n_updates             | 4020         |
|    policy_gradient_loss  | -0.00572     |
|    std                   | 0.741        |
|    value_loss            | 0.726        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.283        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.283        |
| reward                   | -0.43754503  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 19           |
|    time_elapsed          | 8651         |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0048415298 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.65         |
|    cost_value_loss       | 38.1         |
|    cost_values           | 1.19         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.924        |
|    lagrangian_multiplier | 0.00254      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.98         |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.921        |
|    value_loss            | 1.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00719     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00719     |
| reward                   | -0.33681947 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 34          |
|    time_elapsed          | 15894       |
|    total_timesteps       | 872448      |
| train/                   |             |
|    approx_kl             | 0.005926583 |
|    clip_fraction         | 0.0519      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.22        |
|    cost_value_loss       | 63.9        |
|    cost_values           | 1.45        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.00259     |
|    learning_rate         | 0.0003      |
|    loss                  | 15.3        |
|    n_updates             | 4250        |
|    policy_gradient_loss  | -0.00472    |
|    std                   | 0.77        |
|    value_loss            | 0.671       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.74        |
| reward                   | -0.24158108 |
| rollout/                 |             |
|    ep_len_mean           | 575         |
|    ep_rew_mean           | -242        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 10          |
|    time_elapsed          | 5413        |
|    total_timesteps       | 823296      |
| train/                   |             |
|    approx_kl             | 0.015177928 |
|    clip_fraction         | 0.0907      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.43        |
|    cost_value_loss       | 20.7        |
|    cost_values           | 2.62        |
|    entropy               | -1.61       |
|    entropy_loss          | -1.61       |
|    explained_variance    | 0.398       |
|    lagrangian_multiplier | 0.00114     |
|    learning_rate         | 0.0003      |
|    loss                  | 13.9        |
|    n_updates             | 4010        |
|    policy_gradient_loss  | -0.00752    |
|    std                   | 0.55        |
|    value_loss            | 18.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.126        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.126        |
| reward                   | -0.3370537   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 15           |
|    time_elapsed          | 7310         |
|    total_timesteps       | 833536       |
| train/                   |              |
|    approx_kl             | 0.0042627645 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 0.139        |
|    cost_values           | 2.03         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.0634       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.707        |
|    n_updates             | 4060         |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 0.799        |
|    value_loss            | 2.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0857       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0857       |
| reward                   | -0.25481024  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 23           |
|    time_elapsed          | 10873        |
|    total_timesteps       | 849920       |
| train/                   |              |
|    approx_kl             | 0.0058130054 |
|    clip_fraction         | 0.0388       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.254        |
|    cost_value_loss       | 0.00216      |
|    cost_values           | 0.245        |
|    entropy               | -2.3         |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.634        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.03         |
|    n_updates             | 4140         |
|    policy_gradient_loss  | -9.04e-05    |
|    std                   | 0.767        |
|    value_loss            | 2.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.31189647  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 12           |
|    time_elapsed          | 5608         |
|    total_timesteps       | 827392       |
| train/                   |              |
|    approx_kl             | 0.0035517514 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.32         |
|    cost_value_loss       | 98           |
|    cost_values           | 2.42         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0.101        |
|    learning_rate         | 0.0003       |
|    loss                  | 3.23         |
|    n_updates             | 4030         |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 0.741        |
|    value_loss            | 3.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0543       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0543       |
| reward                   | -0.59368646  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 20           |
|    time_elapsed          | 9120         |
|    total_timesteps       | 843776       |
| train/                   |              |
|    approx_kl             | 0.0073274793 |
|    clip_fraction         | 0.0582       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.3         |
|    cost_value_loss       | 156          |
|    cost_values           | 1.58         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0.0171       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.36         |
|    n_updates             | 4110         |
|    policy_gradient_loss  | -0.00445     |
|    std                   | 0.921        |
|    value_loss            | 0.495        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.299       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.299       |
| reward                   | -0.49016276 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 35          |
|    time_elapsed          | 16377       |
|    total_timesteps       | 874496      |
| train/                   |             |
|    approx_kl             | 0.00643274  |
|    clip_fraction         | 0.0975      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.49        |
|    cost_value_loss       | 1.88        |
|    cost_values           | 1.35        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0.000127    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.02        |
|    n_updates             | 4260        |
|    policy_gradient_loss  | -0.0054     |
|    std                   | 0.766       |
|    value_loss            | 0.585       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -0.40065327  |
| rollout/                 |              |
|    ep_len_mean           | 578          |
|    ep_rew_mean           | -241         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 11           |
|    time_elapsed          | 5967         |
|    total_timesteps       | 825344       |
| train/                   |              |
|    approx_kl             | 0.0074394722 |
|    clip_fraction         | 0.0591       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.49         |
|    cost_value_loss       | 18.3         |
|    cost_values           | 2.66         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.61        |
|    explained_variance    | 0.114        |
|    lagrangian_multiplier | 0.000339     |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 4020         |
|    policy_gradient_loss  | -0.00594     |
|    std                   | 0.548        |
|    value_loss            | 13           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.47325426 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 24          |
|    time_elapsed          | 11354       |
|    total_timesteps       | 851968      |
| train/                   |             |
|    approx_kl             | 0.007221099 |
|    clip_fraction         | 0.0447      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.62        |
|    cost_value_loss       | 26.3        |
|    cost_values           | 1.07        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.366       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 4150        |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 0.766       |
|    value_loss            | 0.593       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.19        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.19        |
| reward                   | -0.38208702 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 16          |
|    time_elapsed          | 7807        |
|    total_timesteps       | 835584      |
| train/                   |             |
|    approx_kl             | 0.003909285 |
|    clip_fraction         | 0.0132      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.9        |
|    cost_value_loss       | 184         |
|    cost_values           | 2.18        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0.00719     |
|    learning_rate         | 0.0003      |
|    loss                  | 20.8        |
|    n_updates             | 4070        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.798       |
|    value_loss            | 0.316       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.167        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.167        |
| reward                   | -0.48146486  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 13           |
|    time_elapsed          | 6087         |
|    total_timesteps       | 829440       |
| train/                   |              |
|    approx_kl             | 0.0032737586 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.26         |
|    cost_value_loss       | 50.4         |
|    cost_values           | 2.16         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.0432       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.2         |
|    n_updates             | 4040         |
|    policy_gradient_loss  | -0.00202     |
|    std                   | 0.741        |
|    value_loss            | 0.705        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.218       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.218       |
| reward                   | -0.46307188 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 21          |
|    time_elapsed          | 9590        |
|    total_timesteps       | 845824      |
| train/                   |             |
|    approx_kl             | 0.006988645 |
|    clip_fraction         | 0.0774      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.84        |
|    cost_value_loss       | 135         |
|    cost_values           | 1.43        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.023       |
|    learning_rate         | 0.0003      |
|    loss                  | 7.01        |
|    n_updates             | 4120        |
|    policy_gradient_loss  | -0.00726    |
|    std                   | 0.926       |
|    value_loss            | 0.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0263      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0263      |
| reward                   | -0.4712144  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 36          |
|    time_elapsed          | 16869       |
|    total_timesteps       | 876544      |
| train/                   |             |
|    approx_kl             | 0.018203571 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.84        |
|    cost_value_loss       | 93.2        |
|    cost_values           | 1.62        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0.00543     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.8        |
|    n_updates             | 4270        |
|    policy_gradient_loss  | -0.0101     |
|    std                   | 0.763       |
|    value_loss            | 0.467       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.51665473  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 25           |
|    time_elapsed          | 11836        |
|    total_timesteps       | 854016       |
| train/                   |              |
|    approx_kl             | 0.0025334442 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.76         |
|    cost_value_loss       | 46.4         |
|    cost_values           | 0.74         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.904        |
|    lagrangian_multiplier | 0.00396      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.38         |
|    n_updates             | 4160         |
|    policy_gradient_loss  | -0.000442    |
|    std                   | 0.766        |
|    value_loss            | 3.01         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.106       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.106       |
| reward                   | -0.45823473 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 17          |
|    time_elapsed          | 8309        |
|    total_timesteps       | 837632      |
| train/                   |             |
|    approx_kl             | 0.005395312 |
|    clip_fraction         | 0.0307      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 131         |
|    cost_values           | 2.18        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0.0151      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.57        |
|    n_updates             | 4080        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.798       |
|    value_loss            | 0.625       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.03        |
| reward                   | -0.39034355 |
| rollout/                 |             |
|    ep_len_mean           | 559         |
|    ep_rew_mean           | -232        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 12          |
|    time_elapsed          | 6522        |
|    total_timesteps       | 827392      |
| train/                   |             |
|    approx_kl             | 0.012924535 |
|    clip_fraction         | 0.0751      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.9         |
|    cost_value_loss       | 19.6        |
|    cost_values           | 2.92        |
|    entropy               | -1.6        |
|    entropy_loss          | -1.6        |
|    explained_variance    | 0.273       |
|    lagrangian_multiplier | 0.00544     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.64        |
|    n_updates             | 4030        |
|    policy_gradient_loss  | -0.00384    |
|    std                   | 0.547       |
|    value_loss            | 8.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.253       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.253       |
| reward                   | -0.48299176 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -390        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 14          |
|    time_elapsed          | 6573        |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.006861757 |
|    clip_fraction         | 0.0355      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.76        |
|    cost_value_loss       | 72.3        |
|    cost_values           | 2.48        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.695       |
|    lagrangian_multiplier | 0.00826     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.44        |
|    n_updates             | 4050        |
|    policy_gradient_loss  | -0.00358    |
|    std                   | 0.74        |
|    value_loss            | 0.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.134       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.134       |
| reward                   | -0.5476727  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -412        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 22          |
|    time_elapsed          | 10059       |
|    total_timesteps       | 847872      |
| train/                   |             |
|    approx_kl             | 0.012179796 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.69        |
|    cost_value_loss       | 117         |
|    cost_values           | 1.39        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.0157      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.1         |
|    n_updates             | 4130        |
|    policy_gradient_loss  | -0.0139     |
|    std                   | 0.928       |
|    value_loss            | 0.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.117       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.117       |
| reward                   | -0.31625968 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 37          |
|    time_elapsed          | 17358       |
|    total_timesteps       | 878592      |
| train/                   |             |
|    approx_kl             | 0.004200661 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.2         |
|    cost_value_loss       | 0.278       |
|    cost_values           | 1.28        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.297       |
|    n_updates             | 4280        |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.762       |
|    value_loss            | 0.806       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00202      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00202      |
| reward                   | -0.32381067  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 26           |
|    time_elapsed          | 12325        |
|    total_timesteps       | 856064       |
| train/                   |              |
|    approx_kl             | 0.0051074233 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.32         |
|    cost_value_loss       | 99.2         |
|    cost_values           | 1.04         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.942        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 50           |
|    n_updates             | 4170         |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.765        |
|    value_loss            | 2.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.261        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.261        |
| reward                   | -0.4549302   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 18           |
|    time_elapsed          | 8807         |
|    total_timesteps       | 839680       |
| train/                   |              |
|    approx_kl             | 0.0061390437 |
|    clip_fraction         | 0.0486       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 42.6         |
|    cost_values           | 2.03         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0.00614      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.73         |
|    n_updates             | 4090         |
|    policy_gradient_loss  | -0.00574     |
|    std                   | 0.795        |
|    value_loss            | 0.468        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0111       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0111       |
| reward                   | -0.34166357  |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 15           |
|    time_elapsed          | 7054         |
|    total_timesteps       | 833536       |
| train/                   |              |
|    approx_kl             | 0.0035826466 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.9         |
|    cost_value_loss       | 135          |
|    cost_values           | 2.83         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.642        |
|    lagrangian_multiplier | 0.0228       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.26         |
|    n_updates             | 4060         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.738        |
|    value_loss            | 1.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0637       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0637       |
| reward                   | -0.33879668  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 23           |
|    time_elapsed          | 10523        |
|    total_timesteps       | 849920       |
| train/                   |              |
|    approx_kl             | 0.0061489088 |
|    clip_fraction         | 0.0669       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 164          |
|    cost_values           | 1.48         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.69        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0.0172       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.98         |
|    n_updates             | 4140         |
|    policy_gradient_loss  | -0.00611     |
|    std                   | 0.925        |
|    value_loss            | 0.326        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.33        |
| reward                   | -0.23274072 |
| rollout/                 |             |
|    ep_len_mean           | 562         |
|    ep_rew_mean           | -233        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 13          |
|    time_elapsed          | 7075        |
|    total_timesteps       | 829440      |
| train/                   |             |
|    approx_kl             | 0.012777521 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 6.76        |
|    cost_value_loss       | 20.1        |
|    cost_values           | 2.92        |
|    entropy               | -1.6        |
|    entropy_loss          | -1.6        |
|    explained_variance    | 0.0561      |
|    lagrangian_multiplier | 0.00654     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.86        |
|    n_updates             | 4040        |
|    policy_gradient_loss  | -0.00527    |
|    std                   | 0.547       |
|    value_loss            | 24.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.041        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.041        |
| reward                   | -0.43018174  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 38           |
|    time_elapsed          | 17847        |
|    total_timesteps       | 880640       |
| train/                   |              |
|    approx_kl             | 0.0058316207 |
|    clip_fraction         | 0.139        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.6          |
|    cost_value_loss       | 18.5         |
|    cost_values           | 1.12         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0.000506     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.72         |
|    n_updates             | 4290         |
|    policy_gradient_loss  | 0.0142       |
|    std                   | 0.763        |
|    value_loss            | 1.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0788       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0788       |
| reward                   | -0.43693462  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 27           |
|    time_elapsed          | 12810        |
|    total_timesteps       | 858112       |
| train/                   |              |
|    approx_kl             | 0.0007724317 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 9.5          |
|    cost_value_loss       | 134          |
|    cost_values           | 0.982        |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.852        |
|    lagrangian_multiplier | 0.0135       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.03         |
|    n_updates             | 4180         |
|    policy_gradient_loss  | -0.000367    |
|    std                   | 0.765        |
|    value_loss            | 2.24         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.193        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.193        |
| reward                   | -0.59551185  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 16           |
|    time_elapsed          | 7526         |
|    total_timesteps       | 835584       |
| train/                   |              |
|    approx_kl             | 0.0057728733 |
|    clip_fraction         | 0.0418       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.72         |
|    cost_value_loss       | 18.2         |
|    cost_values           | 2.84         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.102        |
|    lagrangian_multiplier | 0.00495      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.03         |
|    n_updates             | 4070         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.738        |
|    value_loss            | 1.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0386       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0386       |
| reward                   | -0.414472    |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 24           |
|    time_elapsed          | 10994        |
|    total_timesteps       | 851968       |
| train/                   |              |
|    approx_kl             | 0.0050756205 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.03         |
|    cost_value_loss       | 41.9         |
|    cost_values           | 1.39         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0.00679      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.49         |
|    n_updates             | 4150         |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.923        |
|    value_loss            | 0.835        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0738       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0738       |
| reward                   | -0.55740535  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 19           |
|    time_elapsed          | 9303         |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0028888783 |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.75         |
|    cost_value_loss       | 1.5          |
|    cost_values           | 1.71         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.871        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.1          |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.792        |
|    value_loss            | 0.575        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0659      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0659      |
| reward                   | -0.44605723 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 39          |
|    time_elapsed          | 18338       |
|    total_timesteps       | 882688      |
| train/                   |             |
|    approx_kl             | 0.005570614 |
|    clip_fraction         | 0.0262      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.41        |
|    cost_value_loss       | 7.71        |
|    cost_values           | 0.742       |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.269       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.28        |
|    n_updates             | 4300        |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.761       |
|    value_loss            | 1.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.72        |
| reward                   | -0.57880086 |
| rollout/                 |             |
|    ep_len_mean           | 547         |
|    ep_rew_mean           | -227        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 14          |
|    time_elapsed          | 7635        |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.0156558   |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.25        |
|    cost_value_loss       | 18.3        |
|    cost_values           | 2.68        |
|    entropy               | -1.58       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0.125       |
|    lagrangian_multiplier | 0.00516     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.56        |
|    n_updates             | 4050        |
|    policy_gradient_loss  | -0.00384    |
|    std                   | 0.542       |
|    value_loss            | 9.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0246      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0246      |
| reward                   | -0.51845825 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 28          |
|    time_elapsed          | 13296       |
|    total_timesteps       | 860160      |
| train/                   |             |
|    approx_kl             | 0.00421041  |
|    clip_fraction         | 0.00376     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 69          |
|    cost_values           | 0.728       |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.787       |
|    lagrangian_multiplier | 0.009       |
|    learning_rate         | 0.0003      |
|    loss                  | 7.42        |
|    n_updates             | 4190        |
|    policy_gradient_loss  | -0.000645   |
|    std                   | 0.766       |
|    value_loss            | 2.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.126        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.126        |
| reward                   | -0.37177652  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 17           |
|    time_elapsed          | 8003         |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0039784014 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 99.1         |
|    cost_values           | 2.83         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.281        |
|    lagrangian_multiplier | 0.0114       |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 0.737        |
|    value_loss            | 7.24         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.283        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.283        |
| reward                   | -0.24379753  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 25           |
|    time_elapsed          | 11466        |
|    total_timesteps       | 854016       |
| train/                   |              |
|    approx_kl             | 0.0027423953 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.73         |
|    cost_value_loss       | 35           |
|    cost_values           | 1.42         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0.00907      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.53         |
|    n_updates             | 4160         |
|    policy_gradient_loss  | -0.00301     |
|    std                   | 0.918        |
|    value_loss            | 0.894        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.135        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.135        |
| reward                   | -0.47984704  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 20           |
|    time_elapsed          | 9797         |
|    total_timesteps       | 843776       |
| train/                   |              |
|    approx_kl             | 0.0017968573 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 0.0482       |
|    cost_values           | 1.47         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.37        |
|    explained_variance    | -0.00802     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.361        |
|    n_updates             | 4110         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.791        |
|    value_loss            | 0.925        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.154       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.154       |
| reward                   | -0.50808394 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 40          |
|    time_elapsed          | 18823       |
|    total_timesteps       | 884736      |
| train/                   |             |
|    approx_kl             | 0.00813322  |
|    clip_fraction         | 0.0402      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.14        |
|    cost_value_loss       | 120         |
|    cost_values           | 1.3         |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0.00772     |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 4310        |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 0.759       |
|    value_loss            | 0.608       |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.42         |
| reward                   | -0.40595013  |
| rollout/                 |              |
|    ep_len_mean           | 529          |
|    ep_rew_mean           | -216         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 15           |
|    time_elapsed          | 8199         |
|    total_timesteps       | 833536       |
| train/                   |              |
|    approx_kl             | 0.0067729126 |
|    clip_fraction         | 0.114        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.66         |
|    cost_value_loss       | 21.6         |
|    cost_values           | 2.56         |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.148        |
|    lagrangian_multiplier | 0.00755      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.88         |
|    n_updates             | 4060         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.54         |
|    value_loss            | 21.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0349      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0349      |
| reward                   | -0.4344324  |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 29          |
|    time_elapsed          | 13785       |
|    total_timesteps       | 862208      |
| train/                   |             |
|    approx_kl             | 0.001110539 |
|    clip_fraction         | 0.00444     |
|    clip_range            | 0.2         |
|    cost_returns          | 3.65        |
|    cost_value_loss       | 43.1        |
|    cost_values           | 0.799       |
|    entropy               | -2.3        |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0.00539     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.42        |
|    n_updates             | 4200        |
|    policy_gradient_loss  | -5.76e-05   |
|    std                   | 0.767       |
|    value_loss            | 1.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.181        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.181        |
| reward                   | -0.57579625  |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 18           |
|    time_elapsed          | 8483         |
|    total_timesteps       | 839680       |
| train/                   |              |
|    approx_kl             | 0.0053475206 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.4         |
|    cost_value_loss       | 149          |
|    cost_values           | 2.78         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.853        |
|    lagrangian_multiplier | 0.0184       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.96         |
|    n_updates             | 4090         |
|    policy_gradient_loss  | -0.000972    |
|    std                   | 0.734        |
|    value_loss            | 2.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.168        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.168        |
| reward                   | -0.34017035  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 26           |
|    time_elapsed          | 11956        |
|    total_timesteps       | 856064       |
| train/                   |              |
|    approx_kl             | 0.0059909797 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 16           |
|    cost_value_loss       | 227          |
|    cost_values           | 1.67         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.889        |
|    lagrangian_multiplier | 0.0225       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 4170         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.916        |
|    value_loss            | 0.693        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00121     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00121     |
| reward                   | -0.5566103  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 21          |
|    time_elapsed          | 10306       |
|    total_timesteps       | 845824      |
| train/                   |             |
|    approx_kl             | 0.008483118 |
|    clip_fraction         | 0.0847      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.72        |
|    cost_value_loss       | 35.9        |
|    cost_values           | 1.02        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.0875      |
|    learning_rate         | 0.0003      |
|    loss                  | 1.46        |
|    n_updates             | 4120        |
|    policy_gradient_loss  | -0.000358   |
|    std                   | 0.79        |
|    value_loss            | 7.3         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0623       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0623       |
| reward                   | -0.35518336  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 41           |
|    time_elapsed          | 19317        |
|    total_timesteps       | 886784       |
| train/                   |              |
|    approx_kl             | 0.0011499822 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 16           |
|    cost_value_loss       | 230          |
|    cost_values           | 1.79         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.777        |
|    lagrangian_multiplier | 0.0315       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.74         |
|    n_updates             | 4320         |
|    policy_gradient_loss  | -0.000461    |
|    std                   | 0.759        |
|    value_loss            | 6.84         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.05         |
| reward                   | -0.3659291   |
| rollout/                 |              |
|    ep_len_mean           | 533          |
|    ep_rew_mean           | -218         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 16           |
|    time_elapsed          | 8764         |
|    total_timesteps       | 835584       |
| train/                   |              |
|    approx_kl             | 0.0081172455 |
|    clip_fraction         | 0.159        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.09         |
|    cost_value_loss       | 18.3         |
|    cost_values           | 2.54         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.171        |
|    lagrangian_multiplier | 0.00639      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.36         |
|    n_updates             | 4070         |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 0.538        |
|    value_loss            | 24.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.151        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.151        |
| reward                   | -0.53264314  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 19           |
|    time_elapsed          | 8965         |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0039947648 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.17         |
|    cost_value_loss       | 98.1         |
|    cost_values           | 2.73         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0.0116       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.37         |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 0.733        |
|    value_loss            | 2.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0261       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0261       |
| reward                   | -0.2685136   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 30           |
|    time_elapsed          | 14277        |
|    total_timesteps       | 864256       |
| train/                   |              |
|    approx_kl             | 0.0018071685 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.422        |
|    cost_value_loss       | 0.00373      |
|    cost_values           | 0.447        |
|    entropy               | -2.27        |
|    entropy_loss          | -2.29        |
|    explained_variance    | -0.0448      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.727        |
|    n_updates             | 4210         |
|    policy_gradient_loss  | -0.000867    |
|    std                   | 0.755        |
|    value_loss            | 1.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0378       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0378       |
| reward                   | -0.3261537   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 27           |
|    time_elapsed          | 12462        |
|    total_timesteps       | 858112       |
| train/                   |              |
|    approx_kl             | 0.0057578404 |
|    clip_fraction         | 0.0119       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.3          |
|    cost_value_loss       | 78.2         |
|    cost_values           | 1.44         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | -0.311       |
|    lagrangian_multiplier | 0.00946      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.42         |
|    n_updates             | 4180         |
|    policy_gradient_loss  | -0.000457    |
|    std                   | 0.916        |
|    value_loss            | 0.917        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0956      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0956      |
| reward                   | -0.521279   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 22          |
|    time_elapsed          | 10822       |
|    total_timesteps       | 847872      |
| train/                   |             |
|    approx_kl             | 0.004415349 |
|    clip_fraction         | 0.00649     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.79        |
|    cost_value_loss       | 25.7        |
|    cost_values           | 0.846       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 4130        |
|    policy_gradient_loss  | -0.00104    |
|    std                   | 0.79        |
|    value_loss            | 1.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.176       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.176       |
| reward                   | -0.39892137 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 42          |
|    time_elapsed          | 19811       |
|    total_timesteps       | 888832      |
| train/                   |             |
|    approx_kl             | 0.008985013 |
|    clip_fraction         | 0.0361      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.88        |
|    cost_value_loss       | 135         |
|    cost_values           | 1.45        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.0163      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.01        |
|    n_updates             | 4330        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.758       |
|    value_loss            | 3.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.64        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.64        |
| reward                   | -0.52827924 |
| rollout/                 |             |
|    ep_len_mean           | 517         |
|    ep_rew_mean           | -210        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 17          |
|    time_elapsed          | 9325        |
|    total_timesteps       | 837632      |
| train/                   |             |
|    approx_kl             | 0.008812608 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.64        |
|    cost_value_loss       | 20.3        |
|    cost_values           | 2.22        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.481       |
|    lagrangian_multiplier | 0.00142     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.35        |
|    n_updates             | 4080        |
|    policy_gradient_loss  | -0.00683    |
|    std                   | 0.538       |
|    value_loss            | 9.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.115        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.115        |
| reward                   | -0.3023827   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 20           |
|    time_elapsed          | 9440         |
|    total_timesteps       | 843776       |
| train/                   |              |
|    approx_kl             | 0.0068911705 |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 125          |
|    cost_values           | 2.69         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.934        |
|    lagrangian_multiplier | 0.0133       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 4110         |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 0.733        |
|    value_loss            | 1.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0376       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0376       |
| reward                   | -0.36868834  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 31           |
|    time_elapsed          | 14772        |
|    total_timesteps       | 866304       |
| train/                   |              |
|    approx_kl             | 0.0059631923 |
|    clip_fraction         | 0.0327       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 18.6         |
|    cost_values           | 1.1          |
|    entropy               | -2.26        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 0.00279      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.14         |
|    n_updates             | 4220         |
|    policy_gradient_loss  | -0.000661    |
|    std                   | 0.753        |
|    value_loss            | 0.727        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.177       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.177       |
| reward                   | -0.25709116 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 28          |
|    time_elapsed          | 12974       |
|    total_timesteps       | 860160      |
| train/                   |             |
|    approx_kl             | 0.011180564 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 0.0623      |
|    cost_values           | 1.15        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.471       |
|    lagrangian_multiplier | 0.001       |
|    learning_rate         | 0.0003      |
|    loss                  | 1.48        |
|    n_updates             | 4190        |
|    policy_gradient_loss  | -0.00357    |
|    std                   | 0.915       |
|    value_loss            | 4.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.164        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.164        |
| reward                   | -0.34255236  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 23           |
|    time_elapsed          | 11331        |
|    total_timesteps       | 849920       |
| train/                   |              |
|    approx_kl             | 0.0052215736 |
|    clip_fraction         | 0.0359       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.557        |
|    cost_value_loss       | 0.0167       |
|    cost_values           | 0.67         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -0.187       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.33         |
|    n_updates             | 4140         |
|    policy_gradient_loss  | 9.97e-05     |
|    std                   | 0.793        |
|    value_loss            | 0.868        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0316       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0316       |
| reward                   | -0.3825192   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 43           |
|    time_elapsed          | 20308        |
|    total_timesteps       | 890880       |
| train/                   |              |
|    approx_kl             | 0.0016809731 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 21.3         |
|    cost_values           | 1.19         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.716        |
|    lagrangian_multiplier | 0.00247      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.12         |
|    n_updates             | 4340         |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 0.758        |
|    value_loss            | 1.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.147       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.147       |
| reward                   | -0.49000195 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 21          |
|    time_elapsed          | 9914        |
|    total_timesteps       | 845824      |
| train/                   |             |
|    approx_kl             | 0.005729843 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.24        |
|    cost_value_loss       | 61.9        |
|    cost_values           | 2.57        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.00871     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.25        |
|    n_updates             | 4120        |
|    policy_gradient_loss  | -0.00444    |
|    std                   | 0.733       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.5         |
| reward                   | -0.38607308 |
| rollout/                 |             |
|    ep_len_mean           | 511         |
|    ep_rew_mean           | -206        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 18          |
|    time_elapsed          | 9891        |
|    total_timesteps       | 839680      |
| train/                   |             |
|    approx_kl             | 0.010859053 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.23        |
|    cost_value_loss       | 19.7        |
|    cost_values           | 2.34        |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.448       |
|    lagrangian_multiplier | 0.0034      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.46        |
|    n_updates             | 4090        |
|    policy_gradient_loss  | -0.00729    |
|    std                   | 0.539       |
|    value_loss            | 15.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0371       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0371       |
| reward                   | -0.44627768  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 32           |
|    time_elapsed          | 15266        |
|    total_timesteps       | 868352       |
| train/                   |              |
|    approx_kl             | 0.0030258421 |
|    clip_fraction         | 0.058        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.61         |
|    cost_value_loss       | 47.8         |
|    cost_values           | 1.51         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.685        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.6         |
|    n_updates             | 4230         |
|    policy_gradient_loss  | -0.00156     |
|    std                   | 0.752        |
|    value_loss            | 1.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.198        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.198        |
| reward                   | -0.3084566   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 29           |
|    time_elapsed          | 13489        |
|    total_timesteps       | 862208       |
| train/                   |              |
|    approx_kl             | 0.0027642578 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.628        |
|    cost_value_loss       | 0.0149       |
|    cost_values           | 0.631        |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.555        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.415        |
|    n_updates             | 4200         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.911        |
|    value_loss            | 2.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.42        |
| reward                   | -0.5233062  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 24          |
|    time_elapsed          | 11854       |
|    total_timesteps       | 851968      |
| train/                   |             |
|    approx_kl             | 0.008610571 |
|    clip_fraction         | 0.072       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.502       |
|    cost_value_loss       | 0.00517     |
|    cost_values           | 0.549       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.201       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.16        |
|    n_updates             | 4150        |
|    policy_gradient_loss  | 0.000831    |
|    std                   | 0.79        |
|    value_loss            | 0.371       |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.14       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.14       |
| reward                   | -1.0525396 |
| rollout/                 |            |
|    ep_len_mean           | 971        |
|    ep_rew_mean           | -399       |
| time/                    |            |
|    fps                   | 4          |
|    iterations            | 44         |
|    time_elapsed          | 20799      |
|    total_timesteps       | 892928     |
| train/                   |            |
|    approx_kl             | 0.00431505 |
|    clip_fraction         | 0.0283     |
|    clip_range            | 0.2        |
|    cost_returns          | 7.64       |
|    cost_value_loss       | 95.8       |
|    cost_values           | 1.16       |
|    entropy               | -2.27      |
|    entropy_loss          | -2.27      |
|    explained_variance    | -0.618     |
|    lagrangian_multiplier | 0.00719    |
|    learning_rate         | 0.0003     |
|    loss                  | 11         |
|    n_updates             | 4350       |
|    policy_gradient_loss  | -0.000695  |
|    std                   | 0.756      |
|    value_loss            | 0.717      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.259       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.259       |
| reward                   | -0.41801918 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 22          |
|    time_elapsed          | 10397       |
|    total_timesteps       | 847872      |
| train/                   |             |
|    approx_kl             | 0.004725344 |
|    clip_fraction         | 0.0857      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 134         |
|    cost_values           | 2.67        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0.0146      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 4130        |
|    policy_gradient_loss  | 0.00103     |
|    std                   | 0.735       |
|    value_loss            | 1.57        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0814       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0814       |
| reward                   | -0.30400044  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 33           |
|    time_elapsed          | 15761        |
|    total_timesteps       | 870400       |
| train/                   |              |
|    approx_kl             | 0.0030589893 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.84         |
|    cost_value_loss       | 47.5         |
|    cost_values           | 1.76         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.459        |
|    lagrangian_multiplier | 0.00388      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.93         |
|    n_updates             | 4240         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.752        |
|    value_loss            | 1.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.96        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.96        |
| reward                   | -0.28296533 |
| rollout/                 |             |
|    ep_len_mean           | 510         |
|    ep_rew_mean           | -206        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 19          |
|    time_elapsed          | 10460       |
|    total_timesteps       | 841728      |
| train/                   |             |
|    approx_kl             | 0.018967628 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 15          |
|    cost_values           | 2.27        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.136       |
|    lagrangian_multiplier | 0.00571     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.46        |
|    n_updates             | 4100        |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.538       |
|    value_loss            | 20          |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0446      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0446      |
| reward                   | -0.5426022  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 30          |
|    time_elapsed          | 14003       |
|    total_timesteps       | 864256      |
| train/                   |             |
|    approx_kl             | 0.020574264 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 14.5        |
|    cost_value_loss       | 205         |
|    cost_values           | 1.38        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.39        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 101         |
|    n_updates             | 4210        |
|    policy_gradient_loss  | 0.00286     |
|    std                   | 0.909       |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0644      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0644      |
| reward                   | -0.40346593 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 25          |
|    time_elapsed          | 12372       |
|    total_timesteps       | 854016      |
| train/                   |             |
|    approx_kl             | 0.004662314 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.7         |
|    cost_value_loss       | 127         |
|    cost_values           | 0.995       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 63.1        |
|    n_updates             | 4160        |
|    policy_gradient_loss  | 0.00267     |
|    std                   | 0.789       |
|    value_loss            | 1.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.134        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.134        |
| reward                   | -0.27808592  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 45           |
|    time_elapsed          | 21295        |
|    total_timesteps       | 894976       |
| train/                   |              |
|    approx_kl             | 0.0036769633 |
|    clip_fraction         | 0.00679      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.91         |
|    cost_value_loss       | 53.4         |
|    cost_values           | 1.23         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.685        |
|    lagrangian_multiplier | 0.00549      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.79         |
|    n_updates             | 4360         |
|    policy_gradient_loss  | -0.00119     |
|    std                   | 0.756        |
|    value_loss            | 4.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.53092015  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 23           |
|    time_elapsed          | 10884        |
|    total_timesteps       | 849920       |
| train/                   |              |
|    approx_kl             | 0.0070533436 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.3         |
|    cost_value_loss       | 194          |
|    cost_values           | 2.89         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.57         |
|    lagrangian_multiplier | 0.019        |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 4140         |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 0.734        |
|    value_loss            | 1.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0569       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0569       |
| reward                   | -0.52603984  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 34           |
|    time_elapsed          | 16249        |
|    total_timesteps       | 872448       |
| train/                   |              |
|    approx_kl             | 0.0033771284 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 143          |
|    cost_values           | 2.14         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.924        |
|    lagrangian_multiplier | 0.0189       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.63         |
|    n_updates             | 4250         |
|    policy_gradient_loss  | -0.000492    |
|    std                   | 0.752        |
|    value_loss            | 0.932        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.157       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.157       |
| reward                   | -0.5689955  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 31          |
|    time_elapsed          | 14509       |
|    total_timesteps       | 866304      |
| train/                   |             |
|    approx_kl             | 0.005339037 |
|    clip_fraction         | 0.019       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.4         |
|    cost_value_loss       | 133         |
|    cost_values           | 1.28        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0.000548    |
|    learning_rate         | 0.0003      |
|    loss                  | 53          |
|    n_updates             | 4220        |
|    policy_gradient_loss  | -0.00301    |
|    std                   | 0.908       |
|    value_loss            | 1.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.41240266 |
| rollout/                 |             |
|    ep_len_mean           | 513         |
|    ep_rew_mean           | -206        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 20          |
|    time_elapsed          | 11033       |
|    total_timesteps       | 843776      |
| train/                   |             |
|    approx_kl             | 0.010412307 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.54        |
|    cost_value_loss       | 21.8        |
|    cost_values           | 2.31        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.0493      |
|    lagrangian_multiplier | 0.00362     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.78        |
|    n_updates             | 4110        |
|    policy_gradient_loss  | -0.00209    |
|    std                   | 0.539       |
|    value_loss            | 16.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.55         |
| reward                   | -0.894897    |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 46           |
|    time_elapsed          | 21794        |
|    total_timesteps       | 897024       |
| train/                   |              |
|    approx_kl             | 0.0023886745 |
|    clip_fraction         | 0.0408       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.26         |
|    cost_value_loss       | 34.3         |
|    cost_values           | 1.14         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.686        |
|    lagrangian_multiplier | 0.00457      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.34         |
|    n_updates             | 4370         |
|    policy_gradient_loss  | 0.000185     |
|    std                   | 0.756        |
|    value_loss            | 35.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.12         |
| reward                   | -0.40565574  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 26           |
|    time_elapsed          | 12901        |
|    total_timesteps       | 856064       |
| train/                   |              |
|    approx_kl             | 0.0019205263 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.748        |
|    cost_value_loss       | 0.0331       |
|    cost_values           | 0.915        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -0.347       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.452        |
|    n_updates             | 4170         |
|    policy_gradient_loss  | -0.000491    |
|    std                   | 0.788        |
|    value_loss            | 1.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.181       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.181       |
| reward                   | -0.35945398 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 24          |
|    time_elapsed          | 11366       |
|    total_timesteps       | 851968      |
| train/                   |             |
|    approx_kl             | 0.00821178  |
|    clip_fraction         | 0.0323      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.8        |
|    cost_value_loss       | 179         |
|    cost_values           | 2.99        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.461       |
|    lagrangian_multiplier | 0.0132      |
|    learning_rate         | 0.0003      |
|    loss                  | 14.2        |
|    n_updates             | 4150        |
|    policy_gradient_loss  | -0.00406    |
|    std                   | 0.733       |
|    value_loss            | 0.951       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.228        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.228        |
| reward                   | -0.522721    |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 35           |
|    time_elapsed          | 16743        |
|    total_timesteps       | 874496       |
| train/                   |              |
|    approx_kl             | 0.0046135327 |
|    clip_fraction         | 0.00493      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.14         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 1.04         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.768        |
|    lagrangian_multiplier | 0.000617     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.23         |
|    n_updates             | 4260         |
|    policy_gradient_loss  | -0.000225    |
|    std                   | 0.752        |
|    value_loss            | 1.43         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.414        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.414        |
| reward                   | -0.5948897   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 32           |
|    time_elapsed          | 15024        |
|    total_timesteps       | 868352       |
| train/                   |              |
|    approx_kl             | 0.0046242643 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.28         |
|    cost_value_loss       | 32.8         |
|    cost_values           | 1.12         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.768        |
|    lagrangian_multiplier | 0.000721     |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 4230         |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.909        |
|    value_loss            | 3.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0255      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0255      |
| reward                   | -0.49468917 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 47          |
|    time_elapsed          | 22298       |
|    total_timesteps       | 899072      |
| train/                   |             |
|    approx_kl             | 0.006794108 |
|    clip_fraction         | 0.0475      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.09        |
|    cost_value_loss       | 103         |
|    cost_values           | 1.4         |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0.012       |
|    learning_rate         | 0.0003      |
|    loss                  | 8.9         |
|    n_updates             | 4380        |
|    policy_gradient_loss  | -0.00646    |
|    std                   | 0.756       |
|    value_loss            | 4.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.35746336  |
| rollout/                 |              |
|    ep_len_mean           | 512          |
|    ep_rew_mean           | -204         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 21           |
|    time_elapsed          | 11609        |
|    total_timesteps       | 845824       |
| train/                   |              |
|    approx_kl             | 0.0060278755 |
|    clip_fraction         | 0.106        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.85         |
|    cost_value_loss       | 20.4         |
|    cost_values           | 2.61         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.148        |
|    lagrangian_multiplier | 0.000772     |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 4120         |
|    policy_gradient_loss  | -0.00439     |
|    std                   | 0.539        |
|    value_loss            | 11.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0856       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0856       |
| reward                   | -0.38978532  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 27           |
|    time_elapsed          | 13428        |
|    total_timesteps       | 858112       |
| train/                   |              |
|    approx_kl             | 0.0033331462 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 1.27         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0.000744     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.97         |
|    n_updates             | 4180         |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.788        |
|    value_loss            | 1.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.098       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.098       |
| reward                   | -0.3235369  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 25          |
|    time_elapsed          | 11851       |
|    total_timesteps       | 854016      |
| train/                   |             |
|    approx_kl             | 0.007782668 |
|    clip_fraction         | 0.0285      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.2        |
|    cost_value_loss       | 218         |
|    cost_values           | 2.98        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0.0241      |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 4160        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.734       |
|    value_loss            | 1.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0122      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0122      |
| reward                   | -0.30155244 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 36          |
|    time_elapsed          | 17243       |
|    total_timesteps       | 876544      |
| train/                   |             |
|    approx_kl             | 0.004565548 |
|    clip_fraction         | 0.0742      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.465       |
|    cost_value_loss       | 0.00314     |
|    cost_values           | 0.477       |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | -0.00354    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.18        |
|    n_updates             | 4270        |
|    policy_gradient_loss  | -0.00326    |
|    std                   | 0.748       |
|    value_loss            | 2.63        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.245      |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 0.245      |
| reward                   | -0.5318468 |
| rollout/                 |            |
|    ep_len_mean           | 968        |
|    ep_rew_mean           | -404       |
| time/                    |            |
|    fps                   | 4          |
|    iterations            | 33         |
|    time_elapsed          | 15539      |
|    total_timesteps       | 870400     |
| train/                   |            |
|    approx_kl             | 0.01242822 |
|    clip_fraction         | 0.0744     |
|    clip_range            | 0.2        |
|    cost_returns          | 15.9       |
|    cost_value_loss       | 230        |
|    cost_values           | 1.63       |
|    entropy               | -2.65      |
|    entropy_loss          | -2.65      |
|    explained_variance    | 0.988      |
|    lagrangian_multiplier | 0.00758    |
|    learning_rate         | 0.0003     |
|    loss                  | 24.4       |
|    n_updates             | 4240       |
|    policy_gradient_loss  | -0.00839   |
|    std                   | 0.91       |
|    value_loss            | 2.38       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.419        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.419        |
| reward                   | -0.46538836  |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 48           |
|    time_elapsed          | 22801        |
|    total_timesteps       | 901120       |
| train/                   |              |
|    approx_kl             | 0.0043665185 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 6.47         |
|    cost_values           | 0.894        |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.914        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.25         |
|    n_updates             | 4390         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.757        |
|    value_loss            | 15.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0241      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0241      |
| reward                   | -0.4794878  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -417        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 28          |
|    time_elapsed          | 13948       |
|    total_timesteps       | 860160      |
| train/                   |             |
|    approx_kl             | 0.004755628 |
|    clip_fraction         | 0.01        |
|    clip_range            | 0.2         |
|    cost_returns          | 6.12        |
|    cost_value_loss       | 68.8        |
|    cost_values           | 1.47        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0.00724     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.74        |
|    n_updates             | 4190        |
|    policy_gradient_loss  | -0.000882   |
|    std                   | 0.788       |
|    value_loss            | 2.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.2480466   |
| rollout/                 |              |
|    ep_len_mean           | 522          |
|    ep_rew_mean           | -208         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 22           |
|    time_elapsed          | 12181        |
|    total_timesteps       | 847872       |
| train/                   |              |
|    approx_kl             | 0.0071913307 |
|    clip_fraction         | 0.0727       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.08         |
|    cost_value_loss       | 17.4         |
|    cost_values           | 2.52         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.27         |
|    lagrangian_multiplier | 0.000841     |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 4130         |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.539        |
|    value_loss            | 14.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.036       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.036       |
| reward                   | -0.3716931  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -395        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 26          |
|    time_elapsed          | 12350       |
|    total_timesteps       | 856064      |
| train/                   |             |
|    approx_kl             | 0.004955533 |
|    clip_fraction         | 0.0581      |
|    clip_range            | 0.2         |
|    cost_returns          | 18.6        |
|    cost_value_loss       | 249         |
|    cost_values           | 3           |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.007       |
|    learning_rate         | 0.0003      |
|    loss                  | 29.3        |
|    n_updates             | 4170        |
|    policy_gradient_loss  | -0.00457    |
|    std                   | 0.735       |
|    value_loss            | 0.583       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.341        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.341        |
| reward                   | -0.23567681  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 37           |
|    time_elapsed          | 17744        |
|    total_timesteps       | 878592       |
| train/                   |              |
|    approx_kl             | 0.0033247324 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.16         |
|    cost_value_loss       | 69.4         |
|    cost_values           | 0.863        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.917        |
|    lagrangian_multiplier | 0.00798      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.94         |
|    n_updates             | 4280         |
|    policy_gradient_loss  | -0.000736    |
|    std                   | 0.747        |
|    value_loss            | 1.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00315     |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.00315     |
| reward                   | -0.3226651  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 34          |
|    time_elapsed          | 16062       |
|    total_timesteps       | 872448      |
| train/                   |             |
|    approx_kl             | 0.006228052 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.22        |
|    cost_value_loss       | 100         |
|    cost_values           | 1.44        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.00443     |
|    learning_rate         | 0.0003      |
|    loss                  | 16.8        |
|    n_updates             | 4250        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.909       |
|    value_loss            | 0.738       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0347      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0347      |
| reward                   | -0.5261252  |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 49          |
|    time_elapsed          | 23298       |
|    total_timesteps       | 903168      |
| train/                   |             |
|    approx_kl             | 0.005153263 |
|    clip_fraction         | 0.0614      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 2.68        |
|    cost_values           | 0.827       |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.12        |
|    n_updates             | 4400        |
|    policy_gradient_loss  | -0.00612    |
|    std                   | 0.757       |
|    value_loss            | 1.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0922       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0922       |
| reward                   | -0.2684378   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 29           |
|    time_elapsed          | 14477        |
|    total_timesteps       | 862208       |
| train/                   |              |
|    approx_kl             | 0.0056458735 |
|    clip_fraction         | 0.0294       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.68         |
|    cost_value_loss       | 15.4         |
|    cost_values           | 1.15         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.72         |
|    n_updates             | 4200         |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 0.789        |
|    value_loss            | 0.974        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.9          |
| reward                   | -0.20530836  |
| rollout/                 |              |
|    ep_len_mean           | 511          |
|    ep_rew_mean           | -202         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 23           |
|    time_elapsed          | 12765        |
|    total_timesteps       | 849920       |
| train/                   |              |
|    approx_kl             | 0.0105888825 |
|    clip_fraction         | 0.0899       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.3          |
|    cost_value_loss       | 19.3         |
|    cost_values           | 2.39         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.273        |
|    lagrangian_multiplier | 0.00774      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.71         |
|    n_updates             | 4140         |
|    policy_gradient_loss  | -0.00418     |
|    std                   | 0.539        |
|    value_loss            | 19.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0624       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0624       |
| reward                   | -0.5035042   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 27           |
|    time_elapsed          | 12845        |
|    total_timesteps       | 858112       |
| train/                   |              |
|    approx_kl             | 0.0017842901 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 18.8         |
|    cost_value_loss       | 253          |
|    cost_values           | 3            |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.819        |
|    lagrangian_multiplier | 0.0206       |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 4180         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.734        |
|    value_loss            | 0.683        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.234        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.234        |
| reward                   | -0.43889686  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 38           |
|    time_elapsed          | 18239        |
|    total_timesteps       | 880640       |
| train/                   |              |
|    approx_kl             | 0.0032396074 |
|    clip_fraction         | 0.0144       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.12         |
|    cost_value_loss       | 49.7         |
|    cost_values           | 0.842        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | -0.55        |
|    lagrangian_multiplier | 0.00385      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.22         |
|    n_updates             | 4290         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.747        |
|    value_loss            | 1.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.357       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.357       |
| reward                   | -0.46915734 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 35          |
|    time_elapsed          | 16578       |
|    total_timesteps       | 874496      |
| train/                   |             |
|    approx_kl             | 0.009709452 |
|    clip_fraction         | 0.0459      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.6        |
|    cost_value_loss       | 253         |
|    cost_values           | 1.89        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 123         |
|    n_updates             | 4260        |
|    policy_gradient_loss  | -0.00522    |
|    std                   | 0.908       |
|    value_loss            | 0.297       |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/7xavsi5z
------------------------------------
| avg_speed          | 0.0898      |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.0898      |
| reward             | -0.22032386 |
| rollout/           |             |
|    ep_len_mean     | 979         |
|    ep_rew_mean     | -418        |
| time/              |             |
|    fps             | 4           |
|    iterations      | 1           |
|    time_elapsed    | 498         |
|    total_timesteps | 905216      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.148        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.148        |
| reward                   | -0.22506823  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 30           |
|    time_elapsed          | 15003        |
|    total_timesteps       | 864256       |
| train/                   |              |
|    approx_kl             | 0.0017032293 |
|    clip_fraction         | 0.0701       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.776        |
|    cost_value_loss       | 0.0292       |
|    cost_values           | 0.917        |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.21         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.676        |
|    n_updates             | 4210         |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 0.785        |
|    value_loss            | 1.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.116       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.116       |
| reward                   | -0.37120208 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -394        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 28          |
|    time_elapsed          | 13343       |
|    total_timesteps       | 860160      |
| train/                   |             |
|    approx_kl             | 0.006720529 |
|    clip_fraction         | 0.0924      |
|    clip_range            | 0.2         |
|    cost_returns          | 16.6        |
|    cost_value_loss       | 197         |
|    cost_values           | 3           |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.819       |
|    lagrangian_multiplier | 0.0561      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.19        |
|    n_updates             | 4190        |
|    policy_gradient_loss  | -0.00301    |
|    std                   | 0.734       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3546721  |
| rollout/                 |             |
|    ep_len_mean           | 503         |
|    ep_rew_mean           | -202        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 24          |
|    time_elapsed          | 13340       |
|    total_timesteps       | 851968      |
| train/                   |             |
|    approx_kl             | 0.007252495 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.14        |
|    cost_value_loss       | 14.9        |
|    cost_values           | 2.31        |
|    entropy               | -1.57       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.391       |
|    lagrangian_multiplier | 0.00229     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 4150        |
|    policy_gradient_loss  | -0.000408   |
|    std                   | 0.54        |
|    value_loss            | 20.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0275      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0275      |
| reward                   | -0.5492522  |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 39          |
|    time_elapsed          | 18740       |
|    total_timesteps       | 882688      |
| train/                   |             |
|    approx_kl             | 0.003072388 |
|    clip_fraction         | 0.0129      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.833       |
|    cost_value_loss       | 0.816       |
|    cost_values           | 0.774       |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.719       |
|    n_updates             | 4300        |
|    policy_gradient_loss  | -0.000846   |
|    std                   | 0.747       |
|    value_loss            | 2.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.157        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.157        |
| reward                   | -0.5375948   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 2            |
|    time_elapsed          | 1006         |
|    total_timesteps       | 907264       |
| train/                   |              |
|    approx_kl             | 0.0034014352 |
|    clip_fraction         | 0.00366      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.28         |
|    cost_value_loss       | 60           |
|    cost_values           | 1.34         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.881        |
|    lagrangian_multiplier | 0.00308      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 4420         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.756        |
|    value_loss            | 2.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.356        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.356        |
| reward                   | -0.47765213  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 36           |
|    time_elapsed          | 17094        |
|    total_timesteps       | 876544       |
| train/                   |              |
|    approx_kl             | 0.0031639377 |
|    clip_fraction         | 0.00493      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.3         |
|    cost_value_loss       | 138          |
|    cost_values           | 1.57         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0.0137       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 4270         |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 0.908        |
|    value_loss            | 0.457        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0919      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0919      |
| reward                   | -0.26960495 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 31          |
|    time_elapsed          | 15532       |
|    total_timesteps       | 866304      |
| train/                   |             |
|    approx_kl             | 0.004084763 |
|    clip_fraction         | 0.055       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.44        |
|    cost_value_loss       | 3.81        |
|    cost_values           | 0.941       |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.4         |
|    n_updates             | 4220        |
|    policy_gradient_loss  | -0.00112    |
|    std                   | 0.784       |
|    value_loss            | 1.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.37049612  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -387         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 29           |
|    time_elapsed          | 13840        |
|    total_timesteps       | 862208       |
| train/                   |              |
|    approx_kl             | 0.0029871666 |
|    clip_fraction         | 0.00825      |
|    clip_range            | 0.2          |
|    cost_returns          | 18.5         |
|    cost_value_loss       | 248          |
|    cost_values           | 3.01         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.78         |
|    lagrangian_multiplier | 0.0152       |
|    learning_rate         | 0.0003       |
|    loss                  | 16.7         |
|    n_updates             | 4200         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.734        |
|    value_loss            | 0.591        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.231        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.231        |
| reward                   | -0.47445115  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 40           |
|    time_elapsed          | 19243        |
|    total_timesteps       | 884736       |
| train/                   |              |
|    approx_kl             | 0.0052246484 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 30.1         |
|    cost_values           | 0.693        |
|    entropy               | -2.24        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.876        |
|    lagrangian_multiplier | 0.00536      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.52         |
|    n_updates             | 4310         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.746        |
|    value_loss            | 0.576        |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.29        |
| reward                   | -0.29927632 |
| rollout/                 |             |
|    ep_len_mean           | 511         |
|    ep_rew_mean           | -205        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 25          |
|    time_elapsed          | 13926       |
|    total_timesteps       | 854016      |
| train/                   |             |
|    approx_kl             | 0.006364493 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.8         |
|    cost_value_loss       | 13.5        |
|    cost_values           | 2.25        |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.0819      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 4160        |
|    policy_gradient_loss  | 0.00723     |
|    std                   | 0.54        |
|    value_loss            | 15.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.266        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.266        |
| reward                   | -0.5511701   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 3            |
|    time_elapsed          | 1510         |
|    total_timesteps       | 909312       |
| train/                   |              |
|    approx_kl             | 0.0028959482 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.55         |
|    cost_value_loss       | 127          |
|    cost_values           | 1.38         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.54         |
|    lagrangian_multiplier | 0.0103       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 4430         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.755        |
|    value_loss            | 12.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0934      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0934      |
| reward                   | -0.3256734  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 37          |
|    time_elapsed          | 17616       |
|    total_timesteps       | 878592      |
| train/                   |             |
|    approx_kl             | 0.012695348 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 16.6        |
|    cost_value_loss       | 236         |
|    cost_values           | 1.6         |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 114         |
|    n_updates             | 4280        |
|    policy_gradient_loss  | -0.00992    |
|    std                   | 0.908       |
|    value_loss            | 0.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.442        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.442        |
| reward                   | -0.4304764   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 32           |
|    time_elapsed          | 16060        |
|    total_timesteps       | 868352       |
| train/                   |              |
|    approx_kl             | 2.470336e-05 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 183          |
|    cost_values           | 1.64         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | -0.398       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 83.7         |
|    n_updates             | 4230         |
|    policy_gradient_loss  | -6e-05       |
|    std                   | 0.784        |
|    value_loss            | 0.995        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.117       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.117       |
| reward                   | -0.47490105 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 30          |
|    time_elapsed          | 14341       |
|    total_timesteps       | 864256      |
| train/                   |             |
|    approx_kl             | 0.008447697 |
|    clip_fraction         | 0.0378      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.7        |
|    cost_value_loss       | 234         |
|    cost_values           | 3           |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.537       |
|    lagrangian_multiplier | 0.0639      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.45        |
|    n_updates             | 4210        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.733       |
|    value_loss            | 6.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0231       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0231       |
| reward                   | -0.33244315  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 41           |
|    time_elapsed          | 19741        |
|    total_timesteps       | 886784       |
| train/                   |              |
|    approx_kl             | 0.0034522784 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.257        |
|    cost_value_loss       | 0.00175      |
|    cost_values           | 0.283        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.24        |
|    explained_variance    | -0.015       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.183        |
|    n_updates             | 4320         |
|    policy_gradient_loss  | -0.000209    |
|    std                   | 0.747        |
|    value_loss            | 0.751        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.34        |
| reward                   | -0.36584496 |
| rollout/                 |             |
|    ep_len_mean           | 498         |
|    ep_rew_mean           | -199        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 26          |
|    time_elapsed          | 14504       |
|    total_timesteps       | 856064      |
| train/                   |             |
|    approx_kl             | 0.008225977 |
|    clip_fraction         | 0.0708      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.22        |
|    cost_value_loss       | 21.7        |
|    cost_values           | 2.3         |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.324       |
|    lagrangian_multiplier | 0.00278     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 4170        |
|    policy_gradient_loss  | -0.00556    |
|    std                   | 0.54        |
|    value_loss            | 18.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0386      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0386      |
| reward                   | -0.19017248 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 4           |
|    time_elapsed          | 2014        |
|    total_timesteps       | 911360      |
| train/                   |             |
|    approx_kl             | 0.004555054 |
|    clip_fraction         | 0.0103      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.77        |
|    cost_value_loss       | 51.3        |
|    cost_values           | 1.25        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0.00607     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.06        |
|    n_updates             | 4440        |
|    policy_gradient_loss  | -0.000621   |
|    std                   | 0.754       |
|    value_loss            | 1.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.02         |
| reward                   | -0.25363088  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 38           |
|    time_elapsed          | 18139        |
|    total_timesteps       | 880640       |
| train/                   |              |
|    approx_kl             | 0.0077939946 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.45         |
|    cost_value_loss       | 133          |
|    cost_values           | 1.33         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.803        |
|    lagrangian_multiplier | 0.0064       |
|    learning_rate         | 0.0003       |
|    loss                  | 16.9         |
|    n_updates             | 4290         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.908        |
|    value_loss            | 0.678        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.176        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.176        |
| reward                   | -0.5538779   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 33           |
|    time_elapsed          | 16594        |
|    total_timesteps       | 870400       |
| train/                   |              |
|    approx_kl             | 0.0015228619 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 149          |
|    cost_values           | 1.51         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.771        |
|    lagrangian_multiplier | 0.00542      |
|    learning_rate         | 0.0003       |
|    loss                  | 21.8         |
|    n_updates             | 4240         |
|    policy_gradient_loss  | -0.000931    |
|    std                   | 0.784        |
|    value_loss            | 4.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.194        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.194        |
| reward                   | -0.3749025   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 31           |
|    time_elapsed          | 14847        |
|    total_timesteps       | 866304       |
| train/                   |              |
|    approx_kl             | 0.0029610633 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 17.8         |
|    cost_value_loss       | 229          |
|    cost_values           | 3            |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.903        |
|    lagrangian_multiplier | 0.0562       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.83         |
|    n_updates             | 4220         |
|    policy_gradient_loss  | -0.00529     |
|    std                   | 0.733        |
|    value_loss            | 0.508        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0287      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0287      |
| reward                   | -0.17004207 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 42          |
|    time_elapsed          | 20242       |
|    total_timesteps       | 888832      |
| train/                   |             |
|    approx_kl             | 0.006005323 |
|    clip_fraction         | 0.0673      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.204       |
|    cost_value_loss       | 0.000795    |
|    cost_values           | 0.212       |
|    entropy               | -2.27       |
|    entropy_loss          | -2.26       |
|    explained_variance    | -0.0561     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.234       |
|    n_updates             | 4330        |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.757       |
|    value_loss            | 0.572       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.35321704 |
| rollout/                 |             |
|    ep_len_mean           | 510         |
|    ep_rew_mean           | -204        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 27          |
|    time_elapsed          | 15087       |
|    total_timesteps       | 858112      |
| train/                   |             |
|    approx_kl             | 0.020080261 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.37        |
|    cost_value_loss       | 18.2        |
|    cost_values           | 2.57        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.577       |
|    lagrangian_multiplier | 0.00551     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.09        |
|    n_updates             | 4180        |
|    policy_gradient_loss  | -0.00651    |
|    std                   | 0.539       |
|    value_loss            | 9.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.304        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.304        |
| reward                   | -0.47991133  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 5            |
|    time_elapsed          | 2527         |
|    total_timesteps       | 913408       |
| train/                   |              |
|    approx_kl             | 0.0061514927 |
|    clip_fraction         | 0.0393       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.62         |
|    cost_value_loss       | 53.3         |
|    cost_values           | 1.16         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.94         |
|    lagrangian_multiplier | 0.00468      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.15         |
|    n_updates             | 4450         |
|    policy_gradient_loss  | -0.0042      |
|    std                   | 0.753        |
|    value_loss            | 1.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.12         |
| reward                   | -0.40513295  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 39           |
|    time_elapsed          | 18666        |
|    total_timesteps       | 882688       |
| train/                   |              |
|    approx_kl             | 0.0034279875 |
|    clip_fraction         | 0.00698      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 145          |
|    cost_values           | 1.03         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.875        |
|    lagrangian_multiplier | 0.00897      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.1         |
|    n_updates             | 4300         |
|    policy_gradient_loss  | -0.00329     |
|    std                   | 0.907        |
|    value_loss            | 16.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0486      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0486      |
| reward                   | -0.2772228  |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 32          |
|    time_elapsed          | 15359       |
|    total_timesteps       | 868352      |
| train/                   |             |
|    approx_kl             | 0.006149523 |
|    clip_fraction         | 0.0504      |
|    clip_range            | 0.2         |
|    cost_returns          | 18.7        |
|    cost_value_loss       | 253         |
|    cost_values           | 3           |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0.0347      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.61        |
|    n_updates             | 4230        |
|    policy_gradient_loss  | -0.00602    |
|    std                   | 0.733       |
|    value_loss            | 0.542       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.3          |
| reward                   | -0.43651974  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 34           |
|    time_elapsed          | 17122        |
|    total_timesteps       | 872448       |
| train/                   |              |
|    approx_kl             | 0.0009883315 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.749        |
|    cost_value_loss       | 0.0308       |
|    cost_values           | 0.904        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.186        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.138        |
|    n_updates             | 4250         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.787        |
|    value_loss            | 0.855        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.139        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.139        |
| reward                   | -0.37930673  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 43           |
|    time_elapsed          | 20743        |
|    total_timesteps       | 890880       |
| train/                   |              |
|    approx_kl             | 0.0035608294 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.568        |
|    cost_value_loss       | 0.0157       |
|    cost_values           | 0.638        |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.275        |
|    n_updates             | 4340         |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.759        |
|    value_loss            | 1.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0934       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0934       |
| reward                   | -0.59550506  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 6            |
|    time_elapsed          | 3041         |
|    total_timesteps       | 915456       |
| train/                   |              |
|    approx_kl             | 0.0017553228 |
|    clip_fraction         | 0.00576      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.9         |
|    cost_value_loss       | 158          |
|    cost_values           | 1.57         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0.021        |
|    learning_rate         | 0.0003       |
|    loss                  | 8.61         |
|    n_updates             | 4460         |
|    policy_gradient_loss  | 1.43e-05     |
|    std                   | 0.754        |
|    value_loss            | 1.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.53        |
| reward                   | -0.26979068 |
| rollout/                 |             |
|    ep_len_mean           | 500         |
|    ep_rew_mean           | -201        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 28          |
|    time_elapsed          | 15676       |
|    total_timesteps       | 860160      |
| train/                   |             |
|    approx_kl             | 0.009310218 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.93        |
|    cost_value_loss       | 20.2        |
|    cost_values           | 2.71        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.536       |
|    lagrangian_multiplier | 0.00402     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.44        |
|    n_updates             | 4190        |
|    policy_gradient_loss  | 0.00432     |
|    std                   | 0.538       |
|    value_loss            | 7.28        |
------------------------------------------
----------------------------------------
| avg_speed                | 0.145     |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 0.145     |
| reward                   | -0.157139 |
| rollout/                 |           |
|    ep_len_mean           | 987       |
|    ep_rew_mean           | -421      |
| time/                    |           |
|    fps                   | 4         |
|    iterations            | 40        |
|    time_elapsed          | 19192     |
|    total_timesteps       | 884736    |
| train/                   |           |
|    approx_kl             | 0.00626   |
|    clip_fraction         | 0.0243    |
|    clip_range            | 0.2       |
|    cost_returns          | 4.19      |
|    cost_value_loss       | 54.6      |
|    cost_values           | 0.646     |
|    entropy               | -2.65     |
|    entropy_loss          | -2.64     |
|    explained_variance    | 0.964     |
|    lagrangian_multiplier | 0.00701   |
|    learning_rate         | 0.0003    |
|    loss                  | 6.99      |
|    n_updates             | 4310      |
|    policy_gradient_loss  | -0.00798  |
|    std                   | 0.909     |
|    value_loss            | 3.33      |
----------------------------------------
-------------------------------------------
| avg_speed                | 0.0393       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0393       |
| reward                   | -0.33959344  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 33           |
|    time_elapsed          | 15856        |
|    total_timesteps       | 870400       |
| train/                   |              |
|    approx_kl             | 0.0066740355 |
|    clip_fraction         | 0.0562       |
|    clip_range            | 0.2          |
|    cost_returns          | 18           |
|    cost_value_loss       | 231          |
|    cost_values           | 3            |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.916        |
|    lagrangian_multiplier | 0.000616     |
|    learning_rate         | 0.0003       |
|    loss                  | 87.7         |
|    n_updates             | 4240         |
|    policy_gradient_loss  | -0.00428     |
|    std                   | 0.732        |
|    value_loss            | 0.392        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.267        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.267        |
| reward                   | -0.44483057  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 35           |
|    time_elapsed          | 17652        |
|    total_timesteps       | 874496       |
| train/                   |              |
|    approx_kl             | 0.0023282948 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.57         |
|    cost_value_loss       | 26.9         |
|    cost_values           | 0.963        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.9         |
|    n_updates             | 4260         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.788        |
|    value_loss            | 1.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.43922603  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 44           |
|    time_elapsed          | 21252        |
|    total_timesteps       | 892928       |
| train/                   |              |
|    approx_kl             | 0.0023600766 |
|    clip_fraction         | 0.00142      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.5          |
|    cost_value_loss       | 52.4         |
|    cost_values           | 1.07         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.877        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.5         |
|    n_updates             | 4350         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.759        |
|    value_loss            | 1.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.573        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.573        |
| reward                   | -0.46668676  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 7            |
|    time_elapsed          | 3549         |
|    total_timesteps       | 917504       |
| train/                   |              |
|    approx_kl             | 0.0015595801 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.03         |
|    cost_value_loss       | 47.2         |
|    cost_values           | 1.56         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.822        |
|    lagrangian_multiplier | 0.00679      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.37         |
|    n_updates             | 4470         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.752        |
|    value_loss            | 0.625        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.124        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.124        |
| reward                   | -0.47981384  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 41           |
|    time_elapsed          | 19724        |
|    total_timesteps       | 886784       |
| train/                   |              |
|    approx_kl             | 0.0062288996 |
|    clip_fraction         | 0.0499       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.525        |
|    cost_value_loss       | 0.0134       |
|    cost_values           | 0.532        |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.745        |
|    lagrangian_multiplier | 3.34e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 0.152        |
|    n_updates             | 4320         |
|    policy_gradient_loss  | -0.0051      |
|    std                   | 0.905        |
|    value_loss            | 1.1          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.82        |
| reward                   | -0.50038403 |
| rollout/                 |             |
|    ep_len_mean           | 490         |
|    ep_rew_mean           | -196        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 29          |
|    time_elapsed          | 16265       |
|    total_timesteps       | 862208      |
| train/                   |             |
|    approx_kl             | 0.013065184 |
|    clip_fraction         | 0.0807      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.74        |
|    cost_value_loss       | 20.9        |
|    cost_values           | 2.8         |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.136       |
|    lagrangian_multiplier | 0.00472     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.98        |
|    n_updates             | 4200        |
|    policy_gradient_loss  | -0.00388    |
|    std                   | 0.537       |
|    value_loss            | 30.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.66         |
| reward                   | -0.3601918   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -382         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 34           |
|    time_elapsed          | 16351        |
|    total_timesteps       | 872448       |
| train/                   |              |
|    approx_kl             | 0.0027045333 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 130          |
|    cost_values           | 2.64         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.0382       |
|    lagrangian_multiplier | 0.0172       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.07         |
|    n_updates             | 4250         |
|    policy_gradient_loss  | -0.00337     |
|    std                   | 0.732        |
|    value_loss            | 3.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.285        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.285        |
| reward                   | -0.39197874  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 36           |
|    time_elapsed          | 18182        |
|    total_timesteps       | 876544       |
| train/                   |              |
|    approx_kl             | 0.0011885521 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 209          |
|    cost_values           | 1.39         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0.0165       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 4270         |
|    policy_gradient_loss  | -0.000249    |
|    std                   | 0.788        |
|    value_loss            | 0.602        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0129       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0129       |
| reward                   | -0.28342772  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 45           |
|    time_elapsed          | 21760        |
|    total_timesteps       | 894976       |
| train/                   |              |
|    approx_kl             | 0.0036532446 |
|    clip_fraction         | 0.00469      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.67         |
|    cost_value_loss       | 91.2         |
|    cost_values           | 0.85         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0.0102       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.62         |
|    n_updates             | 4360         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.76         |
|    value_loss            | 0.397        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.249       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.249       |
| reward                   | -0.22507152 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 8           |
|    time_elapsed          | 4056        |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.002559781 |
|    clip_fraction         | 0.0644      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.81        |
|    cost_value_loss       | 89.8        |
|    cost_values           | 1.93        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.499       |
|    lagrangian_multiplier | 0.0107      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.85        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | 0.00041     |
|    std                   | 0.751       |
|    value_loss            | 0.416       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.206       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.206       |
| reward                   | -0.19825332 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 42          |
|    time_elapsed          | 20305       |
|    total_timesteps       | 888832      |
| train/                   |             |
|    approx_kl             | 0.004819478 |
|    clip_fraction         | 0.0773      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.35        |
|    cost_value_loss       | 92.7        |
|    cost_values           | 1.05        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.0133      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.97        |
|    n_updates             | 4330        |
|    policy_gradient_loss  | 0.000179    |
|    std                   | 0.901       |
|    value_loss            | 1.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.169        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.169        |
| reward                   | -0.49635482  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -381         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 35           |
|    time_elapsed          | 16858        |
|    total_timesteps       | 874496       |
| train/                   |              |
|    approx_kl             | 0.0010907997 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | 17.2         |
|    cost_value_loss       | 234          |
|    cost_values           | 2.41         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.604        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 117          |
|    n_updates             | 4260         |
|    policy_gradient_loss  | -0.000154    |
|    std                   | 0.732        |
|    value_loss            | 0.612        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.36738795  |
| rollout/                 |              |
|    ep_len_mean           | 504          |
|    ep_rew_mean           | -201         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 30           |
|    time_elapsed          | 16862        |
|    total_timesteps       | 864256       |
| train/                   |              |
|    approx_kl             | 0.0087021915 |
|    clip_fraction         | 0.131        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.66         |
|    cost_value_loss       | 19.2         |
|    cost_values           | 2.8          |
|    entropy               | -1.55        |
|    entropy_loss          | -1.55        |
|    explained_variance    | 0.53         |
|    lagrangian_multiplier | 0.00814      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.81         |
|    n_updates             | 4210         |
|    policy_gradient_loss  | -0.00663     |
|    std                   | 0.535        |
|    value_loss            | 17.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.138        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.138        |
| reward                   | -0.39110824  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 46           |
|    time_elapsed          | 22266        |
|    total_timesteps       | 897024       |
| train/                   |              |
|    approx_kl             | 0.0021302314 |
|    clip_fraction         | 0.00894      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.74         |
|    cost_value_loss       | 115          |
|    cost_values           | 1.35         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.824        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.5         |
|    n_updates             | 4370         |
|    policy_gradient_loss  | 0.000555     |
|    std                   | 0.76         |
|    value_loss            | 1.44         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 2.31          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 2.31          |
| reward                   | -0.49960905   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -408          |
| time/                    |               |
|    fps                   | 4             |
|    iterations            | 37            |
|    time_elapsed          | 18726         |
|    total_timesteps       | 878592        |
| train/                   |               |
|    approx_kl             | 0.00040639628 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 17.5          |
|    cost_value_loss       | 249           |
|    cost_values           | 1.91          |
|    entropy               | -2.36         |
|    entropy_loss          | -2.36         |
|    explained_variance    | -0.141        |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 122           |
|    n_updates             | 4280          |
|    policy_gradient_loss  | -0.000405     |
|    std                   | 0.788         |
|    value_loss            | 0.401         |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.0546       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0546       |
| reward                   | -0.5886313   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 9            |
|    time_elapsed          | 4561         |
|    total_timesteps       | 921600       |
| train/                   |              |
|    approx_kl             | 0.0044845454 |
|    clip_fraction         | 0.057        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.06         |
|    cost_value_loss       | 90.9         |
|    cost_values           | 1.74         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0.00871      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 4490         |
|    policy_gradient_loss  | 0.00173      |
|    std                   | 0.751        |
|    value_loss            | 0.985        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.000419     |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.000419     |
| reward                   | -0.38438317  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -381         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 36           |
|    time_elapsed          | 17365        |
|    total_timesteps       | 876544       |
| train/                   |              |
|    approx_kl             | 0.0006593926 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 18.1         |
|    cost_value_loss       | 241          |
|    cost_values           | 2.75         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0.00275      |
|    learning_rate         | 0.0003       |
|    loss                  | 51.1         |
|    n_updates             | 4270         |
|    policy_gradient_loss  | -0.00062     |
|    std                   | 0.732        |
|    value_loss            | 0.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0614       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0614       |
| reward                   | -0.3572622   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 43           |
|    time_elapsed          | 20838        |
|    total_timesteps       | 890880       |
| train/                   |              |
|    approx_kl             | 0.0061936826 |
|    clip_fraction         | 0.106        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.42         |
|    cost_value_loss       | 101          |
|    cost_values           | 0.864        |
|    entropy               | -2.62        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0.00852      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 4340         |
|    policy_gradient_loss  | -0.00542     |
|    std                   | 0.899        |
|    value_loss            | 0.739        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0245       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0245       |
| reward                   | -0.52589715  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 47           |
|    time_elapsed          | 22774        |
|    total_timesteps       | 899072       |
| train/                   |              |
|    approx_kl             | 0.0004544536 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 4.57         |
|    cost_value_loss       | 52.7         |
|    cost_values           | 0.957        |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.842        |
|    lagrangian_multiplier | 3.36e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 27.8         |
|    n_updates             | 4380         |
|    policy_gradient_loss  | -0.000328    |
|    std                   | 0.76         |
|    value_loss            | 4.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.48793316 |
| rollout/                 |             |
|    ep_len_mean           | 501         |
|    ep_rew_mean           | -200        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 31          |
|    time_elapsed          | 17461       |
|    total_timesteps       | 866304      |
| train/                   |             |
|    approx_kl             | 0.006301336 |
|    clip_fraction         | 0.0912      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.78        |
|    cost_value_loss       | 18.2        |
|    cost_values           | 2.77        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0.402       |
|    lagrangian_multiplier | 0.00862     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.26        |
|    n_updates             | 4220        |
|    policy_gradient_loss  | -0.00352    |
|    std                   | 0.533       |
|    value_loss            | 4.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0443       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0443       |
| reward                   | -0.45637506  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 38           |
|    time_elapsed          | 19274        |
|    total_timesteps       | 880640       |
| train/                   |              |
|    approx_kl             | 0.0017233323 |
|    clip_fraction         | 0.000439     |
|    clip_range            | 0.2          |
|    cost_returns          | 8.66         |
|    cost_value_loss       | 79.8         |
|    cost_values           | 2.36         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.501        |
|    lagrangian_multiplier | 0.00529      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 4290         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.789        |
|    value_loss            | 1.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0477       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0477       |
| reward                   | -0.6091      |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 10           |
|    time_elapsed          | 5080         |
|    total_timesteps       | 923648       |
| train/                   |              |
|    approx_kl             | 0.0033576915 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.59         |
|    cost_value_loss       | 31.7         |
|    cost_values           | 1.55         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0.00241      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.67         |
|    n_updates             | 4500         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 0.75         |
|    value_loss            | 1.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.192        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.192        |
| reward                   | -0.49724802  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -383         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 37           |
|    time_elapsed          | 17873        |
|    total_timesteps       | 878592       |
| train/                   |              |
|    approx_kl             | 0.0053080847 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.6         |
|    cost_value_loss       | 248          |
|    cost_values           | 3            |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | -0.275       |
|    lagrangian_multiplier | 0.00988      |
|    learning_rate         | 0.0003       |
|    loss                  | 23           |
|    n_updates             | 4280         |
|    policy_gradient_loss  | -0.00158     |
|    std                   | 0.731        |
|    value_loss            | 0.652        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.237       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.237       |
| reward                   | -0.5387829  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 44          |
|    time_elapsed          | 21364       |
|    total_timesteps       | 892928      |
| train/                   |             |
|    approx_kl             | 0.018829286 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.31        |
|    cost_value_loss       | 17.3        |
|    cost_values           | 0.889       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00288     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.08        |
|    n_updates             | 4350        |
|    policy_gradient_loss  | -0.00439    |
|    std                   | 0.891       |
|    value_loss            | 0.345       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.184        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.184        |
| reward                   | -0.47868517  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 48           |
|    time_elapsed          | 23283        |
|    total_timesteps       | 901120       |
| train/                   |              |
|    approx_kl             | 0.0020063599 |
|    clip_fraction         | 0.00879      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.64         |
|    cost_value_loss       | 139          |
|    cost_values           | 0.971        |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0.0159       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.37         |
|    n_updates             | 4390         |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 0.759        |
|    value_loss            | 0.661        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0203       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0203       |
| reward                   | -0.51108974  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 39           |
|    time_elapsed          | 19833        |
|    total_timesteps       | 882688       |
| train/                   |              |
|    approx_kl             | 0.0032739895 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.95         |
|    cost_value_loss       | 102          |
|    cost_values           | 2.03         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.94         |
|    lagrangian_multiplier | 0.328        |
|    learning_rate         | 0.0003       |
|    loss                  | 2.19         |
|    n_updates             | 4300         |
|    policy_gradient_loss  | 0.00177      |
|    std                   | 0.788        |
|    value_loss            | 9.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.64        |
| reward                   | -0.3630014  |
| rollout/                 |             |
|    ep_len_mean           | 487         |
|    ep_rew_mean           | -195        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 32          |
|    time_elapsed          | 18062       |
|    total_timesteps       | 868352      |
| train/                   |             |
|    approx_kl             | 0.007858461 |
|    clip_fraction         | 0.0975      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.77        |
|    cost_value_loss       | 22.9        |
|    cost_values           | 2.71        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0.264       |
|    lagrangian_multiplier | 0.0032      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 4230        |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 0.533       |
|    value_loss            | 27.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0202      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0202      |
| reward                   | -0.39715835 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 11          |
|    time_elapsed          | 5599        |
|    total_timesteps       | 925696      |
| train/                   |             |
|    approx_kl             | 0.002922993 |
|    clip_fraction         | 0.0356      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.09        |
|    cost_value_loss       | 6.75        |
|    cost_values           | 1.58        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0.000481    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.26        |
|    n_updates             | 4510        |
|    policy_gradient_loss  | -0.00091    |
|    std                   | 0.744       |
|    value_loss            | 0.626       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.256        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.256        |
| reward                   | -0.3675603   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 38           |
|    time_elapsed          | 18375        |
|    total_timesteps       | 880640       |
| train/                   |              |
|    approx_kl             | 0.0039737113 |
|    clip_fraction         | 0.0378       |
|    clip_range            | 0.2          |
|    cost_returns          | 13           |
|    cost_value_loss       | 155          |
|    cost_values           | 2.99         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.82         |
|    lagrangian_multiplier | 0.0236       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.77         |
|    n_updates             | 4290         |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 0.731        |
|    value_loss            | 5.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0834      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0834      |
| reward                   | -0.26207802 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 45          |
|    time_elapsed          | 21888       |
|    total_timesteps       | 894976      |
| train/                   |             |
|    approx_kl             | 0.012258375 |
|    clip_fraction         | 0.0837      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.87        |
|    cost_value_loss       | 72.3        |
|    cost_values           | 0.809       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0.00558     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 4360        |
|    policy_gradient_loss  | -0.00511    |
|    std                   | 0.891       |
|    value_loss            | 2.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.207       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.207       |
| reward                   | -0.392137   |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 49          |
|    time_elapsed          | 23796       |
|    total_timesteps       | 903168      |
| train/                   |             |
|    approx_kl             | 0.003047837 |
|    clip_fraction         | 0.0298      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.47        |
|    cost_value_loss       | 86.3        |
|    cost_values           | 0.893       |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.0083      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.05        |
|    n_updates             | 4400        |
|    policy_gradient_loss  | 6.95e-05    |
|    std                   | 0.761       |
|    value_loss            | 0.643       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.128       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.128       |
| reward                   | -0.53171283 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 40          |
|    time_elapsed          | 20366       |
|    total_timesteps       | 884736      |
| train/                   |             |
|    approx_kl             | 0.003091185 |
|    clip_fraction         | 0.00171     |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 147         |
|    cost_values           | 1.28        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0.0344      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.27        |
|    n_updates             | 4310        |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.789       |
|    value_loss            | 2.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.3336228  |
| rollout/                 |             |
|    ep_len_mean           | 488         |
|    ep_rew_mean           | -195        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 33          |
|    time_elapsed          | 18656       |
|    total_timesteps       | 870400      |
| train/                   |             |
|    approx_kl             | 0.007891687 |
|    clip_fraction         | 0.0739      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 2.35        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0.613       |
|    lagrangian_multiplier | 0.00788     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.16        |
|    n_updates             | 4240        |
|    policy_gradient_loss  | -0.00357    |
|    std                   | 0.532       |
|    value_loss            | 21.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0401       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0401       |
| reward                   | -0.38667852  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 12           |
|    time_elapsed          | 6120         |
|    total_timesteps       | 927744       |
| train/                   |              |
|    approx_kl             | 0.0011252873 |
|    clip_fraction         | 0.00664      |
|    clip_range            | 0.2          |
|    cost_returns          | 16.6         |
|    cost_value_loss       | 232          |
|    cost_values           | 2.1          |
|    entropy               | -2.22        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0.00931      |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 4520         |
|    policy_gradient_loss  | 0.000297     |
|    std                   | 0.741        |
|    value_loss            | 0.602        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.000153    |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.000153    |
| reward                   | -0.3791333  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -386        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 39          |
|    time_elapsed          | 18883       |
|    total_timesteps       | 882688      |
| train/                   |             |
|    approx_kl             | 0.005434895 |
|    clip_fraction         | 0.0441      |
|    clip_range            | 0.2         |
|    cost_returns          | 18.2        |
|    cost_value_loss       | 239         |
|    cost_values           | 3           |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0.032       |
|    learning_rate         | 0.0003      |
|    loss                  | 9.76        |
|    n_updates             | 4300        |
|    policy_gradient_loss  | -0.00279    |
|    std                   | 0.733       |
|    value_loss            | 0.608       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.235       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.235       |
| reward                   | -0.40420064 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 46          |
|    time_elapsed          | 22418       |
|    total_timesteps       | 897024      |
| train/                   |             |
|    approx_kl             | 0.005600609 |
|    clip_fraction         | 0.014       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.7        |
|    cost_value_loss       | 228         |
|    cost_values           | 1.38        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.0267      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.18        |
|    n_updates             | 4370        |
|    policy_gradient_loss  | -0.00321    |
|    std                   | 0.893       |
|    value_loss            | 2.28        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/uhktx3ql
------------------------------------
| avg_speed          | 0.0801      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0801      |
| reward             | -0.39046666 |
| rollout/           |             |
|    ep_len_mean     | 996         |
|    ep_rew_mean     | -422        |
| time/              |             |
|    fps             | 3           |
|    iterations      | 1           |
|    time_elapsed    | 512         |
|    total_timesteps | 905216      |
------------------------------------
------------------------------------------
| avg_speed                | 0.111       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.111       |
| reward                   | -0.43319523 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 41          |
|    time_elapsed          | 20900       |
|    total_timesteps       | 886784      |
| train/                   |             |
|    approx_kl             | 0.004818489 |
|    clip_fraction         | 0.00962     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.178       |
|    cost_value_loss       | 0.0241      |
|    cost_values           | 0.0773      |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.00136     |
|    learning_rate         | 0.0003      |
|    loss                  | 0.526       |
|    n_updates             | 4320        |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 0.789       |
|    value_loss            | 2.98        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0394       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0394       |
| reward                   | -0.52745044  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 13           |
|    time_elapsed          | 6639         |
|    total_timesteps       | 929792       |
| train/                   |              |
|    approx_kl             | 0.0024616276 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.3         |
|    cost_value_loss       | 128          |
|    cost_values           | 2.28         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0.00626      |
|    learning_rate         | 0.0003       |
|    loss                  | 17.3         |
|    n_updates             | 4530         |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.742        |
|    value_loss            | 0.403        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.6612728  |
| rollout/                 |             |
|    ep_len_mean           | 487         |
|    ep_rew_mean           | -195        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 34          |
|    time_elapsed          | 19263       |
|    total_timesteps       | 872448      |
| train/                   |             |
|    approx_kl             | 0.006754511 |
|    clip_fraction         | 0.0566      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.95        |
|    cost_value_loss       | 17.1        |
|    cost_values           | 2.2         |
|    entropy               | -1.53       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0.309       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.5        |
|    n_updates             | 4250        |
|    policy_gradient_loss  | -0.00392    |
|    std                   | 0.531       |
|    value_loss            | 13.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.451       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.451       |
| reward                   | -0.40472916 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -390        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 40          |
|    time_elapsed          | 19389       |
|    total_timesteps       | 884736      |
| train/                   |             |
|    approx_kl             | 0.007955484 |
|    clip_fraction         | 0.0547      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.4        |
|    cost_value_loss       | 219         |
|    cost_values           | 2.99        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.0104      |
|    learning_rate         | 0.0003      |
|    loss                  | 20.1        |
|    n_updates             | 4310        |
|    policy_gradient_loss  | -0.00407    |
|    std                   | 0.734       |
|    value_loss            | 0.305       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0604       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0604       |
| reward                   | -0.62460274  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 47           |
|    time_elapsed          | 22956        |
|    total_timesteps       | 899072       |
| train/                   |              |
|    approx_kl             | 0.0034362986 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | 5.66         |
|    cost_value_loss       | 78.3         |
|    cost_values           | 0.779        |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.811        |
|    lagrangian_multiplier | 0.00402      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.7         |
|    n_updates             | 4380         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.892        |
|    value_loss            | 6.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0487       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0487       |
| reward                   | -0.34348178  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 2            |
|    time_elapsed          | 1025         |
|    total_timesteps       | 907264       |
| train/                   |              |
|    approx_kl             | 0.0028572052 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.33         |
|    cost_value_loss       | 47           |
|    cost_values           | 0.372        |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0.00621      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.74         |
|    n_updates             | 4420         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.759        |
|    value_loss            | 0.785        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.426        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.426        |
| reward                   | -0.5368068   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 42           |
|    time_elapsed          | 21445        |
|    total_timesteps       | 888832       |
| train/                   |              |
|    approx_kl             | 0.0038203702 |
|    clip_fraction         | 0.00957      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.21         |
|    cost_value_loss       | 123          |
|    cost_values           | 0.677        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.961        |
|    lagrangian_multiplier | 0.013        |
|    learning_rate         | 0.0003       |
|    loss                  | 8.98         |
|    n_updates             | 4330         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.788        |
|    value_loss            | 1.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.201       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.201       |
| reward                   | -0.30530918 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 14          |
|    time_elapsed          | 7159        |
|    total_timesteps       | 931840      |
| train/                   |             |
|    approx_kl             | 0.008958556 |
|    clip_fraction         | 0.0252      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 20.1        |
|    cost_values           | 1.47        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00845     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.75        |
|    n_updates             | 4540        |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.743       |
|    value_loss            | 0.849       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0292      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0292      |
| reward                   | -0.34151843 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 41          |
|    time_elapsed          | 19896       |
|    total_timesteps       | 886784      |
| train/                   |             |
|    approx_kl             | 0.002158345 |
|    clip_fraction         | 0.0155      |
|    clip_range            | 0.2         |
|    cost_returns          | 17          |
|    cost_value_loss       | 219         |
|    cost_values           | 3           |
|    entropy               | -2.21       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.768       |
|    lagrangian_multiplier | 0.0343      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.73        |
|    n_updates             | 4320        |
|    policy_gradient_loss  | -0.00159    |
|    std                   | 0.732       |
|    value_loss            | 0.957       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.6130626  |
| rollout/                 |             |
|    ep_len_mean           | 493         |
|    ep_rew_mean           | -199        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 35          |
|    time_elapsed          | 19867       |
|    total_timesteps       | 874496      |
| train/                   |             |
|    approx_kl             | 0.010638353 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.88        |
|    cost_value_loss       | 17.5        |
|    cost_values           | 2.33        |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.457       |
|    lagrangian_multiplier | 0.00561     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.52        |
|    n_updates             | 4260        |
|    policy_gradient_loss  | -0.00529    |
|    std                   | 0.53        |
|    value_loss            | 12.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.168        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.168        |
| reward                   | -0.5628745   |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 3            |
|    time_elapsed          | 1538         |
|    total_timesteps       | 909312       |
| train/                   |              |
|    approx_kl             | 0.0036713718 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.74         |
|    cost_value_loss       | 63.2         |
|    cost_values           | 0.668        |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.803        |
|    lagrangian_multiplier | 0.00738      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.95         |
|    n_updates             | 4430         |
|    policy_gradient_loss  | 0.000916     |
|    std                   | 0.759        |
|    value_loss            | 2.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.535        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.535        |
| reward                   | -0.5062663   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 48           |
|    time_elapsed          | 23496        |
|    total_timesteps       | 901120       |
| train/                   |              |
|    approx_kl             | 0.0054768575 |
|    clip_fraction         | 0.0143       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 186          |
|    cost_values           | 1.44         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 91.4         |
|    n_updates             | 4390         |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 0.892        |
|    value_loss            | 0.893        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.317        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.317        |
| reward                   | -0.48122132  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 43           |
|    time_elapsed          | 21988        |
|    total_timesteps       | 890880       |
| train/                   |              |
|    approx_kl             | 0.0010352216 |
|    clip_fraction         | 0.00625      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.461        |
|    cost_value_loss       | 0.0178       |
|    cost_values           | 0.585        |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -9.91        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.117        |
|    n_updates             | 4340         |
|    policy_gradient_loss  | -0.000246    |
|    std                   | 0.788        |
|    value_loss            | 1            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.273        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.273        |
| reward                   | -0.28105724  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 15           |
|    time_elapsed          | 7680         |
|    total_timesteps       | 933888       |
| train/                   |              |
|    approx_kl             | 0.0007587122 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 195          |
|    cost_values           | 1.51         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0.00105      |
|    learning_rate         | 0.0003       |
|    loss                  | 64           |
|    n_updates             | 4550         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.743        |
|    value_loss            | 0.161        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.108       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.108       |
| reward                   | -0.20795795 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -393        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 42          |
|    time_elapsed          | 20401       |
|    total_timesteps       | 888832      |
| train/                   |             |
|    approx_kl             | 0.005996093 |
|    clip_fraction         | 0.0211      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.2        |
|    cost_value_loss       | 144         |
|    cost_values           | 2.76        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.0125      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 4330        |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.732       |
|    value_loss            | 1.03        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.59         |
| reward                   | -0.5173473   |
| rollout/                 |              |
|    ep_len_mean           | 496          |
|    ep_rew_mean           | -201         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 36           |
|    time_elapsed          | 20475        |
|    total_timesteps       | 876544       |
| train/                   |              |
|    approx_kl             | 0.0089848805 |
|    clip_fraction         | 0.107        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.71         |
|    cost_value_loss       | 20.9         |
|    cost_values           | 2.5          |
|    entropy               | -1.52        |
|    entropy_loss          | -1.53        |
|    explained_variance    | 0.442        |
|    lagrangian_multiplier | 0.00647      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.74         |
|    n_updates             | 4270         |
|    policy_gradient_loss  | -0.00245     |
|    std                   | 0.53         |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0051       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0051       |
| reward                   | -0.27347592  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 4            |
|    time_elapsed          | 2054         |
|    total_timesteps       | 911360       |
| train/                   |              |
|    approx_kl             | 0.0021973986 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.46         |
|    cost_value_loss       | 71.6         |
|    cost_values           | 0.693        |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.942        |
|    lagrangian_multiplier | 0.00709      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.93         |
|    n_updates             | 4440         |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 0.757        |
|    value_loss            | 1.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0758      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0758      |
| reward                   | -0.48803234 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 49          |
|    time_elapsed          | 24036       |
|    total_timesteps       | 903168      |
| train/                   |             |
|    approx_kl             | 0.007369306 |
|    clip_fraction         | 0.0284      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.5        |
|    cost_value_loss       | 204         |
|    cost_values           | 1.89        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00835     |
|    learning_rate         | 0.0003      |
|    loss                  | 20.6        |
|    n_updates             | 4400        |
|    policy_gradient_loss  | -0.00604    |
|    std                   | 0.891       |
|    value_loss            | 1.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0157       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0157       |
| reward                   | -0.5649635   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 44           |
|    time_elapsed          | 22529        |
|    total_timesteps       | 892928       |
| train/                   |              |
|    approx_kl             | 0.0101057645 |
|    clip_fraction         | 0.0601       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.457        |
|    cost_value_loss       | 0.00694      |
|    cost_values           | 0.52         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | -0.0289      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0182       |
|    n_updates             | 4350         |
|    policy_gradient_loss  | -0.00159     |
|    std                   | 0.79         |
|    value_loss            | 0.249        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.118       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.118       |
| reward                   | -0.22859956 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 16          |
|    time_elapsed          | 8205        |
|    total_timesteps       | 935936      |
| train/                   |             |
|    approx_kl             | 0.003313271 |
|    clip_fraction         | 0.00781     |
|    clip_range            | 0.2         |
|    cost_returns          | 8.25        |
|    cost_value_loss       | 108         |
|    cost_values           | 1.21        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00611     |
|    learning_rate         | 0.0003      |
|    loss                  | 15.3        |
|    n_updates             | 4560        |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.742       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.17        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.17        |
| reward                   | -0.42425963 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 43          |
|    time_elapsed          | 20903       |
|    total_timesteps       | 890880      |
| train/                   |             |
|    approx_kl             | 0.005117286 |
|    clip_fraction         | 0.0125      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 158         |
|    cost_values           | 2.75        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.00605     |
|    learning_rate         | 0.0003      |
|    loss                  | 21          |
|    n_updates             | 4340        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.732       |
|    value_loss            | 2.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.113       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.113       |
| reward                   | -0.48262414 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 5           |
|    time_elapsed          | 2571        |
|    total_timesteps       | 913408      |
| train/                   |             |
|    approx_kl             | 0.004036627 |
|    clip_fraction         | 0.018       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.507       |
|    cost_value_loss       | 0.009       |
|    cost_values           | 0.5         |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.826       |
|    n_updates             | 4450        |
|    policy_gradient_loss  | -0.00128    |
|    std                   | 0.758       |
|    value_loss            | 2.74        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/p13vkfbg
------------------------------------
| avg_speed          | 0.105       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.105       |
| reward             | -0.32855412 |
| rollout/           |             |
|    ep_len_mean     | 994         |
|    ep_rew_mean     | -411        |
| time/              |             |
|    fps             | 3           |
|    iterations      | 1           |
|    time_elapsed    | 533         |
|    total_timesteps | 905216      |
------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.42898354 |
| rollout/                 |             |
|    ep_len_mean           | 503         |
|    ep_rew_mean           | -204        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 37          |
|    time_elapsed          | 21085       |
|    total_timesteps       | 878592      |
| train/                   |             |
|    approx_kl             | 0.01011136  |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.06        |
|    cost_value_loss       | 22.6        |
|    cost_values           | 2.66        |
|    entropy               | -1.52       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0.584       |
|    lagrangian_multiplier | 0.000319    |
|    learning_rate         | 0.0003      |
|    loss                  | 14.9        |
|    n_updates             | 4280        |
|    policy_gradient_loss  | -0.00272    |
|    std                   | 0.528       |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0105      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0105      |
| reward                   | -0.5574712  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 45          |
|    time_elapsed          | 23070       |
|    total_timesteps       | 894976      |
| train/                   |             |
|    approx_kl             | 0.004107425 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.55        |
|    cost_value_loss       | 124         |
|    cost_values           | 0.933       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.0162      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.32        |
|    n_updates             | 4360        |
|    policy_gradient_loss  | 0.00594     |
|    std                   | 0.791       |
|    value_loss            | 0.473       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0911      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0911      |
| reward                   | -0.26547933 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 17          |
|    time_elapsed          | 8730        |
|    total_timesteps       | 937984      |
| train/                   |             |
|    approx_kl             | 0.008595614 |
|    clip_fraction         | 0.0289      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.3        |
|    cost_value_loss       | 130         |
|    cost_values           | 1.67        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.000562    |
|    learning_rate         | 0.0003      |
|    loss                  | 48.8        |
|    n_updates             | 4570        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 0.742       |
|    value_loss            | 0.389       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0991       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0991       |
| reward                   | -0.36388704  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 44           |
|    time_elapsed          | 21415        |
|    total_timesteps       | 892928       |
| train/                   |              |
|    approx_kl             | 0.0047236723 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | 17           |
|    cost_value_loss       | 220          |
|    cost_values           | 3            |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.769        |
|    lagrangian_multiplier | 0.0113       |
|    learning_rate         | 0.0003       |
|    loss                  | 19.8         |
|    n_updates             | 4350         |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 0.732        |
|    value_loss            | 6.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.143        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.143        |
| reward                   | -0.34411556  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 6            |
|    time_elapsed          | 3090         |
|    total_timesteps       | 915456       |
| train/                   |              |
|    approx_kl             | 0.0039996407 |
|    clip_fraction         | 0.00859      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.19         |
|    cost_value_loss       | 87.1         |
|    cost_values           | 0.742        |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0.00754      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.29         |
|    n_updates             | 4460         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.758        |
|    value_loss            | 0.711        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0799      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0799      |
| reward                   | -0.47780636 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 2           |
|    time_elapsed          | 1077        |
|    total_timesteps       | 907264      |
| train/                   |             |
|    approx_kl             | 0.006785131 |
|    clip_fraction         | 0.0455      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 161         |
|    cost_values           | 1.21        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.0237      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.54        |
|    n_updates             | 4420        |
|    policy_gradient_loss  | -0.00418    |
|    std                   | 0.893       |
|    value_loss            | 1.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.62        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.62        |
| reward                   | -0.52165276 |
| rollout/                 |             |
|    ep_len_mean           | 489         |
|    ep_rew_mean           | -199        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 38          |
|    time_elapsed          | 21703       |
|    total_timesteps       | 880640      |
| train/                   |             |
|    approx_kl             | 0.014482062 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.13        |
|    cost_value_loss       | 21.6        |
|    cost_values           | 2.86        |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | 0.447       |
|    lagrangian_multiplier | 0.00631     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.09        |
|    n_updates             | 4290        |
|    policy_gradient_loss  | -0.00425    |
|    std                   | 0.526       |
|    value_loss            | 15.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.155        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.155        |
| reward                   | -0.55121094  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 46           |
|    time_elapsed          | 23628        |
|    total_timesteps       | 897024       |
| train/                   |              |
|    approx_kl             | 0.0034461687 |
|    clip_fraction         | 0.0301       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.88         |
|    cost_value_loss       | 130          |
|    cost_values           | 0.96         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0.0155       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.77         |
|    n_updates             | 4370         |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.791        |
|    value_loss            | 0.303        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.183        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.183        |
| reward                   | -0.26800635  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 18           |
|    time_elapsed          | 9251         |
|    total_timesteps       | 940032       |
| train/                   |              |
|    approx_kl             | 0.0018978659 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 5.64         |
|    cost_value_loss       | 54.2         |
|    cost_values           | 1.39         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.561        |
|    lagrangian_multiplier | 0.0021       |
|    learning_rate         | 0.0003       |
|    loss                  | 14.7         |
|    n_updates             | 4580         |
|    policy_gradient_loss  | -0.00031     |
|    std                   | 0.742        |
|    value_loss            | 2.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.154        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.154        |
| reward                   | -0.20531821  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 45           |
|    time_elapsed          | 21930        |
|    total_timesteps       | 894976       |
| train/                   |              |
|    approx_kl             | 0.0019230505 |
|    clip_fraction         | 0.123        |
|    clip_range            | 0.2          |
|    cost_returns          | 18.4         |
|    cost_value_loss       | 245          |
|    cost_values           | 3            |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0.00279      |
|    learning_rate         | 0.0003       |
|    loss                  | 52.3         |
|    n_updates             | 4360         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.732        |
|    value_loss            | 1.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.121        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.121        |
| reward                   | -0.44097745  |
| rollout/                 |              |
|    ep_len_mean           | 996          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 7            |
|    time_elapsed          | 3598         |
|    total_timesteps       | 917504       |
| train/                   |              |
|    approx_kl             | 0.0026201573 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 11.6         |
|    cost_value_loss       | 167          |
|    cost_values           | 1.07         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 0.0142       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 4470         |
|    policy_gradient_loss  | -0.000241    |
|    std                   | 0.757        |
|    value_loss            | 0.762        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.286        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.286        |
| reward                   | -0.3225537   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 3            |
|    time_elapsed          | 1621         |
|    total_timesteps       | 909312       |
| train/                   |              |
|    approx_kl             | 0.0059312596 |
|    clip_fraction         | 0.00996      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.978        |
|    cost_value_loss       | 0.0422       |
|    cost_values           | 1            |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.899        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.693        |
|    n_updates             | 4430         |
|    policy_gradient_loss  | -0.00171     |
|    std                   | 0.894        |
|    value_loss            | 6.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.23701254 |
| rollout/                 |             |
|    ep_len_mean           | 491         |
|    ep_rew_mean           | -200        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 39          |
|    time_elapsed          | 22322       |
|    total_timesteps       | 882688      |
| train/                   |             |
|    approx_kl             | 0.011950152 |
|    clip_fraction         | 0.0835      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.97        |
|    cost_value_loss       | 17.8        |
|    cost_values           | 2.61        |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.129       |
|    lagrangian_multiplier | 0.00827     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.21        |
|    n_updates             | 4300        |
|    policy_gradient_loss  | -0.00358    |
|    std                   | 0.524       |
|    value_loss            | 36.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0171       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0171       |
| reward                   | -0.5630699   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 19           |
|    time_elapsed          | 9782         |
|    total_timesteps       | 942080       |
| train/                   |              |
|    approx_kl             | 0.0066051143 |
|    clip_fraction         | 0.0511       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 3.75         |
|    cost_values           | 0.723        |
|    entropy               | -2.22        |
|    entropy_loss          | -2.23        |
|    explained_variance    | -0.0962      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.63         |
|    n_updates             | 4590         |
|    policy_gradient_loss  | -0.00341     |
|    std                   | 0.74         |
|    value_loss            | 0.872        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.163         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.163         |
| reward                   | -0.52863026   |
| rollout/                 |               |
|    ep_len_mean           | 1e+03         |
|    ep_rew_mean           | -421          |
| time/                    |               |
|    fps                   | 3             |
|    iterations            | 47            |
|    time_elapsed          | 24177         |
|    total_timesteps       | 899072        |
| train/                   |               |
|    approx_kl             | 0.00089075096 |
|    clip_fraction         | 0.00405       |
|    clip_range            | 0.2           |
|    cost_returns          | 6.66          |
|    cost_value_loss       | 82.2          |
|    cost_values           | 0.992         |
|    entropy               | -2.37         |
|    entropy_loss          | -2.37         |
|    explained_variance    | 0.996         |
|    lagrangian_multiplier | 0.00911       |
|    learning_rate         | 0.0003        |
|    loss                  | 8.47          |
|    n_updates             | 4380          |
|    policy_gradient_loss  | 0.000905      |
|    std                   | 0.792         |
|    value_loss            | 0.649         |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.181        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.181        |
| reward                   | -0.45513862  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 46           |
|    time_elapsed          | 22443        |
|    total_timesteps       | 897024       |
| train/                   |              |
|    approx_kl             | 0.0077536376 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.2         |
|    cost_value_loss       | 216          |
|    cost_values           | 3            |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0.0462       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.36         |
|    n_updates             | 4370         |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 0.732        |
|    value_loss            | 0.733        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0455      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0455      |
| reward                   | -0.52570564 |
| rollout/                 |             |
|    ep_len_mean           | 996         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 8           |
|    time_elapsed          | 4111        |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.007734215 |
|    clip_fraction         | 0.0205      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.19        |
|    cost_value_loss       | 103         |
|    cost_values           | 0.551       |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0.00952     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.79        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.756       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00781     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00781     |
| reward                   | -0.18716374 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 4           |
|    time_elapsed          | 2160        |
|    total_timesteps       | 911360      |
| train/                   |             |
|    approx_kl             | 0.002599799 |
|    clip_fraction         | 0.00669     |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 173         |
|    cost_values           | 1.16        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0.0138      |
|    learning_rate         | 0.0003      |
|    loss                  | 12          |
|    n_updates             | 4440        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.893       |
|    value_loss            | 4.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.152        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.152        |
| reward                   | -0.45281333  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 20           |
|    time_elapsed          | 10310        |
|    total_timesteps       | 944128       |
| train/                   |              |
|    approx_kl             | 0.0036515633 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.66         |
|    cost_value_loss       | 136          |
|    cost_values           | 1.14         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.939        |
|    lagrangian_multiplier | 0.0134       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.99         |
|    n_updates             | 4600         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.738        |
|    value_loss            | 0.909        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.173       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.173       |
| reward                   | -0.3987905  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 47          |
|    time_elapsed          | 22955       |
|    total_timesteps       | 899072      |
| train/                   |             |
|    approx_kl             | 0.013706902 |
|    clip_fraction         | 0.0797      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.6        |
|    cost_value_loss       | 236         |
|    cost_values           | 3           |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.0526      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.21        |
|    n_updates             | 4380        |
|    policy_gradient_loss  | -0.0013     |
|    std                   | 0.732       |
|    value_loss            | 0.391       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0326      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0326      |
| reward                   | -0.49714455 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 48          |
|    time_elapsed          | 24731       |
|    total_timesteps       | 901120      |
| train/                   |             |
|    approx_kl             | 0.005177914 |
|    clip_fraction         | 0.0318      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.589       |
|    cost_value_loss       | 0.00979     |
|    cost_values           | 0.657       |
|    entropy               | -2.35       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.371       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0185      |
|    n_updates             | 4390        |
|    policy_gradient_loss  | -0.000517   |
|    std                   | 0.787       |
|    value_loss            | 0.18        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.29677448  |
| rollout/                 |              |
|    ep_len_mean           | 488          |
|    ep_rew_mean           | -199         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 40           |
|    time_elapsed          | 22943        |
|    total_timesteps       | 884736       |
| train/                   |              |
|    approx_kl             | 0.0075131953 |
|    clip_fraction         | 0.0973       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.73         |
|    cost_value_loss       | 12.3         |
|    cost_values           | 2.17         |
|    entropy               | -1.49        |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0.491        |
|    lagrangian_multiplier | 0.00111      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 4310         |
|    policy_gradient_loss  | -0.00594     |
|    std                   | 0.522        |
|    value_loss            | 12           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.135       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.135       |
| reward                   | -0.5501933  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 9           |
|    time_elapsed          | 4632        |
|    total_timesteps       | 921600      |
| train/                   |             |
|    approx_kl             | 0.003139774 |
|    clip_fraction         | 0.00728     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.02        |
|    cost_value_loss       | 83.5        |
|    cost_values           | 0.586       |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.00976     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.46        |
|    n_updates             | 4490        |
|    policy_gradient_loss  | -0.000907   |
|    std                   | 0.757       |
|    value_loss            | 0.851       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.261        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.261        |
| reward                   | -0.34219405  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -399         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 5            |
|    time_elapsed          | 2695         |
|    total_timesteps       | 913408       |
| train/                   |              |
|    approx_kl             | 0.0074548367 |
|    clip_fraction         | 0.046        |
|    clip_range            | 0.2          |
|    cost_returns          | 9.97         |
|    cost_value_loss       | 139          |
|    cost_values           | 1.45         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0.0197       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.11         |
|    n_updates             | 4450         |
|    policy_gradient_loss  | -0.00384     |
|    std                   | 0.891        |
|    value_loss            | 0.532        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0959      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0959      |
| reward                   | -0.32367158 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 48          |
|    time_elapsed          | 23452       |
|    total_timesteps       | 901120      |
| train/                   |             |
|    approx_kl             | 0.010176967 |
|    clip_fraction         | 0.0381      |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 163         |
|    cost_values           | 2.72        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0.0135      |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 4390        |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.733       |
|    value_loss            | 0.736       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0997       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0997       |
| reward                   | -0.4298128   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 21           |
|    time_elapsed          | 10845        |
|    total_timesteps       | 946176       |
| train/                   |              |
|    approx_kl             | 0.0051257233 |
|    clip_fraction         | 0.00786      |
|    clip_range            | 0.2          |
|    cost_returns          | 16.2         |
|    cost_value_loss       | 228          |
|    cost_values           | 1.69         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0.00105      |
|    learning_rate         | 0.0003       |
|    loss                  | 72.7         |
|    n_updates             | 4610         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.737        |
|    value_loss            | 0.709        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0755      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0755      |
| reward                   | -0.4504032  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 49          |
|    time_elapsed          | 25274       |
|    total_timesteps       | 903168      |
| train/                   |             |
|    approx_kl             | 0.005476957 |
|    clip_fraction         | 0.0907      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.66        |
|    cost_value_loss       | 137         |
|    cost_values           | 1.01        |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.0173      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.94        |
|    n_updates             | 4400        |
|    policy_gradient_loss  | 0.000966    |
|    std                   | 0.786       |
|    value_loss            | 1.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.5         |
| reward                   | -0.53190494 |
| rollout/                 |             |
|    ep_len_mean           | 491         |
|    ep_rew_mean           | -200        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 41          |
|    time_elapsed          | 23562       |
|    total_timesteps       | 886784      |
| train/                   |             |
|    approx_kl             | 0.011748357 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.68        |
|    cost_value_loss       | 15.6        |
|    cost_values           | 2.33        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0.508       |
|    lagrangian_multiplier | 0.00409     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.86        |
|    n_updates             | 4320        |
|    policy_gradient_loss  | -0.00734    |
|    std                   | 0.522       |
|    value_loss            | 15.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0124       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0124       |
| reward                   | -0.25911528  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 10           |
|    time_elapsed          | 5154         |
|    total_timesteps       | 923648       |
| train/                   |              |
|    approx_kl             | 0.0071380846 |
|    clip_fraction         | 0.0488       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0625       |
|    cost_value_loss       | 0.0038       |
|    cost_values           | 0.116        |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.528        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.07         |
|    n_updates             | 4500         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.756        |
|    value_loss            | 1.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0447      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0447      |
| reward                   | -0.56538904 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 6           |
|    time_elapsed          | 3241        |
|    total_timesteps       | 915456      |
| train/                   |             |
|    approx_kl             | 0.008035288 |
|    clip_fraction         | 0.0435      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.63        |
|    cost_value_loss       | 20.8        |
|    cost_values           | 1.3         |
|    entropy               | -2.61       |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00217     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.91        |
|    n_updates             | 4460        |
|    policy_gradient_loss  | -0.00204    |
|    std                   | 0.892       |
|    value_loss            | 3.66        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.156        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.156        |
| reward                   | -0.46569526  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 49           |
|    time_elapsed          | 23958        |
|    total_timesteps       | 903168       |
| train/                   |              |
|    approx_kl             | 0.0048860414 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.8         |
|    cost_value_loss       | 197          |
|    cost_values           | 2.77         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0.00277      |
|    learning_rate         | 0.0003       |
|    loss                  | 41.5         |
|    n_updates             | 4400         |
|    policy_gradient_loss  | -0.00332     |
|    std                   | 0.734        |
|    value_loss            | 0.581        |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.109         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.109         |
| reward                   | -0.485439     |
| rollout/                 |               |
|    ep_len_mean           | 974           |
|    ep_rew_mean           | -423          |
| time/                    |               |
|    fps                   | 3             |
|    iterations            | 22            |
|    time_elapsed          | 11365         |
|    total_timesteps       | 948224        |
| train/                   |               |
|    approx_kl             | 0.00039676434 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 14.6          |
|    cost_value_loss       | 195           |
|    cost_values           | 2.1           |
|    entropy               | -2.21         |
|    entropy_loss          | -2.21         |
|    explained_variance    | 0.955         |
|    lagrangian_multiplier | 0.000678      |
|    learning_rate         | 0.0003        |
|    loss                  | 73.6          |
|    n_updates             | 4620          |
|    policy_gradient_loss  | -0.00033      |
|    std                   | 0.737         |
|    value_loss            | 1.16          |
--------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/4ts77xgw
------------------------------------
| avg_speed          | 0.0184      |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.0184      |
| reward             | -0.45373896 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -426        |
| time/              |             |
|    fps             | 3           |
|    iterations      | 1           |
|    time_elapsed    | 552         |
|    total_timesteps | 905216      |
------------------------------------
------------------------------------------
| avg_speed                | 0.153       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.153       |
| reward                   | -0.33524904 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 11          |
|    time_elapsed          | 5677        |
|    total_timesteps       | 925696      |
| train/                   |             |
|    approx_kl             | 0.002357081 |
|    clip_fraction         | 0.0216      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.86        |
|    cost_value_loss       | 86          |
|    cost_values           | 0.526       |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0.00905     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.12        |
|    n_updates             | 4510        |
|    policy_gradient_loss  | -0.00083    |
|    std                   | 0.756       |
|    value_loss            | 1.01        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.5285908 |
| rollout/                 |            |
|    ep_len_mean           | 480        |
|    ep_rew_mean           | -196       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 42         |
|    time_elapsed          | 24183      |
|    total_timesteps       | 888832     |
| train/                   |            |
|    approx_kl             | 0.01341844 |
|    clip_fraction         | 0.116      |
|    clip_range            | 0.2        |
|    cost_returns          | 6.13       |
|    cost_value_loss       | 17.4       |
|    cost_values           | 2.48       |
|    entropy               | -1.49      |
|    entropy_loss          | -1.49      |
|    explained_variance    | 0.223      |
|    lagrangian_multiplier | 0.00576    |
|    learning_rate         | 0.0003     |
|    loss                  | 6.33       |
|    n_updates             | 4330       |
|    policy_gradient_loss  | -0.00391   |
|    std                   | 0.521      |
|    value_loss            | 22.6       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.507       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.507       |
| reward                   | -0.4324031  |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 7           |
|    time_elapsed          | 3789        |
|    total_timesteps       | 917504      |
| train/                   |             |
|    approx_kl             | 0.005097646 |
|    clip_fraction         | 0.018       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 138         |
|    cost_values           | 1.21        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.0154      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.88        |
|    n_updates             | 4470        |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.892       |
|    value_loss            | 0.42        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/mtgakx2v
------------------------------------
| avg_speed          | 0.0547      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0547      |
| reward             | -0.18998934 |
| rollout/           |             |
|    ep_len_mean     | 981         |
|    ep_rew_mean     | -390        |
| time/              |             |
|    fps             | 3           |
|    iterations      | 1           |
|    time_elapsed    | 517         |
|    total_timesteps | 905216      |
------------------------------------
------------------------------------------
| avg_speed                | 0.288       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.288       |
| reward                   | -0.44862047 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 23          |
|    time_elapsed          | 11895       |
|    total_timesteps       | 950272      |
| train/                   |             |
|    approx_kl             | 0.003395363 |
|    clip_fraction         | 0.00332     |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 161         |
|    cost_values           | 2.08        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.506       |
|    lagrangian_multiplier | 0.00611     |
|    learning_rate         | 0.0003      |
|    loss                  | 22          |
|    n_updates             | 4630        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.737       |
|    value_loss            | 0.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00552      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00552      |
| reward                   | -0.48560923  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 2            |
|    time_elapsed          | 1109         |
|    total_timesteps       | 907264       |
| train/                   |              |
|    approx_kl             | 0.0042651687 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 0.978        |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.762        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.84         |
|    n_updates             | 4420         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.785        |
|    value_loss            | 1.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.32854933  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 12           |
|    time_elapsed          | 6200         |
|    total_timesteps       | 927744       |
| train/                   |              |
|    approx_kl             | 0.0018898797 |
|    clip_fraction         | 0.0019       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0284       |
|    cost_value_loss       | 0.000732     |
|    cost_values           | 0.0506       |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | -0.467       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.784        |
|    n_updates             | 4520         |
|    policy_gradient_loss  | -0.000204    |
|    std                   | 0.757        |
|    value_loss            | 2.35         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.27515328 |
| rollout/                 |             |
|    ep_len_mean           | 474         |
|    ep_rew_mean           | -192        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 43          |
|    time_elapsed          | 24805       |
|    total_timesteps       | 890880      |
| train/                   |             |
|    approx_kl             | 0.008099057 |
|    clip_fraction         | 0.0852      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.97        |
|    cost_value_loss       | 16.1        |
|    cost_values           | 2.57        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.267       |
|    lagrangian_multiplier | 0.00651     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.63        |
|    n_updates             | 4340        |
|    policy_gradient_loss  | -0.00372    |
|    std                   | 0.519       |
|    value_loss            | 26.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.24        |
| reward                   | -0.26081333 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 8           |
|    time_elapsed          | 4300        |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.004561139 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 207         |
|    cost_values           | 1.43        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.0265      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.77        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | -0.000669   |
|    std                   | 0.892       |
|    value_loss            | 0.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0199       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0199       |
| reward                   | -0.2585936   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 2            |
|    time_elapsed          | 1031         |
|    total_timesteps       | 907264       |
| train/                   |              |
|    approx_kl             | 0.0037683242 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 10.9         |
|    cost_value_loss       | 124          |
|    cost_values           | 2.97         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0.0151       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.57         |
|    n_updates             | 4420         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 0.733        |
|    value_loss            | 0.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.174        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.174        |
| reward                   | -0.27286807  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 24           |
|    time_elapsed          | 12419        |
|    total_timesteps       | 952320       |
| train/                   |              |
|    approx_kl             | 0.0019842982 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 12.1         |
|    cost_values           | 0.941        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0.000182     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.09         |
|    n_updates             | 4640         |
|    policy_gradient_loss  | -0.00456     |
|    std                   | 0.736        |
|    value_loss            | 3.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0253       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0253       |
| reward                   | -0.19506818  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 3            |
|    time_elapsed          | 1659         |
|    total_timesteps       | 909312       |
| train/                   |              |
|    approx_kl             | 0.0034299185 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.2         |
|    cost_value_loss       | 162          |
|    cost_values           | 1.53         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.916        |
|    lagrangian_multiplier | 0.0159       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 4430         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.783        |
|    value_loss            | 1.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0683      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0683      |
| reward                   | -0.3335702  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 13          |
|    time_elapsed          | 6719        |
|    total_timesteps       | 929792      |
| train/                   |             |
|    approx_kl             | 0.006265397 |
|    clip_fraction         | 0.0448      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0226      |
|    cost_value_loss       | 0.000166    |
|    cost_values           | 0.0288      |
|    entropy               | -2.26       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.182       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.873       |
|    n_updates             | 4530        |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.754       |
|    value_loss            | 1.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0569      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0569      |
| reward                   | -0.5534993  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 9           |
|    time_elapsed          | 4810        |
|    total_timesteps       | 921600      |
| train/                   |             |
|    approx_kl             | 0.010167471 |
|    clip_fraction         | 0.0483      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.8         |
|    cost_value_loss       | 125         |
|    cost_values           | 1.18        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0.0147      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.77        |
|    n_updates             | 4490        |
|    policy_gradient_loss  | -0.00374    |
|    std                   | 0.892       |
|    value_loss            | 0.163       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.52         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.52         |
| reward                   | -0.30044478  |
| rollout/                 |              |
|    ep_len_mean           | 483          |
|    ep_rew_mean           | -196         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 44           |
|    time_elapsed          | 25434        |
|    total_timesteps       | 892928       |
| train/                   |              |
|    approx_kl             | 0.0082399435 |
|    clip_fraction         | 0.127        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.27         |
|    cost_value_loss       | 17.6         |
|    cost_values           | 2.5          |
|    entropy               | -1.47        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0.277        |
|    lagrangian_multiplier | 0.00547      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.8          |
|    n_updates             | 4350         |
|    policy_gradient_loss  | -0.00666     |
|    std                   | 0.516        |
|    value_loss            | 17.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0871       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0871       |
| reward                   | -0.1769019   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 3            |
|    time_elapsed          | 1540         |
|    total_timesteps       | 909312       |
| train/                   |              |
|    approx_kl             | 0.0023163296 |
|    clip_fraction         | 0.00322      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 133          |
|    cost_values           | 2.98         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.708        |
|    lagrangian_multiplier | 0.0239       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.74         |
|    n_updates             | 4430         |
|    policy_gradient_loss  | -0.000349    |
|    std                   | 0.732        |
|    value_loss            | 2.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.078        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.078        |
| reward                   | -0.45914713  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 25           |
|    time_elapsed          | 12952        |
|    total_timesteps       | 954368       |
| train/                   |              |
|    approx_kl             | 0.0076999944 |
|    clip_fraction         | 0.0364       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.5          |
|    cost_value_loss       | 0.0126       |
|    cost_values           | 0.584        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | -1.36        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.108        |
|    n_updates             | 4650         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.737        |
|    value_loss            | 2.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.195        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.195        |
| reward                   | -0.5173154   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 4            |
|    time_elapsed          | 2216         |
|    total_timesteps       | 911360       |
| train/                   |              |
|    approx_kl             | 0.0066691088 |
|    clip_fraction         | 0.0387       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.951        |
|    cost_value_loss       | 0.0239       |
|    cost_values           | 0.97         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.938        |
|    lagrangian_multiplier | 9.58e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 0.161        |
|    n_updates             | 4440         |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 0.782        |
|    value_loss            | 1.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0688      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0688      |
| reward                   | -0.24977978 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -412        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 14          |
|    time_elapsed          | 7246        |
|    total_timesteps       | 931840      |
| train/                   |             |
|    approx_kl             | 0.008125085 |
|    clip_fraction         | 0.0725      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.123       |
|    cost_value_loss       | 0.0948      |
|    cost_values           | 0.14        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | -0.917      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0515      |
|    n_updates             | 4540        |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 0.753       |
|    value_loss            | 0.429       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0631       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0631       |
| reward                   | -0.5878322   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 10           |
|    time_elapsed          | 5325         |
|    total_timesteps       | 923648       |
| train/                   |              |
|    approx_kl             | 0.0011058422 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.3         |
|    cost_value_loss       | 193          |
|    cost_values           | 1.43         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.93         |
|    lagrangian_multiplier | 0.00149      |
|    learning_rate         | 0.0003       |
|    loss                  | 57.8         |
|    n_updates             | 4500         |
|    policy_gradient_loss  | 0.000883     |
|    std                   | 0.892        |
|    value_loss            | 5.65         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0469      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0469      |
| reward                   | -0.2929124  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -383        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 4           |
|    time_elapsed          | 2058        |
|    total_timesteps       | 911360      |
| train/                   |             |
|    approx_kl             | 0.007032128 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 101         |
|    cost_values           | 3           |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.775       |
|    lagrangian_multiplier | 0.0301      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.84        |
|    n_updates             | 4440        |
|    policy_gradient_loss  | -0.001      |
|    std                   | 0.73        |
|    value_loss            | 1.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.183       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.183       |
| reward                   | -0.34460387 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 26          |
|    time_elapsed          | 13481       |
|    total_timesteps       | 956416      |
| train/                   |             |
|    approx_kl             | 0.002942529 |
|    clip_fraction         | 0.023       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 53          |
|    cost_values           | 0.651       |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0.00419     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.86        |
|    n_updates             | 4660        |
|    policy_gradient_loss  | -0.000635   |
|    std                   | 0.738       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.6573914  |
| rollout/                 |             |
|    ep_len_mean           | 474         |
|    ep_rew_mean           | -193        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 45          |
|    time_elapsed          | 26066       |
|    total_timesteps       | 894976      |
| train/                   |             |
|    approx_kl             | 0.007357708 |
|    clip_fraction         | 0.0742      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.26        |
|    cost_value_loss       | 19.2        |
|    cost_values           | 2.33        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0.706       |
|    lagrangian_multiplier | 0.00341     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 4360        |
|    policy_gradient_loss  | -0.00413    |
|    std                   | 0.515       |
|    value_loss            | 3.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.285        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.285        |
| reward                   | -0.47479966  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 15           |
|    time_elapsed          | 7775         |
|    total_timesteps       | 933888       |
| train/                   |              |
|    approx_kl             | 0.0011898088 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.98         |
|    cost_value_loss       | 47.2         |
|    cost_values           | 0.847        |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.9          |
|    lagrangian_multiplier | 0.00496      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.56         |
|    n_updates             | 4550         |
|    policy_gradient_loss  | 0.000653     |
|    std                   | 0.753        |
|    value_loss            | 0.809        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0341       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0341       |
| reward                   | -0.5426556   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 5            |
|    time_elapsed          | 2776         |
|    total_timesteps       | 913408       |
| train/                   |              |
|    approx_kl             | 0.0034552938 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.685        |
|    cost_value_loss       | 0.0203       |
|    cost_values           | 0.736        |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.94         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.511        |
|    n_updates             | 4450         |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 0.781        |
|    value_loss            | 1.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0779       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0779       |
| reward                   | -0.40658444  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 11           |
|    time_elapsed          | 5837         |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0040304163 |
|    clip_fraction         | 0.00522      |
|    clip_range            | 0.2          |
|    cost_returns          | 17.5         |
|    cost_value_loss       | 249          |
|    cost_values           | 1.93         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 122          |
|    n_updates             | 4510         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.892        |
|    value_loss            | 0.426        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0274       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0274       |
| reward                   | -0.3410032   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -381         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 5            |
|    time_elapsed          | 2578         |
|    total_timesteps       | 913408       |
| train/                   |              |
|    approx_kl             | 0.0030685957 |
|    clip_fraction         | 0.0363       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.1         |
|    cost_value_loss       | 155          |
|    cost_values           | 3            |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.0698       |
|    lagrangian_multiplier | 0.0384       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.69         |
|    n_updates             | 4450         |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 0.729        |
|    value_loss            | 1.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0375      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0375      |
| reward                   | -0.50941515 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -436        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 27          |
|    time_elapsed          | 14014       |
|    total_timesteps       | 958464      |
| train/                   |             |
|    approx_kl             | 0.00926953  |
|    clip_fraction         | 0.0402      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.2        |
|    cost_value_loss       | 190         |
|    cost_values           | 1.29        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0.0222      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.19        |
|    n_updates             | 4670        |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.739       |
|    value_loss            | 1.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.66        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.66        |
| reward                   | -0.4818217  |
| rollout/                 |             |
|    ep_len_mean           | 487         |
|    ep_rew_mean           | -198        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 46          |
|    time_elapsed          | 26698       |
|    total_timesteps       | 897024      |
| train/                   |             |
|    approx_kl             | 0.010893963 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.86        |
|    cost_value_loss       | 16          |
|    cost_values           | 2.36        |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.385       |
|    lagrangian_multiplier | 0.00313     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.93        |
|    n_updates             | 4370        |
|    policy_gradient_loss  | -0.0042     |
|    std                   | 0.514       |
|    value_loss            | 17.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0466       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0466       |
| reward                   | -0.33457437  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 16           |
|    time_elapsed          | 8304         |
|    total_timesteps       | 935936       |
| train/                   |              |
|    approx_kl             | 0.0036912228 |
|    clip_fraction         | 0.00718      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.38         |
|    cost_value_loss       | 113          |
|    cost_values           | 1.23         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.883        |
|    lagrangian_multiplier | 0.0134       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.61         |
|    n_updates             | 4560         |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.752        |
|    value_loss            | 1.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0841       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0841       |
| reward                   | -0.40451422  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -425         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 6            |
|    time_elapsed          | 3346         |
|    total_timesteps       | 915456       |
| train/                   |              |
|    approx_kl             | 0.0033001048 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.2         |
|    cost_value_loss       | 130          |
|    cost_values           | 1.07         |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.905        |
|    lagrangian_multiplier | 0.0159       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.15         |
|    n_updates             | 4460         |
|    policy_gradient_loss  | -0.000784    |
|    std                   | 0.781        |
|    value_loss            | 3.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.199       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.199       |
| reward                   | -0.29427013 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 12          |
|    time_elapsed          | 6347        |
|    total_timesteps       | 927744      |
| train/                   |             |
|    approx_kl             | 0.003549886 |
|    clip_fraction         | 0.0169      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.44        |
|    cost_value_loss       | 47.7        |
|    cost_values           | 1.43        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.00239     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 4520        |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 0.891       |
|    value_loss            | 0.575       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.192        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.192        |
| reward                   | -0.46498683  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -378         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 6            |
|    time_elapsed          | 3094         |
|    total_timesteps       | 915456       |
| train/                   |              |
|    approx_kl             | 0.0058580814 |
|    clip_fraction         | 0.0363       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.2         |
|    cost_value_loss       | 237          |
|    cost_values           | 2.99         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0.013        |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 4460         |
|    policy_gradient_loss  | -0.00533     |
|    std                   | 0.728        |
|    value_loss            | 0.311        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0403       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0403       |
| reward                   | -0.39429772  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 28           |
|    time_elapsed          | 14552        |
|    total_timesteps       | 960512       |
| train/                   |              |
|    approx_kl             | 0.0031734614 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.4         |
|    cost_value_loss       | 146          |
|    cost_values           | 1.61         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0.0134       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 4680         |
|    policy_gradient_loss  | 5.98e-05     |
|    std                   | 0.739        |
|    value_loss            | 1.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.239        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.239        |
| reward                   | -0.4457093   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 17           |
|    time_elapsed          | 8830         |
|    total_timesteps       | 937984       |
| train/                   |              |
|    approx_kl             | 0.0011231762 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 4.32         |
|    cost_value_loss       | 56.7         |
|    cost_values           | 0.616        |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.934        |
|    lagrangian_multiplier | 0.00443      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.38         |
|    n_updates             | 4570         |
|    policy_gradient_loss  | -0.000515    |
|    std                   | 0.753        |
|    value_loss            | 0.797        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.49         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.49         |
| reward                   | -0.33201486  |
| rollout/                 |              |
|    ep_len_mean           | 478          |
|    ep_rew_mean           | -192         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 47           |
|    time_elapsed          | 27330        |
|    total_timesteps       | 899072       |
| train/                   |              |
|    approx_kl             | 0.0075713997 |
|    clip_fraction         | 0.119        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.89         |
|    cost_value_loss       | 23.3         |
|    cost_values           | 2.5          |
|    entropy               | -1.45        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0.121        |
|    lagrangian_multiplier | 0.0114       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.6          |
|    n_updates             | 4380         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.513        |
|    value_loss            | 18.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.23         |
| reward                   | -0.55493885  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 7            |
|    time_elapsed          | 3902         |
|    total_timesteps       | 917504       |
| train/                   |              |
|    approx_kl             | 0.0070955274 |
|    clip_fraction         | 0.0202       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.8          |
|    cost_value_loss       | 102          |
|    cost_values           | 0.981        |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0.0144       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.49         |
|    n_updates             | 4470         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.78         |
|    value_loss            | 1.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.015       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.015       |
| reward                   | -0.44073117 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 13          |
|    time_elapsed          | 6857        |
|    total_timesteps       | 929792      |
| train/                   |             |
|    approx_kl             | 0.009419228 |
|    clip_fraction         | 0.0688      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 162         |
|    cost_values           | 1.46        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.0139      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 4530        |
|    policy_gradient_loss  | -0.008      |
|    std                   | 0.889       |
|    value_loss            | 0.899       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.341        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.341        |
| reward                   | -0.23069647  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -376         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 7            |
|    time_elapsed          | 3612         |
|    total_timesteps       | 917504       |
| train/                   |              |
|    approx_kl             | 0.0054464056 |
|    clip_fraction         | 0.031        |
|    clip_range            | 0.2          |
|    cost_returns          | 18.4         |
|    cost_value_loss       | 243          |
|    cost_values           | 3            |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.651        |
|    lagrangian_multiplier | 0.00416      |
|    learning_rate         | 0.0003       |
|    loss                  | 41.1         |
|    n_updates             | 4470         |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.727        |
|    value_loss            | 0.502        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.132       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.132       |
| reward                   | -0.43413648 |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -430        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 29          |
|    time_elapsed          | 15089       |
|    total_timesteps       | 962560      |
| train/                   |             |
|    approx_kl             | 0.011154244 |
|    clip_fraction         | 0.0929      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.04        |
|    cost_value_loss       | 66.4        |
|    cost_values           | 1.58        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.742       |
|    lagrangian_multiplier | 0.00767     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.24        |
|    n_updates             | 4690        |
|    policy_gradient_loss  | -0.00191    |
|    std                   | 0.737       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.335        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.335        |
| reward                   | -0.4837212   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 18           |
|    time_elapsed          | 9358         |
|    total_timesteps       | 940032       |
| train/                   |              |
|    approx_kl             | 0.0022604885 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.155        |
|    cost_value_loss       | 0.0111       |
|    cost_values           | 0.243        |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | -0.492       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0881       |
|    n_updates             | 4580         |
|    policy_gradient_loss  | -0.000939    |
|    std                   | 0.752        |
|    value_loss            | 0.486        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.224        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.224        |
| reward                   | -0.3758633   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 14           |
|    time_elapsed          | 7369         |
|    total_timesteps       | 931840       |
| train/                   |              |
|    approx_kl             | 0.0031710118 |
|    clip_fraction         | 0.00693      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.9         |
|    cost_value_loss       | 181          |
|    cost_values           | 2.1          |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 88.2         |
|    n_updates             | 4540         |
|    policy_gradient_loss  | -0.00327     |
|    std                   | 0.889        |
|    value_loss            | 0.644        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.221       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.221       |
| reward                   | -0.4825098  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 8           |
|    time_elapsed          | 4458        |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.008438258 |
|    clip_fraction         | 0.0199      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.87        |
|    cost_value_loss       | 51.5        |
|    cost_values           | 0.781       |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.00664     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.35        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | -0.000169   |
|    std                   | 0.782       |
|    value_loss            | 0.733       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.27474186 |
| rollout/                 |             |
|    ep_len_mean           | 479         |
|    ep_rew_mean           | -192        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 48          |
|    time_elapsed          | 27961       |
|    total_timesteps       | 901120      |
| train/                   |             |
|    approx_kl             | 0.011360107 |
|    clip_fraction         | 0.0982      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.59        |
|    cost_value_loss       | 20.2        |
|    cost_values           | 2.52        |
|    entropy               | -1.45       |
|    entropy_loss          | -1.45       |
|    explained_variance    | 0.257       |
|    lagrangian_multiplier | 0.00297     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.83        |
|    n_updates             | 4390        |
|    policy_gradient_loss  | -0.00292    |
|    std                   | 0.511       |
|    value_loss            | 21.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0462       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0462       |
| reward                   | -0.22061495  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -376         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 8            |
|    time_elapsed          | 4120         |
|    total_timesteps       | 919552       |
| train/                   |              |
|    approx_kl             | 0.0011611768 |
|    clip_fraction         | 0.00112      |
|    clip_range            | 0.2          |
|    cost_returns          | 17.2         |
|    cost_value_loss       | 225          |
|    cost_values           | 3            |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.917        |
|    lagrangian_multiplier | 0.0425       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.74         |
|    n_updates             | 4480         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.726        |
|    value_loss            | 1.01         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.169       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.169       |
| reward                   | -0.32440835 |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 30          |
|    time_elapsed          | 15625       |
|    total_timesteps       | 964608      |
| train/                   |             |
|    approx_kl             | 0.024826456 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.66        |
|    cost_value_loss       | 25.3        |
|    cost_values           | 0.868       |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0.000722    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.83        |
|    n_updates             | 4700        |
|    policy_gradient_loss  | -0.0108     |
|    std                   | 0.737       |
|    value_loss            | 2.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.148        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.148        |
| reward                   | -0.4879549   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 19           |
|    time_elapsed          | 9891         |
|    total_timesteps       | 942080       |
| train/                   |              |
|    approx_kl             | 0.0041663246 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.147        |
|    cost_value_loss       | 0.0225       |
|    cost_values           | 0.0674       |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | -1.69        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0328       |
|    n_updates             | 4590         |
|    policy_gradient_loss  | -0.0012      |
|    std                   | 0.753        |
|    value_loss            | 0.432        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0165      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0165      |
| reward                   | -0.29919854 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 15          |
|    time_elapsed          | 7883        |
|    total_timesteps       | 933888      |
| train/                   |             |
|    approx_kl             | 0.008044457 |
|    clip_fraction         | 0.0259      |
|    clip_range            | 0.2         |
|    cost_returns          | 12          |
|    cost_value_loss       | 159         |
|    cost_values           | 1.8         |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0.0205      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.61        |
|    n_updates             | 4550        |
|    policy_gradient_loss  | -0.00798    |
|    std                   | 0.888       |
|    value_loss            | 0.997       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.159        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.159        |
| reward                   | -0.38628817  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 9            |
|    time_elapsed          | 5021         |
|    total_timesteps       | 921600       |
| train/                   |              |
|    approx_kl             | 0.0016693512 |
|    clip_fraction         | 0.0653       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.567        |
|    cost_value_loss       | 0.00933      |
|    cost_values           | 0.642        |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | -0.309       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.119        |
|    n_updates             | 4490         |
|    policy_gradient_loss  | 0.00247      |
|    std                   | 0.781        |
|    value_loss            | 0.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0456       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0456       |
| reward                   | -0.25516003  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -375         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 9            |
|    time_elapsed          | 4650         |
|    total_timesteps       | 921600       |
| train/                   |              |
|    approx_kl             | 0.0026085158 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 137          |
|    cost_values           | 3            |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.901        |
|    lagrangian_multiplier | 0.00691      |
|    learning_rate         | 0.0003       |
|    loss                  | 17.3         |
|    n_updates             | 4490         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.725        |
|    value_loss            | 0.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.7         |
| reward                   | -0.54582965 |
| rollout/                 |             |
|    ep_len_mean           | 466         |
|    ep_rew_mean           | -186        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 49          |
|    time_elapsed          | 28595       |
|    total_timesteps       | 903168      |
| train/                   |             |
|    approx_kl             | 0.026978854 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.54        |
|    cost_value_loss       | 17.1        |
|    cost_values           | 2.78        |
|    entropy               | -1.45       |
|    entropy_loss          | -1.45       |
|    explained_variance    | 0.166       |
|    lagrangian_multiplier | 0.00767     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.13        |
|    n_updates             | 4400        |
|    policy_gradient_loss  | -0.00575    |
|    std                   | 0.512       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.224        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.224        |
| reward                   | -0.5516189   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 31           |
|    time_elapsed          | 16161        |
|    total_timesteps       | 966656       |
| train/                   |              |
|    approx_kl             | 0.0077226474 |
|    clip_fraction         | 0.0628       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.25         |
|    cost_value_loss       | 86.5         |
|    cost_values           | 1.06         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0.00605      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.6         |
|    n_updates             | 4710         |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 0.736        |
|    value_loss            | 0.652        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.233       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.233       |
| reward                   | -0.39759728 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -412        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 20          |
|    time_elapsed          | 10422       |
|    total_timesteps       | 944128      |
| train/                   |             |
|    approx_kl             | 0.005246993 |
|    clip_fraction         | 0.0407      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 57.5        |
|    cost_values           | 0.635       |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.00722     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.15        |
|    n_updates             | 4600        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.751       |
|    value_loss            | 0.513       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.024       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.024       |
| reward                   | -0.6281198  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 16          |
|    time_elapsed          | 8401        |
|    total_timesteps       | 935936      |
| train/                   |             |
|    approx_kl             | 0.016646039 |
|    clip_fraction         | 0.144       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 143         |
|    cost_values           | 1.42        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0.00273     |
|    learning_rate         | 0.0003      |
|    loss                  | 29.8        |
|    n_updates             | 4560        |
|    policy_gradient_loss  | -0.00965    |
|    std                   | 0.888       |
|    value_loss            | 0.615       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00554     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00554     |
| reward                   | -0.21556154 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -428        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 10          |
|    time_elapsed          | 5588        |
|    total_timesteps       | 923648      |
| train/                   |             |
|    approx_kl             | 0.004085528 |
|    clip_fraction         | 0.0513      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.66        |
|    cost_value_loss       | 125         |
|    cost_values           | 0.972       |
|    entropy               | -2.34       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.0139      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.81        |
|    n_updates             | 4500        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.78        |
|    value_loss            | 0.809       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.91528016  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -372         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 10           |
|    time_elapsed          | 5172         |
|    total_timesteps       | 923648       |
| train/                   |              |
|    approx_kl             | 0.0037461277 |
|    clip_fraction         | 0.0318       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.2         |
|    cost_value_loss       | 173          |
|    cost_values           | 3            |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0.0166       |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 4500         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.723        |
|    value_loss            | 1.23         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/pe6a45mq
-----------------------------------
| avg_speed          | 7.79       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.79       |
| reward             | -0.5870467 |
| rollout/           |            |
|    ep_len_mean     | 457        |
|    ep_rew_mean     | -182       |
| time/              |            |
|    fps             | 3          |
|    iterations      | 1          |
|    time_elapsed    | 641        |
|    total_timesteps | 905216     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.223        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.223        |
| reward                   | -0.24511844  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 32           |
|    time_elapsed          | 16701        |
|    total_timesteps       | 968704       |
| train/                   |              |
|    approx_kl             | 0.0049775047 |
|    clip_fraction         | 0.0661       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 26.4         |
|    cost_values           | 0.857        |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 5.15e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 4720         |
|    policy_gradient_loss  | -0.0045      |
|    std                   | 0.737        |
|    value_loss            | 0.594        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0416      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0416      |
| reward                   | -0.47697124 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 21          |
|    time_elapsed          | 10961       |
|    total_timesteps       | 946176      |
| train/                   |             |
|    approx_kl             | 0.002917457 |
|    clip_fraction         | 0.00845     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.38        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 0.361       |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0.0013      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.62        |
|    n_updates             | 4610        |
|    policy_gradient_loss  | -0.000479   |
|    std                   | 0.75        |
|    value_loss            | 0.679       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.132       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.132       |
| reward                   | -0.28440282 |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 17          |
|    time_elapsed          | 8920        |
|    total_timesteps       | 937984      |
| train/                   |             |
|    approx_kl             | 0.0043695   |
|    clip_fraction         | 0.00996     |
|    clip_range            | 0.2         |
|    cost_returns          | 2.84        |
|    cost_value_loss       | 29.1        |
|    cost_values           | 0.895       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00275     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.21        |
|    n_updates             | 4570        |
|    policy_gradient_loss  | -0.00352    |
|    std                   | 0.888       |
|    value_loss            | 7.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.127        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.127        |
| reward                   | -0.50585103  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -375         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 11           |
|    time_elapsed          | 5693         |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0022414858 |
|    clip_fraction         | 0.0064       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 158          |
|    cost_values           | 2.77         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.91         |
|    lagrangian_multiplier | 0.035        |
|    learning_rate         | 0.0003       |
|    loss                  | 6.77         |
|    n_updates             | 4510         |
|    policy_gradient_loss  | -0.00487     |
|    std                   | 0.724        |
|    value_loss            | 3.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0375       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0375       |
| reward                   | -0.34619182  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -428         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 11           |
|    time_elapsed          | 6151         |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0042960644 |
|    clip_fraction         | 0.0342       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.75         |
|    cost_value_loss       | 23.4         |
|    cost_values           | 1.33         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.789        |
|    lagrangian_multiplier | 0.00458      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.73         |
|    n_updates             | 4510         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.777        |
|    value_loss            | 2.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0362       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0362       |
| reward                   | -0.32240757  |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -427         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 33           |
|    time_elapsed          | 17247        |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0030861138 |
|    clip_fraction         | 0.0397       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.89         |
|    cost_value_loss       | 12.4         |
|    cost_values           | 1.04         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.947        |
|    lagrangian_multiplier | 0.000301     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.27         |
|    n_updates             | 4730         |
|    policy_gradient_loss  | -0.00465     |
|    std                   | 0.736        |
|    value_loss            | 1.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.44        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.44        |
| reward                   | -0.44639573 |
| rollout/                 |             |
|    ep_len_mean           | 468         |
|    ep_rew_mean           | -187        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 2           |
|    time_elapsed          | 1287        |
|    total_timesteps       | 907264      |
| train/                   |             |
|    approx_kl             | 0.008908218 |
|    clip_fraction         | 0.155       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.76        |
|    cost_value_loss       | 18.6        |
|    cost_values           | 2.95        |
|    entropy               | -1.45       |
|    entropy_loss          | -1.45       |
|    explained_variance    | 0.106       |
|    lagrangian_multiplier | 0.00588     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.48        |
|    n_updates             | 4420        |
|    policy_gradient_loss  | -0.00758    |
|    std                   | 0.513       |
|    value_loss            | 20.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0983      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0983      |
| reward                   | -0.55317885 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 22          |
|    time_elapsed          | 11495       |
|    total_timesteps       | 948224      |
| train/                   |             |
|    approx_kl             | 0.004094638 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.1         |
|    cost_value_loss       | 106         |
|    cost_values           | 1.22        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 51.7        |
|    n_updates             | 4620        |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.75        |
|    value_loss            | 1.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.149        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.149        |
| reward                   | -0.3427235   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 18           |
|    time_elapsed          | 9441         |
|    total_timesteps       | 940032       |
| train/                   |              |
|    approx_kl             | 0.0062027313 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 9.3          |
|    cost_value_loss       | 131          |
|    cost_values           | 0.963        |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.828        |
|    lagrangian_multiplier | 0.00178      |
|    learning_rate         | 0.0003       |
|    loss                  | 36.6         |
|    n_updates             | 4580         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.888        |
|    value_loss            | 5.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0626      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0626      |
| reward                   | -0.36215085 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -376        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 12          |
|    time_elapsed          | 6216        |
|    total_timesteps       | 927744      |
| train/                   |             |
|    approx_kl             | 0.004109583 |
|    clip_fraction         | 0.0269      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 201         |
|    cost_values           | 1.99        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.0159      |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 4520        |
|    policy_gradient_loss  | 0.000938    |
|    std                   | 0.724       |
|    value_loss            | 3.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.205       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.205       |
| reward                   | -0.4474071  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 12          |
|    time_elapsed          | 6689        |
|    total_timesteps       | 927744      |
| train/                   |             |
|    approx_kl             | 0.003852231 |
|    clip_fraction         | 0.0201      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.83        |
|    cost_value_loss       | 94.2        |
|    cost_values           | 1.01        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.00854     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.21        |
|    n_updates             | 4520        |
|    policy_gradient_loss  | -0.000706   |
|    std                   | 0.776       |
|    value_loss            | 0.718       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.171       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.171       |
| reward                   | -0.24416061 |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -426        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 34          |
|    time_elapsed          | 17788       |
|    total_timesteps       | 972800      |
| train/                   |             |
|    approx_kl             | 0.006164295 |
|    clip_fraction         | 0.0183      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 45.4        |
|    cost_values           | 1.33        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0.00716     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.18        |
|    n_updates             | 4740        |
|    policy_gradient_loss  | -0.000894   |
|    std                   | 0.735       |
|    value_loss            | 1.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.316        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.316        |
| reward                   | -0.48708913  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 23           |
|    time_elapsed          | 12031        |
|    total_timesteps       | 950272       |
| train/                   |              |
|    approx_kl             | 0.0019820868 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 17.1         |
|    cost_values           | 0.802        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.767        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.19         |
|    n_updates             | 4630         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.749        |
|    value_loss            | 2.38         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00172     |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.00172     |
| reward                   | -0.60226727 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 19          |
|    time_elapsed          | 9963        |
|    total_timesteps       | 942080      |
| train/                   |             |
|    approx_kl             | 0.006737794 |
|    clip_fraction         | 0.03        |
|    clip_range            | 0.2         |
|    cost_returns          | 14.3        |
|    cost_value_loss       | 199         |
|    cost_values           | 1.59        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.505       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 96.3        |
|    n_updates             | 4590        |
|    policy_gradient_loss  | -0.00303    |
|    std                   | 0.888       |
|    value_loss            | 4.59        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.61       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.61       |
| reward                   | -0.4948457 |
| rollout/                 |            |
|    ep_len_mean           | 452        |
|    ep_rew_mean           | -182       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 3          |
|    time_elapsed          | 1931       |
|    total_timesteps       | 909312     |
| train/                   |            |
|    approx_kl             | 0.0211135  |
|    clip_fraction         | 0.144      |
|    clip_range            | 0.2        |
|    cost_returns          | 7.01       |
|    cost_value_loss       | 19.3       |
|    cost_values           | 2.96       |
|    entropy               | -1.44      |
|    entropy_loss          | -1.45      |
|    explained_variance    | 0.2        |
|    lagrangian_multiplier | 0.00732    |
|    learning_rate         | 0.0003     |
|    loss                  | 6.01       |
|    n_updates             | 4430       |
|    policy_gradient_loss  | -0.00386   |
|    std                   | 0.511      |
|    value_loss            | 17.4       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.0531      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0531      |
| reward                   | -0.38069806 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -374        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 13          |
|    time_elapsed          | 6733        |
|    total_timesteps       | 929792      |
| train/                   |             |
|    approx_kl             | 0.00416761  |
|    clip_fraction         | 0.00767     |
|    clip_range            | 0.2         |
|    cost_returns          | 17.9        |
|    cost_value_loss       | 257         |
|    cost_values           | 2.03        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 126         |
|    n_updates             | 4530        |
|    policy_gradient_loss  | -0.00201    |
|    std                   | 0.724       |
|    value_loss            | 0.814       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.096       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.096       |
| reward                   | -0.51677245 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 13          |
|    time_elapsed          | 7242        |
|    total_timesteps       | 929792      |
| train/                   |             |
|    approx_kl             | 0.005027767 |
|    clip_fraction         | 0.0254      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 20.5        |
|    cost_values           | 0.711       |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.791       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.3        |
|    n_updates             | 4530        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.776       |
|    value_loss            | 3.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00114     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00114     |
| reward                   | -0.26943642 |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -423        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 35          |
|    time_elapsed          | 18329       |
|    total_timesteps       | 974848      |
| train/                   |             |
|    approx_kl             | 0.007874259 |
|    clip_fraction         | 0.0487      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.42        |
|    cost_value_loss       | 54.3        |
|    cost_values           | 1.18        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.00227     |
|    learning_rate         | 0.0003      |
|    loss                  | 13.9        |
|    n_updates             | 4750        |
|    policy_gradient_loss  | -0.004      |
|    std                   | 0.736       |
|    value_loss            | 0.56        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.177        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.177        |
| reward                   | -0.5048828   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 24           |
|    time_elapsed          | 12566        |
|    total_timesteps       | 952320       |
| train/                   |              |
|    approx_kl             | 0.0045746416 |
|    clip_fraction         | 0.025        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.27         |
|    cost_value_loss       | 54.6         |
|    cost_values           | 0.902        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 0.00434      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.26         |
|    n_updates             | 4640         |
|    policy_gradient_loss  | -0.00218     |
|    std                   | 0.75         |
|    value_loss            | 0.641        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.093       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.093       |
| reward                   | -0.5109317  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 20          |
|    time_elapsed          | 10487       |
|    total_timesteps       | 944128      |
| train/                   |             |
|    approx_kl             | 0.004659726 |
|    clip_fraction         | 0.0213      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.84        |
|    cost_value_loss       | 22.3        |
|    cost_values           | 0.913       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.00832     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.62        |
|    n_updates             | 4600        |
|    policy_gradient_loss  | -0.00674    |
|    std                   | 0.888       |
|    value_loss            | 4.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.112        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.112        |
| reward                   | -0.21570486  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -372         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 14           |
|    time_elapsed          | 7256         |
|    total_timesteps       | 931840       |
| train/                   |              |
|    approx_kl             | 0.0044105663 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.9         |
|    cost_value_loss       | 133          |
|    cost_values           | 2.36         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0.000517     |
|    learning_rate         | 0.0003       |
|    loss                  | 50.6         |
|    n_updates             | 4540         |
|    policy_gradient_loss  | -0.00389     |
|    std                   | 0.723        |
|    value_loss            | 0.771        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.28773066 |
| rollout/                 |             |
|    ep_len_mean           | 457         |
|    ep_rew_mean           | -184        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 4           |
|    time_elapsed          | 2584        |
|    total_timesteps       | 911360      |
| train/                   |             |
|    approx_kl             | 0.01242909  |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.81        |
|    cost_value_loss       | 18.3        |
|    cost_values           | 2.97        |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0.234       |
|    lagrangian_multiplier | 0.00695     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.62        |
|    n_updates             | 4440        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.51        |
|    value_loss            | 23.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0511       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0511       |
| reward                   | -0.44502315  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -426         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 14           |
|    time_elapsed          | 7797         |
|    total_timesteps       | 931840       |
| train/                   |              |
|    approx_kl             | 0.0008155162 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 16.1         |
|    cost_value_loss       | 234          |
|    cost_values           | 1.53         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.74         |
|    lagrangian_multiplier | 0.0188       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 4540         |
|    policy_gradient_loss  | -6.03e-05    |
|    std                   | 0.776        |
|    value_loss            | 3.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.279       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.279       |
| reward                   | -0.34732673 |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 36          |
|    time_elapsed          | 18870       |
|    total_timesteps       | 976896      |
| train/                   |             |
|    approx_kl             | 0.005332756 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.57        |
|    cost_value_loss       | 49          |
|    cost_values           | 1.31        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.601       |
|    lagrangian_multiplier | 0.00136     |
|    learning_rate         | 0.0003      |
|    loss                  | 15.8        |
|    n_updates             | 4760        |
|    policy_gradient_loss  | -0.00652    |
|    std                   | 0.735       |
|    value_loss            | 4.32        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0113       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0113       |
| reward                   | -0.5073393   |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 21           |
|    time_elapsed          | 11011        |
|    total_timesteps       | 946176       |
| train/                   |              |
|    approx_kl             | 0.0045456346 |
|    clip_fraction         | 0.0477       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.1          |
|    cost_value_loss       | 53.6         |
|    cost_values           | 0.595        |
|    entropy               | -2.59        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0.000311     |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 4610         |
|    policy_gradient_loss  | -0.005       |
|    std                   | 0.885        |
|    value_loss            | 0.919        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.184       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.184       |
| reward                   | -0.312547   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 25          |
|    time_elapsed          | 13104       |
|    total_timesteps       | 954368      |
| train/                   |             |
|    approx_kl             | 0.004465186 |
|    clip_fraction         | 0.0264      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.23        |
|    cost_value_loss       | 81.3        |
|    cost_values           | 0.685       |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.717       |
|    lagrangian_multiplier | 0.00261     |
|    learning_rate         | 0.0003      |
|    loss                  | 18.5        |
|    n_updates             | 4650        |
|    policy_gradient_loss  | -0.00297    |
|    std                   | 0.75        |
|    value_loss            | 0.468       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.046        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.046        |
| reward                   | -0.41620857  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 15           |
|    time_elapsed          | 7787         |
|    total_timesteps       | 933888       |
| train/                   |              |
|    approx_kl             | 0.0056213485 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 181          |
|    cost_values           | 2.71         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0.0205       |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 4550         |
|    policy_gradient_loss  | -0.00516     |
|    std                   | 0.724        |
|    value_loss            | 0.927        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.183       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.183       |
| reward                   | -0.5508088  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 15          |
|    time_elapsed          | 8360        |
|    total_timesteps       | 933888      |
| train/                   |             |
|    approx_kl             | 0.005941614 |
|    clip_fraction         | 0.0993      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.53        |
|    cost_value_loss       | 8.14        |
|    cost_values           | 1.12        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.738       |
|    lagrangian_multiplier | 0.000443    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.75        |
|    n_updates             | 4550        |
|    policy_gradient_loss  | -0.00645    |
|    std                   | 0.775       |
|    value_loss            | 0.316       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.33246633 |
| rollout/                 |             |
|    ep_len_mean           | 459         |
|    ep_rew_mean           | -182        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 5           |
|    time_elapsed          | 3236        |
|    total_timesteps       | 913408      |
| train/                   |             |
|    approx_kl             | 0.008959612 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.84        |
|    cost_value_loss       | 20.9        |
|    cost_values           | 2.7         |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0.226       |
|    lagrangian_multiplier | 0.00453     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.88        |
|    n_updates             | 4450        |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 0.51        |
|    value_loss            | 13.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.262        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.262        |
| reward                   | -0.4926655   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -420         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 37           |
|    time_elapsed          | 19423        |
|    total_timesteps       | 978944       |
| train/                   |              |
|    approx_kl             | 0.0024201963 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.15         |
|    cost_value_loss       | 50           |
|    cost_values           | 1.52         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0.00471      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.29         |
|    n_updates             | 4770         |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 0.734        |
|    value_loss            | 0.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.067       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.067       |
| reward                   | -0.4397611  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 22          |
|    time_elapsed          | 11526       |
|    total_timesteps       | 948224      |
| train/                   |             |
|    approx_kl             | 0.008373175 |
|    clip_fraction         | 0.0479      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.02        |
|    cost_value_loss       | 19.4        |
|    cost_values           | 0.7         |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0.000712    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.16        |
|    n_updates             | 4620        |
|    policy_gradient_loss  | -0.00568    |
|    std                   | 0.885       |
|    value_loss            | 0.422       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0794      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0794      |
| reward                   | -0.53117085 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 26          |
|    time_elapsed          | 13638       |
|    total_timesteps       | 956416      |
| train/                   |             |
|    approx_kl             | 0.004242787 |
|    clip_fraction         | 0.0117      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 49.4        |
|    cost_values           | 1.53        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.6        |
|    n_updates             | 4660        |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.75        |
|    value_loss            | 1.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.154       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.154       |
| reward                   | -0.3652503  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -372        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 16          |
|    time_elapsed          | 8310        |
|    total_timesteps       | 935936      |
| train/                   |             |
|    approx_kl             | 0.003561194 |
|    clip_fraction         | 0.0152      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.46        |
|    cost_value_loss       | 97.5        |
|    cost_values           | 2.54        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.109       |
|    learning_rate         | 0.0003      |
|    loss                  | 3.19        |
|    n_updates             | 4560        |
|    policy_gradient_loss  | -0.000422   |
|    std                   | 0.724       |
|    value_loss            | 4.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.289        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.289        |
| reward                   | -0.25783747  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 16           |
|    time_elapsed          | 8918         |
|    total_timesteps       | 935936       |
| train/                   |              |
|    approx_kl             | 0.0023922084 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 5.92         |
|    cost_values           | 1.01         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | -0.817       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.59         |
|    n_updates             | 4560         |
|    policy_gradient_loss  | -0.000881    |
|    std                   | 0.774        |
|    value_loss            | 1.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.91         |
| reward                   | -0.3456097   |
| rollout/                 |              |
|    ep_len_mean           | 473          |
|    ep_rew_mean           | -188         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 6            |
|    time_elapsed          | 3891         |
|    total_timesteps       | 915456       |
| train/                   |              |
|    approx_kl             | 0.0065765996 |
|    clip_fraction         | 0.058        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.62         |
|    cost_value_loss       | 20.9         |
|    cost_values           | 2.46         |
|    entropy               | -1.43        |
|    entropy_loss          | -1.44        |
|    explained_variance    | -0.0577      |
|    lagrangian_multiplier | 0.00397      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.38         |
|    n_updates             | 4460         |
|    policy_gradient_loss  | -0.00399     |
|    std                   | 0.51         |
|    value_loss            | 20.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0731      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0731      |
| reward                   | -0.26476237 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -425        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 38          |
|    time_elapsed          | 19971       |
|    total_timesteps       | 980992      |
| train/                   |             |
|    approx_kl             | 0.005594464 |
|    clip_fraction         | 0.0298      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.26        |
|    cost_value_loss       | 62.4        |
|    cost_values           | 1.65        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0.00869     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.67        |
|    n_updates             | 4780        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.733       |
|    value_loss            | 0.942       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.331       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.331       |
| reward                   | -0.55236614 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 23          |
|    time_elapsed          | 12054       |
|    total_timesteps       | 950272      |
| train/                   |             |
|    approx_kl             | 0.017432917 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 8.88        |
|    cost_value_loss       | 126         |
|    cost_values           | 1.09        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.0133      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.36        |
|    n_updates             | 4630        |
|    policy_gradient_loss  | -0.00496    |
|    std                   | 0.888       |
|    value_loss            | 0.239       |
------------------------------------------
--------------------------------------------
| avg_speed                | 0.019         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.019         |
| reward                   | -0.4888156    |
| rollout/                 |               |
|    ep_len_mean           | 993           |
|    ep_rew_mean           | -407          |
| time/                    |               |
|    fps                   | 3             |
|    iterations            | 27            |
|    time_elapsed          | 14175         |
|    total_timesteps       | 958464        |
| train/                   |               |
|    approx_kl             | 0.00014143126 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 6.8           |
|    cost_value_loss       | 88.4          |
|    cost_values           | 1.26          |
|    entropy               | -2.25         |
|    entropy_loss          | -2.25         |
|    explained_variance    | 0.658         |
|    lagrangian_multiplier | 0.00107       |
|    learning_rate         | 0.0003        |
|    loss                  | 36.9          |
|    n_updates             | 4670          |
|    policy_gradient_loss  | -2.15e-05     |
|    std                   | 0.75          |
|    value_loss            | 11.8          |
--------------------------------------------
-------------------------------------------
| avg_speed                | 0.138        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.138        |
| reward                   | -0.5744565   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -373         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 17           |
|    time_elapsed          | 8831         |
|    total_timesteps       | 937984       |
| train/                   |              |
|    approx_kl             | 0.0044954093 |
|    clip_fraction         | 0.00835      |
|    clip_range            | 0.2          |
|    cost_returns          | 18.2         |
|    cost_value_loss       | 256          |
|    cost_values           | 2.37         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.00535      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 125          |
|    n_updates             | 4570         |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 0.723        |
|    value_loss            | 0.731        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.22         |
| reward                   | -0.48763427  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -424         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 17           |
|    time_elapsed          | 9458         |
|    total_timesteps       | 937984       |
| train/                   |              |
|    approx_kl             | 0.0035097974 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.32         |
|    cost_value_loss       | 116          |
|    cost_values           | 1.08         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0.0132       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.9          |
|    n_updates             | 4570         |
|    policy_gradient_loss  | -0.000847    |
|    std                   | 0.774        |
|    value_loss            | 0.979        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.189       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.189       |
| reward                   | -0.43137297 |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 39          |
|    time_elapsed          | 20511       |
|    total_timesteps       | 983040      |
| train/                   |             |
|    approx_kl             | 0.006736695 |
|    clip_fraction         | 0.0399      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.1        |
|    cost_value_loss       | 188         |
|    cost_values           | 2.01        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0.0182      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 4790        |
|    policy_gradient_loss  | -0.00461    |
|    std                   | 0.733       |
|    value_loss            | 0.304       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0658      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0658      |
| reward                   | -0.3792543  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 24          |
|    time_elapsed          | 12582       |
|    total_timesteps       | 952320      |
| train/                   |             |
|    approx_kl             | 0.011538862 |
|    clip_fraction         | 0.0661      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.4        |
|    cost_value_loss       | 174         |
|    cost_values           | 1.33        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0.014       |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 4640        |
|    policy_gradient_loss  | -0.00669    |
|    std                   | 0.888       |
|    value_loss            | 0.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.3811518  |
| rollout/                 |             |
|    ep_len_mean           | 473         |
|    ep_rew_mean           | -187        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 7           |
|    time_elapsed          | 4545        |
|    total_timesteps       | 917504      |
| train/                   |             |
|    approx_kl             | 0.021498319 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.02        |
|    cost_value_loss       | 16.3        |
|    cost_values           | 2.44        |
|    entropy               | -1.42       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.4         |
|    lagrangian_multiplier | 0.004       |
|    learning_rate         | 0.0003      |
|    loss                  | 5.33        |
|    n_updates             | 4470        |
|    policy_gradient_loss  | -0.00138    |
|    std                   | 0.507       |
|    value_loss            | 8.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.104        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.104        |
| reward                   | -0.37197     |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 28           |
|    time_elapsed          | 14717        |
|    total_timesteps       | 960512       |
| train/                   |              |
|    approx_kl             | 0.0045165103 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.93         |
|    cost_value_loss       | 50.6         |
|    cost_values           | 0.697        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.892        |
|    lagrangian_multiplier | 0.00765      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.41         |
|    n_updates             | 4680         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.75         |
|    value_loss            | 0.911        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.306        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.306        |
| reward                   | -0.35414165  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 18           |
|    time_elapsed          | 9366         |
|    total_timesteps       | 940032       |
| train/                   |              |
|    approx_kl             | 0.0006150398 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 18.2         |
|    cost_value_loss       | 246          |
|    cost_values           | 2.7          |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.894        |
|    lagrangian_multiplier | 0.000124     |
|    learning_rate         | 0.0003       |
|    loss                  | 114          |
|    n_updates             | 4580         |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.723        |
|    value_loss            | 1.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.284       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.284       |
| reward                   | -0.52704585 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 18          |
|    time_elapsed          | 10008       |
|    total_timesteps       | 940032      |
| train/                   |             |
|    approx_kl             | 0.004354757 |
|    clip_fraction         | 0.0578      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.793       |
|    cost_value_loss       | 1.77        |
|    cost_values           | 0.752       |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | -0.0232     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 4580        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.773       |
|    value_loss            | 2.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0495      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0495      |
| reward                   | -0.45184135 |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 40          |
|    time_elapsed          | 21062       |
|    total_timesteps       | 985088      |
| train/                   |             |
|    approx_kl             | 0.011032215 |
|    clip_fraction         | 0.0449      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 197         |
|    cost_values           | 2.22        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0.0276      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.6         |
|    n_updates             | 4800        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.731       |
|    value_loss            | 4.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0565       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0565       |
| reward                   | -0.5406883   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 25           |
|    time_elapsed          | 13112        |
|    total_timesteps       | 954368       |
| train/                   |              |
|    approx_kl             | 0.0052652946 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.4         |
|    cost_value_loss       | 251          |
|    cost_values           | 1.77         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.6         |
|    explained_variance    | -1.65        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 124          |
|    n_updates             | 4650         |
|    policy_gradient_loss  | -0.00306     |
|    std                   | 0.887        |
|    value_loss            | 1.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0208       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0208       |
| reward                   | -0.52950144  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 29           |
|    time_elapsed          | 15264        |
|    total_timesteps       | 962560       |
| train/                   |              |
|    approx_kl             | 0.0016352428 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.64         |
|    cost_value_loss       | 55.2         |
|    cost_values           | 0.63         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 0.00819      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.37         |
|    n_updates             | 4690         |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 0.75         |
|    value_loss            | 1.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.91        |
| reward                   | -0.4868976  |
| rollout/                 |             |
|    ep_len_mean           | 443         |
|    ep_rew_mean           | -173        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 8           |
|    time_elapsed          | 5202        |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.010056388 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.18        |
|    cost_value_loss       | 15.7        |
|    cost_values           | 2.57        |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.117       |
|    lagrangian_multiplier | 0.00258     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.61        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.506       |
|    value_loss            | 13.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.24997765  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 19           |
|    time_elapsed          | 9896         |
|    total_timesteps       | 942080       |
| train/                   |              |
|    approx_kl             | 0.0046482137 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.5         |
|    cost_value_loss       | 247          |
|    cost_values           | 2.93         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.813        |
|    lagrangian_multiplier | 0.0463       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.89         |
|    n_updates             | 4590         |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.721        |
|    value_loss            | 0.711        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00474      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00474      |
| reward                   | -0.51133966  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 19           |
|    time_elapsed          | 10569        |
|    total_timesteps       | 942080       |
| train/                   |              |
|    approx_kl             | 0.0027184086 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.33         |
|    cost_value_loss       | 117          |
|    cost_values           | 1.09         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.24         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 60.9         |
|    n_updates             | 4590         |
|    policy_gradient_loss  | -0.000517    |
|    std                   | 0.773        |
|    value_loss            | 1.95         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.163      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.163      |
| reward                   | -0.5672793 |
| rollout/                 |            |
|    ep_len_mean           | 966        |
|    ep_rew_mean           | -413       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 26         |
|    time_elapsed          | 13636      |
|    total_timesteps       | 956416     |
| train/                   |            |
|    approx_kl             | 0.01090271 |
|    clip_fraction         | 0.0499     |
|    clip_range            | 0.2        |
|    cost_returns          | 9.13       |
|    cost_value_loss       | 118        |
|    cost_values           | 1.51       |
|    entropy               | -2.59      |
|    entropy_loss          | -2.59      |
|    explained_variance    | 0.998      |
|    lagrangian_multiplier | 0.00221    |
|    learning_rate         | 0.0003     |
|    loss                  | 28.6       |
|    n_updates             | 4660       |
|    policy_gradient_loss  | -0.00586   |
|    std                   | 0.887      |
|    value_loss            | 0.295      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.0384       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0384       |
| reward                   | -0.16508752  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 41           |
|    time_elapsed          | 21612        |
|    total_timesteps       | 987136       |
| train/                   |              |
|    approx_kl             | 0.0047331136 |
|    clip_fraction         | 0.00688      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.3         |
|    cost_value_loss       | 144          |
|    cost_values           | 1.92         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.866        |
|    lagrangian_multiplier | 0.0167       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.37         |
|    n_updates             | 4810         |
|    policy_gradient_loss  | -0.00098     |
|    std                   | 0.729        |
|    value_loss            | 7.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.126        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.126        |
| reward                   | -0.49301738  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 30           |
|    time_elapsed          | 15803        |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0059099942 |
|    clip_fraction         | 0.0382       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.46         |
|    cost_value_loss       | 56.6         |
|    cost_values           | 0.918        |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.947        |
|    lagrangian_multiplier | 0.0057       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.25         |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.0039      |
|    std                   | 0.751        |
|    value_loss            | 1.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.361        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.361        |
| reward                   | -0.5456011   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -372         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 20           |
|    time_elapsed          | 10425        |
|    total_timesteps       | 944128       |
| train/                   |              |
|    approx_kl             | 0.0050517977 |
|    clip_fraction         | 0.034        |
|    clip_range            | 0.2          |
|    cost_returns          | 13.2         |
|    cost_value_loss       | 157          |
|    cost_values           | 2.92         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0.0158       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 4600         |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 0.723        |
|    value_loss            | 0.887        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.43        |
| reward                   | -0.29982695 |
| rollout/                 |             |
|    ep_len_mean           | 425         |
|    ep_rew_mean           | -165        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 9           |
|    time_elapsed          | 5865        |
|    total_timesteps       | 921600      |
| train/                   |             |
|    approx_kl             | 0.010855887 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.42        |
|    cost_value_loss       | 16.1        |
|    cost_values           | 2.89        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.202       |
|    lagrangian_multiplier | 0.00709     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.95        |
|    n_updates             | 4490        |
|    policy_gradient_loss  | -0.00435    |
|    std                   | 0.505       |
|    value_loss            | 21.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.13         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.13         |
| reward                   | -0.435524    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 20           |
|    time_elapsed          | 11131        |
|    total_timesteps       | 944128       |
| train/                   |              |
|    approx_kl             | 0.0059000216 |
|    clip_fraction         | 0.055        |
|    clip_range            | 0.2          |
|    cost_returns          | 9.47         |
|    cost_value_loss       | 126          |
|    cost_values           | 1.47         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.76         |
|    lagrangian_multiplier | 0.00444      |
|    learning_rate         | 0.0003       |
|    loss                  | 20           |
|    n_updates             | 4600         |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 0.773        |
|    value_loss            | 0.942        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0535       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0535       |
| reward                   | -0.28599036  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 27           |
|    time_elapsed          | 14165        |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0076177823 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.62         |
|    cost_value_loss       | 83.9         |
|    cost_values           | 1.4          |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0.0129       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.1          |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.00434     |
|    std                   | 0.887        |
|    value_loss            | 0.459        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.15         |
| reward                   | -0.21724327  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 42           |
|    time_elapsed          | 22171        |
|    total_timesteps       | 989184       |
| train/                   |              |
|    approx_kl             | 0.0038747357 |
|    clip_fraction         | 0.0547       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.84         |
|    cost_value_loss       | 93.2         |
|    cost_values           | 1.94         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.933        |
|    lagrangian_multiplier | 0.0133       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.7          |
|    n_updates             | 4820         |
|    policy_gradient_loss  | -0.00349     |
|    std                   | 0.731        |
|    value_loss            | 0.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.159       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.159       |
| reward                   | -0.44883364 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 31          |
|    time_elapsed          | 16347       |
|    total_timesteps       | 966656      |
| train/                   |             |
|    approx_kl             | 0.007039074 |
|    clip_fraction         | 0.0573      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.81        |
|    cost_value_loss       | 50.3        |
|    cost_values           | 0.652       |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00628     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 4710        |
|    policy_gradient_loss  | -0.00498    |
|    std                   | 0.752       |
|    value_loss            | 0.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0348      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0348      |
| reward                   | -0.48709407 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -375        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 21          |
|    time_elapsed          | 10960       |
|    total_timesteps       | 946176      |
| train/                   |             |
|    approx_kl             | 0.003293996 |
|    clip_fraction         | 0.0236      |
|    clip_range            | 0.2         |
|    cost_returns          | 16.9        |
|    cost_value_loss       | 226         |
|    cost_values           | 2.81        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0.0224      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 4610        |
|    policy_gradient_loss  | -0.00379    |
|    std                   | 0.724       |
|    value_loss            | 1.06        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.6        |
| reward                   | -0.4130754 |
| rollout/                 |            |
|    ep_len_mean           | 429        |
|    ep_rew_mean           | -166       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 10         |
|    time_elapsed          | 6527       |
|    total_timesteps       | 923648     |
| train/                   |            |
|    approx_kl             | 0.0118485  |
|    clip_fraction         | 0.105      |
|    clip_range            | 0.2        |
|    cost_returns          | 6.55       |
|    cost_value_loss       | 16.9       |
|    cost_values           | 2.95       |
|    entropy               | -1.41      |
|    entropy_loss          | -1.41      |
|    explained_variance    | 0.265      |
|    lagrangian_multiplier | 0.00582    |
|    learning_rate         | 0.0003     |
|    loss                  | 6.59       |
|    n_updates             | 4500       |
|    policy_gradient_loss  | -0.00599   |
|    std                   | 0.504      |
|    value_loss            | 20.7       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.0873      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0873      |
| reward                   | -0.33868974 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -424        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 21          |
|    time_elapsed          | 11688       |
|    total_timesteps       | 946176      |
| train/                   |             |
|    approx_kl             | 0.005047236 |
|    clip_fraction         | 0.00688     |
|    clip_range            | 0.2         |
|    cost_returns          | 17.4        |
|    cost_value_loss       | 248         |
|    cost_values           | 1.89        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.785       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 121         |
|    n_updates             | 4610        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.773       |
|    value_loss            | 1.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0361      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0361      |
| reward                   | -0.48536965 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 28          |
|    time_elapsed          | 14700       |
|    total_timesteps       | 960512      |
| train/                   |             |
|    approx_kl             | 0.010579309 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.33        |
|    cost_value_loss       | 50          |
|    cost_values           | 1.35        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00342     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 4680        |
|    policy_gradient_loss  | 0.00774     |
|    std                   | 0.886       |
|    value_loss            | 0.447       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.144        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.144        |
| reward                   | -0.55391353  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 43           |
|    time_elapsed          | 22728        |
|    total_timesteps       | 991232       |
| train/                   |              |
|    approx_kl             | 0.0056272307 |
|    clip_fraction         | 0.0589       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.1          |
|    cost_value_loss       | 54.4         |
|    cost_values           | 2            |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.801        |
|    lagrangian_multiplier | 0.00281      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 4830         |
|    policy_gradient_loss  | -0.00499     |
|    std                   | 0.731        |
|    value_loss            | 0.539        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0209      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0209      |
| reward                   | -0.41412023 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 32          |
|    time_elapsed          | 16896       |
|    total_timesteps       | 968704      |
| train/                   |             |
|    approx_kl             | 0.0039523   |
|    clip_fraction         | 0.0324      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.36        |
|    cost_value_loss       | 70.1        |
|    cost_values           | 0.73        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0.00786     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.89        |
|    n_updates             | 4720        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.755       |
|    value_loss            | 0.144       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.127        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.127        |
| reward                   | -0.3229157   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 22           |
|    time_elapsed          | 11500        |
|    total_timesteps       | 948224       |
| train/                   |              |
|    approx_kl             | 0.0011913687 |
|    clip_fraction         | 0.00371      |
|    clip_range            | 0.2          |
|    cost_returns          | 18.2         |
|    cost_value_loss       | 242          |
|    cost_values           | 2.83         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.726        |
|    lagrangian_multiplier | 0.0209       |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 4620         |
|    policy_gradient_loss  | 0.000307     |
|    std                   | 0.725        |
|    value_loss            | 0.582        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.116       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.116       |
| reward                   | -0.25584748 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 22          |
|    time_elapsed          | 12249       |
|    total_timesteps       | 948224      |
| train/                   |             |
|    approx_kl             | 0.006126671 |
|    clip_fraction         | 0.0348      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.48        |
|    cost_value_loss       | 123         |
|    cost_values           | 1.7         |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.828       |
|    lagrangian_multiplier | 0.0129      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.7         |
|    n_updates             | 4620        |
|    policy_gradient_loss  | -0.0039     |
|    std                   | 0.772       |
|    value_loss            | 0.507       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.156       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.156       |
| reward                   | -0.4564144  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 29          |
|    time_elapsed          | 15235       |
|    total_timesteps       | 962560      |
| train/                   |             |
|    approx_kl             | 0.004391184 |
|    clip_fraction         | 0.0222      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.89        |
|    cost_value_loss       | 84.6        |
|    cost_values           | 1.61        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0.0118      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.12        |
|    n_updates             | 4690        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.888       |
|    value_loss            | 0.605       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.56        |
| reward                   | -0.46567106 |
| rollout/                 |             |
|    ep_len_mean           | 418         |
|    ep_rew_mean           | -161        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 11          |
|    time_elapsed          | 7201        |
|    total_timesteps       | 925696      |
| train/                   |             |
|    approx_kl             | 0.029765692 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.61        |
|    cost_value_loss       | 17          |
|    cost_values           | 2.91        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0.258       |
|    lagrangian_multiplier | 0.0058      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.52        |
|    n_updates             | 4510        |
|    policy_gradient_loss  | 0.000356    |
|    std                   | 0.504       |
|    value_loss            | 21.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0325      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0325      |
| reward                   | -0.45408878 |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -395        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 44          |
|    time_elapsed          | 23286       |
|    total_timesteps       | 993280      |
| train/                   |             |
|    approx_kl             | 0.003274703 |
|    clip_fraction         | 0.00352     |
|    clip_range            | 0.2         |
|    cost_returns          | 9.77        |
|    cost_value_loss       | 121         |
|    cost_values           | 2.23        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0.0188      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.84        |
|    n_updates             | 4840        |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.73        |
|    value_loss            | 1.97        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0759       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0759       |
| reward                   | -0.47183046  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 33           |
|    time_elapsed          | 17445        |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0034343451 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.443        |
|    cost_value_loss       | 0.693        |
|    cost_values           | 0.427        |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.238        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.851        |
|    n_updates             | 4730         |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 0.755        |
|    value_loss            | 1.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.341       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.341       |
| reward                   | -0.40474817 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -374        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 23          |
|    time_elapsed          | 12039       |
|    total_timesteps       | 950272      |
| train/                   |             |
|    approx_kl             | 0.002962042 |
|    clip_fraction         | 0.0267      |
|    clip_range            | 0.2         |
|    cost_returns          | 18.4        |
|    cost_value_loss       | 245         |
|    cost_values           | 3           |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0.00897     |
|    learning_rate         | 0.0003      |
|    loss                  | 24          |
|    n_updates             | 4630        |
|    policy_gradient_loss  | -0.0041     |
|    std                   | 0.726       |
|    value_loss            | 0.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.244       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.244       |
| reward                   | -0.39627084 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 23          |
|    time_elapsed          | 12813       |
|    total_timesteps       | 950272      |
| train/                   |             |
|    approx_kl             | 0.003538779 |
|    clip_fraction         | 0.00513     |
|    clip_range            | 0.2         |
|    cost_returns          | 7.37        |
|    cost_value_loss       | 93.9        |
|    cost_values           | 1.59        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.0299      |
|    lagrangian_multiplier | 0.0147      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.64        |
|    n_updates             | 4630        |
|    policy_gradient_loss  | -0.00125    |
|    std                   | 0.771       |
|    value_loss            | 0.974       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0476       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0476       |
| reward                   | -0.54603153  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 30           |
|    time_elapsed          | 15769        |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0045516547 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.32         |
|    cost_value_loss       | 9.77         |
|    cost_values           | 1.08         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0.00371      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.97         |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.889        |
|    value_loss            | 2.88         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00174      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00174      |
| reward                   | -0.3616839   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 45           |
|    time_elapsed          | 23847        |
|    total_timesteps       | 995328       |
| train/                   |              |
|    approx_kl             | 0.0071403915 |
|    clip_fraction         | 0.0487       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.7         |
|    cost_value_loss       | 125          |
|    cost_values           | 2.07         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0.0159       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.66         |
|    n_updates             | 4850         |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 0.731        |
|    value_loss            | 0.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.217        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.217        |
| reward                   | -0.53739303  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 34           |
|    time_elapsed          | 17996        |
|    total_timesteps       | 972800       |
| train/                   |              |
|    approx_kl             | 0.0048449505 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.8         |
|    cost_value_loss       | 142          |
|    cost_values           | 1.39         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.919        |
|    lagrangian_multiplier | 0.0151       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.43         |
|    n_updates             | 4740         |
|    policy_gradient_loss  | -0.00025     |
|    std                   | 0.755        |
|    value_loss            | 0.469        |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.7        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.7        |
| reward                   | -0.3585121 |
| rollout/                 |            |
|    ep_len_mean           | 410        |
|    ep_rew_mean           | -157       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 12         |
|    time_elapsed          | 7877       |
|    total_timesteps       | 927744     |
| train/                   |            |
|    approx_kl             | 0.00951505 |
|    clip_fraction         | 0.144      |
|    clip_range            | 0.2        |
|    cost_returns          | 6.62       |
|    cost_value_loss       | 18         |
|    cost_values           | 2.96       |
|    entropy               | -1.4       |
|    entropy_loss          | -1.4       |
|    explained_variance    | 0.152      |
|    lagrangian_multiplier | 0.0064     |
|    learning_rate         | 0.0003     |
|    loss                  | 6.89       |
|    n_updates             | 4520       |
|    policy_gradient_loss  | -0.000737  |
|    std                   | 0.503      |
|    value_loss            | 24.3       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.373        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.373        |
| reward                   | -0.35314196  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 24           |
|    time_elapsed          | 12580        |
|    total_timesteps       | 952320       |
| train/                   |              |
|    approx_kl             | 0.0073724627 |
|    clip_fraction         | 0.0785       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.4         |
|    cost_value_loss       | 221          |
|    cost_values           | 3            |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0.0351       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.59         |
|    n_updates             | 4640         |
|    policy_gradient_loss  | -0.0056      |
|    std                   | 0.724        |
|    value_loss            | 0.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.148        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.148        |
| reward                   | -0.39597493  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 31           |
|    time_elapsed          | 16302        |
|    total_timesteps       | 966656       |
| train/                   |              |
|    approx_kl             | 0.0038715017 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.73         |
|    cost_value_loss       | 105          |
|    cost_values           | 0.973        |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0.00707      |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 4710         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.888        |
|    value_loss            | 0.583        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0224      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0224      |
| reward                   | -0.37023404 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -420        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 24          |
|    time_elapsed          | 13382       |
|    total_timesteps       | 952320      |
| train/                   |             |
|    approx_kl             | 0.005031836 |
|    clip_fraction         | 0.0222      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 42.8        |
|    cost_values           | 1.57        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | -0.534      |
|    lagrangian_multiplier | 0.00491     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.31        |
|    n_updates             | 4640        |
|    policy_gradient_loss  | -0.00356    |
|    std                   | 0.77        |
|    value_loss            | 2.67        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00703      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00703      |
| reward                   | -0.42477807  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 35           |
|    time_elapsed          | 18537        |
|    total_timesteps       | 974848       |
| train/                   |              |
|    approx_kl             | 0.0012070577 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.78         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 0.635        |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.816        |
|    lagrangian_multiplier | 0.000324     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.56         |
|    n_updates             | 4750         |
|    policy_gradient_loss  | -0.000594    |
|    std                   | 0.754        |
|    value_loss            | 0.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00942      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00942      |
| reward                   | -0.44371232  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 46           |
|    time_elapsed          | 24413        |
|    total_timesteps       | 997376       |
| train/                   |              |
|    approx_kl             | 0.0054555386 |
|    clip_fraction         | 0.0285       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.5         |
|    cost_value_loss       | 174          |
|    cost_values           | 2.07         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0.0124       |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 4860         |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 0.731        |
|    value_loss            | 0.824        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.225        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.225        |
| reward                   | -0.512744    |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -375         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 25           |
|    time_elapsed          | 13123        |
|    total_timesteps       | 954368       |
| train/                   |              |
|    approx_kl             | 0.0033886172 |
|    clip_fraction         | 0.0568       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.5         |
|    cost_value_loss       | 247          |
|    cost_values           | 3            |
|    entropy               | -2.18        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.49         |
|    lagrangian_multiplier | 0.0359       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.24         |
|    n_updates             | 4650         |
|    policy_gradient_loss  | -0.00581     |
|    std                   | 0.722        |
|    value_loss            | 0.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.16        |
| reward                   | -0.4074882  |
| rollout/                 |             |
|    ep_len_mean           | 411         |
|    ep_rew_mean           | -157        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 13          |
|    time_elapsed          | 8560        |
|    total_timesteps       | 929792      |
| train/                   |             |
|    approx_kl             | 0.012637379 |
|    clip_fraction         | 0.0929      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.55        |
|    cost_value_loss       | 16.4        |
|    cost_values           | 2.96        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.209       |
|    lagrangian_multiplier | 0.00569     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.15        |
|    n_updates             | 4530        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.505       |
|    value_loss            | 15.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.195        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.195        |
| reward                   | -0.39473805  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 32           |
|    time_elapsed          | 16838        |
|    total_timesteps       | 968704       |
| train/                   |              |
|    approx_kl             | 0.0045892745 |
|    clip_fraction         | 0.0406       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.15         |
|    cost_value_loss       | 65.4         |
|    cost_values           | 1.21         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 0.00709      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.04         |
|    n_updates             | 4720         |
|    policy_gradient_loss  | -0.00574     |
|    std                   | 0.889        |
|    value_loss            | 6.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.047        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.047        |
| reward                   | -0.54373276  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 25           |
|    time_elapsed          | 13949        |
|    total_timesteps       | 954368       |
| train/                   |              |
|    approx_kl             | 0.0043813465 |
|    clip_fraction         | 0.06         |
|    clip_range            | 0.2          |
|    cost_returns          | 6.68         |
|    cost_value_loss       | 77.8         |
|    cost_values           | 1.58         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.574        |
|    lagrangian_multiplier | 0.009        |
|    learning_rate         | 0.0003       |
|    loss                  | 8.4          |
|    n_updates             | 4650         |
|    policy_gradient_loss  | -0.00368     |
|    std                   | 0.77         |
|    value_loss            | 0.208        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.25         |
| reward                   | -0.31852725  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 36           |
|    time_elapsed          | 19079        |
|    total_timesteps       | 976896       |
| train/                   |              |
|    approx_kl             | 0.0048416713 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.1          |
|    cost_value_loss       | 68.8         |
|    cost_values           | 1.5          |
|    entropy               | -2.27        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.691        |
|    lagrangian_multiplier | 0.011        |
|    learning_rate         | 0.0003       |
|    loss                  | 6.54         |
|    n_updates             | 4760         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.755        |
|    value_loss            | 2.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.031        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.031        |
| reward                   | -0.4039354   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 47           |
|    time_elapsed          | 24970        |
|    total_timesteps       | 999424       |
| train/                   |              |
|    approx_kl             | 0.0043615643 |
|    clip_fraction         | 0.0234       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.65         |
|    cost_value_loss       | 122          |
|    cost_values           | 2.04         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0.0204       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.79         |
|    n_updates             | 4870         |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.732        |
|    value_loss            | 0.453        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0209      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0209      |
| reward                   | -0.5147573  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -377        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 26          |
|    time_elapsed          | 13661       |
|    total_timesteps       | 956416      |
| train/                   |             |
|    approx_kl             | 0.008418848 |
|    clip_fraction         | 0.0739      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 148         |
|    cost_values           | 2.53        |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.0934      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.98        |
|    n_updates             | 4660        |
|    policy_gradient_loss  | 1.9e-05     |
|    std                   | 0.721       |
|    value_loss            | 4.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.49        |
| reward                   | -0.46927902 |
| rollout/                 |             |
|    ep_len_mean           | 393         |
|    ep_rew_mean           | -149        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 14          |
|    time_elapsed          | 9240        |
|    total_timesteps       | 931840      |
| train/                   |             |
|    approx_kl             | 0.012454703 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.94        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.58        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0.191       |
|    lagrangian_multiplier | 0.00685     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.44        |
|    n_updates             | 4540        |
|    policy_gradient_loss  | -0.00457    |
|    std                   | 0.505       |
|    value_loss            | 17.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00109      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00109      |
| reward                   | -0.2497787   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 33           |
|    time_elapsed          | 17376        |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0043084566 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.33         |
|    cost_value_loss       | 103          |
|    cost_values           | 1.39         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | -0.364       |
|    lagrangian_multiplier | 0.00445      |
|    learning_rate         | 0.0003       |
|    loss                  | 16.1         |
|    n_updates             | 4730         |
|    policy_gradient_loss  | -0.00207     |
|    std                   | 0.89         |
|    value_loss            | 0.743        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.443       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.443       |
| reward                   | -0.2551473  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 26          |
|    time_elapsed          | 14510       |
|    total_timesteps       | 956416      |
| train/                   |             |
|    approx_kl             | 0.003547316 |
|    clip_fraction         | 0.0516      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.25        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 1.64        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.0771      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.91        |
|    n_updates             | 4660        |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 0.773       |
|    value_loss            | 3.29        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0973       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0973       |
| reward                   | -0.5139486   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 37           |
|    time_elapsed          | 19629        |
|    total_timesteps       | 978944       |
| train/                   |              |
|    approx_kl             | 0.0035139138 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.993        |
|    cost_value_loss       | 2.19         |
|    cost_values           | 0.882        |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.786        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.967        |
|    n_updates             | 4770         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.752        |
|    value_loss            | 0.436        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0756       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0756       |
| reward                   | -0.24993412  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 48           |
|    time_elapsed          | 25526        |
|    total_timesteps       | 1001472      |
| train/                   |              |
|    approx_kl             | 0.0025070333 |
|    clip_fraction         | 0.0213       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.2         |
|    cost_value_loss       | 160          |
|    cost_values           | 2.18         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.948        |
|    lagrangian_multiplier | 0.0176       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 4880         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.733        |
|    value_loss            | 0.614        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.431        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.431        |
| reward                   | -0.4315485   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -379         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 27           |
|    time_elapsed          | 14203        |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0075640185 |
|    clip_fraction         | 0.0384       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.3         |
|    cost_value_loss       | 257          |
|    cost_values           | 2.35         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.704        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 125          |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 0.721        |
|    value_loss            | 0.509        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.142        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.142        |
| reward                   | -0.2957309   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 34           |
|    time_elapsed          | 17914        |
|    total_timesteps       | 972800       |
| train/                   |              |
|    approx_kl             | 0.0030546202 |
|    clip_fraction         | 0.0659       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.46         |
|    cost_value_loss       | 95.6         |
|    cost_values           | 1.44         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0.0126       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.75         |
|    n_updates             | 4740         |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 0.889        |
|    value_loss            | 0.707        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.84        |
| reward                   | -0.5360736  |
| rollout/                 |             |
|    ep_len_mean           | 359         |
|    ep_rew_mean           | -136        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 15          |
|    time_elapsed          | 9924        |
|    total_timesteps       | 933888      |
| train/                   |             |
|    approx_kl             | 0.011171402 |
|    clip_fraction         | 0.0777      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.56        |
|    cost_value_loss       | 21.8        |
|    cost_values           | 2.33        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.306       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.2        |
|    n_updates             | 4550        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.504       |
|    value_loss            | 16.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.282        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.282        |
| reward                   | -0.40070114  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 27           |
|    time_elapsed          | 15069        |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0038531926 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.65         |
|    cost_value_loss       | 1.93         |
|    cost_values           | 1.67         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.0926       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.21         |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.000563    |
|    std                   | 0.773        |
|    value_loss            | 2.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0856       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0856       |
| reward                   | -0.43227     |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 38           |
|    time_elapsed          | 20183        |
|    total_timesteps       | 980992       |
| train/                   |              |
|    approx_kl             | 0.0010598074 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.19         |
|    cost_value_loss       | 43.8         |
|    cost_values           | 1.41         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.621        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24           |
|    n_updates             | 4780         |
|    policy_gradient_loss  | -5.71e-05    |
|    std                   | 0.751        |
|    value_loss            | 1.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0818       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0818       |
| reward                   | -0.51565987  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 49           |
|    time_elapsed          | 26084        |
|    total_timesteps       | 1003520      |
| train/                   |              |
|    approx_kl             | 0.0025686661 |
|    clip_fraction         | 0.00483      |
|    clip_range            | 0.2          |
|    cost_returns          | 10           |
|    cost_value_loss       | 114          |
|    cost_values           | 2.21         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0.00759      |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 4890         |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 0.734        |
|    value_loss            | 0.507        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0552      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0552      |
| reward                   | -0.5670751  |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 28          |
|    time_elapsed          | 14749       |
|    total_timesteps       | 960512      |
| train/                   |             |
|    approx_kl             | 0.002411152 |
|    clip_fraction         | 0.00132     |
|    clip_range            | 0.2         |
|    cost_returns          | 18.1        |
|    cost_value_loss       | 244         |
|    cost_values           | 2.67        |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.0209      |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 4680        |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.721       |
|    value_loss            | 0.969       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.022       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.022       |
| reward                   | -0.37924978 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 35          |
|    time_elapsed          | 18444       |
|    total_timesteps       | 974848      |
| train/                   |             |
|    approx_kl             | 0.003214846 |
|    clip_fraction         | 0.0234      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.5        |
|    cost_value_loss       | 154         |
|    cost_values           | 1.71        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.00221     |
|    learning_rate         | 0.0003      |
|    loss                  | 34.5        |
|    n_updates             | 4750        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.889       |
|    value_loss            | 0.983       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.396975    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 28           |
|    time_elapsed          | 15635        |
|    total_timesteps       | 960512       |
| train/                   |              |
|    approx_kl             | 0.0024417855 |
|    clip_fraction         | 0.0175       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.13         |
|    cost_value_loss       | 82.4         |
|    cost_values           | 1.97         |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | -0.11        |
|    lagrangian_multiplier | 0.00836      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.74         |
|    n_updates             | 4680         |
|    policy_gradient_loss  | -0.000786    |
|    std                   | 0.773        |
|    value_loss            | 1.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.074        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.074        |
| reward                   | -0.38270274  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 39           |
|    time_elapsed          | 20730        |
|    total_timesteps       | 983040       |
| train/                   |              |
|    approx_kl             | 0.0045079063 |
|    clip_fraction         | 0.0372       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 0.0481       |
|    cost_values           | 1.34         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.25        |
|    explained_variance    | -2.93        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0567       |
|    n_updates             | 4790         |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 0.747        |
|    value_loss            | 0.782        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.139        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.139        |
| reward                   | -0.45728284  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 29           |
|    time_elapsed          | 15299        |
|    total_timesteps       | 962560       |
| train/                   |              |
|    approx_kl             | 0.0011886121 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.96         |
|    cost_value_loss       | 121          |
|    cost_values           | 2.33         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0.182        |
|    learning_rate         | 0.0003       |
|    loss                  | 3.04         |
|    n_updates             | 4690         |
|    policy_gradient_loss  | -0.000709    |
|    std                   | 0.72         |
|    value_loss            | 6.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3644258   |
| rollout/                 |              |
|    ep_len_mean           | 334          |
|    ep_rew_mean           | -127         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 16           |
|    time_elapsed          | 10614        |
|    total_timesteps       | 935936       |
| train/                   |              |
|    approx_kl             | 0.0064664455 |
|    clip_fraction         | 0.0554       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.33         |
|    cost_value_loss       | 16.7         |
|    cost_values           | 2.21         |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0.316        |
|    lagrangian_multiplier | 0.000754     |
|    learning_rate         | 0.0003       |
|    loss                  | 16           |
|    n_updates             | 4560         |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 0.503        |
|    value_loss            | 32.9         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.106      |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.106      |
| reward             | -0.3817719 |
| rollout/           |            |
|    ep_len_mean     | 962        |
|    ep_rew_mean     | -397       |
| time/              |            |
|    fps             | 3          |
|    iterations      | 1          |
|    time_elapsed    | 562        |
|    total_timesteps | 1005568    |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.255        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.255        |
| reward                   | -0.47357884  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 36           |
|    time_elapsed          | 18978        |
|    total_timesteps       | 976896       |
| train/                   |              |
|    approx_kl             | 0.0043265694 |
|    clip_fraction         | 0.0578       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.17         |
|    cost_value_loss       | 24.2         |
|    cost_values           | 1.3          |
|    entropy               | -2.59        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.412        |
|    lagrangian_multiplier | 0.0022       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.14         |
|    n_updates             | 4760         |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 0.887        |
|    value_loss            | 0.867        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0901      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0901      |
| reward                   | -0.21744469 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -416        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 29          |
|    time_elapsed          | 16196       |
|    total_timesteps       | 962560      |
| train/                   |             |
|    approx_kl             | 0.007633851 |
|    clip_fraction         | 0.0494      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 23.8        |
|    cost_values           | 1.87        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0.00474     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.88        |
|    n_updates             | 4690        |
|    policy_gradient_loss  | -0.00442    |
|    std                   | 0.772       |
|    value_loss            | 0.149       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00544      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00544      |
| reward                   | -0.33242995  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 40           |
|    time_elapsed          | 21278        |
|    total_timesteps       | 985088       |
| train/                   |              |
|    approx_kl             | 0.0006481695 |
|    clip_fraction         | 0.0621       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 0.0172       |
|    cost_values           | 1.07         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.79         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0884       |
|    n_updates             | 4800         |
|    policy_gradient_loss  | 0.00132      |
|    std                   | 0.746        |
|    value_loss            | 0.572        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.93116885  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 30           |
|    time_elapsed          | 15843        |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0032096053 |
|    clip_fraction         | 0.00918      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.5         |
|    cost_value_loss       | 142          |
|    cost_values           | 1.69         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0.00552      |
|    learning_rate         | 0.0003       |
|    loss                  | 20.3         |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 0.72         |
|    value_loss            | 4.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.121        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.121        |
| reward                   | -0.32504654  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 2            |
|    time_elapsed          | 1133         |
|    total_timesteps       | 1007616      |
| train/                   |              |
|    approx_kl             | 0.0039863777 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.4         |
|    cost_value_loss       | 215          |
|    cost_values           | 1.78         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.953        |
|    lagrangian_multiplier | 0.0161       |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 4910         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.736        |
|    value_loss            | 0.519        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3459079  |
| rollout/                 |             |
|    ep_len_mean           | 346         |
|    ep_rew_mean           | -131        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 17          |
|    time_elapsed          | 11305       |
|    total_timesteps       | 937984      |
| train/                   |             |
|    approx_kl             | 0.006112937 |
|    clip_fraction         | 0.0478      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.97        |
|    cost_value_loss       | 20.7        |
|    cost_values           | 2.09        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0.393       |
|    lagrangian_multiplier | 0.00269     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.3         |
|    n_updates             | 4570        |
|    policy_gradient_loss  | -0.00484    |
|    std                   | 0.501       |
|    value_loss            | 20          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.317        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.317        |
| reward                   | -0.43760222  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 37           |
|    time_elapsed          | 19519        |
|    total_timesteps       | 978944       |
| train/                   |              |
|    approx_kl             | 0.0039190724 |
|    clip_fraction         | 0.145        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 0.0532       |
|    cost_values           | 1.31         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.845        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.071        |
|    n_updates             | 4770         |
|    policy_gradient_loss  | 0.00665      |
|    std                   | 0.886        |
|    value_loss            | 0.934        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0713       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0713       |
| reward                   | -0.4105417   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 30           |
|    time_elapsed          | 16761        |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0016064004 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.97         |
|    cost_value_loss       | 9            |
|    cost_values           | 2.16         |
|    entropy               | -2.31        |
|    entropy_loss          | -2.31        |
|    explained_variance    | 0.1          |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.85         |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.000716    |
|    std                   | 0.768        |
|    value_loss            | 1.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0684       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0684       |
| reward                   | -0.40296072  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 41           |
|    time_elapsed          | 21833        |
|    total_timesteps       | 987136       |
| train/                   |              |
|    approx_kl             | 0.0015438548 |
|    clip_fraction         | 0.0152       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.85         |
|    cost_value_loss       | 106          |
|    cost_values           | 1.46         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.651        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54.3         |
|    n_updates             | 4810         |
|    policy_gradient_loss  | 0.0004       |
|    std                   | 0.747        |
|    value_loss            | 1.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.56490326 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 31          |
|    time_elapsed          | 16376       |
|    total_timesteps       | 966656      |
| train/                   |             |
|    approx_kl             | 0.009267681 |
|    clip_fraction         | 0.0636      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.08        |
|    cost_value_loss       | 107         |
|    cost_values           | 1.4         |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.0118      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.25        |
|    n_updates             | 4710        |
|    policy_gradient_loss  | -0.00636    |
|    std                   | 0.72        |
|    value_loss            | 4.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.357       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.357       |
| reward                   | -0.59889215 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -395        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 3           |
|    time_elapsed          | 1697        |
|    total_timesteps       | 1009664     |
| train/                   |             |
|    approx_kl             | 0.004881365 |
|    clip_fraction         | 0.0183      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.3        |
|    cost_value_loss       | 165         |
|    cost_values           | 1.87        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0.0161      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 4920        |
|    policy_gradient_loss  | -0.000772   |
|    std                   | 0.738       |
|    value_loss            | 0.429       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0424       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0424       |
| reward                   | -0.52169997  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 38           |
|    time_elapsed          | 20062        |
|    total_timesteps       | 980992       |
| train/                   |              |
|    approx_kl             | 0.0048671467 |
|    clip_fraction         | 0.206        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.67         |
|    cost_value_loss       | 94.2         |
|    cost_values           | 1.33         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.817        |
|    lagrangian_multiplier | 0.0049       |
|    learning_rate         | 0.0003       |
|    loss                  | 15.9         |
|    n_updates             | 4780         |
|    policy_gradient_loss  | 0.00243      |
|    std                   | 0.885        |
|    value_loss            | 4.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.30372983 |
| rollout/                 |             |
|    ep_len_mean           | 353         |
|    ep_rew_mean           | -134        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 18          |
|    time_elapsed          | 12000       |
|    total_timesteps       | 940032      |
| train/                   |             |
|    approx_kl             | 0.010149394 |
|    clip_fraction         | 0.0935      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.13        |
|    cost_value_loss       | 17.9        |
|    cost_values           | 2.31        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0.521       |
|    lagrangian_multiplier | 0.00492     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.54        |
|    n_updates             | 4580        |
|    policy_gradient_loss  | -0.00496    |
|    std                   | 0.501       |
|    value_loss            | 8.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0315       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0315       |
| reward                   | -0.29192123  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 31           |
|    time_elapsed          | 17329        |
|    total_timesteps       | 966656       |
| train/                   |              |
|    approx_kl             | 0.0075760474 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.85         |
|    cost_value_loss       | 15.7         |
|    cost_values           | 1.76         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | 0.524        |
|    lagrangian_multiplier | 0.00179      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.72         |
|    n_updates             | 4710         |
|    policy_gradient_loss  | -0.000427    |
|    std                   | 0.766        |
|    value_loss            | 1.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.339       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.339       |
| reward                   | -0.4666699  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 42          |
|    time_elapsed          | 22389       |
|    total_timesteps       | 989184      |
| train/                   |             |
|    approx_kl             | 0.006084419 |
|    clip_fraction         | 0.0371      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.86        |
|    cost_value_loss       | 5.86        |
|    cost_values           | 1.41        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.658       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.37        |
|    n_updates             | 4820        |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.748       |
|    value_loss            | 1.34        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.90788823  |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 32           |
|    time_elapsed          | 16927        |
|    total_timesteps       | 968704       |
| train/                   |              |
|    approx_kl             | 0.0029441528 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 13           |
|    cost_value_loss       | 185          |
|    cost_values           | 1.67         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0.0211       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.53         |
|    n_updates             | 4720         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.721        |
|    value_loss            | 1.72         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.0461     |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.0461     |
| reward                   | -0.5799302 |
| rollout/                 |            |
|    ep_len_mean           | 956        |
|    ep_rew_mean           | -389       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 4          |
|    time_elapsed          | 2257       |
|    total_timesteps       | 1011712    |
| train/                   |            |
|    approx_kl             | 0.00421165 |
|    clip_fraction         | 0.0504     |
|    clip_range            | 0.2        |
|    cost_returns          | 6.23       |
|    cost_value_loss       | 73.1       |
|    cost_values           | 1.43       |
|    entropy               | -2.22      |
|    entropy_loss          | -2.22      |
|    explained_variance    | 0.975      |
|    lagrangian_multiplier | 0.00863    |
|    learning_rate         | 0.0003     |
|    loss                  | 8.95       |
|    n_updates             | 4930       |
|    policy_gradient_loss  | 0.00135    |
|    std                   | 0.739      |
|    value_loss            | 0.64       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.162       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.162       |
| reward                   | -0.5114828  |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 39          |
|    time_elapsed          | 20606       |
|    total_timesteps       | 983040      |
| train/                   |             |
|    approx_kl             | 0.005949108 |
|    clip_fraction         | 0.0252      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.55        |
|    cost_value_loss       | 120         |
|    cost_values           | 1.17        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.631       |
|    lagrangian_multiplier | 0.00981     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 4790        |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.887       |
|    value_loss            | 0.931       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.4214443  |
| rollout/                 |             |
|    ep_len_mean           | 348         |
|    ep_rew_mean           | -131        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 19          |
|    time_elapsed          | 12694       |
|    total_timesteps       | 942080      |
| train/                   |             |
|    approx_kl             | 0.015649874 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 15.5        |
|    cost_values           | 2.17        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0.753       |
|    lagrangian_multiplier | 0.000764    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.23        |
|    n_updates             | 4590        |
|    policy_gradient_loss  | -0.00723    |
|    std                   | 0.501       |
|    value_loss            | 7.04        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.162      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.162      |
| reward                   | -0.5354229 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -416       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 32         |
|    time_elapsed          | 17909      |
|    total_timesteps       | 968704     |
| train/                   |            |
|    approx_kl             | 0.01736118 |
|    clip_fraction         | 0.0896     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.05       |
|    cost_value_loss       | 2.55       |
|    cost_values           | 1.75       |
|    entropy               | -2.3       |
|    entropy_loss          | -2.3       |
|    explained_variance    | 0.822      |
|    lagrangian_multiplier | 0.000778   |
|    learning_rate         | 0.0003     |
|    loss                  | 1.67       |
|    n_updates             | 4720       |
|    policy_gradient_loss  | -0.000607  |
|    std                   | 0.765      |
|    value_loss            | 0.722      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.4051246   |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 33           |
|    time_elapsed          | 17473        |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0053593386 |
|    clip_fraction         | 0.0509       |
|    clip_range            | 0.2          |
|    cost_returns          | 13           |
|    cost_value_loss       | 181          |
|    cost_values           | 1.76         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0.0211       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.46         |
|    n_updates             | 4730         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.722        |
|    value_loss            | 3.27         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.167       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.167       |
| reward                   | -0.5176066  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 43          |
|    time_elapsed          | 22952       |
|    total_timesteps       | 991232      |
| train/                   |             |
|    approx_kl             | 0.003014615 |
|    clip_fraction         | 0.00376     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.63        |
|    cost_value_loss       | 38.6        |
|    cost_values           | 1.77        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.723       |
|    lagrangian_multiplier | 3.02e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 19.3        |
|    n_updates             | 4830        |
|    policy_gradient_loss  | -0.000784   |
|    std                   | 0.747       |
|    value_loss            | 0.108       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.496       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.496       |
| reward                   | -0.18498611 |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 5           |
|    time_elapsed          | 2821        |
|    total_timesteps       | 1013760     |
| train/                   |             |
|    approx_kl             | 0.004626333 |
|    clip_fraction         | 0.0442      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.28        |
|    cost_value_loss       | 99.4        |
|    cost_values           | 1.68        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00507     |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 4940        |
|    policy_gradient_loss  | -0.0022     |
|    std                   | 0.739       |
|    value_loss            | 2.88        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.173        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.173        |
| reward                   | -0.3197394   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 40           |
|    time_elapsed          | 21153        |
|    total_timesteps       | 985088       |
| train/                   |              |
|    approx_kl             | 0.0047086654 |
|    clip_fraction         | 0.0376       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.84         |
|    cost_value_loss       | 65.5         |
|    cost_values           | 0.92         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0.00974      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.35         |
|    n_updates             | 4800         |
|    policy_gradient_loss  | -0.000854    |
|    std                   | 0.891        |
|    value_loss            | 1.94         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.36906907 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 34          |
|    time_elapsed          | 18022       |
|    total_timesteps       | 972800      |
| train/                   |             |
|    approx_kl             | 0.009349046 |
|    clip_fraction         | 0.0757      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.6        |
|    cost_value_loss       | 189         |
|    cost_values           | 1.86        |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.018       |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 4740        |
|    policy_gradient_loss  | -0.00491    |
|    std                   | 0.723       |
|    value_loss            | 0.722       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00878      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00878      |
| reward                   | -0.36167306  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 33           |
|    time_elapsed          | 18482        |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0032807426 |
|    clip_fraction         | 0.116        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 4.87         |
|    cost_values           | 1.57         |
|    entropy               | -2.3         |
|    entropy_loss          | -2.3         |
|    explained_variance    | -1.53        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.64         |
|    n_updates             | 4730         |
|    policy_gradient_loss  | 0.0045       |
|    std                   | 0.766        |
|    value_loss            | 2.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.164        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.164        |
| reward                   | -0.27759147  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 44           |
|    time_elapsed          | 23508        |
|    total_timesteps       | 993280       |
| train/                   |              |
|    approx_kl             | 0.0030845876 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.16         |
|    cost_value_loss       | 20.4         |
|    cost_values           | 2.14         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0.00209      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.89         |
|    n_updates             | 4840         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.747        |
|    value_loss            | 0.622        |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.97        |
| reward                   | -0.2500614  |
| rollout/                 |             |
|    ep_len_mean           | 340         |
|    ep_rew_mean           | -128        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 20          |
|    time_elapsed          | 13391       |
|    total_timesteps       | 944128      |
| train/                   |             |
|    approx_kl             | 0.012134009 |
|    clip_fraction         | 0.0739      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.45        |
|    cost_value_loss       | 15.7        |
|    cost_values           | 2.12        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.384       |
|    lagrangian_multiplier | 0.00715     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.53        |
|    n_updates             | 4600        |
|    policy_gradient_loss  | -0.00562    |
|    std                   | 0.499       |
|    value_loss            | 19.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0606      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0606      |
| reward                   | -0.35011986 |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 6           |
|    time_elapsed          | 3389        |
|    total_timesteps       | 1015808     |
| train/                   |             |
|    approx_kl             | 0.007870635 |
|    clip_fraction         | 0.0799      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.88        |
|    cost_value_loss       | 106         |
|    cost_values           | 1.99        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0.0173      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.33        |
|    n_updates             | 4950        |
|    policy_gradient_loss  | -0.00522    |
|    std                   | 0.738       |
|    value_loss            | 0.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0508      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0508      |
| reward                   | -0.39643466 |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -396        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 41          |
|    time_elapsed          | 21703       |
|    total_timesteps       | 987136      |
| train/                   |             |
|    approx_kl             | 0.00897446  |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 17.3        |
|    cost_value_loss       | 255         |
|    cost_values           | 1.51        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 126         |
|    n_updates             | 4810        |
|    policy_gradient_loss  | -0.00779    |
|    std                   | 0.893       |
|    value_loss            | 0.421       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0761       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0761       |
| reward                   | -0.5417353   |
| rollout/                 |              |
|    ep_len_mean           | 998          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 35           |
|    time_elapsed          | 18579        |
|    total_timesteps       | 974848       |
| train/                   |              |
|    approx_kl             | 0.0069933413 |
|    clip_fraction         | 0.082        |
|    clip_range            | 0.2          |
|    cost_returns          | 12           |
|    cost_value_loss       | 166          |
|    cost_values           | 1.71         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0.0189       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.68         |
|    n_updates             | 4750         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 0.721        |
|    value_loss            | 1.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.199        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.199        |
| reward                   | -0.2910328   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 45           |
|    time_elapsed          | 24064        |
|    total_timesteps       | 995328       |
| train/                   |              |
|    approx_kl             | 0.0017117437 |
|    clip_fraction         | 0.000391     |
|    clip_range            | 0.2          |
|    cost_returns          | 12.8         |
|    cost_value_loss       | 161          |
|    cost_values           | 2.49         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.498        |
|    lagrangian_multiplier | 0.00512      |
|    learning_rate         | 0.0003       |
|    loss                  | 22.8         |
|    n_updates             | 4850         |
|    policy_gradient_loss  | -0.000819    |
|    std                   | 0.747        |
|    value_loss            | 1.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.123       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.123       |
| reward                   | -0.52528954 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 34          |
|    time_elapsed          | 19060       |
|    total_timesteps       | 972800      |
| train/                   |             |
|    approx_kl             | 0.007631846 |
|    clip_fraction         | 0.041       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.03        |
|    cost_value_loss       | 9.32        |
|    cost_values           | 1.51        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.0869      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.13        |
|    n_updates             | 4740        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.763       |
|    value_loss            | 0.798       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0022       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0022       |
| reward                   | -0.25641778  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 7            |
|    time_elapsed          | 3957         |
|    total_timesteps       | 1017856      |
| train/                   |              |
|    approx_kl             | 0.0073100254 |
|    clip_fraction         | 0.0591       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.8         |
|    cost_value_loss       | 135          |
|    cost_values           | 2.14         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0.0177       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.14         |
|    n_updates             | 4960         |
|    policy_gradient_loss  | -0.00403     |
|    std                   | 0.737        |
|    value_loss            | 0.443        |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.32182515 |
| rollout/                 |             |
|    ep_len_mean           | 315         |
|    ep_rew_mean           | -118        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 21          |
|    time_elapsed          | 14106       |
|    total_timesteps       | 946176      |
| train/                   |             |
|    approx_kl             | 0.007394389 |
|    clip_fraction         | 0.0974      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.22        |
|    cost_value_loss       | 19.9        |
|    cost_values           | 2.25        |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | -0.0391     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.5        |
|    n_updates             | 4610        |
|    policy_gradient_loss  | -0.00427    |
|    std                   | 0.499       |
|    value_loss            | 20.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0874       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0874       |
| reward                   | -0.24217424  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 42           |
|    time_elapsed          | 22253        |
|    total_timesteps       | 989184       |
| train/                   |              |
|    approx_kl             | 0.0050860355 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.01         |
|    cost_value_loss       | 112          |
|    cost_values           | 1.13         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0.0043       |
|    learning_rate         | 0.0003       |
|    loss                  | 18.2         |
|    n_updates             | 4820         |
|    policy_gradient_loss  | -0.00234     |
|    std                   | 0.893        |
|    value_loss            | 2.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0815      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0815      |
| reward                   | -0.54585755 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 36          |
|    time_elapsed          | 19124       |
|    total_timesteps       | 976896      |
| train/                   |             |
|    approx_kl             | 0.00802158  |
|    clip_fraction         | 0.052       |
|    clip_range            | 0.2         |
|    cost_returns          | 15          |
|    cost_value_loss       | 212         |
|    cost_values           | 1.82        |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.0222      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 4760        |
|    policy_gradient_loss  | -0.00796    |
|    std                   | 0.721       |
|    value_loss            | 1.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.298        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.298        |
| reward                   | -0.43219346  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 46           |
|    time_elapsed          | 24629        |
|    total_timesteps       | 997376       |
| train/                   |              |
|    approx_kl             | 0.0023206393 |
|    clip_fraction         | 0.000977     |
|    clip_range            | 0.2          |
|    cost_returns          | 9.37         |
|    cost_value_loss       | 106          |
|    cost_values           | 2.51         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.764        |
|    lagrangian_multiplier | 0.0117       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.36         |
|    n_updates             | 4860         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.747        |
|    value_loss            | 2.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.165        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.165        |
| reward                   | -0.3605441   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 35           |
|    time_elapsed          | 19636        |
|    total_timesteps       | 974848       |
| train/                   |              |
|    approx_kl             | 0.0021074293 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.39         |
|    cost_value_loss       | 48.4         |
|    cost_values           | 2.05         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | -0.836       |
|    lagrangian_multiplier | 0.00053      |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 4750         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.762        |
|    value_loss            | 3.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.209        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.209        |
| reward                   | -0.28800493  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -383         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 8            |
|    time_elapsed          | 4534         |
|    total_timesteps       | 1019904      |
| train/                   |              |
|    approx_kl             | 0.0032617738 |
|    clip_fraction         | 0.00835      |
|    clip_range            | 0.2          |
|    cost_returns          | 16.9         |
|    cost_value_loss       | 221          |
|    cost_values           | 2.57         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.824        |
|    lagrangian_multiplier | 0.0284       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.58         |
|    n_updates             | 4970         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.737        |
|    value_loss            | 0.232        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.13         |
| reward                   | -0.4253688   |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 43           |
|    time_elapsed          | 22804        |
|    total_timesteps       | 991232       |
| train/                   |              |
|    approx_kl             | 0.0051810774 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.67         |
|    cost_value_loss       | 73.7         |
|    cost_values           | 1.05         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.898        |
|    lagrangian_multiplier | 0.00793      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.39         |
|    n_updates             | 4830         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.893        |
|    value_loss            | 0.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.33        |
| reward                   | -0.4368325  |
| rollout/                 |             |
|    ep_len_mean           | 304         |
|    ep_rew_mean           | -115        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 22          |
|    time_elapsed          | 14822       |
|    total_timesteps       | 948224      |
| train/                   |             |
|    approx_kl             | 0.014676992 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.94        |
|    cost_value_loss       | 17.9        |
|    cost_values           | 2.38        |
|    entropy               | -1.37       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.267       |
|    lagrangian_multiplier | 0.00558     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.79        |
|    n_updates             | 4620        |
|    policy_gradient_loss  | -0.0065     |
|    std                   | 0.497       |
|    value_loss            | 27.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.115       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.115       |
| reward                   | -0.45543715 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 37          |
|    time_elapsed          | 19678       |
|    total_timesteps       | 978944      |
| train/                   |             |
|    approx_kl             | 0.001036308 |
|    clip_fraction         | 0.00522     |
|    clip_range            | 0.2         |
|    cost_returns          | 17.2        |
|    cost_value_loss       | 242         |
|    cost_values           | 2.07        |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 118         |
|    n_updates             | 4770        |
|    policy_gradient_loss  | -0.000736   |
|    std                   | 0.72        |
|    value_loss            | 0.627       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0829      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0829      |
| reward                   | -0.3259154  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 47          |
|    time_elapsed          | 25193       |
|    total_timesteps       | 999424      |
| train/                   |             |
|    approx_kl             | 0.004131506 |
|    clip_fraction         | 0.0171      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.49        |
|    cost_value_loss       | 95.7        |
|    cost_values           | 2.41        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.127       |
|    lagrangian_multiplier | 0.0103      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.25        |
|    n_updates             | 4870        |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.748       |
|    value_loss            | 1.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.125        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.125        |
| reward                   | -0.46747887  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -414         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 36           |
|    time_elapsed          | 20206        |
|    total_timesteps       | 976896       |
| train/                   |              |
|    approx_kl             | 0.0035747217 |
|    clip_fraction         | 0.00762      |
|    clip_range            | 0.2          |
|    cost_returns          | 4.76         |
|    cost_value_loss       | 30.5         |
|    cost_values           | 2.41         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0.678        |
|    lagrangian_multiplier | 0.00675      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.73         |
|    n_updates             | 4760         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.762        |
|    value_loss            | 0.927        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.071        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.071        |
| reward                   | -0.54958314  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -380         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 9            |
|    time_elapsed          | 5113         |
|    total_timesteps       | 1021952      |
| train/                   |              |
|    approx_kl             | 0.0066192662 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.7         |
|    cost_value_loss       | 143          |
|    cost_values           | 2.55         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.521        |
|    lagrangian_multiplier | 0.0183       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.45         |
|    n_updates             | 4980         |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 0.735        |
|    value_loss            | 0.882        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0113      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0113      |
| reward                   | -0.5084674  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 44          |
|    time_elapsed          | 23353       |
|    total_timesteps       | 993280      |
| train/                   |             |
|    approx_kl             | 0.004272012 |
|    clip_fraction         | 0.0854      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.2         |
|    cost_value_loss       | 16.6        |
|    cost_values           | 0.834       |
|    entropy               | -2.6        |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0.00166     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.19        |
|    n_updates             | 4840        |
|    policy_gradient_loss  | 0.00255     |
|    std                   | 0.892       |
|    value_loss            | 0.595       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.57        |
| reward                   | -0.33103454 |
| rollout/                 |             |
|    ep_len_mean           | 306         |
|    ep_rew_mean           | -116        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 23          |
|    time_elapsed          | 15540       |
|    total_timesteps       | 950272      |
| train/                   |             |
|    approx_kl             | 0.013906704 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.15        |
|    cost_value_loss       | 18.3        |
|    cost_values           | 2.34        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0.206       |
|    lagrangian_multiplier | 0.00285     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.09        |
|    n_updates             | 4630        |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 0.494       |
|    value_loss            | 18.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.125       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.125       |
| reward                   | -0.2862794  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -412        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 38          |
|    time_elapsed          | 20239       |
|    total_timesteps       | 980992      |
| train/                   |             |
|    approx_kl             | 0.007340879 |
|    clip_fraction         | 0.0274      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.1        |
|    cost_value_loss       | 212         |
|    cost_values           | 1.99        |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.0193      |
|    learning_rate         | 0.0003      |
|    loss                  | 12          |
|    n_updates             | 4780        |
|    policy_gradient_loss  | -0.00208    |
|    std                   | 0.72        |
|    value_loss            | 1.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.128        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.128        |
| reward                   | -0.39160043  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 48           |
|    time_elapsed          | 25755        |
|    total_timesteps       | 1001472      |
| train/                   |              |
|    approx_kl             | 0.0047066854 |
|    clip_fraction         | 0.0208       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.43         |
|    cost_value_loss       | 79.5         |
|    cost_values           | 2.53         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.846        |
|    lagrangian_multiplier | 0.0105       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.97         |
|    n_updates             | 4880         |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.747        |
|    value_loss            | 0.799        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.368       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.368       |
| reward                   | -0.46182296 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 37          |
|    time_elapsed          | 20786       |
|    total_timesteps       | 978944      |
| train/                   |             |
|    approx_kl             | 0.005814125 |
|    clip_fraction         | 0.0317      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.41        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | -0.791      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.44        |
|    n_updates             | 4770        |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.763       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0197      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0197      |
| reward                   | -0.26201463 |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -381        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 10          |
|    time_elapsed          | 5684        |
|    total_timesteps       | 1024000     |
| train/                   |             |
|    approx_kl             | 0.005220782 |
|    clip_fraction         | 0.0295      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 109         |
|    cost_values           | 2.61        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0.0155      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.45        |
|    n_updates             | 4990        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.734       |
|    value_loss            | 0.158       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0357      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0357      |
| reward                   | -0.5046925  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -396        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 45          |
|    time_elapsed          | 23906       |
|    total_timesteps       | 995328      |
| train/                   |             |
|    approx_kl             | 0.005737952 |
|    clip_fraction         | 0.0952      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.65        |
|    cost_value_loss       | 124         |
|    cost_values           | 1.08        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 60.4        |
|    n_updates             | 4850        |
|    policy_gradient_loss  | -0.000709   |
|    std                   | 0.892       |
|    value_loss            | 1.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.23614268  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 39           |
|    time_elapsed          | 20798        |
|    total_timesteps       | 983040       |
| train/                   |              |
|    approx_kl             | 0.0027188803 |
|    clip_fraction         | 0.00283      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.9         |
|    cost_value_loss       | 199          |
|    cost_values           | 1.99         |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0.0105       |
|    learning_rate         | 0.0003       |
|    loss                  | 16.8         |
|    n_updates             | 4790         |
|    policy_gradient_loss  | -0.000706    |
|    std                   | 0.72         |
|    value_loss            | 0.606        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.395        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.395        |
| reward                   | -0.48145905  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 49           |
|    time_elapsed          | 26325        |
|    total_timesteps       | 1003520      |
| train/                   |              |
|    approx_kl             | 0.0038558333 |
|    clip_fraction         | 0.00601      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.89         |
|    cost_value_loss       | 58           |
|    cost_values           | 2.18         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.659        |
|    lagrangian_multiplier | 0.00879      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.83         |
|    n_updates             | 4890         |
|    policy_gradient_loss  | -0.000829    |
|    std                   | 0.748        |
|    value_loss            | 6.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.188        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.188        |
| reward                   | -0.3702131   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 38           |
|    time_elapsed          | 21360        |
|    total_timesteps       | 980992       |
| train/                   |              |
|    approx_kl             | 0.0021533421 |
|    clip_fraction         | 0.00889      |
|    clip_range            | 0.2          |
|    cost_returns          | 3.15         |
|    cost_value_loss       | 5.72         |
|    cost_values           | 2.61         |
|    entropy               | -2.29        |
|    entropy_loss          | -2.29        |
|    explained_variance    | 0.531        |
|    lagrangian_multiplier | 0.00053      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.11         |
|    n_updates             | 4780         |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 0.763        |
|    value_loss            | 0.614        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.33071116 |
| rollout/                 |             |
|    ep_len_mean           | 307         |
|    ep_rew_mean           | -115        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 24          |
|    time_elapsed          | 16255       |
|    total_timesteps       | 952320      |
| train/                   |             |
|    approx_kl             | 0.009298028 |
|    clip_fraction         | 0.094       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.35        |
|    cost_value_loss       | 18.7        |
|    cost_values           | 2.59        |
|    entropy               | -1.35       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.282       |
|    lagrangian_multiplier | 0.000658    |
|    learning_rate         | 0.0003      |
|    loss                  | 13.9        |
|    n_updates             | 4640        |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 0.493       |
|    value_loss            | 19.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.184        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.184        |
| reward                   | -0.31615913  |
| rollout/                 |              |
|    ep_len_mean           | 956          |
|    ep_rew_mean           | -379         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 11           |
|    time_elapsed          | 6258         |
|    total_timesteps       | 1026048      |
| train/                   |              |
|    approx_kl             | 0.0015003106 |
|    clip_fraction         | 0.0648       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.1         |
|    cost_value_loss       | 171          |
|    cost_values           | 2.43         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0.0101       |
|    learning_rate         | 0.0003       |
|    loss                  | 16.2         |
|    n_updates             | 5000         |
|    policy_gradient_loss  | 0.00256      |
|    std                   | 0.734        |
|    value_loss            | 0.837        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0314      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0314      |
| reward                   | -0.44635516 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 46          |
|    time_elapsed          | 24456       |
|    total_timesteps       | 997376      |
| train/                   |             |
|    approx_kl             | 0.005270924 |
|    clip_fraction         | 0.0274      |
|    clip_range            | 0.2         |
|    cost_returns          | 13          |
|    cost_value_loss       | 171         |
|    cost_values           | 1.66        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.00112     |
|    learning_rate         | 0.0003      |
|    loss                  | 51.8        |
|    n_updates             | 4860        |
|    policy_gradient_loss  | -0.00343    |
|    std                   | 0.892       |
|    value_loss            | 0.265       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0157       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0157       |
| reward                   | -0.39153576  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 40           |
|    time_elapsed          | 21355        |
|    total_timesteps       | 985088       |
| train/                   |              |
|    approx_kl             | 0.0036591412 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.7         |
|    cost_value_loss       | 178          |
|    cost_values           | 2.34         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0.000133     |
|    learning_rate         | 0.0003       |
|    loss                  | 78.5         |
|    n_updates             | 4800         |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 0.719        |
|    value_loss            | 1.16         |
-------------------------------------------
------------------------------------
| avg_speed          | 0.0305      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0305      |
| reward             | -0.45156208 |
| rollout/           |             |
|    ep_len_mean     | 985         |
|    ep_rew_mean     | -407        |
| time/              |             |
|    fps             | 3           |
|    iterations      | 1           |
|    time_elapsed    | 565         |
|    total_timesteps | 1005568     |
------------------------------------
------------------------------------------
| avg_speed                | 0.00211     |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.00211     |
| reward                   | -0.51483345 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 39          |
|    time_elapsed          | 21943       |
|    total_timesteps       | 983040      |
| train/                   |             |
|    approx_kl             | 0.004380473 |
|    clip_fraction         | 0.0225      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.27        |
|    cost_value_loss       | 12          |
|    cost_values           | 2.3         |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | -0.169      |
|    lagrangian_multiplier | 8.54e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.96        |
|    n_updates             | 4790        |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 0.761       |
|    value_loss            | 0.858       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.105       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.105       |
| reward                   | -0.3510809  |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -377        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 12          |
|    time_elapsed          | 6830        |
|    total_timesteps       | 1028096     |
| train/                   |             |
|    approx_kl             | 0.004219064 |
|    clip_fraction         | 0.0278      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.2        |
|    cost_value_loss       | 98.7        |
|    cost_values           | 2.3         |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.523       |
|    lagrangian_multiplier | 0.00819     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 5010        |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 0.735       |
|    value_loss            | 0.935       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -1.2040303  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 47          |
|    time_elapsed          | 25009       |
|    total_timesteps       | 999424      |
| train/                   |             |
|    approx_kl             | 0.000485895 |
|    clip_fraction         | 4.88e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 9.18        |
|    cost_value_loss       | 123         |
|    cost_values           | 1.25        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.114       |
|    learning_rate         | 0.0003      |
|    loss                  | 2.57        |
|    n_updates             | 4870        |
|    policy_gradient_loss  | -0.000795   |
|    std                   | 0.893       |
|    value_loss            | 8.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.28421372 |
| rollout/                 |             |
|    ep_len_mean           | 302         |
|    ep_rew_mean           | -114        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 25          |
|    time_elapsed          | 16975       |
|    total_timesteps       | 954368      |
| train/                   |             |
|    approx_kl             | 0.011555085 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.48        |
|    cost_value_loss       | 16.2        |
|    cost_values           | 2.86        |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.27        |
|    lagrangian_multiplier | 0.00386     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.97        |
|    n_updates             | 4650        |
|    policy_gradient_loss  | -0.00176    |
|    std                   | 0.493       |
|    value_loss            | 15.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0433       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0433       |
| reward                   | -0.49759507  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 41           |
|    time_elapsed          | 21905        |
|    total_timesteps       | 987136       |
| train/                   |              |
|    approx_kl             | 0.0054844692 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.8         |
|    cost_value_loss       | 237          |
|    cost_values           | 2.75         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0.0258       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 4810         |
|    policy_gradient_loss  | -0.00302     |
|    std                   | 0.719        |
|    value_loss            | 0.409        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.139        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.139        |
| reward                   | -0.36755064  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 2            |
|    time_elapsed          | 1137         |
|    total_timesteps       | 1007616      |
| train/                   |              |
|    approx_kl             | 0.0033333185 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.47         |
|    cost_value_loss       | 106          |
|    cost_values           | 1.83         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0.0118       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.79         |
|    n_updates             | 4910         |
|    policy_gradient_loss  | -0.000913    |
|    std                   | 0.748        |
|    value_loss            | 0.361        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.139        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.139        |
| reward                   | -0.2734774   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 40           |
|    time_elapsed          | 22518        |
|    total_timesteps       | 985088       |
| train/                   |              |
|    approx_kl             | 0.0072273277 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.8          |
|    cost_value_loss       | 12.1         |
|    cost_values           | 2.51         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | -9.42        |
|    lagrangian_multiplier | 0.00377      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.88         |
|    n_updates             | 4800         |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 0.758        |
|    value_loss            | 0.505        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0314      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0314      |
| reward                   | -0.46457395 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -372        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 13          |
|    time_elapsed          | 7404        |
|    total_timesteps       | 1030144     |
| train/                   |             |
|    approx_kl             | 0.007840335 |
|    clip_fraction         | 0.0882      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.75        |
|    cost_value_loss       | 82.5        |
|    cost_values           | 2.47        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0.00956     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.72        |
|    n_updates             | 5020        |
|    policy_gradient_loss  | -0.00751    |
|    std                   | 0.737       |
|    value_loss            | 0.431       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0773      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0773      |
| reward                   | -0.4180426  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 48          |
|    time_elapsed          | 25565       |
|    total_timesteps       | 1001472     |
| train/                   |             |
|    approx_kl             | 0.007876011 |
|    clip_fraction         | 0.0422      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.6         |
|    cost_value_loss       | 9.83        |
|    cost_values           | 0.527       |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000194    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 4880        |
|    policy_gradient_loss  | -0.00658    |
|    std                   | 0.894       |
|    value_loss            | 6.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.63        |
| reward                   | -0.23258345 |
| rollout/                 |             |
|    ep_len_mean           | 291         |
|    ep_rew_mean           | -110        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 26          |
|    time_elapsed          | 17697       |
|    total_timesteps       | 956416      |
| train/                   |             |
|    approx_kl             | 0.010325089 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 6.44        |
|    cost_value_loss       | 16.3        |
|    cost_values           | 2.92        |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.342       |
|    lagrangian_multiplier | 0.00584     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.48        |
|    n_updates             | 4660        |
|    policy_gradient_loss  | -0.00529    |
|    std                   | 0.492       |
|    value_loss            | 21.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.229        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.229        |
| reward                   | -0.43735737  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 42           |
|    time_elapsed          | 22456        |
|    total_timesteps       | 989184       |
| train/                   |              |
|    approx_kl             | 0.0029897885 |
|    clip_fraction         | 0.0489       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.3         |
|    cost_value_loss       | 245          |
|    cost_values           | 2.98         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0.028        |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 4820         |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 0.719        |
|    value_loss            | 0.521        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0177      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0177      |
| reward                   | -0.4459644  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 3           |
|    time_elapsed          | 1707        |
|    total_timesteps       | 1009664     |
| train/                   |             |
|    approx_kl             | 0.003569658 |
|    clip_fraction         | 0.00459     |
|    clip_range            | 0.2         |
|    cost_returns          | 8.49        |
|    cost_value_loss       | 91.2        |
|    cost_values           | 1.93        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.0188      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.1         |
|    n_updates             | 4920        |
|    policy_gradient_loss  | -0.00109    |
|    std                   | 0.746       |
|    value_loss            | 0.426       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.139        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.139        |
| reward                   | -0.3459976   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 41           |
|    time_elapsed          | 23103        |
|    total_timesteps       | 987136       |
| train/                   |              |
|    approx_kl             | 0.0032315906 |
|    clip_fraction         | 0.0363       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.64         |
|    cost_value_loss       | 8.15         |
|    cost_values           | 2.1          |
|    entropy               | -2.27        |
|    entropy_loss          | -2.28        |
|    explained_variance    | -0.385       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.82         |
|    n_updates             | 4810         |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.755        |
|    value_loss            | 2.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.23         |
| reward                   | -0.6151232   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 14           |
|    time_elapsed          | 7982         |
|    total_timesteps       | 1032192      |
| train/                   |              |
|    approx_kl             | 0.0038270308 |
|    clip_fraction         | 0.031        |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 194          |
|    cost_values           | 2.58         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.887        |
|    lagrangian_multiplier | 0.0247       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.68         |
|    n_updates             | 5030         |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.735        |
|    value_loss            | 3.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.063       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.063       |
| reward                   | -0.4344944  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 49          |
|    time_elapsed          | 26120       |
|    total_timesteps       | 1003520     |
| train/                   |             |
|    approx_kl             | 0.016103636 |
|    clip_fraction         | 0.0344      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 156         |
|    cost_values           | 1.15        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.0159      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.66        |
|    n_updates             | 4890        |
|    policy_gradient_loss  | -0.0116     |
|    std                   | 0.894       |
|    value_loss            | 1.67        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.19         |
| reward                   | -0.48200324  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 43           |
|    time_elapsed          | 23025        |
|    total_timesteps       | 991232       |
| train/                   |              |
|    approx_kl             | 0.0064518307 |
|    clip_fraction         | 0.0242       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.8         |
|    cost_value_loss       | 254          |
|    cost_values           | 3            |
|    entropy               | -2.18        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.537        |
|    lagrangian_multiplier | 0.00638      |
|    learning_rate         | 0.0003       |
|    loss                  | 32.1         |
|    n_updates             | 4830         |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.72         |
|    value_loss            | 0.382        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.97         |
| reward                   | -0.3308666   |
| rollout/                 |              |
|    ep_len_mean           | 284          |
|    ep_rew_mean           | -107         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 27           |
|    time_elapsed          | 18432        |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0066284556 |
|    clip_fraction         | 0.0722       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.31         |
|    cost_value_loss       | 16.3         |
|    cost_values           | 2.92         |
|    entropy               | -1.35        |
|    entropy_loss          | -1.35        |
|    explained_variance    | 0.345        |
|    lagrangian_multiplier | 0.00515      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.59         |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.00538     |
|    std                   | 0.492        |
|    value_loss            | 25.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.105       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.105       |
| reward                   | -0.2505709  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 4           |
|    time_elapsed          | 2275        |
|    total_timesteps       | 1011712     |
| train/                   |             |
|    approx_kl             | 0.004350708 |
|    clip_fraction         | 0.0181      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.18        |
|    cost_value_loss       | 83.8        |
|    cost_values           | 1.97        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0.00803     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 4930        |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.746       |
|    value_loss            | 0.646       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0863       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0863       |
| reward                   | -0.4735234   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 42           |
|    time_elapsed          | 23681        |
|    total_timesteps       | 989184       |
| train/                   |              |
|    approx_kl             | 0.0072995927 |
|    clip_fraction         | 0.0285       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 3.16         |
|    cost_values           | 2.17         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.27        |
|    explained_variance    | -4.22        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.12         |
|    n_updates             | 4820         |
|    policy_gradient_loss  | -0.00388     |
|    std                   | 0.751        |
|    value_loss            | 1.18         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.315      |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 0.315      |
| reward             | -0.5508097 |
| rollout/           |            |
|    ep_len_mean     | 964        |
|    ep_rew_mean     | -413       |
| time/              |            |
|    fps             | 3          |
|    iterations      | 1          |
|    time_elapsed    | 553        |
|    total_timesteps | 1005568    |
-----------------------------------
------------------------------------------
| avg_speed                | 0.105       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.105       |
| reward                   | -0.41193298 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -378        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 15          |
|    time_elapsed          | 8562        |
|    total_timesteps       | 1034240     |
| train/                   |             |
|    approx_kl             | 0.010353469 |
|    clip_fraction         | 0.0644      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.22        |
|    cost_value_loss       | 61.7        |
|    cost_values           | 2.12        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0.00661     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.86        |
|    n_updates             | 5040        |
|    policy_gradient_loss  | -0.00554    |
|    std                   | 0.735       |
|    value_loss            | 0.365       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.142       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.142       |
| reward                   | -0.35399485 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 44          |
|    time_elapsed          | 23589       |
|    total_timesteps       | 993280      |
| train/                   |             |
|    approx_kl             | 0.008840279 |
|    clip_fraction         | 0.0553      |
|    clip_range            | 0.2         |
|    cost_returns          | 18.6        |
|    cost_value_loss       | 250         |
|    cost_values           | 3           |
|    entropy               | -2.17       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0.017       |
|    learning_rate         | 0.0003      |
|    loss                  | 15.6        |
|    n_updates             | 4840        |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 0.718       |
|    value_loss            | 0.154       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0349      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0349      |
| reward                   | -0.5031327  |
| rollout/                 |             |
|    ep_len_mean           | 985         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 5           |
|    time_elapsed          | 2845        |
|    total_timesteps       | 1013760     |
| train/                   |             |
|    approx_kl             | 0.005832751 |
|    clip_fraction         | 0.0386      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 129         |
|    cost_values           | 2.06        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.0161      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.1         |
|    n_updates             | 4940        |
|    policy_gradient_loss  | -0.00335    |
|    std                   | 0.746       |
|    value_loss            | 0.215       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.397        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.397        |
| reward                   | -0.38293973  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 43           |
|    time_elapsed          | 24272        |
|    total_timesteps       | 991232       |
| train/                   |              |
|    approx_kl             | 0.0021012158 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.52         |
|    cost_value_loss       | 6.01         |
|    cost_values           | 2.17         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | -0.354       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.22         |
|    n_updates             | 4830         |
|    policy_gradient_loss  | 9.93e-05     |
|    std                   | 0.751        |
|    value_loss            | 2.35         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0732      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0732      |
| reward                   | -0.51902014 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 2           |
|    time_elapsed          | 1112        |
|    total_timesteps       | 1007616     |
| train/                   |             |
|    approx_kl             | 0.006058792 |
|    clip_fraction         | 0.0398      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.5        |
|    cost_value_loss       | 200         |
|    cost_values           | 0.994       |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.0187      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 4910        |
|    policy_gradient_loss  | -0.0041     |
|    std                   | 0.887       |
|    value_loss            | 2.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.26        |
| reward                   | -0.33290064 |
| rollout/                 |             |
|    ep_len_mean           | 288         |
|    ep_rew_mean           | -108        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 28          |
|    time_elapsed          | 19165       |
|    total_timesteps       | 960512      |
| train/                   |             |
|    approx_kl             | 0.009470285 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.05        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.91        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.214       |
|    lagrangian_multiplier | 0.00506     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.12        |
|    n_updates             | 4680        |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.491       |
|    value_loss            | 19.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0872       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0872       |
| reward                   | -0.4663211   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -382         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 16           |
|    time_elapsed          | 9133         |
|    total_timesteps       | 1036288      |
| train/                   |              |
|    approx_kl             | 0.0054101385 |
|    clip_fraction         | 0.0185       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.1         |
|    cost_value_loss       | 157          |
|    cost_values           | 2.08         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0.0243       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.9          |
|    n_updates             | 5050         |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.737        |
|    value_loss            | 1.3          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.207        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.207        |
| reward                   | -0.35747424  |
| rollout/                 |              |
|    ep_len_mean           | 999          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 45           |
|    time_elapsed          | 24146        |
|    total_timesteps       | 995328       |
| train/                   |              |
|    approx_kl             | 0.0021754506 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.14         |
|    cost_value_loss       | 102          |
|    cost_values           | 2.59         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0.189        |
|    learning_rate         | 0.0003       |
|    loss                  | 2.97         |
|    n_updates             | 4850         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.718        |
|    value_loss            | 5.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.11         |
| reward                   | -0.40591973  |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 6            |
|    time_elapsed          | 3420         |
|    total_timesteps       | 1015808      |
| train/                   |              |
|    approx_kl             | 0.0033864155 |
|    clip_fraction         | 0.00698      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.96         |
|    cost_value_loss       | 84.2         |
|    cost_values           | 1.56         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.553        |
|    lagrangian_multiplier | 0.00118      |
|    learning_rate         | 0.0003       |
|    loss                  | 28.9         |
|    n_updates             | 4950         |
|    policy_gradient_loss  | -0.00144     |
|    std                   | 0.746        |
|    value_loss            | 1.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.203        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.203        |
| reward                   | -0.32403204  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 3            |
|    time_elapsed          | 1667         |
|    total_timesteps       | 1009664      |
| train/                   |              |
|    approx_kl             | 0.0069636535 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.3         |
|    cost_value_loss       | 218          |
|    cost_values           | 1.38         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 4920         |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 0.888        |
|    value_loss            | 0.223        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0126      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0126      |
| reward                   | -0.47098348 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 44          |
|    time_elapsed          | 24857       |
|    total_timesteps       | 993280      |
| train/                   |             |
|    approx_kl             | 0.005243813 |
|    clip_fraction         | 0.0545      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.46        |
|    cost_value_loss       | 6.72        |
|    cost_values           | 2.03        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | -1.22       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.94        |
|    n_updates             | 4840        |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.751       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.011       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.011       |
| reward                   | -0.29449105 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -380        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 17          |
|    time_elapsed          | 9711        |
|    total_timesteps       | 1038336     |
| train/                   |             |
|    approx_kl             | 0.004077434 |
|    clip_fraction         | 0.0533      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.91        |
|    cost_value_loss       | 71          |
|    cost_values           | 2.07        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0.00793     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.26        |
|    n_updates             | 5060        |
|    policy_gradient_loss  | -0.00431    |
|    std                   | 0.737       |
|    value_loss            | 0.601       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.57        |
| reward                   | -0.41291153 |
| rollout/                 |             |
|    ep_len_mean           | 287         |
|    ep_rew_mean           | -107        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 29          |
|    time_elapsed          | 19901       |
|    total_timesteps       | 962560      |
| train/                   |             |
|    approx_kl             | 0.009205361 |
|    clip_fraction         | 0.0822      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.03        |
|    cost_value_loss       | 16.2        |
|    cost_values           | 2.63        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.258       |
|    lagrangian_multiplier | 0.00476     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.79        |
|    n_updates             | 4690        |
|    policy_gradient_loss  | -0.000937   |
|    std                   | 0.489       |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0415      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0415      |
| reward                   | -0.34511495 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 46          |
|    time_elapsed          | 24711       |
|    total_timesteps       | 997376      |
| train/                   |             |
|    approx_kl             | 0.007646753 |
|    clip_fraction         | 0.0629      |
|    clip_range            | 0.2         |
|    cost_returns          | 18.4        |
|    cost_value_loss       | 256         |
|    cost_values           | 2.47        |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 126         |
|    n_updates             | 4860        |
|    policy_gradient_loss  | -0.00586    |
|    std                   | 0.718       |
|    value_loss            | 0.469       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.275        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.275        |
| reward                   | -0.3728616   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 7            |
|    time_elapsed          | 3997         |
|    total_timesteps       | 1017856      |
| train/                   |              |
|    approx_kl             | 0.0050961375 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.65         |
|    cost_value_loss       | 107          |
|    cost_values           | 1.87         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.937        |
|    lagrangian_multiplier | 0.0158       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.93         |
|    n_updates             | 4960         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.745        |
|    value_loss            | 0.289        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0596      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0596      |
| reward                   | -0.48306194 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -421        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 4           |
|    time_elapsed          | 2217        |
|    total_timesteps       | 1011712     |
| train/                   |             |
|    approx_kl             | 0.007221571 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 144         |
|    cost_values           | 1.27        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.0095      |
|    learning_rate         | 0.0003      |
|    loss                  | 12.9        |
|    n_updates             | 4930        |
|    policy_gradient_loss  | -0.00519    |
|    std                   | 0.888       |
|    value_loss            | 2.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0593      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0593      |
| reward                   | -0.3440518  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 45          |
|    time_elapsed          | 25448       |
|    total_timesteps       | 995328      |
| train/                   |             |
|    approx_kl             | 0.014890972 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.58        |
|    cost_value_loss       | 0.0731      |
|    cost_values           | 1.78        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.467       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.103       |
|    n_updates             | 4850        |
|    policy_gradient_loss  | -0.000972   |
|    std                   | 0.75        |
|    value_loss            | 0.248       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.196       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.196       |
| reward                   | -0.3647989  |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -379        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 18          |
|    time_elapsed          | 10293       |
|    total_timesteps       | 1040384     |
| train/                   |             |
|    approx_kl             | 0.004200738 |
|    clip_fraction         | 0.0323      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.22        |
|    cost_value_loss       | 84.4        |
|    cost_values           | 2.12        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.0121      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.97        |
|    n_updates             | 5070        |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 0.732       |
|    value_loss            | 0.466       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.112       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.112       |
| reward                   | -0.38754073 |
| rollout/                 |             |
|    ep_len_mean           | 999         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 47          |
|    time_elapsed          | 25271       |
|    total_timesteps       | 999424      |
| train/                   |             |
|    approx_kl             | 0.005484265 |
|    clip_fraction         | 0.0204      |
|    clip_range            | 0.2         |
|    cost_returns          | 18.5        |
|    cost_value_loss       | 251         |
|    cost_values           | 2.74        |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0.0168      |
|    learning_rate         | 0.0003      |
|    loss                  | 15.6        |
|    n_updates             | 4870        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.718       |
|    value_loss            | 0.288       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.50187904  |
| rollout/                 |              |
|    ep_len_mean           | 304          |
|    ep_rew_mean           | -112         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 30           |
|    time_elapsed          | 20648        |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0069111423 |
|    clip_fraction         | 0.134        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.05         |
|    cost_value_loss       | 15.9         |
|    cost_values           | 2.47         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0.344        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.2         |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.00383     |
|    std                   | 0.487        |
|    value_loss            | 15.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.132        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.132        |
| reward                   | -0.5214745   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 8            |
|    time_elapsed          | 4562         |
|    total_timesteps       | 1019904      |
| train/                   |              |
|    approx_kl             | 0.0029594938 |
|    clip_fraction         | 0.0321       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.39         |
|    cost_value_loss       | 42.5         |
|    cost_values           | 1.45         |
|    entropy               | -2.24        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0.00292      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.96         |
|    n_updates             | 4970         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.745        |
|    value_loss            | 0.0751       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.358       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.358       |
| reward                   | -0.51484734 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -418        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 5           |
|    time_elapsed          | 2768        |
|    total_timesteps       | 1013760     |
| train/                   |             |
|    approx_kl             | 0.008622032 |
|    clip_fraction         | 0.0625      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.59        |
|    cost_value_loss       | 85.3        |
|    cost_values           | 1.05        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0.000898    |
|    learning_rate         | 0.0003      |
|    loss                  | 28.9        |
|    n_updates             | 4940        |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 0.888       |
|    value_loss            | 0.475       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0182       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0182       |
| reward                   | -0.53563005  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 46           |
|    time_elapsed          | 26033        |
|    total_timesteps       | 997376       |
| train/                   |              |
|    approx_kl             | 0.0067433803 |
|    clip_fraction         | 0.0861       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.61         |
|    cost_value_loss       | 16.5         |
|    cost_values           | 1.57         |
|    entropy               | -2.25        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.186        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.47         |
|    n_updates             | 4860         |
|    policy_gradient_loss  | -0.00026     |
|    std                   | 0.748        |
|    value_loss            | 0.624        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0624       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0624       |
| reward                   | -0.46352178  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 19           |
|    time_elapsed          | 10876        |
|    total_timesteps       | 1042432      |
| train/                   |              |
|    approx_kl             | 0.0025291701 |
|    clip_fraction         | 0.0781       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.15         |
|    cost_value_loss       | 94.7         |
|    cost_values           | 2.12         |
|    entropy               | -2.19        |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0.00869      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 5080         |
|    policy_gradient_loss  | -0.0056      |
|    std                   | 0.73         |
|    value_loss            | 0.572        |
-------------------------------------------
