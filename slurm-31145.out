wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20230727_163719-dea1c6d2-eb48-424c-b98c-72f2b767e5fe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cpo-b796
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/fast-safe-rl
wandb: üöÄ View run at https://wandb.ai/ecrl/fast-safe-rl/runs/dea1c6d2-eb48-424c-b98c-72f2b767e5fe
[32;1mLogging data to logs/fast-safe-rl/parking-v0-cost-10/cpo-b796/progress.txt[0m
[36;1mSaving config:
[0m
{
    "action_bound_method":	"clip",
    "action_scaling":	true,
    "backtrack_coeff":	0.8,
    "batch_size":	99999,
    "buffer_size":	100000,
    "cost_limit":	10,
    "damping_coeff":	0.1,
    "deterministic_eval":	true,
    "device":	"cpu",
    "env_config_file":	"configs/ParkingEnv/env-image.txt",
    "episode_per_collect":	20,
    "epoch":	45,
    "gae_lambda":	0.95,
    "gamma":	0.99,
    "group":	null,
    "hidden_sizes":	[
        128,
        128
    ],
    "l2_reg":	0.001,
    "last_layer_scale":	false,
    "logdir":	"logs",
    "lr":	0.001,
    "max_backtracks":	100,
    "max_batchsize":	99999,
    "name":	"cpo-b796",
    "norm_adv":	true,
    "optim_critic_iters":	10,
    "prefix":	"cpo",
    "project":	"fast-safe-rl",
    "render":	null,
    "render_mode":	null,
    "repeat_per_collect":	4,
    "resume":	false,
    "rew_norm":	false,
    "reward_threshold":	10000,
    "save_ckpt":	true,
    "save_interval":	4,
    "seed":	10,
    "step_per_epoch":	10000,
    "suffix":	"",
    "target_kl":	0.01,
    "task":	"parking-v0",
    "testing_num":	2,
    "thread":	320,
    "training_num":	20,
    "unbounded":	false,
    "use_default_cfg":	false,
    "verbose":	true,
    "worker":	"ShmemVectorEnv"
}
Observation Space: Box(0, 255, (4, 128, 128), uint8)
Action Space: Box(-1.0, 1.0, (2,), float32)
Render Mode: None
Epoch #1:   0%|          | 0/10000 [00:00<?, ?it/s]Epoch #1: 100%|##########| 10000/10000 [00:19<00:00, 517.66it/s]Epoch #1: 100%|##########| 10000/10000 [00:30<00:00, 517.66it/s]Epoch #1: 100%|##########| 10000/10000 [07:34<00:00, 517.66it/s, cost=0, length=500, rew=-372]Epoch #1: 100%|##########| 10000/10000 [07:34<00:00, 21.99it/s, cost=0, length=500, rew=-372] 
-------------------------------------------------
|              loss/cost_loss |        0.000812 |
|                loss/entropy |            2.86 |
|                     loss/kl |         0.00342 |
|                loss/optim_A |        0.000961 |
|                loss/optim_B |       -1.55e+05 |
|                loss/optim_C |             -10 |
|                loss/optim_Q |         0.00211 |
|                loss/optim_R |       -0.000846 |
|                loss/optim_S |        0.000919 |
|             loss/optim_case |               3 |
|              loss/optim_lam |           0.297 |
|               loss/optim_nu |               0 |
|               loss/rew_loss |        0.000341 |
|              loss/step_size |           0.156 |
|                    loss/vf0 |        2.68e+04 |
|                    loss/vf1 |        1.06e+05 |
|               loss/vf_total |        1.33e+05 |
|                   test/cost |               0 |
|                 test/length |             500 |
|                 test/reward |            -207 |
|                  train/cost |               0 |
|                train/length |             500 |
|                train/reward |            -372 |
|             update/cum_cost |               0 |
|             update/duration |             466 |
|             update/env_step |           1e+04 |
|              update/episode |              20 |
|       update/gradient_steps |               4 |
|      update/remaining_epoch |              44 |
|           update/test_speed |            90.4 |
|            update/test_time |            11.1 |
| update/train_collector_time |            19.3 |
|     update/train_model_time |             435 |
|          update/train_speed |              22 |
-------------------------------------------------
Epoch: 1 {'duration': 465.8307771682739, 'test_time': 11.059735536575317, 'test_speed': 90.41807525079874, 'train_collector_time': 19.28469181060791, 'train_model_time': 435.4863498210907, 'train_speed': 21.98908700105538, 'remaining_epoch': 44, 'best_reward': -207.4811817930158, 'best_cost': 0.0}
Epoch #2:   0%|          | 0/10000 [00:00<?, ?it/s]Epoch #2:  87%|########7 | 8702/10000 [00:18<00:02, 465.72it/s]Epoch #2:  87%|########7 | 8702/10000 [00:33<00:02, 465.72it/s]Epoch #2:  87%|########7 | 8702/10000 [06:48<00:02, 465.72it/s, cost=0, length=435, rew=-348]Epoch #2: 18702it [07:08, 38.04it/s, cost=0, length=435, rew=-348]                           Epoch #2: 18702it [07:23, 38.04it/s, cost=0, length=435, rew=-348]Epoch #2: 18702it [12:41, 38.04it/s, cost=0, length=500, rew=-411]Epoch #2: 18702it [12:41, 24.55it/s, cost=0, length=500, rew=-411]
-------------------------------------------------
|              loss/cost_loss |         0.00188 |
|                loss/entropy |            2.88 |
|                     loss/kl |         0.00357 |
|                loss/optim_A |        0.000151 |
|                loss/optim_B |       -7.33e+05 |
|                loss/optim_C |             -10 |
|                loss/optim_Q |         0.00579 |
|                loss/optim_R |         -0.0085 |
|                loss/optim_S |          0.0133 |
|             loss/optim_case |            2.75 |
|              loss/optim_lam |           0.299 |
|               loss/optim_nu |               0 |
|               loss/rew_loss |         0.00106 |
|              loss/step_size |          0.0565 |
|                    loss/vf0 |        1.93e+03 |
|                    loss/vf1 |        1.29e+03 |
|               loss/vf_total |        3.22e+03 |
|                   test/cost |               0 |
|                 test/length |             500 |
|                 test/reward |            -212 |
|                  train/cost |               0 |
|            train/cost_limit |              10 |
|                train/length |             468 |
|                train/reward |            -380 |
|             update/cum_cost |               0 |
|             update/duration |        1.24e+03 |
|             update/env_step |        2.87e+04 |
|              update/episode |              50 |
|       update/gradient_steps |              10 |
|      update/remaining_epoch |              43 |
|           update/test_speed |            90.2 |
|            update/test_time |            22.2 |
| update/train_collector_time |            57.6 |
|     update/train_model_time |        1.16e+03 |
|          update/train_speed |            23.6 |
-------------------------------------------------
Epoch: 2 {'duration': 1239.09432888031, 'test_time': 22.169092416763306, 'test_speed': 90.21569139599448, 'train_collector_time': 57.58923602104187, 'train_model_time': 1159.3360004425049, 'train_speed': 23.585672430797498, 'remaining_epoch': 43, 'best_reward': -207.4811817930158, 'best_cost': 0.0}
slurmstepd: error: *** JOB 31145 ON gan.ist.berkeley.edu CANCELLED AT 2023-07-27T17:03:47 ***
Epoch #3:   0%|          | 0/10000 [00:00<?, ?it/s]Epoch #3: 100%|##########| 10000/10000 [00:19<00:00, 509.40it/s]Epoch #3: 100%|##########| 10000/10000 [00:30<00:00, 509.40it/s]slurmstepd: error: *** STEP 31145.0 ON gan.ist.berkeley.edu CANCELLED AT 2023-07-27T17:03:47 ***
