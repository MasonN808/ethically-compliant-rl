Steps	update/episode	update/cum_cost	train/reward	train/cost	train/length	loss/kl	loss/entropy	loss/rew_loss	loss/cost_loss	loss/optim_A	loss/optim_B	loss/optim_C	loss/optim_Q	loss/optim_R	loss/optim_S	loss/optim_lam	loss/optim_nu	loss/optim_case	loss/step_size	loss/vf0	loss/vf1	loss/vf_total	update/gradient_steps	test/reward	test/cost	test/length	update/duration	update/test_time	update/test_speed	update/train_collector_time	update/train_model_time	update/train_speed	update/remaining_epoch	update/env_step
20000	30.0	16808.327613291305	-462.9827296842121	420.20819033228264	500.0	2675278208.0012417	-14.433698564767838	0.0016467668699107207	420.20858764590025	nan	nan	nan	nan	nan	nan	nan	nan	0.625	0.5640000000763888	214.88528442382812	4.331000560894608	219.21628665924075	6.0	-358.245502187242	0.0	500.0	87.43891310691833	8.31486439704895	120.26654341529762	42.50932002067566	36.614728689193726	252.76765188464552	299.0	20000.0
40000	10.0	70.0	16808.327613291305	-316.88536448471206	0.0	500.0	0.0	-20.18797492980957	1.1175573000343773e-07	7.986997729858559e-10	nan	nan	nan	nan	nan	nan	0.0	nan	0.0	1.0	43.81051856279373	0.12145673763006926	43.931974291801446	14.0	-404.5274125038228	0.0	500.0	166.57500505447388	16.586684226989746	120.57865047829227	84.78245830535889	65.20586252212524	266.6874312567831	298.0	40000.0
60000	10.0	110.0	16808.327613291305	-333.71844314397254	0.0	500.0	0.0	-20.18797492980957	6.132125962565738e-08	5.364473310009998e-10	nan	nan	nan	nan	nan	nan	0.0	nan	0.0	1.0	10.817840218544008	0.10213124193251133	10.919971257448196	22.0	-315.28695314027175	0.0	500.0	245.67405724525452	24.80070972442627	120.96428018934047	126.84896564483643	94.02438187599182	271.6488914278896	297.0	60000.0
