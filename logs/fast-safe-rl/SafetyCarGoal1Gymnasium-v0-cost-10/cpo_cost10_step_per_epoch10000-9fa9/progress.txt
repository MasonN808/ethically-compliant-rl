Steps	update/episode	update/cum_cost	train/reward	train/cost	train/length	loss/kl	loss/entropy	loss/rew_loss	loss/cost_loss	loss/optim_A	loss/optim_B	loss/optim_C	loss/optim_Q	loss/optim_R	loss/optim_S	loss/optim_lam	loss/optim_nu	loss/optim_case	loss/step_size	loss/vf0	loss/vf1	loss/vf_total	update/gradient_steps	test/reward	test/cost	test/length	update/duration	update/test_time	update/test_speed	update/train_collector_time	update/train_model_time	update/train_speed	update/remaining_epoch	update/env_step
20000	20.0	1338.0	-0.1141111339847426	66.9	1000.0	0.0052447032649070024	1.838329792022705	-9.374284723318027e-05	66.89262008666992	-0.0037556308088824157	404309.703125	56.89262008666992	-0.004236432025209069	0.0010881321650231257	-0.0012258621864020824	1.9424065953899117e-05	0.34192603826522827	0.75	0.06615455310934071	0.17408261448144913	12.193318843841553	12.367401361465454	4.0	-0.9682154189755054	69.0	1000.0	50.071223974227905	7.032773971557617	284.3828065694312	10.965958833694458	32.07249116897583	464.7007501143539	99.0	20000.0
40000	10.0	40.0	2370.0	-0.36709036157573394	51.6	1000.0	0.006906924536451697	1.8423511385917664	-0.002055093994643542	51.5888671875	0.020171756856143475	-165566.19921875	41.5888671875	0.020459038205444813	-0.0017258793814107776	0.010653924429789186	0.0	1.380282074213028	0.0	0.10346420033977144	0.11524642817676067	9.151417016983032	9.266663312911987	8.0	-1.426326672653055	0.0	1000.0	100.8445680141449	14.17220687866211	282.24256350804905	24.014384984970093	62.657976150512695	461.5081379573079	98.0	40000.0
