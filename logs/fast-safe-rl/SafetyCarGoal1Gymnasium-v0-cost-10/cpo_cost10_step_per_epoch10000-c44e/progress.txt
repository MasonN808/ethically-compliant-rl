Steps	update/episode	update/cum_cost	train/reward	train/cost	train/length	loss/kl	loss/entropy	loss/rew_loss	loss/cost_loss	loss/optim_A	loss/optim_B	loss/optim_C	loss/optim_Q	loss/optim_R	loss/optim_S	loss/optim_lam	loss/optim_nu	loss/optim_case	loss/step_size	loss/vf0	loss/vf1	loss/vf_total	update/gradient_steps	test/reward	test/cost	test/length	update/duration	update/test_time	update/test_speed	update/train_collector_time	update/train_model_time	update/train_speed	update/remaining_epoch	update/env_step
20000	20.0	1446.0	-0.0952175673736895	72.3	1000.0	0.00722602941095829	1.835484504699707	0.0005215148761634758	72.29068946838379	0.0026828073314391077	-1527672.5	62.29068946838379	0.004587130853906274	0.001571885630255565	0.004600454500177875	0.0	2.68045112490654	0.0	0.07137587882782703	0.17388687282800674	13.898274898529053	14.072161674499512	4.0	-1.5284273629673983	0.0	1000.0	65.94275903701782	5.9581756591796875	335.6732185159101	9.35765814781189	50.626925230026245	333.4190032465773	99.0	20000.0
40000	10.0	40.0	1993.0	-0.21205582284877886	27.35	1000.0	0.006623534602113068	1.8418594300746918	0.0006931644830387995	27.339208126068115	0.01927718659862876	-25403.765625	17.339208126068115	0.019330792129039764	6.816261156927794e-05	0.012069761520251632	0.0	1.2970300614833832	0.0	0.08584576095337423	0.11405986919999123	5.7521891593933105	5.866249084472656	8.0	-0.9303870894585401	0.0	1000.0	124.08543014526367	9.206811904907227	434.4609232070878	19.547420263290405	95.33119797706604	348.19360306292526	98.0	40000.0
