Steps	update/episode	update/cum_cost	train/reward	train/cost	train/length	loss/kl	loss/entropy	loss/rew_loss	loss/cost_loss	loss/optim_A	loss/optim_B	loss/optim_C	loss/optim_Q	loss/optim_R	loss/optim_S	loss/optim_lam	loss/optim_nu	loss/optim_case	loss/step_size	loss/vf0	loss/vf1	loss/vf_total	update/gradient_steps	test/reward	test/cost	test/length	update/duration	update/test_time	update/test_speed	update/train_collector_time	update/train_model_time	update/train_speed	update/remaining_epoch	update/env_step
10000	20.0	0.0	-372.0538326425341	0.0	500.0	0.003424575785174966	2.860645115375519	0.00034117824315238465	0.0008122388631570665	0.0009613474394427612	-155438.267578125	-9.999187707901001	0.002108240601955913	-0.0008459209020656999	0.0009187359901261516	0.2972172051668167	0.0	3.0	0.15643226399097399	26833.188110351562	106068.16009521483	132901.35107421875	4.0	-207.4811817930158	0.0	500.0	465.8307771682739	11.059735536575317	90.41807525079874	19.28469181060791	435.4863498210907	21.98908700105538	44.0	10000.0
28702	10.0	50.0	0.0	-379.7521222643297	0.0	467.5	0.003571980754998094	2.8789392113685603	0.001064617808519186	0.0018814056041569494	0.00015070954145812723	-732647.8540802002	-9.9981187582016	0.005791782248252276	-0.00849824377519326	0.01333474265447876	0.29911981243640184	0.0	2.75	0.05646800848102819	1926.4027273654933	1292.0383386611938	3218.4410343170166	10.0	-211.5064919144878	0.0	500.0	1239.09432888031	22.169092416763306	90.21569139599448	57.58923602104187	1159.3360004425049	23.585672430797498	43.0	28702.0
