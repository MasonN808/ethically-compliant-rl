Steps	update/episode	update/cum_cost	train/reward	train/cost	train/length	loss/kl	loss/entropy	loss/rew_loss	loss/cost_loss	loss/optim_A	loss/optim_B	loss/optim_C	loss/optim_Q	loss/optim_R	loss/optim_S	loss/optim_lam	loss/optim_nu	loss/optim_case	loss/step_size	loss/vf0	loss/vf1	loss/vf_total	update/gradient_steps	test/reward	test/cost	test/length	update/duration	update/test_time	update/test_speed	update/train_collector_time	update/train_model_time	update/train_speed	update/remaining_epoch	update/env_step
10839	90.0	0.0	-37.15153736820501	0.0	67.5	0.0065799783915281304	1.8379115387797356	0.016099136139928322	-0.013528891593045945	0.007274563094597397	-2458.47618484497	-10.013528883457184	0.02922456021042307	0.02284658344069612	0.02382107049925253	nan	-0.07021739089395852	2.7187500000000004	0.09412401565340307	2485133.8207817064	6367222.816557168	8852356.637229918	18.0	-175.77192711387664	0.0	334.0	182.94204473495483	4.6063759326934814	145.23347850352638	20.557246446609497	157.77842235565186	60.77864328990903	1.0	10839.0
21507	10.0	250.0	0.0	-36.97376617209984	0.0	66.25	0.006514305729069747	1.837952759116888	0.02011445305885808	0.0033870733595229912	0.005960816191873162	-3821.6750739216805	-9.996612995862959	0.028660489364483503	0.018904902271970052	0.1774727544689085	nan	0.0	2.96875	0.12542628002117653	10824.717529058458	36.85997259616851	10861.57720041275	50.0	-38.40073797854942	0.0	80.0	360.46192479133606	5.6142637729644775	147.83772789530664	40.57403826713562	314.27362275123596	60.6091074076053	0.0	21507.0
