Steps	update/episode	update/cum_cost	train/reward	train/cost	train/length	loss/kl	loss/entropy	loss/rew_loss	loss/cost_loss	loss/optim_A	loss/optim_B	loss/optim_C	loss/optim_Q	loss/optim_R	loss/optim_S	loss/optim_lam	loss/optim_nu	loss/optim_case	loss/step_size	loss/vf0	loss/vf1	loss/vf_total	update/gradient_steps	test/reward	test/cost	test/length	update/duration	update/test_time	update/test_speed	update/train_collector_time	update/train_model_time	update/train_speed	update/remaining_epoch	update/env_step
30000	30.0	0.0	-749.0661115422638	0.0	750.0	0.0061775752692483366	2.780166983604431	0.010060921291383806	0.004336118222842855	-0.013452703482471406	-6176.501953125	-9.99566376209259	0.00048121227882802486	-0.01702073145133909	0.02525852399412543	nan	0.0	3.0	0.5667388580909483	36.856115937232964	0.08490980323404074	36.94102549552917	6.0	-473.52319329657394	0.0	750.0	156.48423171043396	7.523236036300659	199.3822861282421	145.31497955322266	3.6460161209106445	201.39500185422983	99.0	30000.0
60000	10.0	70.0	0.0	-532.4011892034111	0.0	750.0	0.006594973441679031	2.7653917372226715	0.010102049246492328	-0.0006520792576663048	0.005458402680233121	-15677.700805664062	-10.000652074813843	0.0054757798789069065	0.00016167625108209904	0.006434493756387383	0.5229595229029654	0.0	3.0	0.126632186126222	3.56197789311409	0.02795620588585734	3.5899341106414795	14.0	-372.12609259536737	0.0	750.0	311.9926884174347	14.964966058731079	200.46821277283794	288.70891976356506	8.31880259513855	202.00134695690588	98.0	60000.0
89294	10.0	110.0	0.0	-389.2418349442007	0.0	732.0	0.006861108297016472	2.7066667079925537	0.007198462996058669	-0.0019559177966128605	0.00285924575291574	-16510.768676757812	-10.00195598602295	0.0030559773003915325	0.0008613313800651667	0.006154270144179463	0.38488391786813736	0.0	3.0	0.12931004639576144	1.8641086518764494	0.009853183117229491	1.8739618360996246	22.0	-452.2971401999147	0.0	750.0	464.76814579963684	22.29103708267212	201.87486043428925	428.8020100593567	13.675098657608032	201.80478998997862	97.0	89294.0
