Steps	update/episode	update/cum_cost	train/reward	train/cost	train/length	loss/kl	loss/entropy	loss/rew_loss	loss/cost_loss	loss/optim_A	loss/optim_B	loss/optim_C	loss/optim_Q	loss/optim_R	loss/optim_S	loss/optim_lam	loss/optim_nu	loss/optim_case	loss/step_size	loss/vf0	loss/vf1	loss/vf_total	update/gradient_steps	test/reward	test/cost	test/length	update/duration	update/test_time	update/test_speed	update/train_collector_time	update/train_model_time	update/train_speed	update/remaining_epoch	update/env_step
30000	30.0	0.0	-962.7680302335026	0.0	750.0	0.007142688264138997	2.8375879228115086	0.009962634925854807	-0.0020236704041870497	-0.1660114944097586	-4671.844512939453	-10.002023935317993	-0.13679574779234827	-0.011404223827412352	0.021742080803960562	nan	0.0	3.0	0.5010114345939777	53.176188349723816	0.11106750555336475	53.28725624084473	6.0	-598.8864101198785	0.0	750.0	28.181071996688843	2.5776121616363525	581.9339396070163	16.849079847335815	8.754379987716675	1171.7166427221846	99.0	30000.0
60000	10.0	70.0	0.0	-845.1426556604516	0.0	750.0	0.0072440896183252335	2.8555471003055573	0.008709122679630976	0.0005168743028616253	0.00913033145479858	-8788.398071289062	-9.999482989311218	0.010305141797289252	-0.0029570453334599733	0.01226204982958734	0.7136664986610413	0.0	3.0	0.13812727442018477	9.841458976268768	0.060322130564600236	9.901781141757965	14.0	-550.1250686928339	0.0	750.0	56.76892304420471	5.078765153884888	590.6947671532355	33.50593090057373	18.184226989746094	1160.7625600082833	98.0	60000.0
90000	10.0	110.0	0.0	-515.2090167017324	0.0	750.0	0.007301640929654241	2.8384658098220825	0.009446801858271195	-0.0001986068680415176	0.005422192538389936	-10382.586486816406	-10.000198602676392	0.005462673143483698	-7.035903036012313e-05	0.010249735263641924	0.5081358812749386	0.0	3.0	0.1514999283901	3.5814179182052612	0.036755274049937725	3.618173211812973	22.0	-461.273783038907	0.0	750.0	85.7091281414032	7.641507148742676	588.8890649981822	50.14294195175171	27.924679040908813	1152.8467097577022	97.0	90000.0
