task: parking-v0
cost_limit: 10
device: cuda
thread: 320
seed: 10
use_default_cfg: false
lr: 0.001
hidden_sizes: !!python/tuple
- 128
- 128
unbounded: false
last_layer_scale: false
target_kl: 0.01
backtrack_coeff: 0.8
damping_coeff: 0.1
max_backtracks: 100
optim_critic_iters: 10
l2_reg: 0.001
gae_lambda: 0.95
norm_adv: true
gamma: 0.99
max_batchsize: 99999
rew_norm: false
deterministic_eval: true
action_scaling: true
action_bound_method: clip
epoch: 500
episode_per_collect: 20
step_per_epoch: 50000
repeat_per_collect: 4
buffer_size: 100000
worker: ShmemVectorEnv
training_num: 20
testing_num: 2
batch_size: 99999
reward_threshold: 10000
save_interval: 4
resume: false
save_ckpt: true
verbose: true
render: null
logdir: logs
project: fast-safe-rl
group: null
name: cpo_step_per_epoch50000-af06
prefix: cpo
suffix: ''
render_mode: null
env_config_file: configs/ParkingEnv/env-kinematicsGoal-high-reward.txt
