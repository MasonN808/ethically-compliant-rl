task: parking-v0
cost_limit: 10
device: cpu
thread: 320
seed: 10
use_default_cfg: false
lr: 0.0005
hidden_sizes: !!python/tuple
- 128
- 128
unbounded: false
last_layer_scale: false
target_kl: 0.005
vf_coef: 0.25
max_grad_norm: 0.5
gae_lambda: 0.95
eps_clip: 0.2
dual_clip: null
value_clip: false
norm_adv: true
recompute_adv: false
use_lagrangian: true
lagrangian_pid: !!python/tuple
- 0.05
- 0.0005
- 0.1
rescaling: true
gamma: 0.99
max_batchsize: 100000
rew_norm: false
deterministic_eval: true
action_scaling: true
action_bound_method: clip
epoch: 300
episode_per_collect: 20
step_per_epoch: 20000
repeat_per_collect: 4
buffer_size: 100000
worker: ShmemVectorEnv
training_num: 20
testing_num: 2
batch_size: 256
reward_threshold: 10000
save_interval: 4
resume: false
save_ckpt: true
verbose: true
render: null
logdir: logs
project: PPO
group: null
name: ppol_step_per_epoch20000_target_kl0.005-8e95
prefix: ppol
suffix: ''
render_mode: null
env_config_file: configs/ParkingEnv/env-kinematicsGoal.txt
constraints: false
