task: parking-v0
cost_limit: []
device: cpu
thread: 100
seed: 10
use_default_cfg: false
lr: 0.001
hidden_sizes: !!python/tuple
- 128
- 128
unbounded: false
last_layer_scale: false
target_kl: 0.01
vf_coef: 0.25
max_grad_norm: 0.5
gae_lambda: 0.95
eps_clip: 0.2
dual_clip: null
value_clip: false
norm_adv: true
recompute_adv: false
use_lagrangian: true
lagrangian_pid: !!python/tuple
- 0.05
- 0.0005
- 0.1
rescaling: true
gamma: 0.99
max_batchsize: 100000
rew_norm: false
deterministic_eval: true
action_scaling: true
action_bound_method: clip
epoch: 100
episode_per_collect: 20
step_per_epoch: 1000
repeat_per_collect: 4
buffer_size: 100000
worker: ShmemVectorEnv
training_num: 20
testing_num: 2
batch_size: 256
reward_threshold: 10000
save_interval: 4
resume: false
save_ckpt: true
verbose: true
render: null
logdir: logs
project: PPOL-100Epochs
group: null
name: ppol_cost_lr0.001_step_per_epoch1000_target_kl0.01-df65
prefix: ppol
suffix: ''
render_mode: null
constraint_type: []
env_config_file: configs/ParkingEnv/env-kinematicsGoalConstraints.txt
