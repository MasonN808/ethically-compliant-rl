wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240130_094216-3nvj5b1g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-firefly-70
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/seed-testing
wandb: üöÄ View run at https://wandb.ai/ecrl/seed-testing/runs/3nvj5b1g
Using cpu device
------------------------------------
| avg_speed          | 0.114       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.114       |
| reward             | -0.40254623 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.59e+03   |
| time/              |             |
|    fps             | 98          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 2048        |
------------------------------------
-------------------------------------------
| avg_speed                | 0.797        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.797        |
| reward                   | -0.8889552   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.84e+03    |
| time/                    |              |
|    fps                   | 96           |
|    iterations            | 2            |
|    time_elapsed          | 42           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0033232816 |
|    clip_fraction         | 0.0258       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.8         |
|    cost_value_loss       | 221          |
|    cost_values           | 0.22         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.00357      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 473          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 1            |
|    value_loss            | 808          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.01         |
| reward                   | -1.0131344   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.72e+03    |
| time/                    |              |
|    fps                   | 95           |
|    iterations            | 3            |
|    time_elapsed          | 64           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0040137796 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.2         |
|    cost_value_loss       | 200          |
|    cost_values           | 0.656        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0669       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 770          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 1.01         |
|    value_loss            | 1.4e+03      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.68         |
| reward                   | -0.9305225   |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 95           |
|    iterations            | 4            |
|    time_elapsed          | 86           |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0046451176 |
|    clip_fraction         | 0.0359       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.61         |
|    cost_value_loss       | 137          |
|    cost_values           | 0.993        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.139        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 430          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 1            |
|    value_loss            | 758          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.01         |
| reward                   | -0.43837827  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 5            |
|    time_elapsed          | 107          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0045402986 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.58         |
|    cost_value_loss       | 104          |
|    cost_values           | 1.23         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.201        |
|    lagrangian_multiplier | 0.00966      |
|    learning_rate         | 0.0003       |
|    loss                  | 41.9         |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00386     |
|    std                   | 1.01         |
|    value_loss            | 407          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.39         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.39         |
| reward                   | -0.7189703   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 6            |
|    time_elapsed          | 129          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0045278408 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 0.126        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.327       |
|    lagrangian_multiplier | 0.00192      |
|    learning_rate         | 0.0003       |
|    loss                  | 75.3         |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 1.01         |
|    value_loss            | 342          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.28         |
| reward                   | -1.0980954   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 7            |
|    time_elapsed          | 150          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0046761995 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.94         |
|    cost_value_loss       | 100          |
|    cost_values           | 0.341        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.425       |
|    lagrangian_multiplier | 0.00277      |
|    learning_rate         | 0.0003       |
|    loss                  | 120          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 1.01         |
|    value_loss            | 522          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.56         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.56         |
| reward                   | -1.3248767   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 8            |
|    time_elapsed          | 172          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0039393315 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.21         |
|    cost_value_loss       | 29.9         |
|    cost_values           | 1.13         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.307        |
|    lagrangian_multiplier | 0.00273      |
|    learning_rate         | 0.0003       |
|    loss                  | 56.4         |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 1.01         |
|    value_loss            | 242          |
-------------------------------------------
slurmstepd: error: *** JOB 124295 ON gail.ist.berkeley.edu CANCELLED AT 2024-01-30T09:45:24 ***
slurmstepd: error: *** STEP 124295.0 ON gail.ist.berkeley.edu CANCELLED AT 2024-01-30T09:45:24 ***
