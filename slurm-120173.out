wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240123_021837-tggzx3rw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-frost-48
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/seed-testing
wandb: üöÄ View run at https://wandb.ai/ecrl/seed-testing/runs/tggzx3rw
Using cpu device
------------------------------------
| avg_speed          | 0.114       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.114       |
| reward             | -0.40254623 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.59e+03   |
| time/              |             |
|    fps             | 98          |
|    iterations      | 1           |
|    time_elapsed    | 20          |
|    total_timesteps | 2048        |
------------------------------------
-------------------------------------------
| avg_speed                | 0.797        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.797        |
| reward                   | -0.8889552   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.84e+03    |
| time/                    |              |
|    fps                   | 96           |
|    iterations            | 2            |
|    time_elapsed          | 42           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0033232816 |
|    clip_fraction         | 0.0258       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.8         |
|    cost_value_loss       | 221          |
|    cost_values           | 0.22         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.00357      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 473          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 1            |
|    value_loss            | 808          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.01         |
| reward                   | -1.0131344   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.72e+03    |
| time/                    |              |
|    fps                   | 95           |
|    iterations            | 3            |
|    time_elapsed          | 64           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0040137796 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.2         |
|    cost_value_loss       | 200          |
|    cost_values           | 0.656        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0669       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 770          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 1.01         |
|    value_loss            | 1.4e+03      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.68         |
| reward                   | -0.9305225   |
| rollout/                 |              |
|    ep_len_mean           | 894          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 95           |
|    iterations            | 4            |
|    time_elapsed          | 86           |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0046451176 |
|    clip_fraction         | 0.0359       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.61         |
|    cost_value_loss       | 137          |
|    cost_values           | 0.993        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.139        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 430          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 1            |
|    value_loss            | 758          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.01         |
| reward                   | -0.43837827  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 5            |
|    time_elapsed          | 107          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0045402986 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.58         |
|    cost_value_loss       | 104          |
|    cost_values           | 1.23         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.201        |
|    lagrangian_multiplier | 0.00966      |
|    learning_rate         | 0.0003       |
|    loss                  | 41.9         |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00386     |
|    std                   | 1.01         |
|    value_loss            | 407          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.39         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.39         |
| reward                   | -0.7189703   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 6            |
|    time_elapsed          | 129          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0045278408 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 0.126        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.327       |
|    lagrangian_multiplier | 0.00192      |
|    learning_rate         | 0.0003       |
|    loss                  | 75.3         |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 1.01         |
|    value_loss            | 342          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.28         |
| reward                   | -1.0980954   |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 7            |
|    time_elapsed          | 152          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0046761995 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.94         |
|    cost_value_loss       | 100          |
|    cost_values           | 0.341        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.425       |
|    lagrangian_multiplier | 0.00277      |
|    learning_rate         | 0.0003       |
|    loss                  | 120          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 1.01         |
|    value_loss            | 522          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.56         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.56         |
| reward                   | -1.3248767   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 8            |
|    time_elapsed          | 174          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0039393315 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.21         |
|    cost_value_loss       | 29.9         |
|    cost_values           | 1.13         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.307        |
|    lagrangian_multiplier | 0.00273      |
|    learning_rate         | 0.0003       |
|    loss                  | 56.4         |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 1.01         |
|    value_loss            | 242          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.71        |
| reward                   | -1.868908   |
| rollout/                 |             |
|    ep_len_mean           | 950         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 9           |
|    time_elapsed          | 195         |
|    total_timesteps       | 18432       |
| train/                   |             |
|    approx_kl             | 0.004316902 |
|    clip_fraction         | 0.0545      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.19        |
|    cost_value_loss       | 119         |
|    cost_values           | 1.62        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.122       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 134         |
|    n_updates             | 80          |
|    policy_gradient_loss  | -0.00592    |
|    std                   | 1.01        |
|    value_loss            | 181         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.787       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.787       |
| reward                   | -1.8983787  |
| rollout/                 |             |
|    ep_len_mean           | 955         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 10          |
|    time_elapsed          | 217         |
|    total_timesteps       | 20480       |
| train/                   |             |
|    approx_kl             | 0.001733542 |
|    clip_fraction         | 0.000732    |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 182         |
|    cost_values           | 1.01        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.0644      |
|    lagrangian_multiplier | 0.000929    |
|    learning_rate         | 0.0003      |
|    loss                  | 198         |
|    n_updates             | 90          |
|    policy_gradient_loss  | -0.000686   |
|    std                   | 1.01        |
|    value_loss            | 437         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.9          |
| reward                   | -1.2134907   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 239          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0026256659 |
|    clip_fraction         | 0.00425      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.4         |
|    cost_value_loss       | 147          |
|    cost_values           | 0.949        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.438       |
|    lagrangian_multiplier | 0.000906     |
|    learning_rate         | 0.0003       |
|    loss                  | 214          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.000964    |
|    std                   | 1.01         |
|    value_loss            | 552          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.56        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.56        |
| reward                   | -1.3401548  |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 12          |
|    time_elapsed          | 262         |
|    total_timesteps       | 24576       |
| train/                   |             |
|    approx_kl             | 0.005886983 |
|    clip_fraction         | 0.0412      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.26        |
|    cost_value_loss       | 102         |
|    cost_values           | 1.1         |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | -0.566      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 285         |
|    n_updates             | 110         |
|    policy_gradient_loss  | -0.00452    |
|    std                   | 1.01        |
|    value_loss            | 584         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.37         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.37         |
| reward                   | -1.3454003   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 13           |
|    time_elapsed          | 284          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0069873864 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.6         |
|    cost_value_loss       | 168          |
|    cost_values           | 1.68         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.389       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 276          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00398     |
|    std                   | 1.01         |
|    value_loss            | 464          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.24         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.24         |
| reward                   | -1.0179756   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 306          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0073965006 |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_returns          | 14.4         |
|    cost_value_loss       | 185          |
|    cost_values           | 2.5          |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.207        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 318          |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00452     |
|    std                   | 1.01         |
|    value_loss            | 463          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.69         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.69         |
| reward                   | -1.7717607   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 15           |
|    time_elapsed          | 327          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0024980325 |
|    clip_fraction         | 0.00259      |
|    clip_range            | 0.2          |
|    cost_returns          | 12.2         |
|    cost_value_loss       | 148          |
|    cost_values           | 2.75         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0678       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 174          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 1.01         |
|    value_loss            | 230          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -1.6648998   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 16           |
|    time_elapsed          | 349          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0020775348 |
|    clip_fraction         | 0.00132      |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 234          |
|    cost_values           | 0.566        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -1.99        |
|    lagrangian_multiplier | 0.0221       |
|    learning_rate         | 0.0003       |
|    loss                  | 31.6         |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 1.01         |
|    value_loss            | 554          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -2.4647408   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 371          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0046269596 |
|    clip_fraction         | 0.0464       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.3         |
|    cost_value_loss       | 163          |
|    cost_values           | 1.96         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.16         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 418          |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.00473     |
|    std                   | 1.01         |
|    value_loss            | 698          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.28         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.28         |
| reward                   | -1.3516723   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 18           |
|    time_elapsed          | 393          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0057348446 |
|    clip_fraction         | 0.0253       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.4         |
|    cost_value_loss       | 219          |
|    cost_values           | 2.46         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.188        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 405          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00329     |
|    std                   | 1.01         |
|    value_loss            | 635          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.56        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.56        |
| reward                   | -1.7124499  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 19          |
|    time_elapsed          | 414         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.006084362 |
|    clip_fraction         | 0.0321      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 179         |
|    cost_values           | 2.18        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.116       |
|    lagrangian_multiplier | 0.000718    |
|    learning_rate         | 0.0003      |
|    loss                  | 203         |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.00366    |
|    std                   | 1.01        |
|    value_loss            | 444         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.8343674   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 20           |
|    time_elapsed          | 436          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0052224156 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.5         |
|    cost_value_loss       | 227          |
|    cost_values           | 1.23         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -2.23        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 202          |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 1.01         |
|    value_loss            | 302          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -2.0948963   |
| rollout/                 |              |
|    ep_len_mean           | 979          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 21           |
|    time_elapsed          | 458          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0030370515 |
|    clip_fraction         | 0.00371      |
|    clip_range            | 0.2          |
|    cost_returns          | 15.5         |
|    cost_value_loss       | 213          |
|    cost_values           | 1.93         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.829       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 358          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 1            |
|    value_loss            | 665          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -2.9895685  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -1.33e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 22          |
|    time_elapsed          | 480         |
|    total_timesteps       | 45056       |
| train/                   |             |
|    approx_kl             | 0.004908375 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.5        |
|    cost_value_loss       | 182         |
|    cost_values           | 2.61        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -0.398      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 395         |
|    n_updates             | 210         |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 1           |
|    value_loss            | 643         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.329        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.329        |
| reward                   | -0.5215398   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 23           |
|    time_elapsed          | 501          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0047939476 |
|    clip_fraction         | 0.0181       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.9         |
|    cost_value_loss       | 238          |
|    cost_values           | 2.91         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.000311    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 590          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 1            |
|    value_loss            | 1.01e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.701        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.701        |
| reward                   | -0.63049036  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 24           |
|    time_elapsed          | 523          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0052352096 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 16.7         |
|    cost_value_loss       | 217          |
|    cost_values           | 3.08         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0338       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 598          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 1.01         |
|    value_loss            | 1.02e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.91         |
| reward                   | -0.6667831   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 25           |
|    time_elapsed          | 545          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0055386196 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.1         |
|    cost_value_loss       | 219          |
|    cost_values           | 3.23         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0553       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 274          |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.00218     |
|    std                   | 1            |
|    value_loss            | 347          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.59         |
| reward                   | -0.55567837  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 26           |
|    time_elapsed          | 567          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0046763117 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 159          |
|    cost_values           | 3.46         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.0524      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 194          |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00382     |
|    std                   | 1            |
|    value_loss            | 270          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.66        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.66        |
| reward                   | -0.9561138  |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 27          |
|    time_elapsed          | 588         |
|    total_timesteps       | 55296       |
| train/                   |             |
|    approx_kl             | 0.005290906 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.4        |
|    cost_value_loss       | 214         |
|    cost_values           | 3.79        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.0684      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 209         |
|    n_updates             | 260         |
|    policy_gradient_loss  | -0.00359    |
|    std                   | 1           |
|    value_loss            | 215         |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.3        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.3        |
| reward                   | -1.3481423 |
| rollout/                 |            |
|    ep_len_mean           | 969        |
|    ep_rew_mean           | -1.31e+03  |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 28         |
|    time_elapsed          | 610        |
|    total_timesteps       | 57344      |
| train/                   |            |
|    approx_kl             | 0.00393389 |
|    clip_fraction         | 0.0302     |
|    clip_range            | 0.2        |
|    cost_returns          | 17.4       |
|    cost_value_loss       | 206        |
|    cost_values           | 4.23       |
|    entropy               | -2.85      |
|    entropy_loss          | -2.85      |
|    explained_variance    | 0.0909     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 181        |
|    n_updates             | 270        |
|    policy_gradient_loss  | -0.00344   |
|    std                   | 1.01       |
|    value_loss            | 177        |
-----------------------------------------
--------------------------------------------
| avg_speed                | 6.23          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 6.23          |
| reward                   | -0.6040041    |
| rollout/                 |               |
|    ep_len_mean           | 970           |
|    ep_rew_mean           | -1.31e+03     |
| time/                    |               |
|    fps                   | 93            |
|    iterations            | 29            |
|    time_elapsed          | 632           |
|    total_timesteps       | 59392         |
| train/                   |               |
|    approx_kl             | 0.00017351363 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 9.16          |
|    cost_value_loss       | 95.2          |
|    cost_values           | 2.85          |
|    entropy               | -2.85         |
|    entropy_loss          | -2.85         |
|    explained_variance    | -2.99         |
|    lagrangian_multiplier | 0.456         |
|    learning_rate         | 0.0003        |
|    loss                  | 4.72          |
|    n_updates             | 280           |
|    policy_gradient_loss  | -0.000278     |
|    std                   | 1.01          |
|    value_loss            | 552           |
--------------------------------------------
-------------------------------------------
| avg_speed                | 6.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.02         |
| reward                   | -0.9262051   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 30           |
|    time_elapsed          | 654          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0057319286 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 158          |
|    cost_values           | 3.3          |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | -0.0214      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 189          |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00413     |
|    std                   | 1.01         |
|    value_loss            | 240          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.31        |
| reward                   | -1.5552375  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 31          |
|    time_elapsed          | 676         |
|    total_timesteps       | 63488       |
| train/                   |             |
|    approx_kl             | 0.003940582 |
|    clip_fraction         | 0.0136      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 176         |
|    cost_values           | 3           |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -0.175      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 204         |
|    n_updates             | 300         |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 1.01        |
|    value_loss            | 260         |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.66         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.66         |
| reward                   | -0.5988679   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 32           |
|    time_elapsed          | 698          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0028734924 |
|    clip_fraction         | 0.00483      |
|    clip_range            | 0.2          |
|    cost_returns          | 15.6         |
|    cost_value_loss       | 202          |
|    cost_values           | 2.92         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.382       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 378          |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 1.01         |
|    value_loss            | 601          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.59         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.59         |
| reward                   | -2.1368067   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 33           |
|    time_elapsed          | 720          |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0053419173 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.84         |
|    cost_value_loss       | 90.2         |
|    cost_values           | 3.07         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0115       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 242          |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00353     |
|    std                   | 1.01         |
|    value_loss            | 424          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -1.4713563   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.35e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 34           |
|    time_elapsed          | 743          |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0068123476 |
|    clip_fraction         | 0.0276       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.4         |
|    cost_value_loss       | 196          |
|    cost_values           | 3.09         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0229       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 615          |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 1.02         |
|    value_loss            | 1.07e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.95         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.95         |
| reward                   | -2.2651825   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.35e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 35           |
|    time_elapsed          | 764          |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0026749899 |
|    clip_fraction         | 0.00313      |
|    clip_range            | 0.2          |
|    cost_returns          | 16.2         |
|    cost_value_loss       | 207          |
|    cost_values           | 3.16         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0164       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 538          |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00157     |
|    std                   | 1.01         |
|    value_loss            | 867          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.31        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.31        |
| reward                   | -1.6881467  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.36e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 36          |
|    time_elapsed          | 786         |
|    total_timesteps       | 73728       |
| train/                   |             |
|    approx_kl             | 0.002452142 |
|    clip_fraction         | 0.00449     |
|    clip_range            | 0.2         |
|    cost_returns          | 16          |
|    cost_value_loss       | 202         |
|    cost_values           | 3.29        |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.0423      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 359         |
|    n_updates             | 350         |
|    policy_gradient_loss  | -0.00127    |
|    std                   | 1.02        |
|    value_loss            | 561         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.55         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.55         |
| reward                   | -2.0839257   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 37           |
|    time_elapsed          | 808          |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0038357952 |
|    clip_fraction         | 0.00698      |
|    clip_range            | 0.2          |
|    cost_returns          | 17.9         |
|    cost_value_loss       | 228          |
|    cost_values           | 3.46         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0216       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 423          |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00201     |
|    std                   | 1.02         |
|    value_loss            | 661          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.17         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.17         |
| reward                   | -1.467887    |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 38           |
|    time_elapsed          | 830          |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0068908897 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.8         |
|    cost_value_loss       | 203          |
|    cost_values           | 3.66         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0593       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 278          |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00424     |
|    std                   | 1.02         |
|    value_loss            | 366          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.537       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.537       |
| reward                   | -1.7116201  |
| rollout/                 |             |
|    ep_len_mean           | 977         |
|    ep_rew_mean           | -1.36e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 39          |
|    time_elapsed          | 852         |
|    total_timesteps       | 79872       |
| train/                   |             |
|    approx_kl             | 0.005244083 |
|    clip_fraction         | 0.0369      |
|    clip_range            | 0.2         |
|    cost_returns          | 19.1        |
|    cost_value_loss       | 238         |
|    cost_values           | 3.93        |
|    entropy               | -2.87       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.0443      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 295         |
|    n_updates             | 380         |
|    policy_gradient_loss  | -0.00495    |
|    std                   | 1.02        |
|    value_loss            | 383         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.1          |
| reward                   | -1.6550214   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 40           |
|    time_elapsed          | 873          |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0030259984 |
|    clip_fraction         | 0.00503      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.43         |
|    cost_value_loss       | 70.9         |
|    cost_values           | 4.12         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0285       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 283          |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 1.02         |
|    value_loss            | 516          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.64         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.64         |
| reward                   | -1.7286128   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.35e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 41           |
|    time_elapsed          | 895          |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0049588624 |
|    clip_fraction         | 0.0587       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.81         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 3.97         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.0306       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 197          |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 1.02         |
|    value_loss            | 418          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.73         |
| reward                   | -2.6479084   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 42           |
|    time_elapsed          | 917          |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0034430912 |
|    clip_fraction         | 0.00869      |
|    clip_range            | 0.2          |
|    cost_returns          | 13.7         |
|    cost_value_loss       | 150          |
|    cost_values           | 3.82         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.0272       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 289          |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 1.02         |
|    value_loss            | 453          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.08         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.08         |
| reward                   | -2.9442997   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 43           |
|    time_elapsed          | 939          |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0055274437 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.7         |
|    cost_value_loss       | 200          |
|    cost_values           | 3.93         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0351       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 462          |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00288     |
|    std                   | 1.02         |
|    value_loss            | 715          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.57        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.57        |
| reward                   | -2.1279705  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 44          |
|    time_elapsed          | 961         |
|    total_timesteps       | 90112       |
| train/                   |             |
|    approx_kl             | 0.004054915 |
|    clip_fraction         | 0.0125      |
|    clip_range            | 0.2         |
|    cost_returns          | 18.8        |
|    cost_value_loss       | 232         |
|    cost_values           | 4.06        |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.0262      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 522         |
|    n_updates             | 430         |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 1.02        |
|    value_loss            | 834         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.7         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.7         |
| reward                   | -1.688327   |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 45          |
|    time_elapsed          | 983         |
|    total_timesteps       | 92160       |
| train/                   |             |
|    approx_kl             | 0.004969002 |
|    clip_fraction         | 0.0404      |
|    clip_range            | 0.2         |
|    cost_returns          | 16.7        |
|    cost_value_loss       | 189         |
|    cost_values           | 4.21        |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.0221      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 384         |
|    n_updates             | 440         |
|    policy_gradient_loss  | -0.0042     |
|    std                   | 1.02        |
|    value_loss            | 615         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.569        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.569        |
| reward                   | -2.446192    |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 46           |
|    time_elapsed          | 1005         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0043166187 |
|    clip_fraction         | 0.0393       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 152          |
|    cost_values           | 4.36         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0223       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 256          |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00421     |
|    std                   | 1.03         |
|    value_loss            | 369          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.41         |
| reward                   | -0.40558296  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 47           |
|    time_elapsed          | 1027         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0066961106 |
|    clip_fraction         | 0.0547       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.7         |
|    cost_value_loss       | 172          |
|    cost_values           | 4.51         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0344       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 304          |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00431     |
|    std                   | 1.03         |
|    value_loss            | 440          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.47        |
| reward                   | -0.7106321  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.39e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 48          |
|    time_elapsed          | 1049        |
|    total_timesteps       | 98304       |
| train/                   |             |
|    approx_kl             | 0.004895716 |
|    clip_fraction         | 0.0142      |
|    clip_range            | 0.2         |
|    cost_returns          | 19          |
|    cost_value_loss       | 224         |
|    cost_values           | 4.67        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.026       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 469         |
|    n_updates             | 470         |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 1.03        |
|    value_loss            | 747         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.07        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.07        |
| reward                   | -0.72190547 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.39e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 49          |
|    time_elapsed          | 1071        |
|    total_timesteps       | 100352      |
| train/                   |             |
|    approx_kl             | 0.00372338  |
|    clip_fraction         | 0.0241      |
|    clip_range            | 0.2         |
|    cost_returns          | 18          |
|    cost_value_loss       | 201         |
|    cost_values           | 4.85        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.0351      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 301         |
|    n_updates             | 480         |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 1.03        |
|    value_loss            | 413         |
------------------------------------------
Directory created: PPOL_New/models/seed-testing/tggzx3rw/model_epoch(0)
------------------------------------
| avg_speed          | 3.78        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 3.78        |
| reward             | -0.79681325 |
| rollout/           |             |
|    ep_len_mean     | 972         |
|    ep_rew_mean     | -1.38e+03   |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 102400      |
------------------------------------
-------------------------------------------
| avg_speed                | 2.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.23         |
| reward                   | -0.8544611   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0044582016 |
|    clip_fraction         | 0.0395       |
|    clip_range            | 0.2          |
|    cost_returns          | 19.1         |
|    cost_value_loss       | 215          |
|    cost_values           | 5.29         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0272       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 329          |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 1.03         |
|    value_loss            | 461          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.3469795   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0034329372 |
|    clip_fraction         | 0.0159       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.7         |
|    cost_value_loss       | 188          |
|    cost_values           | 5.52         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0463       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 230          |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00135     |
|    std                   | 1.03         |
|    value_loss            | 295          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.17       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 7.17       |
| reward                   | -2.0410974 |
| rollout/                 |            |
|    ep_len_mean           | 982        |
|    ep_rew_mean           | -1.42e+03  |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 4          |
|    time_elapsed          | 87         |
|    total_timesteps       | 108544     |
| train/                   |            |
|    approx_kl             | 0.00566599 |
|    clip_fraction         | 0.0287     |
|    clip_range            | 0.2        |
|    cost_returns          | 18.1       |
|    cost_value_loss       | 191        |
|    cost_values           | 5.76       |
|    entropy               | -2.9       |
|    entropy_loss          | -2.9       |
|    explained_variance    | 0.0313     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 324        |
|    n_updates             | 520        |
|    policy_gradient_loss  | -0.00287   |
|    std                   | 1.03       |
|    value_loss            | 464        |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -1.7969292  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.43e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 110592      |
| train/                   |             |
|    approx_kl             | 0.007093201 |
|    clip_fraction         | 0.0365      |
|    clip_range            | 0.2         |
|    cost_returns          | 20          |
|    cost_value_loss       | 214         |
|    cost_values           | 5.93        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.0168      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 482         |
|    n_updates             | 530         |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 1.03        |
|    value_loss            | 747         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -1.9992356  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.45e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 112640      |
| train/                   |             |
|    approx_kl             | 0.005042837 |
|    clip_fraction         | 0.0147      |
|    clip_range            | 0.2         |
|    cost_returns          | 20.3        |
|    cost_value_loss       | 220         |
|    cost_values           | 6.07        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.0186      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 491         |
|    n_updates             | 540         |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 1.03        |
|    value_loss            | 763         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -1.890829    |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.48e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0032283566 |
|    clip_fraction         | 0.00586      |
|    clip_range            | 0.2          |
|    cost_returns          | 20.7         |
|    cost_value_loss       | 224          |
|    cost_values           | 6.21         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00637      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 509          |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 1.03         |
|    value_loss            | 812          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.47        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.47        |
| reward                   | -1.7725544  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.49e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 175         |
|    total_timesteps       | 116736      |
| train/                   |             |
|    approx_kl             | 0.007306036 |
|    clip_fraction         | 0.046       |
|    clip_range            | 0.2         |
|    cost_returns          | 20.7        |
|    cost_value_loss       | 221         |
|    cost_values           | 6.36        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.0389      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 433         |
|    n_updates             | 560         |
|    policy_gradient_loss  | -0.00337    |
|    std                   | 1.03        |
|    value_loss            | 651         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.8977078   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.49e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 197          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0040775584 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 21.1         |
|    cost_value_loss       | 223          |
|    cost_values           | 6.55         |
|    entropy               | -2.89        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0191       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 371          |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 1.03         |
|    value_loss            | 551          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.8933896   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.5e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 219          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0034786174 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 20.8         |
|    cost_value_loss       | 216          |
|    cost_values           | 6.73         |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0267       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 398          |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 1.03         |
|    value_loss            | 582          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.52        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.52        |
| reward                   | -1.8410132  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.5e+03    |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 11          |
|    time_elapsed          | 241         |
|    total_timesteps       | 122880      |
| train/                   |             |
|    approx_kl             | 0.003837056 |
|    clip_fraction         | 0.0257      |
|    clip_range            | 0.2         |
|    cost_returns          | 21.3        |
|    cost_value_loss       | 220         |
|    cost_values           | 6.93        |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.0228      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 368         |
|    n_updates             | 590         |
|    policy_gradient_loss  | -0.00303    |
|    std                   | 1.02        |
|    value_loss            | 522         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.7580503  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.51e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 12          |
|    time_elapsed          | 263         |
|    total_timesteps       | 124928      |
| train/                   |             |
|    approx_kl             | 0.004203935 |
|    clip_fraction         | 0.0295      |
|    clip_range            | 0.2         |
|    cost_returns          | 20.6        |
|    cost_value_loss       | 207         |
|    cost_values           | 7.12        |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.032       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 383         |
|    n_updates             | 600         |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 1.02        |
|    value_loss            | 559         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.5          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.5          |
| reward                   | -2.2733004   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.52e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 13           |
|    time_elapsed          | 284          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0075534657 |
|    clip_fraction         | 0.0441       |
|    clip_range            | 0.2          |
|    cost_returns          | 20.5         |
|    cost_value_loss       | 201          |
|    cost_values           | 7.33         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0316       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 265          |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00412     |
|    std                   | 1.02         |
|    value_loss            | 348          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.78        |
| reward                   | -2.1387677  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.53e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 14          |
|    time_elapsed          | 306         |
|    total_timesteps       | 129024      |
| train/                   |             |
|    approx_kl             | 0.005613838 |
|    clip_fraction         | 0.0324      |
|    clip_range            | 0.2         |
|    cost_returns          | 21.1        |
|    cost_value_loss       | 206         |
|    cost_values           | 7.56        |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.0389      |
|    lagrangian_multiplier | 0.00392     |
|    learning_rate         | 0.0003      |
|    loss                  | 113         |
|    n_updates             | 620         |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 1.02        |
|    value_loss            | 430         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.79        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.79        |
| reward                   | -1.9795334  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.53e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 15          |
|    time_elapsed          | 328         |
|    total_timesteps       | 131072      |
| train/                   |             |
|    approx_kl             | 0.006345902 |
|    clip_fraction         | 0.0596      |
|    clip_range            | 0.2         |
|    cost_returns          | 19.3        |
|    cost_value_loss       | 179         |
|    cost_values           | 7.76        |
|    entropy               | -2.89       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.0203      |
|    lagrangian_multiplier | 0.00268     |
|    learning_rate         | 0.0003      |
|    loss                  | 139         |
|    n_updates             | 630         |
|    policy_gradient_loss  | -0.00586    |
|    std                   | 1.03        |
|    value_loss            | 491         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.43        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.43        |
| reward                   | -1.8229542  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.52e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 16          |
|    time_elapsed          | 350         |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.004335129 |
|    clip_fraction         | 0.034       |
|    clip_range            | 0.2         |
|    cost_returns          | 19.3        |
|    cost_value_loss       | 171         |
|    cost_values           | 7.88        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.0283      |
|    lagrangian_multiplier | 0.0138      |
|    learning_rate         | 0.0003      |
|    loss                  | 38.4        |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.00274    |
|    std                   | 1.03        |
|    value_loss            | 348         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.19        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.19        |
| reward                   | -1.7232246  |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -1.52e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 17          |
|    time_elapsed          | 372         |
|    total_timesteps       | 135168      |
| train/                   |             |
|    approx_kl             | 0.004255255 |
|    clip_fraction         | 0.0321      |
|    clip_range            | 0.2         |
|    cost_returns          | 18.6        |
|    cost_value_loss       | 164         |
|    cost_values           | 7.91        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.0265      |
|    lagrangian_multiplier | 0.0124      |
|    learning_rate         | 0.0003      |
|    loss                  | 38.3        |
|    n_updates             | 650         |
|    policy_gradient_loss  | -0.00284    |
|    std                   | 1.03        |
|    value_loss            | 277         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.12         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.12         |
| reward                   | -1.9766366   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.53e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 18           |
|    time_elapsed          | 394          |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0062882905 |
|    clip_fraction         | 0.0405       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.4         |
|    cost_value_loss       | 146          |
|    cost_values           | 7.89         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0285       |
|    lagrangian_multiplier | 0.00706      |
|    learning_rate         | 0.0003       |
|    loss                  | 56.7         |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.00502     |
|    std                   | 1.04         |
|    value_loss            | 344          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 6.79       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.79       |
| reward                   | -2.0595024 |
| rollout/                 |            |
|    ep_len_mean           | 982        |
|    ep_rew_mean           | -1.52e+03  |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 19         |
|    time_elapsed          | 417        |
|    total_timesteps       | 139264     |
| train/                   |            |
|    approx_kl             | 0.00499549 |
|    clip_fraction         | 0.0521     |
|    clip_range            | 0.2        |
|    cost_returns          | 16.1       |
|    cost_value_loss       | 131        |
|    cost_values           | 7.88       |
|    entropy               | -2.91      |
|    entropy_loss          | -2.91      |
|    explained_variance    | 0.0353     |
|    lagrangian_multiplier | 0.00618    |
|    learning_rate         | 0.0003     |
|    loss                  | 46.8       |
|    n_updates             | 670        |
|    policy_gradient_loss  | -0.00516   |
|    std                   | 1.04       |
|    value_loss            | 218        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.660137    |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.48e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 20           |
|    time_elapsed          | 440          |
|    total_timesteps       | 141312       |
| train/                   |              |
|    approx_kl             | 0.0032964589 |
|    clip_fraction         | 0.0262       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.5         |
|    cost_value_loss       | 166          |
|    cost_values           | 7.86         |
|    entropy               | -2.93        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.0407       |
|    lagrangian_multiplier | 0.0151       |
|    learning_rate         | 0.0003       |
|    loss                  | 27.5         |
|    n_updates             | 680          |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 1.05         |
|    value_loss            | 199          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.6          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.6          |
| reward                   | -1.825238    |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.47e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 21           |
|    time_elapsed          | 462          |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0036162457 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.9         |
|    cost_value_loss       | 157          |
|    cost_values           | 7.83         |
|    entropy               | -2.95        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.0403       |
|    lagrangian_multiplier | 0.0152       |
|    learning_rate         | 0.0003       |
|    loss                  | 26.4         |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 1.06         |
|    value_loss            | 193          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -1.718439    |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.46e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 22           |
|    time_elapsed          | 484          |
|    total_timesteps       | 145408       |
| train/                   |              |
|    approx_kl             | 0.0048229746 |
|    clip_fraction         | 0.056        |
|    clip_range            | 0.2          |
|    cost_returns          | 19.7         |
|    cost_value_loss       | 181          |
|    cost_values           | 7.8          |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.0537       |
|    lagrangian_multiplier | 0.0136       |
|    learning_rate         | 0.0003       |
|    loss                  | 36.9         |
|    n_updates             | 700          |
|    policy_gradient_loss  | -0.00427     |
|    std                   | 1.06         |
|    value_loss            | 292          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -2.0040846   |
| rollout/                 |              |
|    ep_len_mean           | 955          |
|    ep_rew_mean           | -1.45e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 506          |
|    total_timesteps       | 147456       |
| train/                   |              |
|    approx_kl             | 0.0067432136 |
|    clip_fraction         | 0.0408       |
|    clip_range            | 0.2          |
|    cost_returns          | 21           |
|    cost_value_loss       | 202          |
|    cost_values           | 7.83         |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.0631       |
|    lagrangian_multiplier | 0.0122       |
|    learning_rate         | 0.0003       |
|    loss                  | 36.2         |
|    n_updates             | 710          |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 1.06         |
|    value_loss            | 235          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -1.8287692  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 528         |
|    total_timesteps       | 149504      |
| train/                   |             |
|    approx_kl             | 0.006215118 |
|    clip_fraction         | 0.0495      |
|    clip_range            | 0.2         |
|    cost_returns          | 19.2        |
|    cost_value_loss       | 175         |
|    cost_values           | 7.8         |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.0528      |
|    lagrangian_multiplier | 0.0153      |
|    learning_rate         | 0.0003      |
|    loss                  | 27.3        |
|    n_updates             | 720         |
|    policy_gradient_loss  | -0.00358    |
|    std                   | 1.06        |
|    value_loss            | 191         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.47        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.47        |
| reward                   | -1.5027053  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 550         |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.005242119 |
|    clip_fraction         | 0.0276      |
|    clip_range            | 0.2         |
|    cost_returns          | 20          |
|    cost_value_loss       | 189         |
|    cost_values           | 7.72        |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.062       |
|    lagrangian_multiplier | 0.0156      |
|    learning_rate         | 0.0003      |
|    loss                  | 33.7        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 1.06        |
|    value_loss            | 292         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.931       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.931       |
| reward                   | -0.45491612 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 573         |
|    total_timesteps       | 153600      |
| train/                   |             |
|    approx_kl             | 0.003931978 |
|    clip_fraction         | 0.0386      |
|    clip_range            | 0.2         |
|    cost_returns          | 19.8        |
|    cost_value_loss       | 195         |
|    cost_values           | 7.33        |
|    entropy               | -2.94       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.00408     |
|    lagrangian_multiplier | 0.00731     |
|    learning_rate         | 0.0003      |
|    loss                  | 35.3        |
|    n_updates             | 740         |
|    policy_gradient_loss  | -0.00484    |
|    std                   | 1.05        |
|    value_loss            | 93.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.66        |
| reward                   | -0.8455397  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.47e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 595         |
|    total_timesteps       | 155648      |
| train/                   |             |
|    approx_kl             | 0.003908477 |
|    clip_fraction         | 0.0221      |
|    clip_range            | 0.2         |
|    cost_returns          | 18          |
|    cost_value_loss       | 166         |
|    cost_values           | 7.18        |
|    entropy               | -2.95       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.0852      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 174         |
|    n_updates             | 750         |
|    policy_gradient_loss  | -0.00247    |
|    std                   | 1.06        |
|    value_loss            | 200         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.522        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.522        |
| reward                   | -0.42557153  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.48e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 617          |
|    total_timesteps       | 157696       |
| train/                   |              |
|    approx_kl             | 0.0001266757 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 16.3         |
|    cost_value_loss       | 165          |
|    cost_values           | 5.85         |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.282        |
|    lagrangian_multiplier | 1.07         |
|    learning_rate         | 0.0003       |
|    loss                  | 6.67         |
|    n_updates             | 760          |
|    policy_gradient_loss  | 0.000417     |
|    std                   | 1.06         |
|    value_loss            | 258          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.02        |
| reward                   | -0.80836886 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.46e+03   |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 639         |
|    total_timesteps       | 159744      |
| train/                   |             |
|    approx_kl             | 0.005682827 |
|    clip_fraction         | 0.056       |
|    clip_range            | 0.2         |
|    cost_returns          | 19.4        |
|    cost_value_loss       | 205         |
|    cost_values           | 6.37        |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | -0.0207     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 185         |
|    n_updates             | 770         |
|    policy_gradient_loss  | -0.00578    |
|    std                   | 1.06        |
|    value_loss            | 175         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.3          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.3          |
| reward                   | -1.4046807   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.45e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 662          |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0037181212 |
|    clip_fraction         | 0.0313       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.4         |
|    cost_value_loss       | 162          |
|    cost_values           | 6.7          |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.103        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 99.4         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 1.06         |
|    value_loss            | 44.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.656        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.656        |
| reward                   | -0.37265685  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.43e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 684          |
|    total_timesteps       | 163840       |
| train/                   |              |
|    approx_kl             | 0.0058237263 |
|    clip_fraction         | 0.0698       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.1         |
|    cost_value_loss       | 104          |
|    cost_values           | 6.87         |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.104        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.8         |
|    n_updates             | 790          |
|    policy_gradient_loss  | -0.00722     |
|    std                   | 1.07         |
|    value_loss            | 29.6         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.592         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.592         |
| reward                   | -0.49198106   |
| rollout/                 |               |
|    ep_len_mean           | 964           |
|    ep_rew_mean           | -1.41e+03     |
| time/                    |               |
|    fps                   | 92            |
|    iterations            | 32            |
|    time_elapsed          | 706           |
|    total_timesteps       | 165888        |
| train/                   |               |
|    approx_kl             | 0.00078861485 |
|    clip_fraction         | 0.000879      |
|    clip_range            | 0.2           |
|    cost_returns          | 7.73          |
|    cost_value_loss       | 40.9          |
|    cost_values           | 5.65          |
|    entropy               | -2.97         |
|    entropy_loss          | -2.97         |
|    explained_variance    | -1.66         |
|    lagrangian_multiplier | 0.741         |
|    learning_rate         | 0.0003        |
|    loss                  | 6.38          |
|    n_updates             | 800           |
|    policy_gradient_loss  | 0.000304      |
|    std                   | 1.07          |
|    value_loss            | 146           |
--------------------------------------------
------------------------------------------
| avg_speed                | 2.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.89        |
| reward                   | -0.7881201  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -1.4e+03    |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 728         |
|    total_timesteps       | 167936      |
| train/                   |             |
|    approx_kl             | 0.006235566 |
|    clip_fraction         | 0.04        |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 82.3        |
|    cost_values           | 6.16        |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.0257      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 73.4        |
|    n_updates             | 810         |
|    policy_gradient_loss  | -0.00433    |
|    std                   | 1.07        |
|    value_loss            | 75          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.361        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.361        |
| reward                   | -0.4877727   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 750          |
|    total_timesteps       | 169984       |
| train/                   |              |
|    approx_kl             | 0.0029786457 |
|    clip_fraction         | 0.00503      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.6         |
|    cost_value_loss       | 93.9         |
|    cost_values           | 5.69         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | -3.19        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 80.8         |
|    n_updates             | 820          |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 1.07         |
|    value_loss            | 141          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.24         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.24         |
| reward                   | -1.3763263   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 772          |
|    total_timesteps       | 172032       |
| train/                   |              |
|    approx_kl             | 0.0035892015 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 13.5         |
|    cost_value_loss       | 121          |
|    cost_values           | 5.9          |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.0204       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 210          |
|    n_updates             | 830          |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 1.07         |
|    value_loss            | 319          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.93         |
| reward                   | -0.6360132   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 793          |
|    total_timesteps       | 174080       |
| train/                   |              |
|    approx_kl             | 0.0035699578 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.9         |
|    cost_value_loss       | 77.9         |
|    cost_values           | 6.07         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.0258       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 108          |
|    n_updates             | 840          |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 1.07         |
|    value_loss            | 145          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0488       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0488       |
| reward                   | -0.7071089   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 815          |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0070332247 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.5         |
|    cost_value_loss       | 124          |
|    cost_values           | 5.57         |
|    entropy               | -2.98        |
|    entropy_loss          | -2.97        |
|    explained_variance    | -4.66        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 72.8         |
|    n_updates             | 850          |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 1.07         |
|    value_loss            | 89.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0924       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0924       |
| reward                   | -1.181257    |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 837          |
|    total_timesteps       | 178176       |
| train/                   |              |
|    approx_kl             | 0.0033004698 |
|    clip_fraction         | 0.012        |
|    clip_range            | 0.2          |
|    cost_returns          | 12.3         |
|    cost_value_loss       | 107          |
|    cost_values           | 5.94         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.012        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 118          |
|    n_updates             | 860          |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 1.07         |
|    value_loss            | 116          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0462       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0462       |
| reward                   | -0.9000613   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 859          |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0030833741 |
|    clip_fraction         | 0.033        |
|    clip_range            | 0.2          |
|    cost_returns          | 9.91         |
|    cost_value_loss       | 69.1         |
|    cost_values           | 6.18         |
|    entropy               | -2.98        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00727      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.4         |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 1.07         |
|    value_loss            | 61.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -1.5920886   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 40           |
|    time_elapsed          | 880          |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0026991994 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.8         |
|    cost_value_loss       | 70.6         |
|    cost_values           | 6.34         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00454      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 93.7         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 1.07         |
|    value_loss            | 117          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.09         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.09         |
| reward                   | -2.2941651   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.35e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 41           |
|    time_elapsed          | 902          |
|    total_timesteps       | 184320       |
| train/                   |              |
|    approx_kl             | 0.0042080367 |
|    clip_fraction         | 0.0497       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.1         |
|    cost_value_loss       | 78.6         |
|    cost_values           | 6.49         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00116      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66           |
|    n_updates             | 890          |
|    policy_gradient_loss  | -0.00626     |
|    std                   | 1.07         |
|    value_loss            | 65           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.78         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.78         |
| reward                   | -1.2282338   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 42           |
|    time_elapsed          | 924          |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0062501696 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 93.2         |
|    cost_values           | 6.65         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | -0.0631      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 177          |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00492     |
|    std                   | 1.07         |
|    value_loss            | 288          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.384        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.384        |
| reward                   | -0.61559206  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 43           |
|    time_elapsed          | 945          |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0038540056 |
|    clip_fraction         | 0.0287       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 83.1         |
|    cost_values           | 6.77         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00367      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 107          |
|    n_updates             | 910          |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 1.07         |
|    value_loss            | 142          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -1.1025745  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 44          |
|    time_elapsed          | 967         |
|    total_timesteps       | 190464      |
| train/                   |             |
|    approx_kl             | 0.002920032 |
|    clip_fraction         | 0.0267      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.29        |
|    cost_value_loss       | 24.3        |
|    cost_values           | 6.84        |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | -0.00541    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24.5        |
|    n_updates             | 920         |
|    policy_gradient_loss  | -0.00307    |
|    std                   | 1.07        |
|    value_loss            | 29.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.02         |
| reward                   | -3.0146956   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 45           |
|    time_elapsed          | 989          |
|    total_timesteps       | 192512       |
| train/                   |              |
|    approx_kl             | 0.0061833616 |
|    clip_fraction         | 0.0634       |
|    clip_range            | 0.2          |
|    cost_returns          | 15           |
|    cost_value_loss       | 132          |
|    cost_values           | 6.9          |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.00515      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 139          |
|    n_updates             | 930          |
|    policy_gradient_loss  | -0.00486     |
|    std                   | 1.07         |
|    value_loss            | 160          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1            |
| reward                   | -1.0651419   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 46           |
|    time_elapsed          | 1011         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0032740503 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.3         |
|    cost_value_loss       | 114          |
|    cost_values           | 7.14         |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.00248      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 209          |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 1.07         |
|    value_loss            | 299          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.05        |
| reward                   | -0.45500547 |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 47          |
|    time_elapsed          | 1033        |
|    total_timesteps       | 196608      |
| train/                   |             |
|    approx_kl             | 0.004460518 |
|    clip_fraction         | 0.0247      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.85        |
|    cost_value_loss       | 19.9        |
|    cost_values           | 7.2         |
|    entropy               | -3.01       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.00689     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 43.6        |
|    n_updates             | 950         |
|    policy_gradient_loss  | -0.00481    |
|    std                   | 1.09        |
|    value_loss            | 82.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.581        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.581        |
| reward                   | -0.56235284  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 48           |
|    time_elapsed          | 1055         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0025411686 |
|    clip_fraction         | 0.00488      |
|    clip_range            | 0.2          |
|    cost_returns          | 13.5         |
|    cost_value_loss       | 105          |
|    cost_values           | 7.2          |
|    entropy               | -3.02        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.0037       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 156          |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.000773    |
|    std                   | 1.09         |
|    value_loss            | 190          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.859        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.859        |
| reward                   | -0.79542714  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 49           |
|    time_elapsed          | 1077         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0051461263 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.3         |
|    cost_value_loss       | 168          |
|    cost_values           | 7.37         |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.00454      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 266          |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.0034      |
|    std                   | 1.09         |
|    value_loss            | 376          |
-------------------------------------------
-----------------------------------
| avg_speed          | 1.04       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 1.04       |
| reward             | -0.7674184 |
| rollout/           |            |
|    ep_len_mean     | 974        |
|    ep_rew_mean     | -1.28e+03  |
| time/              |            |
|    fps             | 96         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 202752     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.465       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.465       |
| reward                   | -0.8591276  |
| rollout/                 |             |
|    ep_len_mean           | 974         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 95          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 204800      |
| train/                   |             |
|    approx_kl             | 0.002430486 |
|    clip_fraction         | 0.00635     |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 82.6        |
|    cost_values           | 7.73        |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.00828     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 127         |
|    n_updates             | 990         |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 1.1         |
|    value_loss            | 185         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.32         |
| reward                   | -0.8994548   |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 206848       |
| train/                   |              |
|    approx_kl             | 0.0051874504 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.9         |
|    cost_value_loss       | 158          |
|    cost_values           | 7.81         |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | -0.0419      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 394          |
|    n_updates             | 1000         |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 1.1          |
|    value_loss            | 618          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0145      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0145      |
| reward                   | -0.77832645 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 208896      |
| train/                   |             |
|    approx_kl             | 0.004727532 |
|    clip_fraction         | 0.0242      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 111         |
|    cost_values           | 7.93        |
|    entropy               | -3.03       |
|    entropy_loss          | -3.03       |
|    explained_variance    | -0.000924   |
|    lagrangian_multiplier | 0.00617     |
|    learning_rate         | 0.0003      |
|    loss                  | 40.7        |
|    n_updates             | 1010        |
|    policy_gradient_loss  | -0.00361    |
|    std                   | 1.1         |
|    value_loss            | 207         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -2.4572809   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 210944       |
| train/                   |              |
|    approx_kl             | 0.0049657975 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.5         |
|    cost_value_loss       | 163          |
|    cost_values           | 7.99         |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.000394     |
|    lagrangian_multiplier | 0.0117       |
|    learning_rate         | 0.0003       |
|    loss                  | 48.8         |
|    n_updates             | 1020         |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 1.1          |
|    value_loss            | 454          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.59        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.59        |
| reward                   | -1.2558309  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 212992      |
| train/                   |             |
|    approx_kl             | 0.005946588 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.7        |
|    cost_value_loss       | 151         |
|    cost_values           | 8           |
|    entropy               | -3.04       |
|    entropy_loss          | -3.04       |
|    explained_variance    | -0.00848    |
|    lagrangian_multiplier | 0.02        |
|    learning_rate         | 0.0003      |
|    loss                  | 21          |
|    n_updates             | 1030        |
|    policy_gradient_loss  | -0.00468    |
|    std                   | 1.11        |
|    value_loss            | 173         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -3.2405527   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 153          |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0048182355 |
|    clip_fraction         | 0.0353       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 108          |
|    cost_values           | 8            |
|    entropy               | -3.05        |
|    entropy_loss          | -3.04        |
|    explained_variance    | -0.0071      |
|    lagrangian_multiplier | 0.0116       |
|    learning_rate         | 0.0003       |
|    loss                  | 27.9         |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.00388     |
|    std                   | 1.11         |
|    value_loss            | 182          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0721      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0721      |
| reward                   | -0.55057204 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 174         |
|    total_timesteps       | 217088      |
| train/                   |             |
|    approx_kl             | 0.003997192 |
|    clip_fraction         | 0.0141      |
|    clip_range            | 0.2         |
|    cost_returns          | 20.2        |
|    cost_value_loss       | 188         |
|    cost_values           | 7.99        |
|    entropy               | -3.05       |
|    entropy_loss          | -3.05       |
|    explained_variance    | -0.0178     |
|    lagrangian_multiplier | 0.0026      |
|    learning_rate         | 0.0003      |
|    loss                  | 153         |
|    n_updates             | 1050        |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 1.11        |
|    value_loss            | 510         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.47         |
| reward                   | -0.6978547   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 196          |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0045431536 |
|    clip_fraction         | 0.0115       |
|    clip_range            | 0.2          |
|    cost_returns          | 19.7         |
|    cost_value_loss       | 178          |
|    cost_values           | 8            |
|    entropy               | -3.06        |
|    entropy_loss          | -3.05        |
|    explained_variance    | -0.000192    |
|    lagrangian_multiplier | 0.0299       |
|    learning_rate         | 0.0003       |
|    loss                  | 23.3         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 1.11         |
|    value_loss            | 347          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.803        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.803        |
| reward                   | -0.5290364   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 218          |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0040035155 |
|    clip_fraction         | 0.00864      |
|    clip_range            | 0.2          |
|    cost_returns          | 21.5         |
|    cost_value_loss       | 206          |
|    cost_values           | 8            |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.00204      |
|    lagrangian_multiplier | 0.00743      |
|    learning_rate         | 0.0003       |
|    loss                  | 85.7         |
|    n_updates             | 1070         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 1.12         |
|    value_loss            | 554          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.82         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.82         |
| reward                   | -1.0019294   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 240          |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0017659599 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 21.9         |
|    cost_value_loss       | 213          |
|    cost_values           | 8            |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.00141      |
|    lagrangian_multiplier | 0.0158       |
|    learning_rate         | 0.0003       |
|    loss                  | 58.7         |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.000988    |
|    std                   | 1.12         |
|    value_loss            | 715          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.777        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.777        |
| reward                   | -0.80343366  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 261          |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0046222056 |
|    clip_fraction         | 0.00859      |
|    clip_range            | 0.2          |
|    cost_returns          | 20.9         |
|    cost_value_loss       | 196          |
|    cost_values           | 8            |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | -3.5e-05     |
|    lagrangian_multiplier | 0.0183       |
|    learning_rate         | 0.0003       |
|    loss                  | 45.7         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 1.12         |
|    value_loss            | 611          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.4169835  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 13          |
|    time_elapsed          | 283         |
|    total_timesteps       | 227328      |
| train/                   |             |
|    approx_kl             | 0.006168438 |
|    clip_fraction         | 0.0198      |
|    clip_range            | 0.2         |
|    cost_returns          | 20.5        |
|    cost_value_loss       | 194         |
|    cost_values           | 8           |
|    entropy               | -3.06       |
|    entropy_loss          | -3.06       |
|    explained_variance    | 0.000725    |
|    lagrangian_multiplier | 0.00348     |
|    learning_rate         | 0.0003      |
|    loss                  | 151         |
|    n_updates             | 1100        |
|    policy_gradient_loss  | -0.00312    |
|    std                   | 1.12        |
|    value_loss            | 659         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.61         |
| reward                   | -0.989907    |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 305          |
|    total_timesteps       | 229376       |
| train/                   |              |
|    approx_kl             | 0.0064180996 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 19.8         |
|    cost_value_loss       | 182          |
|    cost_values           | 8            |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.000791     |
|    lagrangian_multiplier | 0.00153      |
|    learning_rate         | 0.0003       |
|    loss                  | 149          |
|    n_updates             | 1110         |
|    policy_gradient_loss  | -0.00482     |
|    std                   | 1.12         |
|    value_loss            | 343          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.218       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.218       |
| reward                   | -0.78441197 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 15          |
|    time_elapsed          | 327         |
|    total_timesteps       | 231424      |
| train/                   |             |
|    approx_kl             | 0.005300126 |
|    clip_fraction         | 0.0168      |
|    clip_range            | 0.2         |
|    cost_returns          | 20.1        |
|    cost_value_loss       | 184         |
|    cost_values           | 8           |
|    entropy               | -3.06       |
|    entropy_loss          | -3.06       |
|    explained_variance    | -0.00169    |
|    lagrangian_multiplier | 0.0183      |
|    learning_rate         | 0.0003      |
|    loss                  | 31.2        |
|    n_updates             | 1120        |
|    policy_gradient_loss  | -0.00326    |
|    std                   | 1.11        |
|    value_loss            | 326         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -1.1092068  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 16          |
|    time_elapsed          | 349         |
|    total_timesteps       | 233472      |
| train/                   |             |
|    approx_kl             | 0.005858799 |
|    clip_fraction         | 0.0397      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.2        |
|    cost_value_loss       | 142         |
|    cost_values           | 8           |
|    entropy               | -3.05       |
|    entropy_loss          | -3.05       |
|    explained_variance    | 0.00194     |
|    lagrangian_multiplier | 0.000343    |
|    learning_rate         | 0.0003      |
|    loss                  | 155         |
|    n_updates             | 1130        |
|    policy_gradient_loss  | -0.00356    |
|    std                   | 1.11        |
|    value_loss            | 210         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.54         |
| reward                   | -0.53927356  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 371          |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0054377657 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.4         |
|    cost_value_loss       | 115          |
|    cost_values           | 8            |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.00131      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 94.9         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.00365     |
|    std                   | 1.12         |
|    value_loss            | 86.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.44         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.44         |
| reward                   | -0.889789    |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 18           |
|    time_elapsed          | 392          |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0028263167 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 17           |
|    cost_value_loss       | 144          |
|    cost_values           | 8            |
|    entropy               | -3.07        |
|    entropy_loss          | -3.06        |
|    explained_variance    | -0.00222     |
|    lagrangian_multiplier | 0.00423      |
|    learning_rate         | 0.0003       |
|    loss                  | 51.1         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.00427     |
|    std                   | 1.12         |
|    value_loss            | 149          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -1.6750935  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 19          |
|    time_elapsed          | 414         |
|    total_timesteps       | 239616      |
| train/                   |             |
|    approx_kl             | 0.003404856 |
|    clip_fraction         | 0.0289      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.8        |
|    cost_value_loss       | 91.9        |
|    cost_values           | 8           |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | 0.00603     |
|    lagrangian_multiplier | 0.00135     |
|    learning_rate         | 0.0003      |
|    loss                  | 35.9        |
|    n_updates             | 1160        |
|    policy_gradient_loss  | -0.00407    |
|    std                   | 1.13        |
|    value_loss            | 22.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.61         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.61         |
| reward                   | -1.121867    |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 20           |
|    time_elapsed          | 436          |
|    total_timesteps       | 241664       |
| train/                   |              |
|    approx_kl             | 0.0067919926 |
|    clip_fraction         | 0.0596       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.3         |
|    cost_value_loss       | 113          |
|    cost_values           | 8            |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.004        |
|    lagrangian_multiplier | 0.0176       |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 1170         |
|    policy_gradient_loss  | -0.0041      |
|    std                   | 1.13         |
|    value_loss            | 22.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.13         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.13         |
| reward                   | -2.058964    |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 21           |
|    time_elapsed          | 458          |
|    total_timesteps       | 243712       |
| train/                   |              |
|    approx_kl             | 0.0048401137 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 111          |
|    cost_values           | 7.99         |
|    entropy               | -3.09        |
|    entropy_loss          | -3.09        |
|    explained_variance    | 0.00743      |
|    lagrangian_multiplier | 0.0128       |
|    learning_rate         | 0.0003       |
|    loss                  | 20.4         |
|    n_updates             | 1180         |
|    policy_gradient_loss  | -0.00397     |
|    std                   | 1.13         |
|    value_loss            | 93           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.14         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.14         |
| reward                   | -1.9475186   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 22           |
|    time_elapsed          | 479          |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0048644533 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.8         |
|    cost_value_loss       | 137          |
|    cost_values           | 8            |
|    entropy               | -3.09        |
|    entropy_loss          | -3.09        |
|    explained_variance    | 0.0015       |
|    lagrangian_multiplier | 0.0138       |
|    learning_rate         | 0.0003       |
|    loss                  | 29.3         |
|    n_updates             | 1190         |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 1.13         |
|    value_loss            | 211          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.37        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.37        |
| reward                   | -2.1275933  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 23          |
|    time_elapsed          | 501         |
|    total_timesteps       | 247808      |
| train/                   |             |
|    approx_kl             | 0.002722291 |
|    clip_fraction         | 0.00361     |
|    clip_range            | 0.2         |
|    cost_returns          | 19.5        |
|    cost_value_loss       | 177         |
|    cost_values           | 7.99        |
|    entropy               | -3.09       |
|    entropy_loss          | -3.09       |
|    explained_variance    | 0.00981     |
|    lagrangian_multiplier | 0.0121      |
|    learning_rate         | 0.0003      |
|    loss                  | 49.7        |
|    n_updates             | 1200        |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 1.14        |
|    value_loss            | 446         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -2.580499    |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 24           |
|    time_elapsed          | 523          |
|    total_timesteps       | 249856       |
| train/                   |              |
|    approx_kl             | 0.0041727033 |
|    clip_fraction         | 0.0363       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.8         |
|    cost_value_loss       | 122          |
|    cost_values           | 8            |
|    entropy               | -3.1         |
|    entropy_loss          | -3.09        |
|    explained_variance    | 0.00368      |
|    lagrangian_multiplier | 0.0144       |
|    learning_rate         | 0.0003       |
|    loss                  | 25.7         |
|    n_updates             | 1210         |
|    policy_gradient_loss  | -0.00529     |
|    std                   | 1.14         |
|    value_loss            | 196          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -2.660695   |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 25          |
|    time_elapsed          | 544         |
|    total_timesteps       | 251904      |
| train/                   |             |
|    approx_kl             | 0.004563618 |
|    clip_fraction         | 0.0125      |
|    clip_range            | 0.2         |
|    cost_returns          | 18.2        |
|    cost_value_loss       | 156         |
|    cost_values           | 8           |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.00316     |
|    lagrangian_multiplier | 0.0105      |
|    learning_rate         | 0.0003      |
|    loss                  | 37          |
|    n_updates             | 1220        |
|    policy_gradient_loss  | -0.00276    |
|    std                   | 1.14        |
|    value_loss            | 249         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -2.1060069   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 26           |
|    time_elapsed          | 566          |
|    total_timesteps       | 253952       |
| train/                   |              |
|    approx_kl             | 0.0048468877 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 21.6         |
|    cost_value_loss       | 206          |
|    cost_values           | 8            |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.00992      |
|    lagrangian_multiplier | 0.018        |
|    learning_rate         | 0.0003       |
|    loss                  | 41.5         |
|    n_updates             | 1230         |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 1.14         |
|    value_loss            | 466          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.0348     |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.0348     |
| reward                   | -1.9860772 |
| rollout/                 |            |
|    ep_len_mean           | 976        |
|    ep_rew_mean           | -1.31e+03  |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 27         |
|    time_elapsed          | 588        |
|    total_timesteps       | 256000     |
| train/                   |            |
|    approx_kl             | 0.00736464 |
|    clip_fraction         | 0.06       |
|    clip_range            | 0.2        |
|    cost_returns          | 16.9       |
|    cost_value_loss       | 138        |
|    cost_values           | 8          |
|    entropy               | -3.1       |
|    entropy_loss          | -3.1       |
|    explained_variance    | 0.00645    |
|    lagrangian_multiplier | 0.0142     |
|    learning_rate         | 0.0003     |
|    loss                  | 26.8       |
|    n_updates             | 1240       |
|    policy_gradient_loss  | -0.00641   |
|    std                   | 1.14       |
|    value_loss            | 191        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -2.1744204   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 28           |
|    time_elapsed          | 610          |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0040203594 |
|    clip_fraction         | 0.0352       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.9         |
|    cost_value_loss       | 110          |
|    cost_values           | 8            |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.000137     |
|    lagrangian_multiplier | 0.0102       |
|    learning_rate         | 0.0003       |
|    loss                  | 32.4         |
|    n_updates             | 1250         |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 1.15         |
|    value_loss            | 210          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -1.8322827   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 29           |
|    time_elapsed          | 632          |
|    total_timesteps       | 260096       |
| train/                   |              |
|    approx_kl             | 0.0050932383 |
|    clip_fraction         | 0.04         |
|    clip_range            | 0.2          |
|    cost_returns          | 15           |
|    cost_value_loss       | 111          |
|    cost_values           | 8            |
|    entropy               | -3.12        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.0085       |
|    lagrangian_multiplier | 0.0127       |
|    learning_rate         | 0.0003       |
|    loss                  | 19           |
|    n_updates             | 1260         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 1.15         |
|    value_loss            | 69.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -2.7907677   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 30           |
|    time_elapsed          | 654          |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0069198436 |
|    clip_fraction         | 0.0649       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.9         |
|    cost_value_loss       | 74.6         |
|    cost_values           | 7.8          |
|    entropy               | -3.16        |
|    entropy_loss          | -3.14        |
|    explained_variance    | 0.0252       |
|    lagrangian_multiplier | 0.0652       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.04         |
|    n_updates             | 1270         |
|    policy_gradient_loss  | -0.00577     |
|    std                   | 1.17         |
|    value_loss            | 57.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.29         |
| reward                   | -0.33673912  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 31           |
|    time_elapsed          | 677          |
|    total_timesteps       | 264192       |
| train/                   |              |
|    approx_kl             | 0.0055625658 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.4         |
|    cost_value_loss       | 101          |
|    cost_values           | 6.95         |
|    entropy               | -3.16        |
|    entropy_loss          | -3.16        |
|    explained_variance    | 0.135        |
|    lagrangian_multiplier | 0.0275       |
|    learning_rate         | 0.0003       |
|    loss                  | 16.1         |
|    n_updates             | 1280         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 1.18         |
|    value_loss            | 209          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.47         |
| reward                   | -0.6854079   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 32           |
|    time_elapsed          | 699          |
|    total_timesteps       | 266240       |
| train/                   |              |
|    approx_kl             | 0.0020313286 |
|    clip_fraction         | 0.00127      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.61         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 5.88         |
|    entropy               | -3.17        |
|    entropy_loss          | -3.16        |
|    explained_variance    | 0.442        |
|    lagrangian_multiplier | 0.00321      |
|    learning_rate         | 0.0003       |
|    loss                  | 15.6         |
|    n_updates             | 1290         |
|    policy_gradient_loss  | -0.00211     |
|    std                   | 1.18         |
|    value_loss            | 57.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.363        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.363        |
| reward                   | -0.4817217   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 33           |
|    time_elapsed          | 721          |
|    total_timesteps       | 268288       |
| train/                   |              |
|    approx_kl             | 0.0043714726 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 88.8         |
|    cost_values           | 5.39         |
|    entropy               | -3.17        |
|    entropy_loss          | -3.17        |
|    explained_variance    | 0.281        |
|    lagrangian_multiplier | 0.00709      |
|    learning_rate         | 0.0003       |
|    loss                  | 23           |
|    n_updates             | 1300         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 1.18         |
|    value_loss            | 84.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.226        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.226        |
| reward                   | -0.5664817   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 34           |
|    time_elapsed          | 743          |
|    total_timesteps       | 270336       |
| train/                   |              |
|    approx_kl             | 0.0063450583 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.3         |
|    cost_value_loss       | 108          |
|    cost_values           | 4.94         |
|    entropy               | -3.17        |
|    entropy_loss          | -3.17        |
|    explained_variance    | -0.0924      |
|    lagrangian_multiplier | 0.0329       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.1          |
|    n_updates             | 1310         |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 1.18         |
|    value_loss            | 63.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.74         |
| reward                   | -1.2899266   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 35           |
|    time_elapsed          | 765          |
|    total_timesteps       | 272384       |
| train/                   |              |
|    approx_kl             | 0.0035488312 |
|    clip_fraction         | 0.00898      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.1         |
|    cost_value_loss       | 147          |
|    cost_values           | 4.62         |
|    entropy               | -3.17        |
|    entropy_loss          | -3.17        |
|    explained_variance    | -0.732       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 225          |
|    n_updates             | 1320         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 1.18         |
|    value_loss            | 370          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.33         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.33         |
| reward                   | -1.2762028   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 36           |
|    time_elapsed          | 787          |
|    total_timesteps       | 274432       |
| train/                   |              |
|    approx_kl             | 0.0045485105 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 131          |
|    cost_values           | 4.78         |
|    entropy               | -3.18        |
|    entropy_loss          | -3.17        |
|    explained_variance    | 0.00484      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 186          |
|    n_updates             | 1330         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 1.18         |
|    value_loss            | 258          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.01         |
| reward                   | -1.2006541   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 37           |
|    time_elapsed          | 809          |
|    total_timesteps       | 276480       |
| train/                   |              |
|    approx_kl             | 0.0027498612 |
|    clip_fraction         | 0.00322      |
|    clip_range            | 0.2          |
|    cost_returns          | 16.5         |
|    cost_value_loss       | 180          |
|    cost_values           | 5.03         |
|    entropy               | -3.18        |
|    entropy_loss          | -3.18        |
|    explained_variance    | 0.00476      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 270          |
|    n_updates             | 1340         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 1.19         |
|    value_loss            | 401          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.935        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.935        |
| reward                   | -0.6878059   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 38           |
|    time_elapsed          | 830          |
|    total_timesteps       | 278528       |
| train/                   |              |
|    approx_kl             | 0.0027918427 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.1         |
|    cost_value_loss       | 171          |
|    cost_values           | 5.27         |
|    entropy               | -3.18        |
|    entropy_loss          | -3.18        |
|    explained_variance    | 0.00728      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 200          |
|    n_updates             | 1350         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 1.19         |
|    value_loss            | 237          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.754        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.754        |
| reward                   | -0.5620083   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 39           |
|    time_elapsed          | 853          |
|    total_timesteps       | 280576       |
| train/                   |              |
|    approx_kl             | 0.0068173623 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.5         |
|    cost_value_loss       | 172          |
|    cost_values           | 5.43         |
|    entropy               | -3.18        |
|    entropy_loss          | -3.18        |
|    explained_variance    | -0.197       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 137          |
|    n_updates             | 1360         |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 1.19         |
|    value_loss            | 126          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.26        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.26        |
| reward                   | -0.9400769  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.39e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 40          |
|    time_elapsed          | 875         |
|    total_timesteps       | 282624      |
| train/                   |             |
|    approx_kl             | 0.005087178 |
|    clip_fraction         | 0.0237      |
|    clip_range            | 0.2         |
|    cost_returns          | 16          |
|    cost_value_loss       | 162         |
|    cost_values           | 5.67        |
|    entropy               | -3.18       |
|    entropy_loss          | -3.18       |
|    explained_variance    | 0.124       |
|    lagrangian_multiplier | 0.0313      |
|    learning_rate         | 0.0003      |
|    loss                  | 19          |
|    n_updates             | 1370        |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 1.19        |
|    value_loss            | 332         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.01        |
| reward                   | -0.9667687  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.4e+03    |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 41          |
|    time_elapsed          | 897         |
|    total_timesteps       | 284672      |
| train/                   |             |
|    approx_kl             | 0.005837358 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 82.7        |
|    cost_values           | 5.06        |
|    entropy               | -3.2        |
|    entropy_loss          | -3.19       |
|    explained_variance    | 0.611       |
|    lagrangian_multiplier | 0.0115      |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 1380        |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 1.2         |
|    value_loss            | 20.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -1.7998458   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 42           |
|    time_elapsed          | 918          |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0041875895 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 153          |
|    cost_values           | 4.74         |
|    entropy               | -3.21        |
|    entropy_loss          | -3.21        |
|    explained_variance    | 0.345        |
|    lagrangian_multiplier | 0.0273       |
|    learning_rate         | 0.0003       |
|    loss                  | 14.8         |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 1.21         |
|    value_loss            | 152          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.56         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.56         |
| reward                   | -1.5046179   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 43           |
|    time_elapsed          | 941          |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0049929833 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.4         |
|    cost_value_loss       | 122          |
|    cost_values           | 4.2          |
|    entropy               | -3.22        |
|    entropy_loss          | -3.21        |
|    explained_variance    | 0.673        |
|    lagrangian_multiplier | 0.0127       |
|    learning_rate         | 0.0003       |
|    loss                  | 16.3         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 1.21         |
|    value_loss            | 57.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -2.3075178  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.41e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 44          |
|    time_elapsed          | 962         |
|    total_timesteps       | 290816      |
| train/                   |             |
|    approx_kl             | 0.004081148 |
|    clip_fraction         | 0.0148      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 104         |
|    cost_values           | 3.59        |
|    entropy               | -3.23       |
|    entropy_loss          | -3.23       |
|    explained_variance    | 0.578       |
|    lagrangian_multiplier | 0.015       |
|    learning_rate         | 0.0003      |
|    loss                  | 15.4        |
|    n_updates             | 1410        |
|    policy_gradient_loss  | -0.0024     |
|    std                   | 1.22        |
|    value_loss            | 116         |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.46       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4.46       |
| reward                   | -0.9595357 |
| rollout/                 |            |
|    ep_len_mean           | 976        |
|    ep_rew_mean           | -1.43e+03  |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 45         |
|    time_elapsed          | 984        |
|    total_timesteps       | 292864     |
| train/                   |            |
|    approx_kl             | 0.00364077 |
|    clip_fraction         | 0.0064     |
|    clip_range            | 0.2        |
|    cost_returns          | 16.3       |
|    cost_value_loss       | 197        |
|    cost_values           | 3.79       |
|    entropy               | -3.24      |
|    entropy_loss          | -3.24      |
|    explained_variance    | -0.0111    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 197        |
|    n_updates             | 1420       |
|    policy_gradient_loss  | -0.00264   |
|    std                   | 1.22       |
|    value_loss            | 222        |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -1.9166361  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.43e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 46          |
|    time_elapsed          | 1006        |
|    total_timesteps       | 294912      |
| train/                   |             |
|    approx_kl             | 0.004725966 |
|    clip_fraction         | 0.0154      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.6        |
|    cost_value_loss       | 165         |
|    cost_values           | 4.06        |
|    entropy               | -3.24       |
|    entropy_loss          | -3.24       |
|    explained_variance    | -2.3e-05    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 194         |
|    n_updates             | 1430        |
|    policy_gradient_loss  | -0.0026     |
|    std                   | 1.22        |
|    value_loss            | 245         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.1         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.1         |
| reward                   | -1.791788   |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.42e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 47          |
|    time_elapsed          | 1029        |
|    total_timesteps       | 296960      |
| train/                   |             |
|    approx_kl             | 0.005291933 |
|    clip_fraction         | 0.0389      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 137         |
|    cost_values           | 4.29        |
|    entropy               | -3.24       |
|    entropy_loss          | -3.24       |
|    explained_variance    | 0.362       |
|    lagrangian_multiplier | 0.013       |
|    learning_rate         | 0.0003      |
|    loss                  | 17.3        |
|    n_updates             | 1440        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 1.22        |
|    value_loss            | 83.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.6899731   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 48           |
|    time_elapsed          | 1051         |
|    total_timesteps       | 299008       |
| train/                   |              |
|    approx_kl             | 0.0076299366 |
|    clip_fraction         | 0.0414       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.5         |
|    cost_value_loss       | 169          |
|    cost_values           | 4.71         |
|    entropy               | -3.24        |
|    entropy_loss          | -3.24        |
|    explained_variance    | 0.00412      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 138          |
|    n_updates             | 1450         |
|    policy_gradient_loss  | -0.00371     |
|    std                   | 1.22         |
|    value_loss            | 115          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.21        |
| reward                   | -1.1241919  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -1.42e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 49          |
|    time_elapsed          | 1073        |
|    total_timesteps       | 301056      |
| train/                   |             |
|    approx_kl             | 0.003770101 |
|    clip_fraction         | 0.0181      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 160         |
|    cost_values           | 4.63        |
|    entropy               | -3.25       |
|    entropy_loss          | -3.24       |
|    explained_variance    | 0.411       |
|    lagrangian_multiplier | 0.0168      |
|    learning_rate         | 0.0003      |
|    loss                  | 16.2        |
|    n_updates             | 1460        |
|    policy_gradient_loss  | -0.00207    |
|    std                   | 1.23        |
|    value_loss            | 77.7        |
------------------------------------------
-----------------------------------
| avg_speed          | 8.05       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 8.05       |
| reward             | -1.7475805 |
| rollout/           |            |
|    ep_len_mean     | 976        |
|    ep_rew_mean     | -1.4e+03   |
| time/              |            |
|    fps             | 96         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 303104     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -2.2109935   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 95           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 305152       |
| train/                   |              |
|    approx_kl             | 0.0057647093 |
|    clip_fraction         | 0.0326       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.1         |
|    cost_value_loss       | 189          |
|    cost_values           | 4.26         |
|    entropy               | -3.24        |
|    entropy_loss          | -3.24        |
|    explained_variance    | 0.0347       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 133          |
|    n_updates             | 1480         |
|    policy_gradient_loss  | -0.00315     |
|    std                   | 1.23         |
|    value_loss            | 89.9         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 7.66          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 7.66          |
| reward                   | -2.0181835    |
| rollout/                 |               |
|    ep_len_mean           | 976           |
|    ep_rew_mean           | -1.39e+03     |
| time/                    |               |
|    fps                   | 94            |
|    iterations            | 3             |
|    time_elapsed          | 64            |
|    total_timesteps       | 307200        |
| train/                   |               |
|    approx_kl             | 0.00015879516 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 13.3          |
|    cost_value_loss       | 184           |
|    cost_values           | 1.85          |
|    entropy               | -3.25         |
|    entropy_loss          | -3.25         |
|    explained_variance    | 0.879         |
|    lagrangian_multiplier | 1.81          |
|    learning_rate         | 0.0003        |
|    loss                  | 4.04          |
|    n_updates             | 1490          |
|    policy_gradient_loss  | 4.05e-05      |
|    std                   | 1.23          |
|    value_loss            | 554           |
--------------------------------------------
---------------------------------------------
| avg_speed                | 0.475          |
| cost                     | 0              |
| is_success               | 0              |
| max_speed                | 0.475          |
| reward                   | -0.3445439     |
| rollout/                 |                |
|    ep_len_mean           | 991            |
|    ep_rew_mean           | -1.41e+03      |
| time/                    |                |
|    fps                   | 94             |
|    iterations            | 4              |
|    time_elapsed          | 86             |
|    total_timesteps       | 309248         |
| train/                   |                |
|    approx_kl             | 0.000102941645 |
|    clip_fraction         | 0              |
|    clip_range            | 0.2            |
|    cost_returns          | 13.1           |
|    cost_value_loss       | 165            |
|    cost_values           | 2.85           |
|    entropy               | -3.25          |
|    entropy_loss          | -3.25          |
|    explained_variance    | 0.868          |
|    lagrangian_multiplier | 0.153          |
|    learning_rate         | 0.0003         |
|    loss                  | 4.73           |
|    n_updates             | 1500           |
|    policy_gradient_loss  | -0.000328      |
|    std                   | 1.23           |
|    value_loss            | 169            |
---------------------------------------------
-------------------------------------------
| avg_speed                | 0.256        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.256        |
| reward                   | -0.51019907  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 5            |
|    time_elapsed          | 108          |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0063434467 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.18         |
|    cost_value_loss       | 110          |
|    cost_values           | 2.18         |
|    entropy               | -3.25        |
|    entropy_loss          | -3.25        |
|    explained_variance    | 0.742        |
|    lagrangian_multiplier | 0.00266      |
|    learning_rate         | 0.0003       |
|    loss                  | 30.9         |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -0.00603     |
|    std                   | 1.23         |
|    value_loss            | 35.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.76        |
| reward                   | -0.33750108 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.41e+03   |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 6           |
|    time_elapsed          | 130         |
|    total_timesteps       | 313344      |
| train/                   |             |
|    approx_kl             | 0.005022425 |
|    clip_fraction         | 0.0349      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.2        |
|    cost_value_loss       | 187         |
|    cost_values           | 2.48        |
|    entropy               | -3.26       |
|    entropy_loss          | -3.26       |
|    explained_variance    | 0.784       |
|    lagrangian_multiplier | 0.0117      |
|    learning_rate         | 0.0003      |
|    loss                  | 26.2        |
|    n_updates             | 1520        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 1.23        |
|    value_loss            | 146         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.258       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.258       |
| reward                   | -0.38501254 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 7           |
|    time_elapsed          | 152         |
|    total_timesteps       | 315392      |
| train/                   |             |
|    approx_kl             | 0.006611162 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.8        |
|    cost_value_loss       | 168         |
|    cost_values           | 2.18        |
|    entropy               | -3.25       |
|    entropy_loss          | -3.26       |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0.0165      |
|    learning_rate         | 0.0003      |
|    loss                  | 15.7        |
|    n_updates             | 1530        |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 1.23        |
|    value_loss            | 78.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.625        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.625        |
| reward                   | -0.42039785  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 8            |
|    time_elapsed          | 173          |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0015215471 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.4          |
|    cost_value_loss       | 107          |
|    cost_values           | 1.32         |
|    entropy               | -3.25        |
|    entropy_loss          | -3.25        |
|    explained_variance    | 0.887        |
|    lagrangian_multiplier | 0.0842       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.33         |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 1.23         |
|    value_loss            | 88.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.01         |
| reward                   | -1.1041195   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 9            |
|    time_elapsed          | 195          |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0031656362 |
|    clip_fraction         | 0.024        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.17         |
|    cost_value_loss       | 70.3         |
|    cost_values           | 1.66         |
|    entropy               | -3.25        |
|    entropy_loss          | -3.25        |
|    explained_variance    | 0.632        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44.3         |
|    n_updates             | 1550         |
|    policy_gradient_loss  | -0.00471     |
|    std                   | 1.23         |
|    value_loss            | 27.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.498        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.498        |
| reward                   | -0.65356076  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 10           |
|    time_elapsed          | 217          |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0061210566 |
|    clip_fraction         | 0.0342       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.17         |
|    cost_value_loss       | 104          |
|    cost_values           | 2.2          |
|    entropy               | -3.25        |
|    entropy_loss          | -3.25        |
|    explained_variance    | -0.633       |
|    lagrangian_multiplier | 0.00188      |
|    learning_rate         | 0.0003       |
|    loss                  | 38.5         |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.00462     |
|    std                   | 1.23         |
|    value_loss            | 61.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.395       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.395       |
| reward                   | -0.60643363 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 11          |
|    time_elapsed          | 239         |
|    total_timesteps       | 323584      |
| train/                   |             |
|    approx_kl             | 0.005924964 |
|    clip_fraction         | 0.0183      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.3        |
|    cost_value_loss       | 120         |
|    cost_values           | 2.56        |
|    entropy               | -3.26       |
|    entropy_loss          | -3.25       |
|    explained_variance    | -2.08       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 87.2        |
|    n_updates             | 1570        |
|    policy_gradient_loss  | -0.00273    |
|    std                   | 1.23        |
|    value_loss            | 99.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.125        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.125        |
| reward                   | -0.8894382   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 12           |
|    time_elapsed          | 260          |
|    total_timesteps       | 325632       |
| train/                   |              |
|    approx_kl             | 0.0032833507 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.56         |
|    cost_value_loss       | 64.5         |
|    cost_values           | 2.25         |
|    entropy               | -3.25        |
|    entropy_loss          | -3.25        |
|    explained_variance    | 0.761        |
|    lagrangian_multiplier | 0.00386      |
|    learning_rate         | 0.0003       |
|    loss                  | 16.3         |
|    n_updates             | 1580         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 1.23         |
|    value_loss            | 29           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.459        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.459        |
| reward                   | -0.6148192   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 13           |
|    time_elapsed          | 282          |
|    total_timesteps       | 327680       |
| train/                   |              |
|    approx_kl             | 0.0042429017 |
|    clip_fraction         | 0.017        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.83         |
|    cost_value_loss       | 34.4         |
|    cost_values           | 1.57         |
|    entropy               | -3.25        |
|    entropy_loss          | -3.25        |
|    explained_variance    | 0.534        |
|    lagrangian_multiplier | 0.00278      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.3         |
|    n_updates             | 1590         |
|    policy_gradient_loss  | -0.00364     |
|    std                   | 1.23         |
|    value_loss            | 32.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.72         |
| reward                   | -0.560287    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 14           |
|    time_elapsed          | 303          |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0029043313 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.17         |
|    cost_value_loss       | 66.4         |
|    cost_values           | 2.13         |
|    entropy               | -3.27        |
|    entropy_loss          | -3.26        |
|    explained_variance    | 0.66         |
|    lagrangian_multiplier | 0.00231      |
|    learning_rate         | 0.0003       |
|    loss                  | 32.9         |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 1.24         |
|    value_loss            | 88.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.42         |
| reward                   | -0.6802084   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 15           |
|    time_elapsed          | 325          |
|    total_timesteps       | 331776       |
| train/                   |              |
|    approx_kl             | 0.0048325146 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.68         |
|    cost_value_loss       | 15.2         |
|    cost_values           | 1.43         |
|    entropy               | -3.28        |
|    entropy_loss          | -3.28        |
|    explained_variance    | 0.87         |
|    lagrangian_multiplier | 0.000122     |
|    learning_rate         | 0.0003       |
|    loss                  | 22.1         |
|    n_updates             | 1610         |
|    policy_gradient_loss  | -0.00561     |
|    std                   | 1.25         |
|    value_loss            | 31.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0784       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0784       |
| reward                   | -0.73729527  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 16           |
|    time_elapsed          | 347          |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0053971726 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.93         |
|    cost_value_loss       | 48.3         |
|    cost_values           | 1.38         |
|    entropy               | -3.29        |
|    entropy_loss          | -3.29        |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0.00431      |
|    learning_rate         | 0.0003       |
|    loss                  | 13.1         |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 1.25         |
|    value_loss            | 30.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0791       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0791       |
| reward                   | -0.5492501   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.23e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 17           |
|    time_elapsed          | 369          |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0035363554 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.8          |
|    cost_value_loss       | 74.1         |
|    cost_values           | 1.56         |
|    entropy               | -3.29        |
|    entropy_loss          | -3.29        |
|    explained_variance    | 0.87         |
|    lagrangian_multiplier | 0.00854      |
|    learning_rate         | 0.0003       |
|    loss                  | 17.2         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 1.25         |
|    value_loss            | 90.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.236        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.236        |
| reward                   | -0.5500715   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 18           |
|    time_elapsed          | 391          |
|    total_timesteps       | 337920       |
| train/                   |              |
|    approx_kl             | 0.0056398297 |
|    clip_fraction         | 0.0695       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.54         |
|    cost_value_loss       | 45.6         |
|    cost_values           | 1.38         |
|    entropy               | -3.28        |
|    entropy_loss          | -3.28        |
|    explained_variance    | 0.93         |
|    lagrangian_multiplier | 0.00624      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 1640         |
|    policy_gradient_loss  | -0.00708     |
|    std                   | 1.25         |
|    value_loss            | 27.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0801       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0801       |
| reward                   | -0.41608074  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 19           |
|    time_elapsed          | 413          |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0090304185 |
|    clip_fraction         | 0.0697       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.531        |
|    cost_value_loss       | 0.544        |
|    cost_values           | 0.346        |
|    entropy               | -3.25        |
|    entropy_loss          | -3.27        |
|    explained_variance    | 0.951        |
|    lagrangian_multiplier | 0.000221     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.19         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.0116      |
|    std                   | 1.23         |
|    value_loss            | 5.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0888      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0888      |
| reward                   | -0.55258596 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 20          |
|    time_elapsed          | 435         |
|    total_timesteps       | 342016      |
| train/                   |             |
|    approx_kl             | 0.008815471 |
|    clip_fraction         | 0.0531      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.22       |
|    cost_value_loss       | 0.0976      |
|    cost_values           | -0.399      |
|    entropy               | -3.25       |
|    entropy_loss          | -3.24       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 2.85e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.39        |
|    n_updates             | 1660        |
|    policy_gradient_loss  | -0.00791    |
|    std                   | 1.23        |
|    value_loss            | 4.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.36         |
| reward                   | -0.44579354  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 21           |
|    time_elapsed          | 457          |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0054871235 |
|    clip_fraction         | 0.0398       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.1         |
|    cost_value_loss       | 0.202        |
|    cost_values           | -0.234       |
|    entropy               | -3.25        |
|    entropy_loss          | -3.25        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.81         |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 1.23         |
|    value_loss            | 8.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00815      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00815      |
| reward                   | -0.38611686  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 22           |
|    time_elapsed          | 479          |
|    total_timesteps       | 346112       |
| train/                   |              |
|    approx_kl             | 0.0049706385 |
|    clip_fraction         | 0.0142       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.414       |
|    cost_value_loss       | 0.0321       |
|    cost_values           | -0.567       |
|    entropy               | -3.24        |
|    entropy_loss          | -3.25        |
|    explained_variance    | -0.564       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.13         |
|    n_updates             | 1680         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 1.22         |
|    value_loss            | 15.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.132       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.132       |
| reward                   | -0.62324554 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 23          |
|    time_elapsed          | 500         |
|    total_timesteps       | 348160      |
| train/                   |             |
|    approx_kl             | 0.007841676 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.311      |
|    cost_value_loss       | 0.0187      |
|    cost_values           | -0.319      |
|    entropy               | -3.23       |
|    entropy_loss          | -3.23       |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.05        |
|    n_updates             | 1690        |
|    policy_gradient_loss  | -0.00422    |
|    std                   | 1.22        |
|    value_loss            | 3.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.356        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.356        |
| reward                   | -0.44844773  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 24           |
|    time_elapsed          | 522          |
|    total_timesteps       | 350208       |
| train/                   |              |
|    approx_kl             | 0.0066207442 |
|    clip_fraction         | 0.0546       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.358       |
|    cost_value_loss       | 0.00463      |
|    cost_values           | -0.374       |
|    entropy               | -3.16        |
|    entropy_loss          | -3.2         |
|    explained_variance    | 0.617        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.224        |
|    n_updates             | 1700         |
|    policy_gradient_loss  | -0.00524     |
|    std                   | 1.18         |
|    value_loss            | 0.716        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.651        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.651        |
| reward                   | -0.45865142  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 25           |
|    time_elapsed          | 545          |
|    total_timesteps       | 352256       |
| train/                   |              |
|    approx_kl             | 0.0055376254 |
|    clip_fraction         | 0.073        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.298       |
|    cost_value_loss       | 0.00535      |
|    cost_values           | -0.325       |
|    entropy               | -3.15        |
|    entropy_loss          | -3.15        |
|    explained_variance    | 0.858        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.167        |
|    n_updates             | 1710         |
|    policy_gradient_loss  | -0.00509     |
|    std                   | 1.17         |
|    value_loss            | 0.663        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.195       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.195       |
| reward                   | -0.38558292 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 26          |
|    time_elapsed          | 567         |
|    total_timesteps       | 354304      |
| train/                   |             |
|    approx_kl             | 0.008183439 |
|    clip_fraction         | 0.0748      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.285      |
|    cost_value_loss       | 0.00225     |
|    cost_values           | -0.306      |
|    entropy               | -3.17       |
|    entropy_loss          | -3.15       |
|    explained_variance    | -0.0955     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.111       |
|    n_updates             | 1720        |
|    policy_gradient_loss  | -0.00407    |
|    std                   | 1.18        |
|    value_loss            | 0.431       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.235        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.235        |
| reward                   | -0.28823668  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 27           |
|    time_elapsed          | 589          |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0059404043 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.213       |
|    cost_value_loss       | 0.00121      |
|    cost_values           | -0.214       |
|    entropy               | -3.17        |
|    entropy_loss          | -3.17        |
|    explained_variance    | 0.589        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.148        |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 1.18         |
|    value_loss            | 0.736        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0577       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0577       |
| reward                   | -0.45460695  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 28           |
|    time_elapsed          | 611          |
|    total_timesteps       | 358400       |
| train/                   |              |
|    approx_kl             | 0.0046040523 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.202       |
|    cost_value_loss       | 0.0066       |
|    cost_values           | -0.272       |
|    entropy               | -3.16        |
|    entropy_loss          | -3.16        |
|    explained_variance    | 0.142        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.322        |
|    n_updates             | 1740         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 1.17         |
|    value_loss            | 1.38         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0152      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0152      |
| reward                   | -0.3822324  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 29          |
|    time_elapsed          | 633         |
|    total_timesteps       | 360448      |
| train/                   |             |
|    approx_kl             | 0.005166892 |
|    clip_fraction         | 0.0272      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.139      |
|    cost_value_loss       | 0.000725    |
|    cost_values           | -0.138      |
|    entropy               | -3.16       |
|    entropy_loss          | -3.16       |
|    explained_variance    | 0.498       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.219       |
|    n_updates             | 1750        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 1.17        |
|    value_loss            | 0.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0921      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0921      |
| reward                   | -0.3648984  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -989        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 30          |
|    time_elapsed          | 655         |
|    total_timesteps       | 362496      |
| train/                   |             |
|    approx_kl             | 0.003518799 |
|    clip_fraction         | 0.00981     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.163      |
|    cost_value_loss       | 0.00218     |
|    cost_values           | -0.199      |
|    entropy               | -3.15       |
|    entropy_loss          | -3.16       |
|    explained_variance    | -1.27       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.4         |
|    n_updates             | 1760        |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 1.17        |
|    value_loss            | 2.28        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.332        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.332        |
| reward                   | -0.2651271   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -975         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 31           |
|    time_elapsed          | 677          |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0055123847 |
|    clip_fraction         | 0.055        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.101       |
|    cost_value_loss       | 0.000457     |
|    cost_values           | -0.101       |
|    entropy               | -3.16        |
|    entropy_loss          | -3.15        |
|    explained_variance    | -0.537       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.111        |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.00416     |
|    std                   | 1.17         |
|    value_loss            | 0.745        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0539      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0539      |
| reward                   | -0.7337023  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -959        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 32          |
|    time_elapsed          | 699         |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.003023347 |
|    clip_fraction         | 0.0451      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.141      |
|    cost_value_loss       | 0.000384    |
|    cost_values           | -0.148      |
|    entropy               | -3.15       |
|    entropy_loss          | -3.16       |
|    explained_variance    | -0.174      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.881       |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.00395    |
|    std                   | 1.17        |
|    value_loss            | 2.11        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.125        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.125        |
| reward                   | -0.3392914   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -917         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 33           |
|    time_elapsed          | 721          |
|    total_timesteps       | 368640       |
| train/                   |              |
|    approx_kl             | 0.0023451834 |
|    clip_fraction         | 0.0605       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0852      |
|    cost_value_loss       | 0.00149      |
|    cost_values           | -0.0775      |
|    entropy               | -3.15        |
|    entropy_loss          | -3.15        |
|    explained_variance    | 0.622        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.976        |
|    n_updates             | 1790         |
|    policy_gradient_loss  | -0.000378    |
|    std                   | 1.17         |
|    value_loss            | 4.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0106      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0106      |
| reward                   | -0.4285967  |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -891        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 34          |
|    time_elapsed          | 743         |
|    total_timesteps       | 370688      |
| train/                   |             |
|    approx_kl             | 0.002702469 |
|    clip_fraction         | 0.00278     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.088      |
|    cost_value_loss       | 0.00199     |
|    cost_values           | -0.11       |
|    entropy               | -3.15       |
|    entropy_loss          | -3.15       |
|    explained_variance    | 0.16        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.65        |
|    n_updates             | 1800        |
|    policy_gradient_loss  | -0.000737   |
|    std                   | 1.17        |
|    value_loss            | 23          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.029        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.029        |
| reward                   | -0.600888    |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -862         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 35           |
|    time_elapsed          | 765          |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 0.0033546828 |
|    clip_fraction         | 0.00225      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0616      |
|    cost_value_loss       | 0.000371     |
|    cost_values           | -0.0706      |
|    entropy               | -3.15        |
|    entropy_loss          | -3.15        |
|    explained_variance    | 0.28         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.79         |
|    n_updates             | 1810         |
|    policy_gradient_loss  | -0.000961    |
|    std                   | 1.17         |
|    value_loss            | 8.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.015        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.015        |
| reward                   | -0.557535    |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -824         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 36           |
|    time_elapsed          | 788          |
|    total_timesteps       | 374784       |
| train/                   |              |
|    approx_kl             | 0.0044345073 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00456     |
|    cost_value_loss       | 0.00236      |
|    cost_values           | 0.0128       |
|    entropy               | -3.15        |
|    entropy_loss          | -3.15        |
|    explained_variance    | 0.894        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.248        |
|    n_updates             | 1820         |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 1.17         |
|    value_loss            | 1.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.156        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.156        |
| reward                   | -0.5134043   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -806         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 37           |
|    time_elapsed          | 810          |
|    total_timesteps       | 376832       |
| train/                   |              |
|    approx_kl             | 0.0018079663 |
|    clip_fraction         | 0.00874      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0435      |
|    cost_value_loss       | 0.000799     |
|    cost_values           | -0.0449      |
|    entropy               | -3.15        |
|    entropy_loss          | -3.15        |
|    explained_variance    | 0.702        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.86         |
|    n_updates             | 1830         |
|    policy_gradient_loss  | -0.000525    |
|    std                   | 1.17         |
|    value_loss            | 7.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.254       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.254       |
| reward                   | -0.43614796 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -782        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 38          |
|    time_elapsed          | 832         |
|    total_timesteps       | 378880      |
| train/                   |             |
|    approx_kl             | 0.006059129 |
|    clip_fraction         | 0.0276      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0697     |
|    cost_value_loss       | 0.000643    |
|    cost_values           | -0.071      |
|    entropy               | -3.15       |
|    entropy_loss          | -3.15       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.126       |
|    n_updates             | 1840        |
|    policy_gradient_loss  | -0.00336    |
|    std                   | 1.17        |
|    value_loss            | 0.951       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0558       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0558       |
| reward                   | -0.44823438  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 39           |
|    time_elapsed          | 854          |
|    total_timesteps       | 380928       |
| train/                   |              |
|    approx_kl             | 0.0034595993 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0832      |
|    cost_value_loss       | 0.000278     |
|    cost_values           | -0.0969      |
|    entropy               | -3.15        |
|    entropy_loss          | -3.15        |
|    explained_variance    | 0.736        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.712        |
|    n_updates             | 1850         |
|    policy_gradient_loss  | -0.00272     |
|    std                   | 1.17         |
|    value_loss            | 2.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.272        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.272        |
| reward                   | -0.5118234   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -749         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 40           |
|    time_elapsed          | 875          |
|    total_timesteps       | 382976       |
| train/                   |              |
|    approx_kl             | 0.0055387896 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0562      |
|    cost_value_loss       | 0.000273     |
|    cost_values           | -0.0685      |
|    entropy               | -3.14        |
|    entropy_loss          | -3.14        |
|    explained_variance    | 0.9          |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0479       |
|    n_updates             | 1860         |
|    policy_gradient_loss  | -0.00309     |
|    std                   | 1.16         |
|    value_loss            | 0.429        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.287        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.287        |
| reward                   | -0.51299     |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -735         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 41           |
|    time_elapsed          | 897          |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0038861788 |
|    clip_fraction         | 0.0443       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.052       |
|    cost_value_loss       | 4.5e-05      |
|    cost_values           | -0.0548      |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | 0.684        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.479        |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 1.16         |
|    value_loss            | 1.75         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0268       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0268       |
| reward                   | -0.36799887  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -714         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 42           |
|    time_elapsed          | 919          |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0036780685 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0286      |
|    cost_value_loss       | 3.34e-05     |
|    cost_values           | -0.0301      |
|    entropy               | -3.12        |
|    entropy_loss          | -3.13        |
|    explained_variance    | 0.706        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.79         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 1.15         |
|    value_loss            | 2.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0815      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0815      |
| reward                   | -0.41530418 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -687        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 43          |
|    time_elapsed          | 940         |
|    total_timesteps       | 389120      |
| train/                   |             |
|    approx_kl             | 0.005817376 |
|    clip_fraction         | 0.0527      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00061    |
|    cost_value_loss       | 0.000154    |
|    cost_values           | -0.00377    |
|    entropy               | -3.12       |
|    entropy_loss          | -3.12       |
|    explained_variance    | -2.07       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.191       |
|    n_updates             | 1890        |
|    policy_gradient_loss  | -0.00528    |
|    std                   | 1.15        |
|    value_loss            | 0.711       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.53487563  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -671         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 44           |
|    time_elapsed          | 962          |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0043195947 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00622     |
|    cost_value_loss       | 1.36e-05     |
|    cost_values           | -0.0054      |
|    entropy               | -3.11        |
|    entropy_loss          | -3.12        |
|    explained_variance    | -0.15        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.574        |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.00208     |
|    std                   | 1.15         |
|    value_loss            | 1.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.223        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.223        |
| reward                   | -0.30033356  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -659         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 45           |
|    time_elapsed          | 984          |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0061531495 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00404     |
|    cost_value_loss       | 0.000112     |
|    cost_values           | 0.000779     |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.0704       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.593        |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 1.14         |
|    value_loss            | 2.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.318        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.318        |
| reward                   | -0.3404363   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -642         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 46           |
|    time_elapsed          | 1005         |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0067682457 |
|    clip_fraction         | 0.0382       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.02         |
|    cost_value_loss       | 3.52         |
|    cost_values           | 0.5          |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.2         |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -0.00672     |
|    std                   | 1.14         |
|    value_loss            | 39.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.245        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.245        |
| reward                   | -0.5054437   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -619         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 47           |
|    time_elapsed          | 1027         |
|    total_timesteps       | 397312       |
| train/                   |              |
|    approx_kl             | 0.0029840115 |
|    clip_fraction         | 0.00332      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.043        |
|    cost_value_loss       | 0.000534     |
|    cost_values           | 0.0485       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.565        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.467        |
|    n_updates             | 1930         |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 1.14         |
|    value_loss            | 1.91         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0061      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0061      |
| reward                   | -0.49908566 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -604        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 48          |
|    time_elapsed          | 1050        |
|    total_timesteps       | 399360      |
| train/                   |             |
|    approx_kl             | 0.003378254 |
|    clip_fraction         | 0.0145      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.261       |
|    cost_value_loss       | 0.0599      |
|    cost_values           | 0.333       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 1940        |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 1.14        |
|    value_loss            | 17.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0805      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0805      |
| reward                   | -0.22927311 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -589        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 49          |
|    time_elapsed          | 1072        |
|    total_timesteps       | 401408      |
| train/                   |             |
|    approx_kl             | 0.007984924 |
|    clip_fraction         | 0.021       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.268       |
|    cost_value_loss       | 0.0592      |
|    cost_values           | 0.359       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.01        |
|    n_updates             | 1950        |
|    policy_gradient_loss  | -0.00241    |
|    std                   | 1.14        |
|    value_loss            | 4.88        |
------------------------------------------
------------------------------------
| avg_speed          | 0.127       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.127       |
| reward             | -0.43592402 |
| rollout/           |             |
|    ep_len_mean     | 958         |
|    ep_rew_mean     | -573        |
| time/              |             |
|    fps             | 96          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 403456      |
------------------------------------
------------------------------------------
| avg_speed                | 0.105       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.105       |
| reward                   | -0.37415037 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -566        |
| time/                    |             |
|    fps                   | 95          |
|    iterations            | 2           |
|    time_elapsed          | 42          |
|    total_timesteps       | 405504      |
| train/                   |             |
|    approx_kl             | 0.004776182 |
|    clip_fraction         | 0.0109      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0017      |
|    cost_value_loss       | 0.00727     |
|    cost_values           | 0.0419      |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.599       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.966       |
|    n_updates             | 1970        |
|    policy_gradient_loss  | -0.00155    |
|    std                   | 1.15        |
|    value_loss            | 3.72        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.137        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.137        |
| reward                   | -0.47873786  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -548         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 3            |
|    time_elapsed          | 64           |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0054106433 |
|    clip_fraction         | 0.0586       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.107       |
|    cost_value_loss       | 0.00039      |
|    cost_values           | -0.115       |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | -0.284       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.19         |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.00547     |
|    std                   | 1.14         |
|    value_loss            | 0.542        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.348        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.348        |
| reward                   | -0.42531997  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -534         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0037507291 |
|    clip_fraction         | 0.0324       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0427      |
|    cost_value_loss       | 0.00092      |
|    cost_values           | -0.0361      |
|    entropy               | -3.09        |
|    entropy_loss          | -3.09        |
|    explained_variance    | 0.702        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.169        |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.00337     |
|    std                   | 1.13         |
|    value_loss            | 0.816        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.5007665   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -521         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0059407065 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.055       |
|    cost_value_loss       | 0.000337     |
|    cost_values           | -0.0589      |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.408        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0894       |
|    n_updates             | 2000         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 1.13         |
|    value_loss            | 0.778        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.253        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.253        |
| reward                   | -0.3439307   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -514         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 6            |
|    time_elapsed          | 131          |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0025039273 |
|    clip_fraction         | 0.00864      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.013       |
|    cost_value_loss       | 0.00122      |
|    cost_values           | -0.0201      |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.187        |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 1.12         |
|    value_loss            | 0.769        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.177        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.177        |
| reward                   | -0.44427755  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -507         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 153          |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0018099614 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0226       |
|    cost_value_loss       | 0.000636     |
|    cost_values           | 0.0165       |
|    entropy               | -3.06        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.849        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.205        |
|    n_updates             | 2020         |
|    policy_gradient_loss  | -0.000641    |
|    std                   | 1.12         |
|    value_loss            | 0.964        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.19        |
| reward                   | -0.16862185 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -495        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 175         |
|    total_timesteps       | 417792      |
| train/                   |             |
|    approx_kl             | 0.003208628 |
|    clip_fraction         | 0.0104      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0176     |
|    cost_value_loss       | 0.000518    |
|    cost_values           | -0.0324     |
|    entropy               | -3.06       |
|    entropy_loss          | -3.06       |
|    explained_variance    | -4.27       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0427      |
|    n_updates             | 2030        |
|    policy_gradient_loss  | -0.000868   |
|    std                   | 1.12        |
|    value_loss            | 0.597       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.125       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.125       |
| reward                   | -0.3299908  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -483        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 9           |
|    time_elapsed          | 197         |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.002897481 |
|    clip_fraction         | 0.0139      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0282     |
|    cost_value_loss       | 0.000294    |
|    cost_values           | -0.034      |
|    entropy               | -3.05       |
|    entropy_loss          | -3.05       |
|    explained_variance    | 0.22        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 1.11        |
|    value_loss            | 3.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.32         |
| reward                   | -0.33695045  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 219          |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0024201262 |
|    clip_fraction         | 0.00635      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0339       |
|    cost_value_loss       | 0.000326     |
|    cost_values           | 0.0263       |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.799        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.151        |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 1.11         |
|    value_loss            | 1.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.287        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.287        |
| reward                   | -0.19485418  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 241          |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0024222168 |
|    clip_fraction         | 0.0063       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0577      |
|    cost_value_loss       | 0.000122     |
|    cost_values           | -0.0605      |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.582        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0947       |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.00136     |
|    std                   | 1.1          |
|    value_loss            | 0.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.308        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.308        |
| reward                   | -0.32131493  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 264          |
|    total_timesteps       | 425984       |
| train/                   |              |
|    approx_kl             | 0.0051416424 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.014        |
|    cost_value_loss       | 0.00324      |
|    cost_values           | 0.0333       |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.602        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.436        |
|    n_updates             | 2070         |
|    policy_gradient_loss  | -0.0024      |
|    std                   | 1.1          |
|    value_loss            | 2.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0341       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0341       |
| reward                   | -0.16073182  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 286          |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0025713919 |
|    clip_fraction         | 0.00894      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0393       |
|    cost_value_loss       | 0.000283     |
|    cost_values           | 0.0322       |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.848        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.193        |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 1.1          |
|    value_loss            | 0.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.376        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.376        |
| reward                   | -0.57809967  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -419         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 308          |
|    total_timesteps       | 430080       |
| train/                   |              |
|    approx_kl             | 0.0030938648 |
|    clip_fraction         | 0.00298      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0805      |
|    cost_value_loss       | 0.000596     |
|    cost_values           | -0.1         |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.182        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.52         |
|    n_updates             | 2090         |
|    policy_gradient_loss  | -0.000723    |
|    std                   | 1.1          |
|    value_loss            | 6.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.28         |
| reward                   | -0.5074371   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 15           |
|    time_elapsed          | 330          |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0059161563 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0137      |
|    cost_value_loss       | 0.00184      |
|    cost_values           | -0.00312     |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.859        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.541        |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 1.1          |
|    value_loss            | 1.84         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.323        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.323        |
| reward                   | -0.44108495  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 16           |
|    time_elapsed          | 351          |
|    total_timesteps       | 434176       |
| train/                   |              |
|    approx_kl             | 0.0023311214 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0223       |
|    cost_value_loss       | 0.000414     |
|    cost_values           | 0.0204       |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.316        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.964        |
|    n_updates             | 2110         |
|    policy_gradient_loss  | -0.000736    |
|    std                   | 1.1          |
|    value_loss            | 3.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.33         |
| reward                   | -0.32292596  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 373          |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0068750656 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0025      |
|    cost_value_loss       | 0.000501     |
|    cost_values           | -0.00101     |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | -0.691       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0987       |
|    n_updates             | 2120         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 1.09         |
|    value_loss            | 1.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00361     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00361     |
| reward                   | -0.20244496 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 18          |
|    time_elapsed          | 395         |
|    total_timesteps       | 438272      |
| train/                   |             |
|    approx_kl             | 0.004832272 |
|    clip_fraction         | 0.0122      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0145      |
|    cost_value_loss       | 0.000149    |
|    cost_values           | 0.0108      |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | -0.988      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.375       |
|    n_updates             | 2130        |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 1.1         |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0183      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0183      |
| reward                   | -0.5555071  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 19          |
|    time_elapsed          | 417         |
|    total_timesteps       | 440320      |
| train/                   |             |
|    approx_kl             | 0.004056924 |
|    clip_fraction         | 0.02        |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0255     |
|    cost_value_loss       | 8.19e-05    |
|    cost_values           | -0.0238     |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.422       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.491       |
|    n_updates             | 2140        |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 1.09        |
|    value_loss            | 1.78        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.168        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.168        |
| reward                   | -0.43812284  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 20           |
|    time_elapsed          | 439          |
|    total_timesteps       | 442368       |
| train/                   |              |
|    approx_kl             | 0.0038433992 |
|    clip_fraction         | 0.00288      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0664       |
|    cost_value_loss       | 0.00165      |
|    cost_values           | 0.0969       |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.211        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.13         |
|    n_updates             | 2150         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 1.09         |
|    value_loss            | 1.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0931      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0931      |
| reward                   | -0.46172097 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 21          |
|    time_elapsed          | 461         |
|    total_timesteps       | 444416      |
| train/                   |             |
|    approx_kl             | 0.006110342 |
|    clip_fraction         | 0.0166      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00902    |
|    cost_value_loss       | 0.000833    |
|    cost_values           | -0.0128     |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0663      |
|    n_updates             | 2160        |
|    policy_gradient_loss  | -0.00163    |
|    std                   | 1.09        |
|    value_loss            | 0.386       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.44         |
| reward                   | -0.3199967   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 22           |
|    time_elapsed          | 483          |
|    total_timesteps       | 446464       |
| train/                   |              |
|    approx_kl             | 0.0050795623 |
|    clip_fraction         | 0.00933      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0506      |
|    cost_value_loss       | 8.33e-05     |
|    cost_values           | -0.0538      |
|    entropy               | -3           |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.791        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0492       |
|    n_updates             | 2170         |
|    policy_gradient_loss  | -0.000159    |
|    std                   | 1.09         |
|    value_loss            | 0.375        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.131        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.131        |
| reward                   | -0.35357925  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 23           |
|    time_elapsed          | 505          |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0033695349 |
|    clip_fraction         | 0.041        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0433      |
|    cost_value_loss       | 4.79e-05     |
|    cost_values           | -0.0463      |
|    entropy               | -2.99        |
|    entropy_loss          | -3           |
|    explained_variance    | 0.823        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0578       |
|    n_updates             | 2180         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 1.08         |
|    value_loss            | 0.163        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.068       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.068       |
| reward                   | -0.3140247  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 24          |
|    time_elapsed          | 527         |
|    total_timesteps       | 450560      |
| train/                   |             |
|    approx_kl             | 0.003732698 |
|    clip_fraction         | 0.0229      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.049       |
|    cost_value_loss       | 0.000673    |
|    cost_values           | 0.0539      |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0497      |
|    n_updates             | 2190        |
|    policy_gradient_loss  | -0.00121    |
|    std                   | 1.08        |
|    value_loss            | 0.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.231        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.231        |
| reward                   | -0.39442712  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 25           |
|    time_elapsed          | 549          |
|    total_timesteps       | 452608       |
| train/                   |              |
|    approx_kl             | 0.0044537326 |
|    clip_fraction         | 0.0322       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0676       |
|    cost_value_loss       | 0.000304     |
|    cost_values           | 0.0692       |
|    entropy               | -2.98        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.72         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0909       |
|    n_updates             | 2200         |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 1.08         |
|    value_loss            | 0.325        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0398      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0398      |
| reward                   | -0.43492776 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 26          |
|    time_elapsed          | 571         |
|    total_timesteps       | 454656      |
| train/                   |             |
|    approx_kl             | 0.004230295 |
|    clip_fraction         | 0.0202      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0148      |
|    cost_value_loss       | 0.000302    |
|    cost_values           | 0.0139      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.166       |
|    n_updates             | 2210        |
|    policy_gradient_loss  | -0.00266    |
|    std                   | 1.07        |
|    value_loss            | 0.493       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.142        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.142        |
| reward                   | -0.3585282   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 27           |
|    time_elapsed          | 593          |
|    total_timesteps       | 456704       |
| train/                   |              |
|    approx_kl             | 0.0061657205 |
|    clip_fraction         | 0.0331       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0242       |
|    cost_value_loss       | 0.00114      |
|    cost_values           | 0.0356       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0783       |
|    n_updates             | 2220         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 1.07         |
|    value_loss            | 0.616        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.274       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.274       |
| reward                   | -0.523939   |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 28          |
|    time_elapsed          | 614         |
|    total_timesteps       | 458752      |
| train/                   |             |
|    approx_kl             | 0.004101703 |
|    clip_fraction         | 0.029       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00981    |
|    cost_value_loss       | 9.97e-05    |
|    cost_values           | -0.0124     |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0578      |
|    n_updates             | 2230        |
|    policy_gradient_loss  | -0.0009     |
|    std                   | 1.07        |
|    value_loss            | 0.314       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.182        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.182        |
| reward                   | -0.41824853  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 29           |
|    time_elapsed          | 636          |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0010802592 |
|    clip_fraction         | 0.0042       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0258       |
|    cost_value_loss       | 5.97e-05     |
|    cost_values           | 0.0231       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | -0.0517      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.466        |
|    n_updates             | 2240         |
|    policy_gradient_loss  | 1.89e-05     |
|    std                   | 1.07         |
|    value_loss            | 1.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.201       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.201       |
| reward                   | -0.26857743 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 30          |
|    time_elapsed          | 658         |
|    total_timesteps       | 462848      |
| train/                   |             |
|    approx_kl             | 0.003877699 |
|    clip_fraction         | 0.0653      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0293      |
|    cost_value_loss       | 0.00205     |
|    cost_values           | 0.0522      |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.763       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.04        |
|    n_updates             | 2250        |
|    policy_gradient_loss  | -0.00153    |
|    std                   | 1.06        |
|    value_loss            | 1.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0808      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0808      |
| reward                   | -0.5000218  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 31          |
|    time_elapsed          | 680         |
|    total_timesteps       | 464896      |
| train/                   |             |
|    approx_kl             | 0.005990931 |
|    clip_fraction         | 0.00869     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0673     |
|    cost_value_loss       | 0.000391    |
|    cost_values           | -0.0789     |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | -4.78       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0875      |
|    n_updates             | 2260        |
|    policy_gradient_loss  | -0.000998   |
|    std                   | 1.06        |
|    value_loss            | 0.559       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.435        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.435        |
| reward                   | -0.46104756  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 32           |
|    time_elapsed          | 702          |
|    total_timesteps       | 466944       |
| train/                   |              |
|    approx_kl             | 0.0036640624 |
|    clip_fraction         | 0.00752      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0343      |
|    cost_value_loss       | 0.000155     |
|    cost_values           | -0.044       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.265        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.058        |
|    n_updates             | 2270         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 1.06         |
|    value_loss            | 0.775        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0566       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0566       |
| reward                   | -0.43359122  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 33           |
|    time_elapsed          | 725          |
|    total_timesteps       | 468992       |
| train/                   |              |
|    approx_kl             | 0.0042305044 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0409      |
|    cost_value_loss       | 3.43e-05     |
|    cost_values           | -0.0433      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.441        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.343        |
|    n_updates             | 2280         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 1.07         |
|    value_loss            | 0.863        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0255       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0255       |
| reward                   | -0.19126269  |
| rollout/                 |              |
|    ep_len_mean           | 977          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 34           |
|    time_elapsed          | 747          |
|    total_timesteps       | 471040       |
| train/                   |              |
|    approx_kl             | 0.0041431673 |
|    clip_fraction         | 0.0148       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0166      |
|    cost_value_loss       | 1.12e-05     |
|    cost_values           | -0.0172      |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.623        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.083        |
|    n_updates             | 2290         |
|    policy_gradient_loss  | -0.000846    |
|    std                   | 1.07         |
|    value_loss            | 0.507        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.109        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.109        |
| reward                   | -0.49978963  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -409         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 35           |
|    time_elapsed          | 769          |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0040258677 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0112      |
|    cost_value_loss       | 1.58e-05     |
|    cost_values           | -0.0127      |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0468       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.99         |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 1.06         |
|    value_loss            | 2.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.135        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.135        |
| reward                   | -0.37152386  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 36           |
|    time_elapsed          | 791          |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0031612508 |
|    clip_fraction         | 0.00991      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0111      |
|    cost_value_loss       | 0.000251     |
|    cost_values           | -0.00741     |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.302        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.829        |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 1.06         |
|    value_loss            | 2.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0749       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0749       |
| reward                   | -0.44411987  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -410         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 37           |
|    time_elapsed          | 813          |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0037981567 |
|    clip_fraction         | 0.00942      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00757     |
|    cost_value_loss       | 0.00143      |
|    cost_values           | 0.0062       |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.421       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.274        |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 1.06         |
|    value_loss            | 1.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.236        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.236        |
| reward                   | -0.40311795  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 38           |
|    time_elapsed          | 835          |
|    total_timesteps       | 479232       |
| train/                   |              |
|    approx_kl             | 0.0053515136 |
|    clip_fraction         | 0.0404       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.031       |
|    cost_value_loss       | 0.000335     |
|    cost_values           | -0.0315      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.824        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0297       |
|    n_updates             | 2330         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 1.07         |
|    value_loss            | 0.194        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00733     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00733     |
| reward                   | -0.47837868 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -412        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 39          |
|    time_elapsed          | 857         |
|    total_timesteps       | 481280      |
| train/                   |             |
|    approx_kl             | 0.006051852 |
|    clip_fraction         | 0.0485      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0125      |
|    cost_value_loss       | 0.000225    |
|    cost_values           | 0.0123      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0507      |
|    n_updates             | 2340        |
|    policy_gradient_loss  | -0.00371    |
|    std                   | 1.07        |
|    value_loss            | 0.217       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0924      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0924      |
| reward                   | -0.3317464  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 40          |
|    time_elapsed          | 879         |
|    total_timesteps       | 483328      |
| train/                   |             |
|    approx_kl             | 0.005628825 |
|    clip_fraction         | 0.0386      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0278     |
|    cost_value_loss       | 0.000167    |
|    cost_values           | -0.0302     |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | -0.648      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0684      |
|    n_updates             | 2350        |
|    policy_gradient_loss  | -0.00251    |
|    std                   | 1.07        |
|    value_loss            | 0.317       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0353       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0353       |
| reward                   | -0.35733944  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 41           |
|    time_elapsed          | 901          |
|    total_timesteps       | 485376       |
| train/                   |              |
|    approx_kl             | 0.0039628786 |
|    clip_fraction         | 0.00928      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0186      |
|    cost_value_loss       | 0.000106     |
|    cost_values           | -0.024       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.626        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.208        |
|    n_updates             | 2360         |
|    policy_gradient_loss  | -0.000366    |
|    std                   | 1.07         |
|    value_loss            | 0.804        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0447      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0447      |
| reward                   | -0.38916397 |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 42          |
|    time_elapsed          | 923         |
|    total_timesteps       | 487424      |
| train/                   |             |
|    approx_kl             | 0.00714962  |
|    clip_fraction         | 0.056       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.032      |
|    cost_value_loss       | 6.14e-05    |
|    cost_values           | -0.0347     |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.184       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0457      |
|    n_updates             | 2370        |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 1.07        |
|    value_loss            | 0.224       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.177        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.177        |
| reward                   | -0.4217078   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 43           |
|    time_elapsed          | 945          |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0076743015 |
|    clip_fraction         | 0.0347       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.004        |
|    cost_value_loss       | 8.27e-05     |
|    cost_values           | 0.00768      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.833        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.179        |
|    n_updates             | 2380         |
|    policy_gradient_loss  | 0.000835     |
|    std                   | 1.07         |
|    value_loss            | 0.794        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.132        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.132        |
| reward                   | -0.25283682  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 44           |
|    time_elapsed          | 967          |
|    total_timesteps       | 491520       |
| train/                   |              |
|    approx_kl             | 0.0036854895 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0227       |
|    cost_value_loss       | 0.000213     |
|    cost_values           | 0.0317       |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.152        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.437        |
|    n_updates             | 2390         |
|    policy_gradient_loss  | -0.000615    |
|    std                   | 1.07         |
|    value_loss            | 1.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.234        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.234        |
| reward                   | -0.30591893  |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 45           |
|    time_elapsed          | 989          |
|    total_timesteps       | 493568       |
| train/                   |              |
|    approx_kl             | 0.0031445164 |
|    clip_fraction         | 0.00493      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0458      |
|    cost_value_loss       | 0.000168     |
|    cost_values           | -0.0532      |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.503        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.445        |
|    n_updates             | 2400         |
|    policy_gradient_loss  | -0.000513    |
|    std                   | 1.07         |
|    value_loss            | 1.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0901      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0901      |
| reward                   | -0.2977678  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 46          |
|    time_elapsed          | 1012        |
|    total_timesteps       | 495616      |
| train/                   |             |
|    approx_kl             | 0.002359925 |
|    clip_fraction         | 0.00996     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00981    |
|    cost_value_loss       | 0.000212    |
|    cost_values           | -0.0174     |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.684       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.177       |
|    n_updates             | 2410        |
|    policy_gradient_loss  | -0.0012     |
|    std                   | 1.07        |
|    value_loss            | 1.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0304       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0304       |
| reward                   | -0.400686    |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 47           |
|    time_elapsed          | 1034         |
|    total_timesteps       | 497664       |
| train/                   |              |
|    approx_kl             | 0.0022569979 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0121      |
|    cost_value_loss       | 0.000206     |
|    cost_values           | -0.0191      |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.913        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.178        |
|    n_updates             | 2420         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 1.07         |
|    value_loss            | 1.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.281        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.281        |
| reward                   | -0.44430998  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 48           |
|    time_elapsed          | 1056         |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0019844319 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00884     |
|    cost_value_loss       | 7.27e-05     |
|    cost_values           | -0.0131      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.93         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0231       |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 1.07         |
|    value_loss            | 0.154        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0152      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0152      |
| reward                   | -0.35604897 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 49          |
|    time_elapsed          | 1077        |
|    total_timesteps       | 501760      |
| train/                   |             |
|    approx_kl             | 0.006067528 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0232      |
|    cost_value_loss       | 0.00125     |
|    cost_values           | 0.0416      |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.161       |
|    n_updates             | 2440        |
|    policy_gradient_loss  | -0.000998   |
|    std                   | 1.07        |
|    value_loss            | 2.02        |
------------------------------------------
------------------------------------
| avg_speed          | 0.133       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.133       |
| reward             | -0.24824174 |
| rollout/           |             |
|    ep_len_mean     | 995         |
|    ep_rew_mean     | -387        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 503808      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.221        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.221        |
| reward                   | -0.4149174   |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0035038786 |
|    clip_fraction         | 0.00371      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0215      |
|    cost_value_loss       | 3.33e-05     |
|    cost_values           | -0.023       |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | -0.755       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.216        |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 1.07         |
|    value_loss            | 2.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.178        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.178        |
| reward                   | -0.33925393  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -383         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0034272051 |
|    clip_fraction         | 0.0331       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0281      |
|    cost_value_loss       | 3.17e-05     |
|    cost_values           | -0.0309      |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.496        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.45         |
|    n_updates             | 2470         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 1.07         |
|    value_loss            | 1.54         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0373       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0373       |
| reward                   | -0.26308006  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -382         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0065816394 |
|    clip_fraction         | 0.0319       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00639     |
|    cost_value_loss       | 2.4e-05      |
|    cost_values           | -0.00832     |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.406        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.176        |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 1.07         |
|    value_loss            | 0.938        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00508     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00508     |
| reward                   | -0.43689552 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -379        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 512000      |
| train/                   |             |
|    approx_kl             | 0.004900354 |
|    clip_fraction         | 0.0241      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0118     |
|    cost_value_loss       | 6e-06       |
|    cost_values           | -0.0127     |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.416       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.477       |
|    n_updates             | 2490        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 1.07        |
|    value_loss            | 1.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0111       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0111       |
| reward                   | -0.54201794  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -381         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 6            |
|    time_elapsed          | 131          |
|    total_timesteps       | 514048       |
| train/                   |              |
|    approx_kl             | 0.0048349155 |
|    clip_fraction         | 0.0251       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00785     |
|    cost_value_loss       | 9e-06        |
|    cost_values           | -0.0088      |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.325        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.42         |
|    n_updates             | 2500         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 1.07         |
|    value_loss            | 3.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.356       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.356       |
| reward                   | -0.38015708 |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -382        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 153         |
|    total_timesteps       | 516096      |
| train/                   |             |
|    approx_kl             | 0.002951839 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00552    |
|    cost_value_loss       | 9.77e-05    |
|    cost_values           | -0.00165    |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | -0.272      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.156       |
|    n_updates             | 2510        |
|    policy_gradient_loss  | -0.00232    |
|    std                   | 1.07        |
|    value_loss            | 1.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.158        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.158        |
| reward                   | -0.37705156  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -384         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 8            |
|    time_elapsed          | 175          |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0050759707 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00803     |
|    cost_value_loss       | 0.000243     |
|    cost_values           | -0.00549     |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | -1.89        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0639       |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -0.00328     |
|    std                   | 1.07         |
|    value_loss            | 0.913        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0474       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0474       |
| reward                   | -0.19837321  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 197          |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0036449332 |
|    clip_fraction         | 0.0507       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0216      |
|    cost_value_loss       | 0.000108     |
|    cost_values           | -0.0224      |
|    entropy               | -2.95        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.729        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.02         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 1.06         |
|    value_loss            | 0.129        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.189        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.189        |
| reward                   | -0.28187802  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 219          |
|    total_timesteps       | 522240       |
| train/                   |              |
|    approx_kl             | 0.0060986616 |
|    clip_fraction         | 0.0381       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0284      |
|    cost_value_loss       | 0.000334     |
|    cost_values           | -0.0288      |
|    entropy               | -2.93        |
|    entropy_loss          | -2.94        |
|    explained_variance    | -2.29        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.271        |
|    n_updates             | 2540         |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 1.05         |
|    value_loss            | 1.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0325       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0325       |
| reward                   | -0.38469365  |
| rollout/                 |              |
|    ep_len_mean           | 995          |
|    ep_rew_mean           | -384         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 242          |
|    total_timesteps       | 524288       |
| train/                   |              |
|    approx_kl             | 0.0024045082 |
|    clip_fraction         | 0.0149       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00155      |
|    cost_value_loss       | 0.00121      |
|    cost_values           | 0.0182       |
|    entropy               | -2.92        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.216        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.992        |
|    n_updates             | 2550         |
|    policy_gradient_loss  | -0.000109    |
|    std                   | 1.04         |
|    value_loss            | 3.55         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.028       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.028       |
| reward                   | -0.2614977  |
| rollout/                 |             |
|    ep_len_mean           | 995         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 12          |
|    time_elapsed          | 264         |
|    total_timesteps       | 526336      |
| train/                   |             |
|    approx_kl             | 0.004673574 |
|    clip_fraction         | 0.0167      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0169      |
|    cost_value_loss       | 0.00145     |
|    cost_values           | -6.75e-05   |
|    entropy               | -2.93       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.249       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0899      |
|    n_updates             | 2560        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 1.05        |
|    value_loss            | 1.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.167        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.167        |
| reward                   | -0.5217329   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 13           |
|    time_elapsed          | 286          |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0031497627 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000437     |
|    cost_value_loss       | 0.00051      |
|    cost_values           | -0.00736     |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.807        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.288        |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 1.05         |
|    value_loss            | 1.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.153       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.153       |
| reward                   | -0.4380249  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -390        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 14          |
|    time_elapsed          | 308         |
|    total_timesteps       | 530432      |
| train/                   |             |
|    approx_kl             | 0.003821846 |
|    clip_fraction         | 0.00615     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0313      |
|    cost_value_loss       | 0.00196     |
|    cost_values           | 0.0462      |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.869       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0854      |
|    n_updates             | 2580        |
|    policy_gradient_loss  | -0.000998   |
|    std                   | 1.05        |
|    value_loss            | 0.678       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0941       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0941       |
| reward                   | -0.55295366  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 330          |
|    total_timesteps       | 532480       |
| train/                   |              |
|    approx_kl             | 0.0049115513 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0744      |
|    cost_value_loss       | 0.000516     |
|    cost_values           | -0.0753      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.87         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0936       |
|    n_updates             | 2590         |
|    policy_gradient_loss  | 0.000604     |
|    std                   | 1.04         |
|    value_loss            | 1.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0933       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0933       |
| reward                   | -0.42447686  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 352          |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0041758176 |
|    clip_fraction         | 0.0348       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0402      |
|    cost_value_loss       | 0.000154     |
|    cost_values           | -0.0445      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | -0.875       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.26         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 1.04         |
|    value_loss            | 4.09         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0774       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0774       |
| reward                   | -0.4166469   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 374          |
|    total_timesteps       | 536576       |
| train/                   |              |
|    approx_kl             | 0.0031261882 |
|    clip_fraction         | 0.00732      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00381     |
|    cost_value_loss       | 0.000365     |
|    cost_values           | 0.00378      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.671        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0724       |
|    n_updates             | 2610         |
|    policy_gradient_loss  | -0.000907    |
|    std                   | 1.04         |
|    value_loss            | 0.564        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.133        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.133        |
| reward                   | -0.31089744  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 18           |
|    time_elapsed          | 395          |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0018121818 |
|    clip_fraction         | 0.00381      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0437      |
|    cost_value_loss       | 9.92e-05     |
|    cost_values           | -0.0463      |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.874        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0221       |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.000967    |
|    std                   | 1.04         |
|    value_loss            | 0.184        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.297        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.297        |
| reward                   | -0.4562176   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -387         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 19           |
|    time_elapsed          | 417          |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0028106784 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0174      |
|    cost_value_loss       | 0.000151     |
|    cost_values           | -0.0185      |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.505        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.43         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.00106     |
|    std                   | 1.04         |
|    value_loss            | 1.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.227       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.227       |
| reward                   | -0.32911006 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 20          |
|    time_elapsed          | 439         |
|    total_timesteps       | 542720      |
| train/                   |             |
|    approx_kl             | 0.004558013 |
|    clip_fraction         | 0.0226      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0153     |
|    cost_value_loss       | 0.00124     |
|    cost_values           | -0.0112     |
|    entropy               | -2.92       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.797       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0819      |
|    n_updates             | 2640        |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 1.04        |
|    value_loss            | 0.458       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0811       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0811       |
| reward                   | -0.31264645  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -387         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 21           |
|    time_elapsed          | 460          |
|    total_timesteps       | 544768       |
| train/                   |              |
|    approx_kl             | 0.0038361545 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0929      |
|    cost_value_loss       | 0.000286     |
|    cost_values           | -0.0975      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.174        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.221        |
|    n_updates             | 2650         |
|    policy_gradient_loss  | -0.000777    |
|    std                   | 1.04         |
|    value_loss            | 1.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0959       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0959       |
| reward                   | -0.3262767   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 22           |
|    time_elapsed          | 482          |
|    total_timesteps       | 546816       |
| train/                   |              |
|    approx_kl             | 0.0018398648 |
|    clip_fraction         | 0.0141       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.076       |
|    cost_value_loss       | 0.00035      |
|    cost_values           | -0.0759      |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.319        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.221        |
|    n_updates             | 2660         |
|    policy_gradient_loss  | -0.00045     |
|    std                   | 1.04         |
|    value_loss            | 1.95         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.206       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.206       |
| reward                   | -0.36113918 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 23          |
|    time_elapsed          | 504         |
|    total_timesteps       | 548864      |
| train/                   |             |
|    approx_kl             | 0.002218194 |
|    clip_fraction         | 0.00083     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0904     |
|    cost_value_loss       | 0.000217    |
|    cost_values           | -0.0988     |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.282       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.18        |
|    n_updates             | 2670        |
|    policy_gradient_loss  | -0.000498   |
|    std                   | 1.04        |
|    value_loss            | 3.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0785      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0785      |
| reward                   | -0.3802098  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -388        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 24          |
|    time_elapsed          | 526         |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.008021504 |
|    clip_fraction         | 0.0677      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0616     |
|    cost_value_loss       | 0.000131    |
|    cost_values           | -0.0607     |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0209      |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.00362    |
|    std                   | 1.04        |
|    value_loss            | 0.0451      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.159        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.159        |
| reward                   | -0.523394    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 25           |
|    time_elapsed          | 548          |
|    total_timesteps       | 552960       |
| train/                   |              |
|    approx_kl             | 0.0067927334 |
|    clip_fraction         | 0.0717       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0477       |
|    cost_value_loss       | 0.000331     |
|    cost_values           | 0.0432       |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0908       |
|    n_updates             | 2690         |
|    policy_gradient_loss  | 0.00135      |
|    std                   | 1.04         |
|    value_loss            | 0.339        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0887       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0887       |
| reward                   | -0.5283437   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -387         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 26           |
|    time_elapsed          | 570          |
|    total_timesteps       | 555008       |
| train/                   |              |
|    approx_kl             | 0.0017199438 |
|    clip_fraction         | 0.00703      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00893     |
|    cost_value_loss       | 0.000262     |
|    cost_values           | -0.0084      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0539       |
|    n_updates             | 2700         |
|    policy_gradient_loss  | -0.000981    |
|    std                   | 1.03         |
|    value_loss            | 0.673        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.169        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.169        |
| reward                   | -0.15715426  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 27           |
|    time_elapsed          | 592          |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0030963614 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000107    |
|    cost_value_loss       | 0.000222     |
|    cost_values           | -0.00478     |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.183       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.08         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 1.03         |
|    value_loss            | 4.5          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0421       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0421       |
| reward                   | -0.24195722  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -384         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 28           |
|    time_elapsed          | 614          |
|    total_timesteps       | 559104       |
| train/                   |              |
|    approx_kl             | 0.0033491761 |
|    clip_fraction         | 0.00181      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0215      |
|    cost_value_loss       | 1.23e-05     |
|    cost_values           | -0.0211      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.436        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.51         |
|    n_updates             | 2720         |
|    policy_gradient_loss  | -0.000288    |
|    std                   | 1.03         |
|    value_loss            | 5.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0278      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0278      |
| reward                   | -0.22071846 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -378        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 29          |
|    time_elapsed          | 636         |
|    total_timesteps       | 561152      |
| train/                   |             |
|    approx_kl             | 0.004292833 |
|    clip_fraction         | 0.0261      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00436    |
|    cost_value_loss       | 3.07e-05    |
|    cost_values           | -0.0052     |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.32        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.42        |
|    n_updates             | 2730        |
|    policy_gradient_loss  | -0.000495   |
|    std                   | 1.03        |
|    value_loss            | 6.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.228       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.228       |
| reward                   | -0.24345711 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -379        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 30          |
|    time_elapsed          | 658         |
|    total_timesteps       | 563200      |
| train/                   |             |
|    approx_kl             | 0.005673133 |
|    clip_fraction         | 0.00894     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00129     |
|    cost_value_loss       | 6.89e-05    |
|    cost_values           | -0.00293    |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.587       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.333       |
|    n_updates             | 2740        |
|    policy_gradient_loss  | -0.000163   |
|    std                   | 1.03        |
|    value_loss            | 2.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.251       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.251       |
| reward                   | -0.3969952  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -374        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 31          |
|    time_elapsed          | 681         |
|    total_timesteps       | 565248      |
| train/                   |             |
|    approx_kl             | 0.002226747 |
|    clip_fraction         | 0.00293     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00128    |
|    cost_value_loss       | 1.95e-05    |
|    cost_values           | -0.00326    |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.428       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.64        |
|    n_updates             | 2750        |
|    policy_gradient_loss  | -0.00034    |
|    std                   | 1.03        |
|    value_loss            | 5.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0883       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0883       |
| reward                   | -0.46092495  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 32           |
|    time_elapsed          | 703          |
|    total_timesteps       | 567296       |
| train/                   |              |
|    approx_kl             | 0.0066189035 |
|    clip_fraction         | 0.0458       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00178     |
|    cost_value_loss       | 2.79e-05     |
|    cost_values           | -0.00292     |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.395        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.47         |
|    n_updates             | 2760         |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 1.03         |
|    value_loss            | 6            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0144       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0144       |
| reward                   | -0.37190995  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 33           |
|    time_elapsed          | 725          |
|    total_timesteps       | 569344       |
| train/                   |              |
|    approx_kl             | 0.0056193257 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0222      |
|    cost_value_loss       | 0.000292     |
|    cost_values           | -0.0142      |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.925        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.164        |
|    n_updates             | 2770         |
|    policy_gradient_loss  | -0.00177     |
|    std                   | 1.03         |
|    value_loss            | 1.9          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.155       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.155       |
| reward                   | -0.27325585 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -377        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 34          |
|    time_elapsed          | 747         |
|    total_timesteps       | 571392      |
| train/                   |             |
|    approx_kl             | 0.002472059 |
|    clip_fraction         | 0.0225      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0172     |
|    cost_value_loss       | 0.000158    |
|    cost_values           | -0.0148     |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.061       |
|    n_updates             | 2780        |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 1.03        |
|    value_loss            | 0.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.182       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.182       |
| reward                   | -0.4269147  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -374        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 35          |
|    time_elapsed          | 769         |
|    total_timesteps       | 573440      |
| train/                   |             |
|    approx_kl             | 0.003934594 |
|    clip_fraction         | 0.024       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0178     |
|    cost_value_loss       | 8.51e-05    |
|    cost_values           | -0.0213     |
|    entropy               | -2.88       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.759       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.461       |
|    n_updates             | 2790        |
|    policy_gradient_loss  | -0.00109    |
|    std                   | 1.02        |
|    value_loss            | 1.28        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00605      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00605      |
| reward                   | -0.28214884  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 36           |
|    time_elapsed          | 791          |
|    total_timesteps       | 575488       |
| train/                   |              |
|    approx_kl             | 0.0036144496 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0271      |
|    cost_value_loss       | 0.000392     |
|    cost_values           | -0.025       |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.473        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.215        |
|    n_updates             | 2800         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 1.02         |
|    value_loss            | 1.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0217      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0217      |
| reward                   | -0.50816184 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -372        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 37          |
|    time_elapsed          | 813         |
|    total_timesteps       | 577536      |
| train/                   |             |
|    approx_kl             | 0.004093568 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0132     |
|    cost_value_loss       | 3.54e-05    |
|    cost_values           | -0.0123     |
|    entropy               | -2.87       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.135       |
|    n_updates             | 2810        |
|    policy_gradient_loss  | -0.00316    |
|    std                   | 1.02        |
|    value_loss            | 0.346       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.106       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.106       |
| reward                   | -0.474606   |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -374        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 38          |
|    time_elapsed          | 835         |
|    total_timesteps       | 579584      |
| train/                   |             |
|    approx_kl             | 0.004432856 |
|    clip_fraction         | 0.0443      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.018      |
|    cost_value_loss       | 5.35e-05    |
|    cost_values           | -0.0175     |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.115       |
|    n_updates             | 2820        |
|    policy_gradient_loss  | -0.00286    |
|    std                   | 1.02        |
|    value_loss            | 0.535       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0942       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0942       |
| reward                   | -0.30167928  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 39           |
|    time_elapsed          | 857          |
|    total_timesteps       | 581632       |
| train/                   |              |
|    approx_kl             | 0.0055587767 |
|    clip_fraction         | 0.0308       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0322      |
|    cost_value_loss       | 0.00126      |
|    cost_values           | -0.0302      |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | -1.25        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.07         |
|    n_updates             | 2830         |
|    policy_gradient_loss  | 0.000418     |
|    std                   | 1.02         |
|    value_loss            | 1.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0127       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0127       |
| reward                   | -0.46982285  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -371         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 40           |
|    time_elapsed          | 879          |
|    total_timesteps       | 583680       |
| train/                   |              |
|    approx_kl             | 0.0031301586 |
|    clip_fraction         | 0.00742      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.017        |
|    cost_value_loss       | 0.000586     |
|    cost_values           | 0.0226       |
|    entropy               | -2.86        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.446        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.542        |
|    n_updates             | 2840         |
|    policy_gradient_loss  | -0.000445    |
|    std                   | 1.01         |
|    value_loss            | 2            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.053        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.053        |
| reward                   | -0.3272322   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -371         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 41           |
|    time_elapsed          | 901          |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0054053683 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0226      |
|    cost_value_loss       | 0.000253     |
|    cost_values           | -0.0248      |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.597        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.05         |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 1.01         |
|    value_loss            | 6.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0262       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0262       |
| reward                   | -0.31214994  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -371         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 42           |
|    time_elapsed          | 923          |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0011840512 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0134       |
|    cost_value_loss       | 0.000201     |
|    cost_values           | 0.0136       |
|    entropy               | -2.86        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.756        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0777       |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.000658    |
|    std                   | 1.01         |
|    value_loss            | 0.998        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.055        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.055        |
| reward                   | -0.34794658  |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -368         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 43           |
|    time_elapsed          | 945          |
|    total_timesteps       | 589824       |
| train/                   |              |
|    approx_kl             | 0.0041549085 |
|    clip_fraction         | 0.00928      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000772    |
|    cost_value_loss       | 0.000132     |
|    cost_values           | -0.00337     |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -1.31        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0533       |
|    n_updates             | 2870         |
|    policy_gradient_loss  | -0.000846    |
|    std                   | 1.02         |
|    value_loss            | 0.693        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.029        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.029        |
| reward                   | -0.48658234  |
| rollout/                 |              |
|    ep_len_mean           | 974          |
|    ep_rew_mean           | -368         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 44           |
|    time_elapsed          | 967          |
|    total_timesteps       | 591872       |
| train/                   |              |
|    approx_kl             | 0.0040824357 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00379     |
|    cost_value_loss       | 2.76e-05     |
|    cost_values           | -0.00359     |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.283        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.147        |
|    n_updates             | 2880         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 1.02         |
|    value_loss            | 0.509        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0379       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0379       |
| reward                   | -0.30406052  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -368         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 45           |
|    time_elapsed          | 989          |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0027359952 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0341       |
|    cost_value_loss       | 0.000117     |
|    cost_values           | 0.0352       |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.22         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.51         |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 1.02         |
|    value_loss            | 8.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0269       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0269       |
| reward                   | -0.4925716   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -367         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 46           |
|    time_elapsed          | 1011         |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0024435641 |
|    clip_fraction         | 0.00166      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00194      |
|    cost_value_loss       | 9.22e-05     |
|    cost_values           | -0.00108     |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.152        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.61         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.000332    |
|    std                   | 1.02         |
|    value_loss            | 6.69         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0386       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0386       |
| reward                   | -0.4041082   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -366         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 47           |
|    time_elapsed          | 1033         |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0025923245 |
|    clip_fraction         | 0.0042       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0138       |
|    cost_value_loss       | 0.000604     |
|    cost_values           | 0.0187       |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0837       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0377       |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.000732    |
|    std                   | 1.02         |
|    value_loss            | 1.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.271        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.271        |
| reward                   | -0.44285375  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -366         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 48           |
|    time_elapsed          | 1055         |
|    total_timesteps       | 600064       |
| train/                   |              |
|    approx_kl             | 0.0017372762 |
|    clip_fraction         | 0.00879      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00884      |
|    cost_value_loss       | 0.000215     |
|    cost_values           | 0.00974      |
|    entropy               | -2.88        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.873        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0732       |
|    n_updates             | 2920         |
|    policy_gradient_loss  | -0.00105     |
|    std                   | 1.02         |
|    value_loss            | 0.301        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.307        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.307        |
| reward                   | -0.52391803  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -370         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 49           |
|    time_elapsed          | 1077         |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0037175296 |
|    clip_fraction         | 0.0464       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0202       |
|    cost_value_loss       | 0.000144     |
|    cost_values           | 0.0227       |
|    entropy               | -2.87        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.78         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.106        |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 1.02         |
|    value_loss            | 0.386        |
-------------------------------------------
Directory created: PPOL_New/models/seed-testing/tggzx3rw/model_epoch(5)
-----------------------------------
| avg_speed          | 0.111      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.111      |
| reward             | -0.3005795 |
| rollout/           |            |
|    ep_len_mean     | 968        |
|    ep_rew_mean     | -370       |
| time/              |            |
|    fps             | 96         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 604160     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.159       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.159       |
| reward                   | -0.54569834 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -371        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 606208      |
| train/                   |             |
|    approx_kl             | 0.004133595 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0249     |
|    cost_value_loss       | 7.38e-05    |
|    cost_values           | -0.0261     |
|    entropy               | -2.86       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0435      |
|    n_updates             | 2950        |
|    policy_gradient_loss  | -0.00336    |
|    std                   | 1.02        |
|    value_loss            | 0.271       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.58        |
| reward                   | -0.54509157 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -376        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 608256      |
| train/                   |             |
|    approx_kl             | 0.006954279 |
|    clip_fraction         | 0.0261      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0239     |
|    cost_value_loss       | 9.34e-05    |
|    cost_values           | -0.0213     |
|    entropy               | -2.87       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.649       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0693      |
|    n_updates             | 2960        |
|    policy_gradient_loss  | -0.00319    |
|    std                   | 1.02        |
|    value_loss            | 1.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.353        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.353        |
| reward                   | -0.5432139   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -378         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 4            |
|    time_elapsed          | 86           |
|    total_timesteps       | 610304       |
| train/                   |              |
|    approx_kl             | 0.0025895878 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00779     |
|    cost_value_loss       | 3.74e-05     |
|    cost_values           | -0.00707     |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0203       |
|    n_updates             | 2970         |
|    policy_gradient_loss  | -0.00227     |
|    std                   | 1.02         |
|    value_loss            | 0.107        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.127        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.127        |
| reward                   | -0.21041317  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 612352       |
| train/                   |              |
|    approx_kl             | 0.0039342837 |
|    clip_fraction         | 0.0279       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0248      |
|    cost_value_loss       | 0.00027      |
|    cost_values           | -0.0208      |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0786       |
|    n_updates             | 2980         |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 1.02         |
|    value_loss            | 1.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0497      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0497      |
| reward                   | -0.52313834 |
| rollout/                 |             |
|    ep_len_mean           | 963         |
|    ep_rew_mean           | -374        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 6           |
|    time_elapsed          | 130         |
|    total_timesteps       | 614400      |
| train/                   |             |
|    approx_kl             | 0.005189531 |
|    clip_fraction         | 0.032       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00548    |
|    cost_value_loss       | 0.000378    |
|    cost_values           | 0.0022      |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0603      |
|    n_updates             | 2990        |
|    policy_gradient_loss  | -0.00401    |
|    std                   | 1.02        |
|    value_loss            | 1.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0836       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0836       |
| reward                   | -0.22746706  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 7            |
|    time_elapsed          | 151          |
|    total_timesteps       | 616448       |
| train/                   |              |
|    approx_kl             | 0.0069355937 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0284       |
|    cost_value_loss       | 0.000488     |
|    cost_values           | 0.0334       |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.721        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.66         |
|    n_updates             | 3000         |
|    policy_gradient_loss  | -0.00499     |
|    std                   | 1.02         |
|    value_loss            | 7.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.108        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.108        |
| reward                   | -0.36195773  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -373         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 8            |
|    time_elapsed          | 173          |
|    total_timesteps       | 618496       |
| train/                   |              |
|    approx_kl             | 0.0037137787 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.014       |
|    cost_value_loss       | 0.000623     |
|    cost_values           | -0.0199      |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.92         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.158        |
|    n_updates             | 3010         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 1.02         |
|    value_loss            | 1.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00738      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00738      |
| reward                   | -0.22711702  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -376         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 9            |
|    time_elapsed          | 195          |
|    total_timesteps       | 620544       |
| train/                   |              |
|    approx_kl             | 0.0036094598 |
|    clip_fraction         | 0.0154       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0178      |
|    cost_value_loss       | 0.000375     |
|    cost_values           | -0.0154      |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.0779      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.2          |
|    n_updates             | 3020         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 1.02         |
|    value_loss            | 1.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0173       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0173       |
| reward                   | -0.52422804  |
| rollout/                 |              |
|    ep_len_mean           | 963          |
|    ep_rew_mean           | -376         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 10           |
|    time_elapsed          | 217          |
|    total_timesteps       | 622592       |
| train/                   |              |
|    approx_kl             | 0.0043915454 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00726     |
|    cost_value_loss       | 0.000415     |
|    cost_values           | -0.00651     |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.912        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0453       |
|    n_updates             | 3030         |
|    policy_gradient_loss  | -0.00401     |
|    std                   | 1.01         |
|    value_loss            | 0.427        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.236        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.236        |
| reward                   | -0.49435973  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -375         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 11           |
|    time_elapsed          | 239          |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0051249983 |
|    clip_fraction         | 0.0112       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00423     |
|    cost_value_loss       | 0.000333     |
|    cost_values           | -0.00146     |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.886        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.263        |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 1.01         |
|    value_loss            | 1.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.124        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.124        |
| reward                   | -0.41398168  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -375         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 12           |
|    time_elapsed          | 261          |
|    total_timesteps       | 626688       |
| train/                   |              |
|    approx_kl             | 0.0044916216 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0849      |
|    cost_value_loss       | 0.000336     |
|    cost_values           | -0.0889      |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.618        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.27         |
|    n_updates             | 3050         |
|    policy_gradient_loss  | -0.000658    |
|    std                   | 1.01         |
|    value_loss            | 8.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.14        |
| reward                   | -0.3120445  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -375        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 13          |
|    time_elapsed          | 283         |
|    total_timesteps       | 628736      |
| train/                   |             |
|    approx_kl             | 0.004525189 |
|    clip_fraction         | 0.0185      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00572    |
|    cost_value_loss       | 0.000307    |
|    cost_values           | -5.24e-05   |
|    entropy               | -2.84       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -0.137      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0234      |
|    n_updates             | 3060        |
|    policy_gradient_loss  | -0.00234    |
|    std                   | 1           |
|    value_loss            | 0.564       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.106        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.106        |
| reward                   | -0.30445406  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 305          |
|    total_timesteps       | 630784       |
| train/                   |              |
|    approx_kl             | 0.0029809205 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0182      |
|    cost_value_loss       | 0.000136     |
|    cost_values           | -0.0214      |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00892      |
|    n_updates             | 3070         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 1            |
|    value_loss            | 0.111        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0629       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0629       |
| reward                   | -0.43151847  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 15           |
|    time_elapsed          | 327          |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0012264436 |
|    clip_fraction         | 0.00195      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.08        |
|    cost_value_loss       | 0.000239     |
|    cost_values           | -0.0813      |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.64         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.225        |
|    n_updates             | 3080         |
|    policy_gradient_loss  | -0.000278    |
|    std                   | 1.01         |
|    value_loss            | 0.706        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0482      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0482      |
| reward                   | -0.46998683 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -373        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 16          |
|    time_elapsed          | 349         |
|    total_timesteps       | 634880      |
| train/                   |             |
|    approx_kl             | 0.004561297 |
|    clip_fraction         | 0.0221      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0015     |
|    cost_value_loss       | 0.000185    |
|    cost_values           | 0.00202     |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.19        |
|    n_updates             | 3090        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 1.01        |
|    value_loss            | 0.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.284        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.284        |
| reward                   | -0.37167913  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -373         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 372          |
|    total_timesteps       | 636928       |
| train/                   |              |
|    approx_kl             | 0.0022852318 |
|    clip_fraction         | 0.00771      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00168      |
|    cost_value_loss       | 0.000231     |
|    cost_values           | -0.00302     |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.164        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.86         |
|    n_updates             | 3100         |
|    policy_gradient_loss  | -0.00102     |
|    std                   | 1.01         |
|    value_loss            | 8.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.161       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.161       |
| reward                   | -0.46503186 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -374        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 18          |
|    time_elapsed          | 394         |
|    total_timesteps       | 638976      |
| train/                   |             |
|    approx_kl             | 0.003575906 |
|    clip_fraction         | 0.00923     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00327    |
|    cost_value_loss       | 0.000109    |
|    cost_values           | -0.000938   |
|    entropy               | -2.84       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0573      |
|    n_updates             | 3110        |
|    policy_gradient_loss  | -0.00186    |
|    std                   | 1.01        |
|    value_loss            | 0.387       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.168        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.168        |
| reward                   | -0.34191534  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 19           |
|    time_elapsed          | 416          |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0013516026 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0288      |
|    cost_value_loss       | 0.000369     |
|    cost_values           | -0.0266      |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.955        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0965       |
|    n_updates             | 3120         |
|    policy_gradient_loss  | 0.00049      |
|    std                   | 1            |
|    value_loss            | 0.645        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0602       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0602       |
| reward                   | -0.5515806   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -372         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 20           |
|    time_elapsed          | 438          |
|    total_timesteps       | 643072       |
| train/                   |              |
|    approx_kl             | 0.0071435245 |
|    clip_fraction         | 0.0682       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0193      |
|    cost_value_loss       | 2.68e-05     |
|    cost_values           | -0.0201      |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.786        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0792       |
|    n_updates             | 3130         |
|    policy_gradient_loss  | -0.00582     |
|    std                   | 1            |
|    value_loss            | 0.215        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00937      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00937      |
| reward                   | -0.46708035  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -376         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 21           |
|    time_elapsed          | 460          |
|    total_timesteps       | 645120       |
| train/                   |              |
|    approx_kl             | 0.0020134007 |
|    clip_fraction         | 0.00347      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0259      |
|    cost_value_loss       | 8.43e-05     |
|    cost_values           | -0.0291      |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -1.83        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0867       |
|    n_updates             | 3140         |
|    policy_gradient_loss  | -0.000274    |
|    std                   | 1            |
|    value_loss            | 1.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.183        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.183        |
| reward                   | -0.51009774  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -378         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 22           |
|    time_elapsed          | 482          |
|    total_timesteps       | 647168       |
| train/                   |              |
|    approx_kl             | 0.0045360858 |
|    clip_fraction         | 0.046        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0477      |
|    cost_value_loss       | 0.000104     |
|    cost_values           | -0.0452      |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.59         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0721       |
|    n_updates             | 3150         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 0.998        |
|    value_loss            | 1.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0142       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0142       |
| reward                   | -0.3984516   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 23           |
|    time_elapsed          | 504          |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0064697526 |
|    clip_fraction         | 0.0583       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0154       |
|    cost_value_loss       | 2.97e-05     |
|    cost_values           | 0.0157       |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.87         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0456       |
|    n_updates             | 3160         |
|    policy_gradient_loss  | -0.00457     |
|    std                   | 0.996        |
|    value_loss            | 0.393        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0534       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0534       |
| reward                   | -0.4824697   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 24           |
|    time_elapsed          | 526          |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0024816962 |
|    clip_fraction         | 0.00703      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0276      |
|    cost_value_loss       | 9.4e-05      |
|    cost_values           | -0.0263      |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.811        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.165        |
|    n_updates             | 3170         |
|    policy_gradient_loss  | -0.000853    |
|    std                   | 0.993        |
|    value_loss            | 1.29         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.466        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.466        |
| reward                   | -0.39108962  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -381         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 25           |
|    time_elapsed          | 548          |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0046171723 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0145      |
|    cost_value_loss       | 3.17e-05     |
|    cost_values           | -0.0148      |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0565       |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.00185     |
|    std                   | 0.995        |
|    value_loss            | 0.341        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.4277598   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -381         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 26           |
|    time_elapsed          | 571          |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0049857334 |
|    clip_fraction         | 0.00972      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0182      |
|    cost_value_loss       | 4.6e-05      |
|    cost_values           | -0.0171      |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.837        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.382        |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 0.996        |
|    value_loss            | 1.57         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.191        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.191        |
| reward                   | -0.41919065  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -384         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 27           |
|    time_elapsed          | 593          |
|    total_timesteps       | 657408       |
| train/                   |              |
|    approx_kl             | 0.0076936614 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0266      |
|    cost_value_loss       | 5.78e-05     |
|    cost_values           | -0.0282      |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.574        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0497       |
|    n_updates             | 3200         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.993        |
|    value_loss            | 0.331        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.324        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.324        |
| reward                   | -0.25651363  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 28           |
|    time_elapsed          | 615          |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0052362327 |
|    clip_fraction         | 0.0572       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0245      |
|    cost_value_loss       | 2.32e-05     |
|    cost_values           | -0.0248      |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.765        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.216        |
|    n_updates             | 3210         |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 0.988        |
|    value_loss            | 0.538        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.274        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.274        |
| reward                   | -0.35827526  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 29           |
|    time_elapsed          | 637          |
|    total_timesteps       | 661504       |
| train/                   |              |
|    approx_kl             | 0.0037217562 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00804      |
|    cost_value_loss       | 0.000188     |
|    cost_values           | 0.0106       |
|    entropy               | -2.8         |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.796        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.363        |
|    n_updates             | 3220         |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 0.986        |
|    value_loss            | 2.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.022        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.022        |
| reward                   | -0.45885685  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 30           |
|    time_elapsed          | 659          |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0028625778 |
|    clip_fraction         | 0.00752      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0192      |
|    cost_value_loss       | 0.000236     |
|    cost_values           | -0.0155      |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.111        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.463        |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 0.985        |
|    value_loss            | 3.38         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0603       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0603       |
| reward                   | -0.4953161   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 31           |
|    time_elapsed          | 681          |
|    total_timesteps       | 665600       |
| train/                   |              |
|    approx_kl             | 0.0031592147 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00365     |
|    cost_value_loss       | 0.000254     |
|    cost_values           | 3.2e-05      |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.933        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.223        |
|    n_updates             | 3240         |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 0.982        |
|    value_loss            | 0.924        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.5661889   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 32           |
|    time_elapsed          | 704          |
|    total_timesteps       | 667648       |
| train/                   |              |
|    approx_kl             | 0.0007140727 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.042       |
|    cost_value_loss       | 0.000235     |
|    cost_values           | -0.0406      |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.828        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.232        |
|    n_updates             | 3250         |
|    policy_gradient_loss  | -0.000292    |
|    std                   | 0.979        |
|    value_loss            | 0.873        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00673      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00673      |
| reward                   | -0.25725043  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 33           |
|    time_elapsed          | 726          |
|    total_timesteps       | 669696       |
| train/                   |              |
|    approx_kl             | 0.0029648547 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0489      |
|    cost_value_loss       | 0.000415     |
|    cost_values           | -0.0472      |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.845        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.208        |
|    n_updates             | 3260         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.979        |
|    value_loss            | 0.963        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.216        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.216        |
| reward                   | -0.28628707  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 34           |
|    time_elapsed          | 748          |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0056262463 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.103       |
|    cost_value_loss       | 0.000607     |
|    cost_values           | -0.106       |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.87         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.121        |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.977        |
|    value_loss            | 1.03         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00809      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00809      |
| reward                   | -0.5031618   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 35           |
|    time_elapsed          | 770          |
|    total_timesteps       | 673792       |
| train/                   |              |
|    approx_kl             | 0.0060819644 |
|    clip_fraction         | 0.0454       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.019       |
|    cost_value_loss       | 0.00133      |
|    cost_values           | -0.017       |
|    entropy               | -2.79        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.142        |
|    n_updates             | 3280         |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 0.977        |
|    value_loss            | 0.647        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0869      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0869      |
| reward                   | -0.20799671 |
| rollout/                 |             |
|    ep_len_mean           | 965         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 792         |
|    total_timesteps       | 675840      |
| train/                   |             |
|    approx_kl             | 0.006051386 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0644     |
|    cost_value_loss       | 0.000444    |
|    cost_values           | -0.0578     |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.131       |
|    n_updates             | 3290        |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.978       |
|    value_loss            | 1.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.133        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.133        |
| reward                   | -0.46427277  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -387         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 814          |
|    total_timesteps       | 677888       |
| train/                   |              |
|    approx_kl             | 0.0077367756 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0549      |
|    cost_value_loss       | 0.00025      |
|    cost_values           | -0.0533      |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0994       |
|    n_updates             | 3300         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.978        |
|    value_loss            | 1.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0985       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0985       |
| reward                   | -0.23364146  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 837          |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0045828493 |
|    clip_fraction         | 0.0633       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0486      |
|    cost_value_loss       | 5.81e-05     |
|    cost_values           | -0.0492      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0732       |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.00162     |
|    std                   | 0.976        |
|    value_loss            | 0.622        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0198      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0198      |
| reward                   | -0.40846214 |
| rollout/                 |             |
|    ep_len_mean           | 973         |
|    ep_rew_mean           | -390        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 859         |
|    total_timesteps       | 681984      |
| train/                   |             |
|    approx_kl             | 0.003653467 |
|    clip_fraction         | 0.0168      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0375     |
|    cost_value_loss       | 5.09e-05    |
|    cost_values           | -0.0373     |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.121       |
|    n_updates             | 3320        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.975       |
|    value_loss            | 0.997       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.158        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.158        |
| reward                   | -0.2243814   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 881          |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0060014045 |
|    clip_fraction         | 0.0339       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0248      |
|    cost_value_loss       | 5.8e-05      |
|    cost_values           | -0.0259      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.546        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.714        |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 0.976        |
|    value_loss            | 2.59         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.101        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.101        |
| reward                   | -0.40781817  |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 903          |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0022483673 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0308      |
|    cost_value_loss       | 8.91e-05     |
|    cost_values           | -0.0343      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | -1.33        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.125        |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.000528    |
|    std                   | 0.975        |
|    value_loss            | 2.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0124       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0124       |
| reward                   | -0.5324201   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 925          |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0056065945 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0304      |
|    cost_value_loss       | 4.71e-05     |
|    cost_values           | -0.0303      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.896        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.666        |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 0.974        |
|    value_loss            | 2.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.112        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.112        |
| reward                   | -0.5300823   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 947          |
|    total_timesteps       | 690176       |
| train/                   |              |
|    approx_kl             | 0.0052931583 |
|    clip_fraction         | 0.00884      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0145      |
|    cost_value_loss       | 8.28e-05     |
|    cost_values           | -0.0131      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.954        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.142        |
|    n_updates             | 3360         |
|    policy_gradient_loss  | -0.000918    |
|    std                   | 0.973        |
|    value_loss            | 0.824        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0364      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0364      |
| reward                   | -0.38508466 |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 969         |
|    total_timesteps       | 692224      |
| train/                   |             |
|    approx_kl             | 0.006480655 |
|    clip_fraction         | 0.0276      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0212     |
|    cost_value_loss       | 0.000168    |
|    cost_values           | -0.0237     |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.025       |
|    n_updates             | 3370        |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 0.97        |
|    value_loss            | 0.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.147        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.147        |
| reward                   | -0.3542988   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 991          |
|    total_timesteps       | 694272       |
| train/                   |              |
|    approx_kl             | 0.0034760106 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0116      |
|    cost_value_loss       | 0.000227     |
|    cost_values           | -0.0121      |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0267       |
|    n_updates             | 3380         |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.97         |
|    value_loss            | 0.239        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.227        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.227        |
| reward                   | -0.34432784  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1013         |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0063980487 |
|    clip_fraction         | 0.0737       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00535     |
|    cost_value_loss       | 1.35e-05     |
|    cost_values           | -0.00543     |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.921        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.036        |
|    n_updates             | 3390         |
|    policy_gradient_loss  | -0.00433     |
|    std                   | 0.967        |
|    value_loss            | 0.122        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0279       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0279       |
| reward                   | -0.51638085  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1035         |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0040449733 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.021       |
|    cost_value_loss       | 3.37e-05     |
|    cost_values           | -0.0218      |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | -0.505       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0335       |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.00039     |
|    std                   | 0.966        |
|    value_loss            | 0.988        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.165        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.165        |
| reward                   | -0.35021365  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1057         |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0039986535 |
|    clip_fraction         | 0.0162       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0301      |
|    cost_value_loss       | 4.44e-05     |
|    cost_values           | -0.032       |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.023        |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.966        |
|    value_loss            | 0.476        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.314        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.314        |
| reward                   | -0.35589182  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1079         |
|    total_timesteps       | 702464       |
| train/                   |              |
|    approx_kl             | 0.0037205557 |
|    clip_fraction         | 0.00674      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0204      |
|    cost_value_loss       | 4.08e-05     |
|    cost_values           | -0.021       |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0208       |
|    n_updates             | 3420         |
|    policy_gradient_loss  | -0.000131    |
|    std                   | 0.967        |
|    value_loss            | 0.146        |
-------------------------------------------
------------------------------------
| avg_speed          | 0.036       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.036       |
| reward             | -0.19682802 |
| rollout/           |             |
|    ep_len_mean     | 987         |
|    ep_rew_mean     | -402        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 704512      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.305        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.305        |
| reward                   | -0.543974    |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 2            |
|    time_elapsed          | 44           |
|    total_timesteps       | 706560       |
| train/                   |              |
|    approx_kl             | 0.0037025437 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0274      |
|    cost_value_loss       | 3.06e-05     |
|    cost_values           | -0.0286      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.847        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.022        |
|    n_updates             | 3440         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.973        |
|    value_loss            | 0.372        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.131        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.131        |
| reward                   | -0.15133421  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 3            |
|    time_elapsed          | 67           |
|    total_timesteps       | 708608       |
| train/                   |              |
|    approx_kl             | 0.0022875206 |
|    clip_fraction         | 0.00913      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0152      |
|    cost_value_loss       | 0.000346     |
|    cost_values           | -0.0177      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.133        |
|    n_updates             | 3450         |
|    policy_gradient_loss  | -0.000918    |
|    std                   | 0.972        |
|    value_loss            | 2.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0993       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0993       |
| reward                   | -0.51406896  |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 4            |
|    time_elapsed          | 89           |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0056163706 |
|    clip_fraction         | 0.0303       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00482     |
|    cost_value_loss       | 0.000238     |
|    cost_values           | -0.00377     |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.137        |
|    n_updates             | 3460         |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.973        |
|    value_loss            | 1            |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.44252518  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 111          |
|    total_timesteps       | 712704       |
| train/                   |              |
|    approx_kl             | 0.0032909464 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0354      |
|    cost_value_loss       | 9.05e-05     |
|    cost_values           | -0.0404      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.69         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.101        |
|    n_updates             | 3470         |
|    policy_gradient_loss  | -0.000927    |
|    std                   | 0.973        |
|    value_loss            | 1.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.111        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.111        |
| reward                   | -0.5315792   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 133          |
|    total_timesteps       | 714752       |
| train/                   |              |
|    approx_kl             | 0.0032550034 |
|    clip_fraction         | 0.0265       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00469      |
|    cost_value_loss       | 9.24e-05     |
|    cost_values           | 0.00466      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.917        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.111        |
|    n_updates             | 3480         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.974        |
|    value_loss            | 0.582        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0964       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0964       |
| reward                   | -0.39675537  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 716800       |
| train/                   |              |
|    approx_kl             | 0.0073545775 |
|    clip_fraction         | 0.0258       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0308      |
|    cost_value_loss       | 6.71e-05     |
|    cost_values           | -0.0299      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0578       |
|    n_updates             | 3490         |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 0.973        |
|    value_loss            | 0.682        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.129       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.129       |
| reward                   | -0.28724486 |
| rollout/                 |             |
|    ep_len_mean           | 991         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 176         |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.009135056 |
|    clip_fraction         | 0.0468      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0264     |
|    cost_value_loss       | 7.28e-05    |
|    cost_values           | -0.0275     |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0354      |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.975       |
|    value_loss            | 0.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.235        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.235        |
| reward                   | -0.39689246  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 720896       |
| train/                   |              |
|    approx_kl             | 0.0060061747 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0105       |
|    cost_value_loss       | 5.4e-05      |
|    cost_values           | 0.0114       |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.916        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0448       |
|    n_updates             | 3510         |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.975        |
|    value_loss            | 0.573        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0808       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0808       |
| reward                   | -0.24290197  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -399         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 219          |
|    total_timesteps       | 722944       |
| train/                   |              |
|    approx_kl             | 0.0036736878 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00815     |
|    cost_value_loss       | 2.04e-05     |
|    cost_values           | -0.00775     |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0367       |
|    n_updates             | 3520         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.971        |
|    value_loss            | 0.141        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.149        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.149        |
| reward                   | -0.36850262  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 241          |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0047647185 |
|    clip_fraction         | 0.0209       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0305      |
|    cost_value_loss       | 3.03e-05     |
|    cost_values           | -0.0296      |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0236       |
|    n_updates             | 3530         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.969        |
|    value_loss            | 0.134        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.133        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.133        |
| reward                   | -0.5493728   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 263          |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0024779136 |
|    clip_fraction         | 0.0145       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0216      |
|    cost_value_loss       | 2.46e-05     |
|    cost_values           | -0.0236      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.684        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.375        |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.000722    |
|    std                   | 0.971        |
|    value_loss            | 1.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0758       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0758       |
| reward                   | -0.49770632  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -399         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 13           |
|    time_elapsed          | 285          |
|    total_timesteps       | 729088       |
| train/                   |              |
|    approx_kl             | 0.0053433455 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0237      |
|    cost_value_loss       | 5.11e-05     |
|    cost_values           | -0.0236      |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0123       |
|    n_updates             | 3550         |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.969        |
|    value_loss            | 0.203        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0726       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0726       |
| reward                   | -0.22658479  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 308          |
|    total_timesteps       | 731136       |
| train/                   |              |
|    approx_kl             | 0.0041063465 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.03         |
|    cost_value_loss       | 4.95e-05     |
|    cost_values           | 0.031        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.961        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.023        |
|    n_updates             | 3560         |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 0.966        |
|    value_loss            | 0.405        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.028       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.028       |
| reward                   | -0.35502413 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 330         |
|    total_timesteps       | 733184      |
| train/                   |             |
|    approx_kl             | 0.005254999 |
|    clip_fraction         | 0.0428      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0114      |
|    cost_value_loss       | 4.49e-05    |
|    cost_values           | 0.0107      |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0278      |
|    n_updates             | 3570        |
|    policy_gradient_loss  | -0.00271    |
|    std                   | 0.965       |
|    value_loss            | 0.271       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.294732    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 352          |
|    total_timesteps       | 735232       |
| train/                   |              |
|    approx_kl             | 0.0027565002 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0425      |
|    cost_value_loss       | 0.00115      |
|    cost_values           | -0.0423      |
|    entropy               | -2.77        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0912       |
|    n_updates             | 3580         |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.967        |
|    value_loss            | 0.712        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.089        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.089        |
| reward                   | -0.29613823  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 374          |
|    total_timesteps       | 737280       |
| train/                   |              |
|    approx_kl             | 0.0031839407 |
|    clip_fraction         | 0.00693      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0161       |
|    cost_value_loss       | 0.00262      |
|    cost_values           | -7.73e-05    |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0265       |
|    n_updates             | 3590         |
|    policy_gradient_loss  | -0.000477    |
|    std                   | 0.969        |
|    value_loss            | 0.208        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.162       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.162       |
| reward                   | -0.44849038 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 18          |
|    time_elapsed          | 395         |
|    total_timesteps       | 739328      |
| train/                   |             |
|    approx_kl             | 0.00719231  |
|    clip_fraction         | 0.0586      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0442     |
|    cost_value_loss       | 0.000144    |
|    cost_values           | -0.0445     |
|    entropy               | -2.78       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.027       |
|    n_updates             | 3600        |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 0.974       |
|    value_loss            | 0.0832      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.05        |
| reward                   | -0.54426265 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 19          |
|    time_elapsed          | 417         |
|    total_timesteps       | 741376      |
| train/                   |             |
|    approx_kl             | 0.002325627 |
|    clip_fraction         | 0.0161      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0781     |
|    cost_value_loss       | 0.000178    |
|    cost_values           | -0.0768     |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0328      |
|    n_updates             | 3610        |
|    policy_gradient_loss  | 0.000811    |
|    std                   | 0.974       |
|    value_loss            | 0.429       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0136       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0136       |
| reward                   | -0.25922796  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 20           |
|    time_elapsed          | 438          |
|    total_timesteps       | 743424       |
| train/                   |              |
|    approx_kl             | 0.0059188907 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0802      |
|    cost_value_loss       | 0.000215     |
|    cost_values           | -0.0812      |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0266       |
|    n_updates             | 3620         |
|    policy_gradient_loss  | -0.00185     |
|    std                   | 0.973        |
|    value_loss            | 0.534        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0294       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0294       |
| reward                   | -0.22059326  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 21           |
|    time_elapsed          | 460          |
|    total_timesteps       | 745472       |
| train/                   |              |
|    approx_kl             | 0.0067004752 |
|    clip_fraction         | 0.0311       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00157      |
|    cost_value_loss       | 4.65e-05     |
|    cost_values           | 0.00226      |
|    entropy               | -2.77        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0403       |
|    n_updates             | 3630         |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.968        |
|    value_loss            | 0.329        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.127        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.127        |
| reward                   | -0.3626479   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 22           |
|    time_elapsed          | 482          |
|    total_timesteps       | 747520       |
| train/                   |              |
|    approx_kl             | 0.0043005315 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.05        |
|    cost_value_loss       | 0.000196     |
|    cost_values           | -0.0542      |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.877        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0647       |
|    n_updates             | 3640         |
|    policy_gradient_loss  | -0.000425    |
|    std                   | 0.966        |
|    value_loss            | 0.603        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.223       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.223       |
| reward                   | -0.51439106 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -395        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 23          |
|    time_elapsed          | 504         |
|    total_timesteps       | 749568      |
| train/                   |             |
|    approx_kl             | 0.003646643 |
|    clip_fraction         | 0.0239      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0609     |
|    cost_value_loss       | 0.000103    |
|    cost_values           | -0.0616     |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0368      |
|    n_updates             | 3650        |
|    policy_gradient_loss  | -0.00202    |
|    std                   | 0.966       |
|    value_loss            | 0.142       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.116        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.116        |
| reward                   | -0.53792423  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 24           |
|    time_elapsed          | 526          |
|    total_timesteps       | 751616       |
| train/                   |              |
|    approx_kl             | 0.0052583604 |
|    clip_fraction         | 0.0584       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00632     |
|    cost_value_loss       | 0.000127     |
|    cost_values           | -0.00492     |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0138       |
|    n_updates             | 3660         |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 0.964        |
|    value_loss            | 0.217        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.314        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.314        |
| reward                   | -0.46877986  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 25           |
|    time_elapsed          | 548          |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0052840877 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0496      |
|    cost_value_loss       | 0.000155     |
|    cost_values           | -0.0481      |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0257       |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.963        |
|    value_loss            | 0.412        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.354       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.354       |
| reward                   | -0.4062738  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 26          |
|    time_elapsed          | 569         |
|    total_timesteps       | 755712      |
| train/                   |             |
|    approx_kl             | 0.005569493 |
|    clip_fraction         | 0.0395      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0164     |
|    cost_value_loss       | 0.000321    |
|    cost_values           | -0.0176     |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0676      |
|    n_updates             | 3680        |
|    policy_gradient_loss  | -0.0047     |
|    std                   | 0.961       |
|    value_loss            | 0.687       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.164        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.164        |
| reward                   | -0.44354647  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 27           |
|    time_elapsed          | 591          |
|    total_timesteps       | 757760       |
| train/                   |              |
|    approx_kl             | 0.0056472323 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0147      |
|    cost_value_loss       | 0.000106     |
|    cost_values           | -0.0169      |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0119       |
|    n_updates             | 3690         |
|    policy_gradient_loss  | -0.00109     |
|    std                   | 0.959        |
|    value_loss            | 0.0773       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0292       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0292       |
| reward                   | -0.23787604  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 28           |
|    time_elapsed          | 613          |
|    total_timesteps       | 759808       |
| train/                   |              |
|    approx_kl             | 0.0020224443 |
|    clip_fraction         | 0.0103       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0144      |
|    cost_value_loss       | 9.91e-05     |
|    cost_values           | -0.0148      |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.804        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0237       |
|    n_updates             | 3700         |
|    policy_gradient_loss  | -0.000732    |
|    std                   | 0.957        |
|    value_loss            | 0.375        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0479      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0479      |
| reward                   | -0.52378416 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -393        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 29          |
|    time_elapsed          | 635         |
|    total_timesteps       | 761856      |
| train/                   |             |
|    approx_kl             | 0.002492362 |
|    clip_fraction         | 0.00854     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.019       |
|    cost_value_loss       | 0.000233    |
|    cost_values           | 0.026       |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.618       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.295       |
|    n_updates             | 3710        |
|    policy_gradient_loss  | 0.000149    |
|    std                   | 0.957       |
|    value_loss            | 1.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.15         |
| reward                   | -0.29600537  |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 30           |
|    time_elapsed          | 657          |
|    total_timesteps       | 763904       |
| train/                   |              |
|    approx_kl             | 0.0037863045 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000515     |
|    cost_value_loss       | 2.24e-05     |
|    cost_values           | 0.00145      |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0365       |
|    n_updates             | 3720         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.958        |
|    value_loss            | 0.148        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0835      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0835      |
| reward                   | -0.33532083 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -385        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 31          |
|    time_elapsed          | 679         |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.005263781 |
|    clip_fraction         | 0.0634      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00657     |
|    cost_value_loss       | 2.32e-05    |
|    cost_values           | 0.00671     |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.52        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.957       |
|    value_loss            | 4.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0533      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0533      |
| reward                   | -0.34673694 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 32          |
|    time_elapsed          | 701         |
|    total_timesteps       | 768000      |
| train/                   |             |
|    approx_kl             | 0.005018917 |
|    clip_fraction         | 0.0128      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0137     |
|    cost_value_loss       | 9.85e-05    |
|    cost_values           | -0.0144     |
|    entropy               | -2.74       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0477      |
|    n_updates             | 3740        |
|    policy_gradient_loss  | -0.00122    |
|    std                   | 0.955       |
|    value_loss            | 0.253       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.232       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.232       |
| reward                   | -0.3297534  |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 33          |
|    time_elapsed          | 723         |
|    total_timesteps       | 770048      |
| train/                   |             |
|    approx_kl             | 0.005333424 |
|    clip_fraction         | 0.0315      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00402    |
|    cost_value_loss       | 1.15e-05    |
|    cost_values           | -0.00492    |
|    entropy               | -2.75       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0101      |
|    n_updates             | 3750        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.957       |
|    value_loss            | 0.109       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.101        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.101        |
| reward                   | -0.2825229   |
| rollout/                 |              |
|    ep_len_mean           | 994          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 34           |
|    time_elapsed          | 745          |
|    total_timesteps       | 772096       |
| train/                   |              |
|    approx_kl             | 0.0037764949 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0039      |
|    cost_value_loss       | 3.7e-05      |
|    cost_values           | -0.00366     |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0249       |
|    n_updates             | 3760         |
|    policy_gradient_loss  | -0.000901    |
|    std                   | 0.961        |
|    value_loss            | 0.132        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.124       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.124       |
| reward                   | -0.32179645 |
| rollout/                 |             |
|    ep_len_mean           | 994         |
|    ep_rew_mean           | -381        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 35          |
|    time_elapsed          | 766         |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.004996293 |
|    clip_fraction         | 0.0571      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0358     |
|    cost_value_loss       | 4.37e-05    |
|    cost_values           | -0.0363     |
|    entropy               | -2.77       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.0043     |
|    n_updates             | 3770        |
|    policy_gradient_loss  | -0.00787    |
|    std                   | 0.968       |
|    value_loss            | 0.0443      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0545       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0545       |
| reward                   | -0.24943562  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -378         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 36           |
|    time_elapsed          | 788          |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0029832143 |
|    clip_fraction         | 0.00317      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0401      |
|    cost_value_loss       | 3.27e-05     |
|    cost_values           | -0.0415      |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | -0.0926      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0224       |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.000273    |
|    std                   | 0.969        |
|    value_loss            | 0.163        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.191       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.191       |
| reward                   | -0.41275883 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -378        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 37          |
|    time_elapsed          | 811         |
|    total_timesteps       | 778240      |
| train/                   |             |
|    approx_kl             | 0.004409653 |
|    clip_fraction         | 0.0207      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0164     |
|    cost_value_loss       | 0.000107    |
|    cost_values           | -0.0159     |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.753       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.51        |
|    n_updates             | 3790        |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.969       |
|    value_loss            | 4.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0574       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0574       |
| reward                   | -0.3272586   |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -380         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 38           |
|    time_elapsed          | 833          |
|    total_timesteps       | 780288       |
| train/                   |              |
|    approx_kl             | 0.0056414786 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0203      |
|    cost_value_loss       | 2.26e-05     |
|    cost_values           | -0.0201      |
|    entropy               | -2.77        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0293       |
|    n_updates             | 3800         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.966        |
|    value_loss            | 0.0854       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.156       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.156       |
| reward                   | -0.5244813  |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -379        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 39          |
|    time_elapsed          | 855         |
|    total_timesteps       | 782336      |
| train/                   |             |
|    approx_kl             | 0.007342793 |
|    clip_fraction         | 0.0345      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00341    |
|    cost_value_loss       | 8.87e-06    |
|    cost_values           | -0.0032     |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0217      |
|    n_updates             | 3810        |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 0.963       |
|    value_loss            | 0.0789      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0258       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0258       |
| reward                   | -0.31340918  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -383         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 40           |
|    time_elapsed          | 877          |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0018994797 |
|    clip_fraction         | 0.0109       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00937     |
|    cost_value_loss       | 3.97e-05     |
|    cost_values           | -0.00856     |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0141       |
|    n_updates             | 3820         |
|    policy_gradient_loss  | -0.000541    |
|    std                   | 0.963        |
|    value_loss            | 0.202        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.244        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.244        |
| reward                   | -0.45649603  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -382         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 41           |
|    time_elapsed          | 899          |
|    total_timesteps       | 786432       |
| train/                   |              |
|    approx_kl             | 0.0049441983 |
|    clip_fraction         | 0.0243       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00125      |
|    cost_value_loss       | 6.83e-05     |
|    cost_values           | 0.00296      |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0358       |
|    n_updates             | 3830         |
|    policy_gradient_loss  | -0.00149     |
|    std                   | 0.962        |
|    value_loss            | 0.209        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00161      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00161      |
| reward                   | -0.37618265  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -380         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 42           |
|    time_elapsed          | 921          |
|    total_timesteps       | 788480       |
| train/                   |              |
|    approx_kl             | 0.0042334115 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0149      |
|    cost_value_loss       | 3.3e-05      |
|    cost_values           | -0.0147      |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.019        |
|    n_updates             | 3840         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.964        |
|    value_loss            | 0.108        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0503       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0503       |
| reward                   | -0.48607114  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -376         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 43           |
|    time_elapsed          | 944          |
|    total_timesteps       | 790528       |
| train/                   |              |
|    approx_kl             | 0.0020019244 |
|    clip_fraction         | 0.00972      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0377      |
|    cost_value_loss       | 0.000178     |
|    cost_values           | -0.0384      |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.05         |
|    n_updates             | 3850         |
|    policy_gradient_loss  | -0.000912    |
|    std                   | 0.965        |
|    value_loss            | 0.312        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0323      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0323      |
| reward                   | -0.506575   |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -377        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 44          |
|    time_elapsed          | 966         |
|    total_timesteps       | 792576      |
| train/                   |             |
|    approx_kl             | 0.005786705 |
|    clip_fraction         | 0.025       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0488      |
|    cost_value_loss       | 0.00127     |
|    cost_values           | 0.0545      |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.69        |
|    n_updates             | 3860        |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 0.964       |
|    value_loss            | 3.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.244       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.244       |
| reward                   | -0.48064062 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -378        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 45          |
|    time_elapsed          | 988         |
|    total_timesteps       | 794624      |
| train/                   |             |
|    approx_kl             | 0.007968605 |
|    clip_fraction         | 0.0604      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.026      |
|    cost_value_loss       | 0.000182    |
|    cost_values           | -0.0249     |
|    entropy               | -2.75       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0303      |
|    n_updates             | 3870        |
|    policy_gradient_loss  | -0.00778    |
|    std                   | 0.961       |
|    value_loss            | 0.189       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0792       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0792       |
| reward                   | -0.27117863  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -379         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 46           |
|    time_elapsed          | 1010         |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0064154193 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000306     |
|    cost_value_loss       | 0.000127     |
|    cost_values           | 0.00153      |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0285       |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.00785     |
|    std                   | 0.96         |
|    value_loss            | 0.218        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00895     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00895     |
| reward                   | -0.19062129 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -377        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 47          |
|    time_elapsed          | 1033        |
|    total_timesteps       | 798720      |
| train/                   |             |
|    approx_kl             | 0.004216467 |
|    clip_fraction         | 0.0281      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0363     |
|    cost_value_loss       | 4.97e-05    |
|    cost_values           | -0.037      |
|    entropy               | -2.74       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0256      |
|    n_updates             | 3890        |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.955       |
|    value_loss            | 0.108       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0932      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0932      |
| reward                   | -0.30456424 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -376        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 48          |
|    time_elapsed          | 1055        |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.004119888 |
|    clip_fraction         | 0.0239      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0443     |
|    cost_value_loss       | 0.000162    |
|    cost_values           | -0.0448     |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0399      |
|    n_updates             | 3900        |
|    policy_gradient_loss  | -0.00191    |
|    std                   | 0.953       |
|    value_loss            | 0.282       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.152        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.152        |
| reward                   | -0.34841353  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 49           |
|    time_elapsed          | 1077         |
|    total_timesteps       | 802816       |
| train/                   |              |
|    approx_kl             | 0.0033224935 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00965      |
|    cost_value_loss       | 8.48e-05     |
|    cost_values           | 0.00998      |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0151       |
|    n_updates             | 3910         |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.949        |
|    value_loss            | 0.0707       |
-------------------------------------------
------------------------------------
| avg_speed          | 0.0592      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0592      |
| reward             | -0.41179007 |
| rollout/           |             |
|    ep_len_mean     | 981         |
|    ep_rew_mean     | -379        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 804864      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.136        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.136        |
| reward                   | -0.5124816   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -379         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 806912       |
| train/                   |              |
|    approx_kl             | 0.0035235123 |
|    clip_fraction         | 0.0155       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0068      |
|    cost_value_loss       | 7.06e-06     |
|    cost_values           | -0.00684     |
|    entropy               | -2.74        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0213       |
|    n_updates             | 3930         |
|    policy_gradient_loss  | -0.000703    |
|    std                   | 0.955        |
|    value_loss            | 0.0541       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.174        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.174        |
| reward                   | -0.4279838   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -381         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 808960       |
| train/                   |              |
|    approx_kl             | 0.0026248898 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0335      |
|    cost_value_loss       | 2.75e-05     |
|    cost_values           | -0.0327      |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0152       |
|    n_updates             | 3940         |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 0.954        |
|    value_loss            | 0.122        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.142        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.142        |
| reward                   | -0.54913664  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -379         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 811008       |
| train/                   |              |
|    approx_kl             | 0.0019454162 |
|    clip_fraction         | 0.00991      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0517      |
|    cost_value_loss       | 4.18e-05     |
|    cost_values           | -0.053       |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0216       |
|    n_updates             | 3950         |
|    policy_gradient_loss  | -0.00156     |
|    std                   | 0.952        |
|    value_loss            | 0.173        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.17         |
| reward                   | -0.20851685  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 813056       |
| train/                   |              |
|    approx_kl             | 0.0010290153 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0404      |
|    cost_value_loss       | 0.000148     |
|    cost_values           | -0.0424      |
|    entropy               | -2.74        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0547       |
|    n_updates             | 3960         |
|    policy_gradient_loss  | -0.000304    |
|    std                   | 0.954        |
|    value_loss            | 0.297        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.218        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.218        |
| reward                   | -0.30352864  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -373         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 815104       |
| train/                   |              |
|    approx_kl             | 0.0027376302 |
|    clip_fraction         | 0.0455       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00735     |
|    cost_value_loss       | 5.13e-05     |
|    cost_values           | -0.0085      |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0228       |
|    n_updates             | 3970         |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 0.956        |
|    value_loss            | 0.173        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.215        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.215        |
| reward                   | -0.4940329   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -372         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 817152       |
| train/                   |              |
|    approx_kl             | 0.0044898023 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0152      |
|    cost_value_loss       | 0.000217     |
|    cost_values           | -0.0167      |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.935        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0407       |
|    n_updates             | 3980         |
|    policy_gradient_loss  | -0.0015      |
|    std                   | 0.956        |
|    value_loss            | 0.268        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0341       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0341       |
| reward                   | -0.45293173  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -374         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 819200       |
| train/                   |              |
|    approx_kl             | 0.0052757994 |
|    clip_fraction         | 0.0301       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.041       |
|    cost_value_loss       | 8.29e-05     |
|    cost_values           | -0.0439      |
|    entropy               | -2.74        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0199       |
|    n_updates             | 3990         |
|    policy_gradient_loss  | -0.002       |
|    std                   | 0.955        |
|    value_loss            | 0.176        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.194       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.194       |
| reward                   | -0.49107605 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -374        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 199         |
|    total_timesteps       | 821248      |
| train/                   |             |
|    approx_kl             | 0.005486276 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0399     |
|    cost_value_loss       | 3.42e-05    |
|    cost_values           | -0.0406     |
|    entropy               | -2.73       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0124      |
|    n_updates             | 4000        |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 0.953       |
|    value_loss            | 0.0948      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.144       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.144       |
| reward                   | -0.5163446  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -378        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 823296      |
| train/                   |             |
|    approx_kl             | 0.004453105 |
|    clip_fraction         | 0.0257      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0409     |
|    cost_value_loss       | 2.89e-05    |
|    cost_values           | -0.0413     |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0287      |
|    n_updates             | 4010        |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 0.951       |
|    value_loss            | 0.121       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.095        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.095        |
| reward                   | -0.382325    |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -378         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 243          |
|    total_timesteps       | 825344       |
| train/                   |              |
|    approx_kl             | 0.0077844206 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0135      |
|    cost_value_loss       | 0.000366     |
|    cost_values           | -0.0144      |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0132       |
|    n_updates             | 4020         |
|    policy_gradient_loss  | -0.00319     |
|    std                   | 0.95         |
|    value_loss            | 0.0578       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0342       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0342       |
| reward                   | -0.24603043  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -376         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 265          |
|    total_timesteps       | 827392       |
| train/                   |              |
|    approx_kl             | 0.0051865745 |
|    clip_fraction         | 0.0563       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0247      |
|    cost_value_loss       | 0.00129      |
|    cost_values           | -0.036       |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0784       |
|    n_updates             | 4030         |
|    policy_gradient_loss  | -0.000573    |
|    std                   | 0.948        |
|    value_loss            | 0.352        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.216        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.216        |
| reward                   | -0.25832444  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -371         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 287          |
|    total_timesteps       | 829440       |
| train/                   |              |
|    approx_kl             | 0.0015797458 |
|    clip_fraction         | 0.0062       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0736      |
|    cost_value_loss       | 0.00115      |
|    cost_values           | -0.0882      |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0234       |
|    n_updates             | 4040         |
|    policy_gradient_loss  | 0.000205     |
|    std                   | 0.948        |
|    value_loss            | 0.131        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0653      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0653      |
| reward                   | -0.39184853 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -376        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 309         |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.004068575 |
|    clip_fraction         | 0.0252      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0168     |
|    cost_value_loss       | 1.37e-05    |
|    cost_values           | -0.0171     |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.03        |
|    n_updates             | 4050        |
|    policy_gradient_loss  | -0.000713   |
|    std                   | 0.946       |
|    value_loss            | 0.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.166        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.166        |
| reward                   | -0.19509009  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -376         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 331          |
|    total_timesteps       | 833536       |
| train/                   |              |
|    approx_kl             | 0.0076387534 |
|    clip_fraction         | 0.0567       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0426      |
|    cost_value_loss       | 3.74e-05     |
|    cost_values           | -0.0433      |
|    entropy               | -2.72        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0102       |
|    n_updates             | 4060         |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 0.945        |
|    value_loss            | 0.0639       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.22        |
| reward                   | -0.48539975 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -377        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 353         |
|    total_timesteps       | 835584      |
| train/                   |             |
|    approx_kl             | 0.005748165 |
|    clip_fraction         | 0.0356      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0378     |
|    cost_value_loss       | 0.000175    |
|    cost_values           | -0.0386     |
|    entropy               | -2.71       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0384      |
|    n_updates             | 4070        |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.944       |
|    value_loss            | 0.354       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.291        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.291        |
| reward                   | -0.49725232  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -378         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 376          |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0029401875 |
|    clip_fraction         | 0.0285       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0586      |
|    cost_value_loss       | 5.37e-05     |
|    cost_values           | -0.0602      |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00785      |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 0.94         |
|    value_loss            | 0.065        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.184       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.184       |
| reward                   | -0.51667005 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -375        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 398         |
|    total_timesteps       | 839680      |
| train/                   |             |
|    approx_kl             | 0.008815971 |
|    clip_fraction         | 0.0515      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0329     |
|    cost_value_loss       | 3.57e-05    |
|    cost_values           | -0.0332     |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.000379    |
|    n_updates             | 4090        |
|    policy_gradient_loss  | -0.00552    |
|    std                   | 0.937       |
|    value_loss            | 0.0469      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00365      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00365      |
| reward                   | -0.5028444   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -376         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 420          |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0035513556 |
|    clip_fraction         | 0.0131       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0101       |
|    cost_value_loss       | 1.53e-05     |
|    cost_values           | 0.0105       |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0149       |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.000201    |
|    std                   | 0.937        |
|    value_loss            | 0.0653       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.061        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.061        |
| reward                   | -0.48376527  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 442          |
|    total_timesteps       | 843776       |
| train/                   |              |
|    approx_kl             | 0.0056638545 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00823      |
|    cost_value_loss       | 4.36e-05     |
|    cost_values           | 0.00853      |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00429      |
|    n_updates             | 4110         |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 0.936        |
|    value_loss            | 0.0379       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.34         |
| reward                   | -0.48163325  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -381         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 464          |
|    total_timesteps       | 845824       |
| train/                   |              |
|    approx_kl             | 0.0024931608 |
|    clip_fraction         | 0.013        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0279      |
|    cost_value_loss       | 2.18e-05     |
|    cost_values           | -0.0275      |
|    entropy               | -2.69        |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0181       |
|    n_updates             | 4120         |
|    policy_gradient_loss  | -0.000284    |
|    std                   | 0.933        |
|    value_loss            | 0.0528       |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.0192     |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.0192     |
| reward                   | -0.4196261 |
| rollout/                 |            |
|    ep_len_mean           | 981        |
|    ep_rew_mean           | -382       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 22         |
|    time_elapsed          | 486        |
|    total_timesteps       | 847872     |
| train/                   |            |
|    approx_kl             | 0.00296696 |
|    clip_fraction         | 0.0262     |
|    clip_range            | 0.2        |
|    cost_returns          | -0.0196    |
|    cost_value_loss       | 2.12e-05   |
|    cost_values           | -0.0195    |
|    entropy               | -2.69      |
|    entropy_loss          | -2.69      |
|    explained_variance    | 0.957      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.00423    |
|    n_updates             | 4130       |
|    policy_gradient_loss  | -0.0036    |
|    std                   | 0.934      |
|    value_loss            | 0.0324     |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.152       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.152       |
| reward                   | -0.51318663 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -381        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 509         |
|    total_timesteps       | 849920      |
| train/                   |             |
|    approx_kl             | 0.005932182 |
|    clip_fraction         | 0.045       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.003      |
|    cost_value_loss       | 1.19e-05    |
|    cost_values           | -0.00304    |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00836     |
|    n_updates             | 4140        |
|    policy_gradient_loss  | -0.00369    |
|    std                   | 0.932       |
|    value_loss            | 0.0304      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.265        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.265        |
| reward                   | -0.40141165  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -383         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 531          |
|    total_timesteps       | 851968       |
| train/                   |              |
|    approx_kl             | 0.0034807986 |
|    clip_fraction         | 0.0378       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0178       |
|    cost_value_loss       | 1.56e-05     |
|    cost_values           | 0.0181       |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00608      |
|    n_updates             | 4150         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.925        |
|    value_loss            | 0.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0237      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0237      |
| reward                   | -0.45269763 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -383        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 553         |
|    total_timesteps       | 854016      |
| train/                   |             |
|    approx_kl             | 0.004269916 |
|    clip_fraction         | 0.0443      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0179     |
|    cost_value_loss       | 2.18e-05    |
|    cost_values           | -0.0177     |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00841     |
|    n_updates             | 4160        |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.924       |
|    value_loss            | 0.0311      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0966       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0966       |
| reward                   | -0.42772543  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -384         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 576          |
|    total_timesteps       | 856064       |
| train/                   |              |
|    approx_kl             | 0.0037931316 |
|    clip_fraction         | 0.0607       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0145      |
|    cost_value_loss       | 8.7e-06      |
|    cost_values           | -0.0148      |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00571      |
|    n_updates             | 4170         |
|    policy_gradient_loss  | -0.00408     |
|    std                   | 0.923        |
|    value_loss            | 0.0309       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.223        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.223        |
| reward                   | -0.54255015  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 598          |
|    total_timesteps       | 858112       |
| train/                   |              |
|    approx_kl             | 0.0065560513 |
|    clip_fraction         | 0.0483       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00524     |
|    cost_value_loss       | 9.19e-06     |
|    cost_values           | -0.00529     |
|    entropy               | -2.66        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0134       |
|    n_updates             | 4180         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.92         |
|    value_loss            | 0.0308       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0262      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0262      |
| reward                   | -0.44446462 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -385        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 620         |
|    total_timesteps       | 860160      |
| train/                   |             |
|    approx_kl             | 0.008081084 |
|    clip_fraction         | 0.0554      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00528    |
|    cost_value_loss       | 4.29e-06    |
|    cost_values           | -0.00514    |
|    entropy               | -2.67       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.7e-05     |
|    n_updates             | 4190        |
|    policy_gradient_loss  | -0.00529    |
|    std                   | 0.922       |
|    value_loss            | 0.0291      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00148      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00148      |
| reward                   | -0.3203809   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 642          |
|    total_timesteps       | 862208       |
| train/                   |              |
|    approx_kl             | 0.0047143763 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0052       |
|    cost_value_loss       | 3.92e-05     |
|    cost_values           | 0.00477      |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.94         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.431        |
|    n_updates             | 4200         |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 0.921        |
|    value_loss            | 2.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0986       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0986       |
| reward                   | -0.53368187  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 665          |
|    total_timesteps       | 864256       |
| train/                   |              |
|    approx_kl             | 0.0026388937 |
|    clip_fraction         | 0.00806      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0136      |
|    cost_value_loss       | 1.72e-05     |
|    cost_values           | -0.0131      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0192       |
|    n_updates             | 4210         |
|    policy_gradient_loss  | -0.000863    |
|    std                   | 0.919        |
|    value_loss            | 0.125        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0552      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0552      |
| reward                   | -0.20735231 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 687         |
|    total_timesteps       | 866304      |
| train/                   |             |
|    approx_kl             | 0.005736851 |
|    clip_fraction         | 0.042       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0109     |
|    cost_value_loss       | 3.19e-05    |
|    cost_values           | -0.0102     |
|    entropy               | -2.65       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0213      |
|    n_updates             | 4220        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.916       |
|    value_loss            | 0.0712      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0154       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0154       |
| reward                   | -0.5325005   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 709          |
|    total_timesteps       | 868352       |
| train/                   |              |
|    approx_kl             | 0.0032738186 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00633      |
|    cost_value_loss       | 5.18e-06     |
|    cost_values           | 0.00607      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00473      |
|    n_updates             | 4230         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.921        |
|    value_loss            | 0.0322       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.5104029  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 731         |
|    total_timesteps       | 870400      |
| train/                   |             |
|    approx_kl             | 0.002074176 |
|    clip_fraction         | 0.0042      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0292     |
|    cost_value_loss       | 8.31e-05    |
|    cost_values           | -0.0314     |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0506      |
|    n_updates             | 4240        |
|    policy_gradient_loss  | -0.00036    |
|    std                   | 0.922       |
|    value_loss            | 0.577       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.113        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.113        |
| reward                   | -0.5057261   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -387         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 753          |
|    total_timesteps       | 872448       |
| train/                   |              |
|    approx_kl             | 0.0055805584 |
|    clip_fraction         | 0.0331       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0154      |
|    cost_value_loss       | 8.02e-05     |
|    cost_values           | -0.0132      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.755        |
|    n_updates             | 4250         |
|    policy_gradient_loss  | -0.00465     |
|    std                   | 0.921        |
|    value_loss            | 1.99         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.071        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.071        |
| reward                   | -0.4538615   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 775          |
|    total_timesteps       | 874496       |
| train/                   |              |
|    approx_kl             | 0.0037483734 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0361      |
|    cost_value_loss       | 4.6e-05      |
|    cost_values           | -0.038       |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.04         |
|    n_updates             | 4260         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.921        |
|    value_loss            | 2.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0722       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0722       |
| reward                   | -0.45630452  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 797          |
|    total_timesteps       | 876544       |
| train/                   |              |
|    approx_kl             | 0.0066464813 |
|    clip_fraction         | 0.0283       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0319      |
|    cost_value_loss       | 7.79e-05     |
|    cost_values           | -0.0314      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0372       |
|    n_updates             | 4270         |
|    policy_gradient_loss  | -0.00345     |
|    std                   | 0.92         |
|    value_loss            | 0.657        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0493       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0493       |
| reward                   | -0.3441599   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 819          |
|    total_timesteps       | 878592       |
| train/                   |              |
|    approx_kl             | 0.0046528475 |
|    clip_fraction         | 0.0346       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0111      |
|    cost_value_loss       | 1.44e-05     |
|    cost_values           | -0.0112      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00864      |
|    n_updates             | 4280         |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 0.92         |
|    value_loss            | 0.104        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.139       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.139       |
| reward                   | -0.32887417 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 841         |
|    total_timesteps       | 880640      |
| train/                   |             |
|    approx_kl             | 0.007368695 |
|    clip_fraction         | 0.0397      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0118     |
|    cost_value_loss       | 2.09e-05    |
|    cost_values           | -0.0108     |
|    entropy               | -2.67       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0103      |
|    n_updates             | 4290        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.922       |
|    value_loss            | 0.0802      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0187      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0187      |
| reward                   | -0.4799471  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 863         |
|    total_timesteps       | 882688      |
| train/                   |             |
|    approx_kl             | 0.003244772 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00206     |
|    cost_value_loss       | 1.28e-05    |
|    cost_values           | 0.00254     |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0125      |
|    n_updates             | 4300        |
|    policy_gradient_loss  | -0.00309    |
|    std                   | 0.923       |
|    value_loss            | 0.0794      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.155        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.155        |
| reward                   | -0.32707554  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 885          |
|    total_timesteps       | 884736       |
| train/                   |              |
|    approx_kl             | 0.0011101554 |
|    clip_fraction         | 0.00444      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0264      |
|    cost_value_loss       | 1.14e-05     |
|    cost_values           | -0.0265      |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00277      |
|    n_updates             | 4310         |
|    policy_gradient_loss  | 3.83e-05     |
|    std                   | 0.923        |
|    value_loss            | 0.127        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.174        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.174        |
| reward                   | -0.41803783  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 908          |
|    total_timesteps       | 886784       |
| train/                   |              |
|    approx_kl             | 0.0023783518 |
|    clip_fraction         | 0.004        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0128      |
|    cost_value_loss       | 8.29e-06     |
|    cost_values           | -0.0129      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00607      |
|    n_updates             | 4320         |
|    policy_gradient_loss  | -0.000635    |
|    std                   | 0.922        |
|    value_loss            | 0.0708       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00394      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00394      |
| reward                   | -0.43545756  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 930          |
|    total_timesteps       | 888832       |
| train/                   |              |
|    approx_kl             | 0.0061800806 |
|    clip_fraction         | 0.0474       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00691      |
|    cost_value_loss       | 1.44e-05     |
|    cost_values           | 0.007        |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00966      |
|    n_updates             | 4330         |
|    policy_gradient_loss  | -0.00381     |
|    std                   | 0.922        |
|    value_loss            | 0.101        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0807       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0807       |
| reward                   | -0.443404    |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 952          |
|    total_timesteps       | 890880       |
| train/                   |              |
|    approx_kl             | 0.0036519202 |
|    clip_fraction         | 0.0365       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.012       |
|    cost_value_loss       | 2.28e-06     |
|    cost_values           | -0.0123      |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00616      |
|    n_updates             | 4340         |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 0.921        |
|    value_loss            | 0.0703       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.11        |
| reward                   | -0.19022785 |
| rollout/                 |             |
|    ep_len_mean           | 975         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 974         |
|    total_timesteps       | 892928      |
| train/                   |             |
|    approx_kl             | 0.004784575 |
|    clip_fraction         | 0.0204      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000394   |
|    cost_value_loss       | 6.01e-06    |
|    cost_values           | -0.000517   |
|    entropy               | -2.66       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00551     |
|    n_updates             | 4350        |
|    policy_gradient_loss  | -0.00144    |
|    std                   | 0.92        |
|    value_loss            | 0.0134      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.304        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.304        |
| reward                   | -0.32352695  |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 996          |
|    total_timesteps       | 894976       |
| train/                   |              |
|    approx_kl             | 0.0034352955 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000826     |
|    cost_value_loss       | 8.7e-06      |
|    cost_values           | 0.000771     |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00967      |
|    n_updates             | 4360         |
|    policy_gradient_loss  | -0.000967    |
|    std                   | 0.915        |
|    value_loss            | 0.0579       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0423      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0423      |
| reward                   | -0.40006438 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1018        |
|    total_timesteps       | 897024      |
| train/                   |             |
|    approx_kl             | 0.004206937 |
|    clip_fraction         | 0.0357      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00889     |
|    cost_value_loss       | 1.51e-05    |
|    cost_values           | 0.00851     |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00725     |
|    n_updates             | 4370        |
|    policy_gradient_loss  | -0.00218    |
|    std                   | 0.91        |
|    value_loss            | 0.0488      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.122        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.122        |
| reward                   | -0.47414404  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1041         |
|    total_timesteps       | 899072       |
| train/                   |              |
|    approx_kl             | 0.0023355982 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00301     |
|    cost_value_loss       | 2.88e-05     |
|    cost_values           | -0.00322     |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.08         |
|    n_updates             | 4380         |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 0.909        |
|    value_loss            | 1.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.336       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.336       |
| reward                   | -0.37523633 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 901120      |
| train/                   |             |
|    approx_kl             | 0.003122962 |
|    clip_fraction         | 0.0213      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0168      |
|    cost_value_loss       | 3.3e-05     |
|    cost_values           | 0.0162      |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0123      |
|    n_updates             | 4390        |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.908       |
|    value_loss            | 0.0434      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.179        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.179        |
| reward                   | -0.48879096  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1085         |
|    total_timesteps       | 903168       |
| train/                   |              |
|    approx_kl             | 0.0047685625 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00168      |
|    cost_value_loss       | 7.03e-05     |
|    cost_values           | 0.0016       |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.479        |
|    n_updates             | 4400         |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.907        |
|    value_loss            | 1.59         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.03       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.03       |
| reward             | -0.3260414 |
| rollout/           |            |
|    ep_len_mean     | 958        |
|    ep_rew_mean     | -386       |
| time/              |            |
|    fps             | 94         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 905216     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.0516      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0516      |
| reward                   | -0.28187138 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -386        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 907264      |
| train/                   |             |
|    approx_kl             | 0.012650148 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0247      |
|    cost_value_loss       | 2.22e-05    |
|    cost_values           | 0.0251      |
|    entropy               | -2.64       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0051      |
|    n_updates             | 4420        |
|    policy_gradient_loss  | -0.00888    |
|    std                   | 0.908       |
|    value_loss            | 0.034       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.179        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.179        |
| reward                   | -0.37862855  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -384         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 66           |
|    total_timesteps       | 909312       |
| train/                   |              |
|    approx_kl             | 0.0069813523 |
|    clip_fraction         | 0.0493       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0116      |
|    cost_value_loss       | 2.04e-05     |
|    cost_values           | -0.0119      |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00799      |
|    n_updates             | 4430         |
|    policy_gradient_loss  | -0.00505     |
|    std                   | 0.909        |
|    value_loss            | 0.108        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0959      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0959      |
| reward                   | -0.42552122 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -386        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 4           |
|    time_elapsed          | 88          |
|    total_timesteps       | 911360      |
| train/                   |             |
|    approx_kl             | 0.009567525 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00709     |
|    cost_value_loss       | 6.62e-06    |
|    cost_values           | 0.00698     |
|    entropy               | -2.63       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00256     |
|    n_updates             | 4440        |
|    policy_gradient_loss  | -0.00747    |
|    std                   | 0.908       |
|    value_loss            | 0.0247      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0269      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0269      |
| reward                   | -0.4715312  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 913408      |
| train/                   |             |
|    approx_kl             | 0.005381967 |
|    clip_fraction         | 0.0486      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0114     |
|    cost_value_loss       | 1.08e-05    |
|    cost_values           | -0.0117     |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00966     |
|    n_updates             | 4450        |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.907       |
|    value_loss            | 0.053       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0712       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0712       |
| reward                   | -0.16929935  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 915456       |
| train/                   |              |
|    approx_kl             | 0.0036152315 |
|    clip_fraction         | 0.0348       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00334     |
|    cost_value_loss       | 8.79e-06     |
|    cost_values           | -0.00285     |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00673      |
|    n_updates             | 4460         |
|    policy_gradient_loss  | -0.00351     |
|    std                   | 0.907        |
|    value_loss            | 0.0673       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.183        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.183        |
| reward                   | -0.4214855   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 917504       |
| train/                   |              |
|    approx_kl             | 0.0063444497 |
|    clip_fraction         | 0.0685       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0148       |
|    cost_value_loss       | 1.27e-05     |
|    cost_values           | 0.0147       |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0112       |
|    n_updates             | 4470         |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.905        |
|    value_loss            | 0.0515       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.133        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.133        |
| reward                   | -0.25031585  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -384         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 8            |
|    time_elapsed          | 175          |
|    total_timesteps       | 919552       |
| train/                   |              |
|    approx_kl             | 0.0065587256 |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00321     |
|    cost_value_loss       | 1.17e-05     |
|    cost_values           | -0.00292     |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0372       |
|    n_updates             | 4480         |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 0.903        |
|    value_loss            | 0.311        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.202        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.202        |
| reward                   | -0.36863282  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -383         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 921600       |
| train/                   |              |
|    approx_kl             | 0.0029004298 |
|    clip_fraction         | 0.0127       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00291      |
|    cost_value_loss       | 2.02e-05     |
|    cost_values           | 0.00283      |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0193       |
|    n_updates             | 4490         |
|    policy_gradient_loss  | -0.00117     |
|    std                   | 0.901        |
|    value_loss            | 0.116        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.11         |
| reward                   | -0.19429757  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -382         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 220          |
|    total_timesteps       | 923648       |
| train/                   |              |
|    approx_kl             | 0.0022640154 |
|    clip_fraction         | 0.0245       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00922      |
|    cost_value_loss       | 2.63e-05     |
|    cost_values           | 0.00999      |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.01         |
|    n_updates             | 4500         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.902        |
|    value_loss            | 0.057        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.253        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.253        |
| reward                   | -0.52271074  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -384         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 242          |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0063126166 |
|    clip_fraction         | 0.0379       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0175       |
|    cost_value_loss       | 8.05e-05     |
|    cost_values           | 0.0174       |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0159       |
|    n_updates             | 4510         |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 0.903        |
|    value_loss            | 0.081        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0878       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0878       |
| reward                   | -0.33388647  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 263          |
|    total_timesteps       | 927744       |
| train/                   |              |
|    approx_kl             | 0.0042294194 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00091      |
|    cost_value_loss       | 3.81e-05     |
|    cost_values           | 0.000256     |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00573      |
|    n_updates             | 4520         |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 0.904        |
|    value_loss            | 0.0738       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.24        |
| reward                   | -0.3135239  |
| rollout/                 |             |
|    ep_len_mean           | 949         |
|    ep_rew_mean           | -382        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 13          |
|    time_elapsed          | 285         |
|    total_timesteps       | 929792      |
| train/                   |             |
|    approx_kl             | 0.003403016 |
|    clip_fraction         | 0.019       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0127     |
|    cost_value_loss       | 1.68e-05    |
|    cost_values           | -0.0134     |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0166      |
|    n_updates             | 4530        |
|    policy_gradient_loss  | -0.00267    |
|    std                   | 0.903       |
|    value_loss            | 0.0768      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.277       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.277       |
| reward                   | -0.38923728 |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -377        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 14          |
|    time_elapsed          | 307         |
|    total_timesteps       | 931840      |
| train/                   |             |
|    approx_kl             | 0.008339583 |
|    clip_fraction         | 0.0623      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0236     |
|    cost_value_loss       | 2.4e-05     |
|    cost_values           | -0.0251     |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.719       |
|    n_updates             | 4540        |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.902       |
|    value_loss            | 1.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0672       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0672       |
| reward                   | -0.38593927  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 15           |
|    time_elapsed          | 329          |
|    total_timesteps       | 933888       |
| train/                   |              |
|    approx_kl             | 0.0041708294 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00636      |
|    cost_value_loss       | 3.8e-05      |
|    cost_values           | 0.00605      |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.2          |
|    n_updates             | 4550         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.902        |
|    value_loss            | 2.41         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.12        |
| reward                   | -0.33224496 |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -374        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 16          |
|    time_elapsed          | 351         |
|    total_timesteps       | 935936      |
| train/                   |             |
|    approx_kl             | 0.003755929 |
|    clip_fraction         | 0.0252      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00256    |
|    cost_value_loss       | 2.34e-06    |
|    cost_values           | -0.00261    |
|    entropy               | -2.6        |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00181    |
|    n_updates             | 4560        |
|    policy_gradient_loss  | -0.00355    |
|    std                   | 0.893       |
|    value_loss            | 0.0141      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0129       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0129       |
| reward                   | -0.38081014  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -371         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 373          |
|    total_timesteps       | 937984       |
| train/                   |              |
|    approx_kl             | 0.0042187776 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000943    |
|    cost_value_loss       | 3.85e-06     |
|    cost_values           | -0.0011      |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00758      |
|    n_updates             | 4570         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.888        |
|    value_loss            | 0.0231       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0454       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0454       |
| reward                   | -0.14170827  |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -367         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 18           |
|    time_elapsed          | 396          |
|    total_timesteps       | 940032       |
| train/                   |              |
|    approx_kl             | 0.0048713246 |
|    clip_fraction         | 0.0585       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0104       |
|    cost_value_loss       | 1.44e-05     |
|    cost_values           | 0.00973      |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0117       |
|    n_updates             | 4580         |
|    policy_gradient_loss  | -0.00417     |
|    std                   | 0.889        |
|    value_loss            | 0.0942       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.46801218 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -364        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 418         |
|    total_timesteps       | 942080      |
| train/                   |             |
|    approx_kl             | 0.005565798 |
|    clip_fraction         | 0.0178      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0132      |
|    cost_value_loss       | 1.54e-05    |
|    cost_values           | 0.0136      |
|    entropy               | -2.6        |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0346      |
|    n_updates             | 4590        |
|    policy_gradient_loss  | -0.000666   |
|    std                   | 0.891       |
|    value_loss            | 0.112       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00453     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00453     |
| reward                   | -0.5196578  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -365        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 20          |
|    time_elapsed          | 440         |
|    total_timesteps       | 944128      |
| train/                   |             |
|    approx_kl             | 0.008568143 |
|    clip_fraction         | 0.0452      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00928     |
|    cost_value_loss       | 1.04e-05    |
|    cost_values           | 0.00935     |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.937       |
|    n_updates             | 4600        |
|    policy_gradient_loss  | -0.00226    |
|    std                   | 0.892       |
|    value_loss            | 1.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.126       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.126       |
| reward                   | -0.28297967 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -363        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 21          |
|    time_elapsed          | 462         |
|    total_timesteps       | 946176      |
| train/                   |             |
|    approx_kl             | 0.006557745 |
|    clip_fraction         | 0.0487      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0462      |
|    cost_value_loss       | 0.000636    |
|    cost_values           | 0.0471      |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00142     |
|    n_updates             | 4610        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.891       |
|    value_loss            | 0.0514      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.124       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.124       |
| reward                   | -0.4714845  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -362        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 22          |
|    time_elapsed          | 483         |
|    total_timesteps       | 948224      |
| train/                   |             |
|    approx_kl             | 0.006568558 |
|    clip_fraction         | 0.0646      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00811    |
|    cost_value_loss       | 0.000816    |
|    cost_values           | -0.0206     |
|    entropy               | -2.59       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00283     |
|    n_updates             | 4620        |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 0.888       |
|    value_loss            | 0.0532      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.114        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.114        |
| reward                   | -0.16045056  |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -361         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 23           |
|    time_elapsed          | 506          |
|    total_timesteps       | 950272       |
| train/                   |              |
|    approx_kl             | 0.0068724514 |
|    clip_fraction         | 0.0741       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0112       |
|    cost_value_loss       | 5.58e-06     |
|    cost_values           | 0.0112       |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.000794    |
|    n_updates             | 4630         |
|    policy_gradient_loss  | -0.0044      |
|    std                   | 0.883        |
|    value_loss            | 0.0152       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0905      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0905      |
| reward                   | -0.16975822 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -359        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 528         |
|    total_timesteps       | 952320      |
| train/                   |             |
|    approx_kl             | 0.004853407 |
|    clip_fraction         | 0.0248      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00246     |
|    cost_value_loss       | 2.92e-05    |
|    cost_values           | 0.00206     |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0166      |
|    n_updates             | 4640        |
|    policy_gradient_loss  | -0.00144    |
|    std                   | 0.882       |
|    value_loss            | 0.0426      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0327       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0327       |
| reward                   | -0.42008516  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -356         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 551          |
|    total_timesteps       | 954368       |
| train/                   |              |
|    approx_kl             | 0.0053593814 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0251       |
|    cost_value_loss       | 6.58e-06     |
|    cost_values           | 0.0253       |
|    entropy               | -2.56        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0183       |
|    n_updates             | 4650         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 0.878        |
|    value_loss            | 0.1          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.106       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.106       |
| reward                   | -0.3814033  |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -357        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 573         |
|    total_timesteps       | 956416      |
| train/                   |             |
|    approx_kl             | 0.010109719 |
|    clip_fraction         | 0.0768      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00785     |
|    cost_value_loss       | 2.92e-05    |
|    cost_values           | 0.00769     |
|    entropy               | -2.55       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.272       |
|    n_updates             | 4660        |
|    policy_gradient_loss  | -0.00604    |
|    std                   | 0.874       |
|    value_loss            | 1.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0324       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0324       |
| reward                   | -0.1670784   |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -357         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 595          |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0053666057 |
|    clip_fraction         | 0.0742       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00949     |
|    cost_value_loss       | 1.98e-05     |
|    cost_values           | -0.00996     |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00286     |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.00467     |
|    std                   | 0.873        |
|    value_loss            | 0.0394       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.333        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.333        |
| reward                   | -0.37371925  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -354         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 618          |
|    total_timesteps       | 960512       |
| train/                   |              |
|    approx_kl             | 0.0032455283 |
|    clip_fraction         | 0.0384       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0238      |
|    cost_value_loss       | 3.28e-05     |
|    cost_values           | -0.0247      |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00328      |
|    n_updates             | 4680         |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.872        |
|    value_loss            | 0.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0742      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0742      |
| reward                   | -0.5135033  |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -356        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 640         |
|    total_timesteps       | 962560      |
| train/                   |             |
|    approx_kl             | 0.005657782 |
|    clip_fraction         | 0.0518      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00031     |
|    cost_value_loss       | 3.67e-05    |
|    cost_values           | -0.000948   |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0165      |
|    n_updates             | 4690        |
|    policy_gradient_loss  | -0.0039     |
|    std                   | 0.871       |
|    value_loss            | 0.0686      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.22         |
| reward                   | -0.32072604  |
| rollout/                 |              |
|    ep_len_mean           | 948          |
|    ep_rew_mean           | -356         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 662          |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0028230972 |
|    clip_fraction         | 0.0189       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000359    |
|    cost_value_loss       | 3.95e-05     |
|    cost_values           | 0.000731     |
|    entropy               | -2.54        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00985      |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 0.869        |
|    value_loss            | 0.0709       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.178        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.178        |
| reward                   | -0.4669707   |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -360         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 684          |
|    total_timesteps       | 966656       |
| train/                   |              |
|    approx_kl             | 0.0033913362 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0277       |
|    cost_value_loss       | 2.78e-05     |
|    cost_values           | 0.0291       |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0155       |
|    n_updates             | 4710         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.868        |
|    value_loss            | 0.104        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.191        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.191        |
| reward                   | -0.36861232  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -358         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 707          |
|    total_timesteps       | 968704       |
| train/                   |              |
|    approx_kl             | 0.0046589593 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00301      |
|    cost_value_loss       | 1.16e-05     |
|    cost_values           | 0.0033       |
|    entropy               | -2.54        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0238       |
|    n_updates             | 4720         |
|    policy_gradient_loss  | -0.00121     |
|    std                   | 0.867        |
|    value_loss            | 0.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.178        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.178        |
| reward                   | -0.25467756  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -359         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 730          |
|    total_timesteps       | 970752       |
| train/                   |              |
|    approx_kl             | 0.0031245654 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00964      |
|    cost_value_loss       | 9.44e-06     |
|    cost_values           | 0.0098       |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.024        |
|    n_updates             | 4730         |
|    policy_gradient_loss  | -0.00257     |
|    std                   | 0.864        |
|    value_loss            | 0.0772       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0853       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0853       |
| reward                   | -0.5071203   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -359         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 752          |
|    total_timesteps       | 972800       |
| train/                   |              |
|    approx_kl             | 0.0033514355 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00297      |
|    cost_value_loss       | 3.41e-05     |
|    cost_values           | 0.00281      |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0178       |
|    n_updates             | 4740         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.861        |
|    value_loss            | 0.062        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0235       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0235       |
| reward                   | -0.25739583  |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -359         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 774          |
|    total_timesteps       | 974848       |
| train/                   |              |
|    approx_kl             | 0.0027258932 |
|    clip_fraction         | 0.0365       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0191       |
|    cost_value_loss       | 3.77e-05     |
|    cost_values           | 0.0204       |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00311      |
|    n_updates             | 4750         |
|    policy_gradient_loss  | -0.00329     |
|    std                   | 0.862        |
|    value_loss            | 0.0769       |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.0152     |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.0152     |
| reward                   | -0.4233546 |
| rollout/                 |            |
|    ep_len_mean           | 966        |
|    ep_rew_mean           | -360       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 36         |
|    time_elapsed          | 796        |
|    total_timesteps       | 976896     |
| train/                   |            |
|    approx_kl             | 0.00436085 |
|    clip_fraction         | 0.0494     |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00338   |
|    cost_value_loss       | 2.04e-05   |
|    cost_values           | -0.00372   |
|    entropy               | -2.53      |
|    entropy_loss          | -2.53      |
|    explained_variance    | 1          |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.0124     |
|    n_updates             | 4760       |
|    policy_gradient_loss  | -0.00424   |
|    std                   | 0.862      |
|    value_loss            | 0.144      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.115       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.115       |
| reward                   | -0.31910545 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -358        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 819         |
|    total_timesteps       | 978944      |
| train/                   |             |
|    approx_kl             | 0.005855698 |
|    clip_fraction         | 0.0322      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00576     |
|    cost_value_loss       | 8.8e-05     |
|    cost_values           | 0.00603     |
|    entropy               | -2.52       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00588     |
|    n_updates             | 4770        |
|    policy_gradient_loss  | -0.00297    |
|    std                   | 0.859       |
|    value_loss            | 0.0398      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0565      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0565      |
| reward                   | -0.33504862 |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -357        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 840         |
|    total_timesteps       | 980992      |
| train/                   |             |
|    approx_kl             | 0.005289913 |
|    clip_fraction         | 0.0217      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00349     |
|    cost_value_loss       | 2.4e-05     |
|    cost_values           | 0.00366     |
|    entropy               | -2.51       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00905     |
|    n_updates             | 4780        |
|    policy_gradient_loss  | -0.00168    |
|    std                   | 0.856       |
|    value_loss            | 0.039       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.171        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.171        |
| reward                   | -0.4746531   |
| rollout/                 |              |
|    ep_len_mean           | 966          |
|    ep_rew_mean           | -357         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 862          |
|    total_timesteps       | 983040       |
| train/                   |              |
|    approx_kl             | 0.0037814036 |
|    clip_fraction         | 0.037        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00188      |
|    cost_value_loss       | 3.33e-06     |
|    cost_values           | 0.00182      |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00101     |
|    n_updates             | 4790         |
|    policy_gradient_loss  | -0.00187     |
|    std                   | 0.855        |
|    value_loss            | 0.025        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0188      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0188      |
| reward                   | -0.3397751  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -353        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 883         |
|    total_timesteps       | 985088      |
| train/                   |             |
|    approx_kl             | 0.005378185 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00335    |
|    cost_value_loss       | 3.66e-06    |
|    cost_values           | -0.00326    |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00983     |
|    n_updates             | 4800        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.854       |
|    value_loss            | 0.0678      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0415      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0415      |
| reward                   | -0.31856483 |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -352        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 905         |
|    total_timesteps       | 987136      |
| train/                   |             |
|    approx_kl             | 0.009066397 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0196      |
|    cost_value_loss       | 2.81e-05    |
|    cost_values           | 0.0194      |
|    entropy               | -2.5        |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.567       |
|    n_updates             | 4810        |
|    policy_gradient_loss  | -0.00585    |
|    std                   | 0.851       |
|    value_loss            | 2.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0906      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0906      |
| reward                   | -0.3853097  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -350        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 927         |
|    total_timesteps       | 989184      |
| train/                   |             |
|    approx_kl             | 0.009123709 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00416    |
|    cost_value_loss       | 9.46e-06    |
|    cost_values           | -0.00403    |
|    entropy               | -2.49       |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.0101     |
|    n_updates             | 4820        |
|    policy_gradient_loss  | -0.0122     |
|    std                   | 0.846       |
|    value_loss            | 0.0256      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.171        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.171        |
| reward                   | -0.28142846  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -354         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 950          |
|    total_timesteps       | 991232       |
| train/                   |              |
|    approx_kl             | 0.0073950766 |
|    clip_fraction         | 0.0467       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0183      |
|    cost_value_loss       | 2.88e-05     |
|    cost_values           | -0.0189      |
|    entropy               | -2.48        |
|    entropy_loss          | -2.49        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0111       |
|    n_updates             | 4830         |
|    policy_gradient_loss  | -0.00354     |
|    std                   | 0.842        |
|    value_loss            | 0.0296       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0374       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0374       |
| reward                   | -0.519182    |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -355         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 972          |
|    total_timesteps       | 993280       |
| train/                   |              |
|    approx_kl             | 0.0031080213 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0153       |
|    cost_value_loss       | 4.25e-05     |
|    cost_values           | 0.0154       |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00672      |
|    n_updates             | 4840         |
|    policy_gradient_loss  | -0.000822    |
|    std                   | 0.84         |
|    value_loss            | 0.0707       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.214       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.214       |
| reward                   | -0.52764606 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -355        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 994         |
|    total_timesteps       | 995328      |
| train/                   |             |
|    approx_kl             | 0.009087737 |
|    clip_fraction         | 0.0564      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0207      |
|    cost_value_loss       | 2.93e-05    |
|    cost_values           | 0.022       |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00848     |
|    n_updates             | 4850        |
|    policy_gradient_loss  | -0.00379    |
|    std                   | 0.839       |
|    value_loss            | 0.0775      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.17         |
| reward                   | -0.22267678  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -354         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1016         |
|    total_timesteps       | 997376       |
| train/                   |              |
|    approx_kl             | 0.0033227105 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00841      |
|    cost_value_loss       | 4.34e-05     |
|    cost_values           | 0.00912      |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00359      |
|    n_updates             | 4860         |
|    policy_gradient_loss  | -0.00325     |
|    std                   | 0.839        |
|    value_loss            | 0.0552       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.29         |
| reward                   | -0.45277572  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -353         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1038         |
|    total_timesteps       | 999424       |
| train/                   |              |
|    approx_kl             | 0.0045241644 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0237       |
|    cost_value_loss       | 1.11e-05     |
|    cost_values           | 0.0238       |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000138     |
|    n_updates             | 4870         |
|    policy_gradient_loss  | -0.00463     |
|    std                   | 0.839        |
|    value_loss            | 0.0351       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0688      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0688      |
| reward                   | -0.28057    |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -351        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1060        |
|    total_timesteps       | 1001472     |
| train/                   |             |
|    approx_kl             | 0.008139522 |
|    clip_fraction         | 0.0709      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0135      |
|    cost_value_loss       | 2.57e-05    |
|    cost_values           | 0.0142      |
|    entropy               | -2.47       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.76        |
|    n_updates             | 4880        |
|    policy_gradient_loss  | -0.00243    |
|    std                   | 0.838       |
|    value_loss            | 1.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0804       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0804       |
| reward                   | -0.3052695   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -351         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1082         |
|    total_timesteps       | 1003520      |
| train/                   |              |
|    approx_kl             | 0.0035848164 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00414      |
|    cost_value_loss       | 4.49e-06     |
|    cost_values           | 0.00419      |
|    entropy               | -2.48        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.012        |
|    n_updates             | 4890         |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 0.839        |
|    value_loss            | 0.107        |
-------------------------------------------
------------------------------------
| avg_speed          | 0.0218      |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.0218      |
| reward             | -0.48604858 |
| rollout/           |             |
|    ep_len_mean     | 969         |
|    ep_rew_mean     | -354        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1005568     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.202        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.202        |
| reward                   | -0.3857726   |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -353         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 2            |
|    time_elapsed          | 44           |
|    total_timesteps       | 1007616      |
| train/                   |              |
|    approx_kl             | 0.0060105496 |
|    clip_fraction         | 0.0577       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00524      |
|    cost_value_loss       | 1.43e-05     |
|    cost_values           | 0.00501      |
|    entropy               | -2.46        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00422     |
|    n_updates             | 4910         |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.831        |
|    value_loss            | 0.0334       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00383     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00383     |
| reward                   | -0.4887511  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -354        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 1009664     |
| train/                   |             |
|    approx_kl             | 0.009770252 |
|    clip_fraction         | 0.0937      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0205      |
|    cost_value_loss       | 1.87e-05    |
|    cost_values           | 0.0208      |
|    entropy               | -2.45       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.2         |
|    n_updates             | 4920        |
|    policy_gradient_loss  | -0.00155    |
|    std                   | 0.829       |
|    value_loss            | 1.78        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.147        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.147        |
| reward                   | -0.3391716   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -349         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 1011712      |
| train/                   |              |
|    approx_kl             | 0.0042408486 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00651     |
|    cost_value_loss       | 5.22e-05     |
|    cost_values           | -0.0078      |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00734      |
|    n_updates             | 4930         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.832        |
|    value_loss            | 0.0422       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.198        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.198        |
| reward                   | -0.41645342  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -352         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 1013760      |
| train/                   |              |
|    approx_kl             | 0.0037420457 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00604      |
|    cost_value_loss       | 0.000188     |
|    cost_values           | 0.00957      |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.774        |
|    n_updates             | 4940         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 0.833        |
|    value_loss            | 1.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0957       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0957       |
| reward                   | -0.39829803  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -350         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 133          |
|    total_timesteps       | 1015808      |
| train/                   |              |
|    approx_kl             | 0.0051507726 |
|    clip_fraction         | 0.119        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0144      |
|    cost_value_loss       | 1.37e-05     |
|    cost_values           | -0.0146      |
|    entropy               | -2.45        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00446     |
|    n_updates             | 4950         |
|    policy_gradient_loss  | -0.0058      |
|    std                   | 0.826        |
|    value_loss            | 0.0142       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0264      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0264      |
| reward                   | -0.22825067 |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -347        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 155         |
|    total_timesteps       | 1017856     |
| train/                   |             |
|    approx_kl             | 0.010239271 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00146     |
|    cost_value_loss       | 1.06e-05    |
|    cost_values           | 0.00144     |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.000138    |
|    n_updates             | 4960        |
|    policy_gradient_loss  | -0.00967    |
|    std                   | 0.823       |
|    value_loss            | 0.0122      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.276        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.276        |
| reward                   | -0.24533698  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -346         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 8            |
|    time_elapsed          | 178          |
|    total_timesteps       | 1019904      |
| train/                   |              |
|    approx_kl             | 0.0036227028 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0182       |
|    cost_value_loss       | 1.64e-05     |
|    cost_values           | 0.0182       |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.423        |
|    n_updates             | 4970         |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 0.821        |
|    value_loss            | 1.08         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.092        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.092        |
| reward                   | -0.36381772  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -344         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 9            |
|    time_elapsed          | 200          |
|    total_timesteps       | 1021952      |
| train/                   |              |
|    approx_kl             | 0.0016274618 |
|    clip_fraction         | 0.026        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00457     |
|    cost_value_loss       | 1.24e-05     |
|    cost_values           | -0.00422     |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0118       |
|    n_updates             | 4980         |
|    policy_gradient_loss  | -0.000955    |
|    std                   | 0.821        |
|    value_loss            | 0.063        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00595      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00595      |
| reward                   | -0.31281146  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -345         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 222          |
|    total_timesteps       | 1024000      |
| train/                   |              |
|    approx_kl             | 0.0011894441 |
|    clip_fraction         | 0.0368       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0175       |
|    cost_value_loss       | 0.000132     |
|    cost_values           | 0.0169       |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0127       |
|    n_updates             | 4990         |
|    policy_gradient_loss  | 0.000477     |
|    std                   | 0.822        |
|    value_loss            | 0.184        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.133        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.133        |
| reward                   | -0.4214816   |
| rollout/                 |              |
|    ep_len_mean           | 959          |
|    ep_rew_mean           | -347         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 244          |
|    total_timesteps       | 1026048      |
| train/                   |              |
|    approx_kl             | 0.0018849777 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00476     |
|    cost_value_loss       | 6.39e-05     |
|    cost_values           | -0.00416     |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0144       |
|    n_updates             | 5000         |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 0.822        |
|    value_loss            | 0.0432       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.128        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.128        |
| reward                   | -0.3226564   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -350         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 265          |
|    total_timesteps       | 1028096      |
| train/                   |              |
|    approx_kl             | 0.0051321206 |
|    clip_fraction         | 0.0483       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00607     |
|    cost_value_loss       | 1.48e-05     |
|    cost_values           | -0.00572     |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0514       |
|    n_updates             | 5010         |
|    policy_gradient_loss  | -0.0021      |
|    std                   | 0.821        |
|    value_loss            | 0.127        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.261       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.261       |
| reward                   | -0.36051375 |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -347        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 288         |
|    total_timesteps       | 1030144     |
| train/                   |             |
|    approx_kl             | 0.004999837 |
|    clip_fraction         | 0.017       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00285     |
|    cost_value_loss       | 2.74e-05    |
|    cost_values           | 0.00291     |
|    entropy               | -2.43       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00648     |
|    n_updates             | 5020        |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.818       |
|    value_loss            | 0.0272      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.114        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.114        |
| reward                   | -0.16251038  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -346         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 310          |
|    total_timesteps       | 1032192      |
| train/                   |              |
|    approx_kl             | 0.0031396383 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00803     |
|    cost_value_loss       | 3.37e-05     |
|    cost_values           | -0.00835     |
|    entropy               | -2.42        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0098       |
|    n_updates             | 5030         |
|    policy_gradient_loss  | -0.000899    |
|    std                   | 0.815        |
|    value_loss            | 0.0298       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.08         |
| reward                   | -0.37105379  |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -344         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 333          |
|    total_timesteps       | 1034240      |
| train/                   |              |
|    approx_kl             | 0.0016871628 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00128     |
|    cost_value_loss       | 1.47e-05     |
|    cost_values           | -0.00135     |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00598      |
|    n_updates             | 5040         |
|    policy_gradient_loss  | -0.00093     |
|    std                   | 0.813        |
|    value_loss            | 0.0325       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0662       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0662       |
| reward                   | -0.4064217   |
| rollout/                 |              |
|    ep_len_mean           | 964          |
|    ep_rew_mean           | -347         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 355          |
|    total_timesteps       | 1036288      |
| train/                   |              |
|    approx_kl             | 0.0041817874 |
|    clip_fraction         | 0.0121       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.006        |
|    cost_value_loss       | 8.33e-06     |
|    cost_values           | 0.00605      |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0314       |
|    n_updates             | 5050         |
|    policy_gradient_loss  | -0.00165     |
|    std                   | 0.809        |
|    value_loss            | 0.0753       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0412       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0412       |
| reward                   | -0.48853257  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -349         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 376          |
|    total_timesteps       | 1038336      |
| train/                   |              |
|    approx_kl             | 0.0037388643 |
|    clip_fraction         | 0.0382       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0329      |
|    cost_value_loss       | 2.03e-05     |
|    cost_values           | -0.0332      |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00208      |
|    n_updates             | 5060         |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 0.808        |
|    value_loss            | 0.0224       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0976      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0976      |
| reward                   | -0.27808064 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -343        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 398         |
|    total_timesteps       | 1040384     |
| train/                   |             |
|    approx_kl             | 0.005906215 |
|    clip_fraction         | 0.0654      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00435     |
|    cost_value_loss       | 5.67e-05    |
|    cost_values           | 0.00402     |
|    entropy               | -2.4        |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00592     |
|    n_updates             | 5070        |
|    policy_gradient_loss  | -0.00494    |
|    std                   | 0.807       |
|    value_loss            | 0.0135      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.102        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.102        |
| reward                   | -0.24596278  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -342         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 420          |
|    total_timesteps       | 1042432      |
| train/                   |              |
|    approx_kl             | 0.0058433395 |
|    clip_fraction         | 0.081        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0104       |
|    cost_value_loss       | 9.73e-05     |
|    cost_values           | 0.011        |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.645        |
|    n_updates             | 5080         |
|    policy_gradient_loss  | -0.000673    |
|    std                   | 0.809        |
|    value_loss            | 1.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.126        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.126        |
| reward                   | -0.38818625  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -338         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 442          |
|    total_timesteps       | 1044480      |
| train/                   |              |
|    approx_kl             | 0.0039203195 |
|    clip_fraction         | 0.0488       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0381       |
|    cost_value_loss       | 4.15e-05     |
|    cost_values           | 0.0385       |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0156       |
|    n_updates             | 5090         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.809        |
|    value_loss            | 0.0629       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.128       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.128       |
| reward                   | -0.24589486 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -341        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 464         |
|    total_timesteps       | 1046528     |
| train/                   |             |
|    approx_kl             | 0.008893408 |
|    clip_fraction         | 0.0605      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00338    |
|    cost_value_loss       | 1.01e-05    |
|    cost_values           | -0.00278    |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00525     |
|    n_updates             | 5100        |
|    policy_gradient_loss  | -0.00634    |
|    std                   | 0.809       |
|    value_loss            | 0.0981      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.245       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.245       |
| reward                   | -0.36760446 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -335        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 486         |
|    total_timesteps       | 1048576     |
| train/                   |             |
|    approx_kl             | 0.00595936  |
|    clip_fraction         | 0.0789      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00641     |
|    cost_value_loss       | 3.06e-05    |
|    cost_values           | 0.0067      |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00441     |
|    n_updates             | 5110        |
|    policy_gradient_loss  | -0.00743    |
|    std                   | 0.807       |
|    value_loss            | 0.038       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.106        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.106        |
| reward                   | -0.40277565  |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -334         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 508          |
|    total_timesteps       | 1050624      |
| train/                   |              |
|    approx_kl             | 0.0053943167 |
|    clip_fraction         | 0.0662       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0247       |
|    cost_value_loss       | 6.32e-05     |
|    cost_values           | 0.0242       |
|    entropy               | -2.41        |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.321        |
|    n_updates             | 5120         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.809        |
|    value_loss            | 1.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.071       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.071       |
| reward                   | -0.43955752 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -334        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 530         |
|    total_timesteps       | 1052672     |
| train/                   |             |
|    approx_kl             | 0.010931257 |
|    clip_fraction         | 0.0932      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00884     |
|    cost_value_loss       | 6.12e-05    |
|    cost_values           | 0.00934     |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.154       |
|    n_updates             | 5130        |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.808       |
|    value_loss            | 0.862       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0145      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0145      |
| reward                   | -0.22141843 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -336        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 552         |
|    total_timesteps       | 1054720     |
| train/                   |             |
|    approx_kl             | 0.003069082 |
|    clip_fraction         | 0.00146     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0171     |
|    cost_value_loss       | 6.51e-05    |
|    cost_values           | -0.0183     |
|    entropy               | -2.4        |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.64        |
|    n_updates             | 5140        |
|    policy_gradient_loss  | -0.00104    |
|    std                   | 0.807       |
|    value_loss            | 1.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0399       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0399       |
| reward                   | -0.46752137  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -326         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 575          |
|    total_timesteps       | 1056768      |
| train/                   |              |
|    approx_kl             | 0.0045231483 |
|    clip_fraction         | 0.0274       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0171      |
|    cost_value_loss       | 6.91e-05     |
|    cost_values           | -0.0169      |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0204       |
|    n_updates             | 5150         |
|    policy_gradient_loss  | -0.00462     |
|    std                   | 0.805        |
|    value_loss            | 0.496        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0609      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0609      |
| reward                   | -0.2548379  |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -326        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 597         |
|    total_timesteps       | 1058816     |
| train/                   |             |
|    approx_kl             | 0.004699099 |
|    clip_fraction         | 0.0328      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0039     |
|    cost_value_loss       | 0.000112    |
|    cost_values           | -0.00355    |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.4         |
|    n_updates             | 5160        |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 0.804       |
|    value_loss            | 1.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0305       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0305       |
| reward                   | -0.41297692  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -325         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 620          |
|    total_timesteps       | 1060864      |
| train/                   |              |
|    approx_kl             | 0.0032663187 |
|    clip_fraction         | 0.0225       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0118      |
|    cost_value_loss       | 6.55e-05     |
|    cost_values           | -0.0105      |
|    entropy               | -2.39        |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.029        |
|    n_updates             | 5170         |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 0.803        |
|    value_loss            | 0.293        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.195       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.195       |
| reward                   | -0.47370633 |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -329        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 642         |
|    total_timesteps       | 1062912     |
| train/                   |             |
|    approx_kl             | 0.005334641 |
|    clip_fraction         | 0.0286      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0248      |
|    cost_value_loss       | 4.8e-05     |
|    cost_values           | 0.0257      |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0468      |
|    n_updates             | 5180        |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.803       |
|    value_loss            | 0.298       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.166       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.166       |
| reward                   | -0.4643823  |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -328        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 664         |
|    total_timesteps       | 1064960     |
| train/                   |             |
|    approx_kl             | 0.006901378 |
|    clip_fraction         | 0.0467      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00187    |
|    cost_value_loss       | 1.5e-05     |
|    cost_values           | -0.00198    |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00776     |
|    n_updates             | 5190        |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 0.802       |
|    value_loss            | 0.0418      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0398      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0398      |
| reward                   | -0.357322   |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -330        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 686         |
|    total_timesteps       | 1067008     |
| train/                   |             |
|    approx_kl             | 0.008518018 |
|    clip_fraction         | 0.0468      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0223      |
|    cost_value_loss       | 3.58e-05    |
|    cost_values           | 0.0225      |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00241     |
|    n_updates             | 5200        |
|    policy_gradient_loss  | -0.00357    |
|    std                   | 0.803       |
|    value_loss            | 0.0748      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0274       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0274       |
| reward                   | -0.18182358  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -328         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 708          |
|    total_timesteps       | 1069056      |
| train/                   |              |
|    approx_kl             | 0.0072645354 |
|    clip_fraction         | 0.0616       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0095      |
|    cost_value_loss       | 7.68e-06     |
|    cost_values           | -0.0099      |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.000905     |
|    n_updates             | 5210         |
|    policy_gradient_loss  | -0.00639     |
|    std                   | 0.806        |
|    value_loss            | 0.0377       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0416      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0416      |
| reward                   | -0.47729373 |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -329        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 730         |
|    total_timesteps       | 1071104     |
| train/                   |             |
|    approx_kl             | 0.004744121 |
|    clip_fraction         | 0.0665      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00668    |
|    cost_value_loss       | 4.21e-05    |
|    cost_values           | -0.00681    |
|    entropy               | -2.39       |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00826     |
|    n_updates             | 5220        |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 0.802       |
|    value_loss            | 0.034       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.246        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.246        |
| reward                   | -0.2836205   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -330         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 752          |
|    total_timesteps       | 1073152      |
| train/                   |              |
|    approx_kl             | 0.0034935214 |
|    clip_fraction         | 0.011        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00116     |
|    cost_value_loss       | 4.92e-05     |
|    cost_values           | -0.000792    |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0275       |
|    n_updates             | 5230         |
|    policy_gradient_loss  | 0.000145     |
|    std                   | 0.801        |
|    value_loss            | 0.315        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0842       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0842       |
| reward                   | -0.26786837  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -328         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 774          |
|    total_timesteps       | 1075200      |
| train/                   |              |
|    approx_kl             | 0.0053908774 |
|    clip_fraction         | 0.0589       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00988     |
|    cost_value_loss       | 1.87e-05     |
|    cost_values           | -0.00999     |
|    entropy               | -2.4         |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00119      |
|    n_updates             | 5240         |
|    policy_gradient_loss  | -0.00588     |
|    std                   | 0.805        |
|    value_loss            | 0.0274       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.122        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.122        |
| reward                   | -0.41501945  |
| rollout/                 |              |
|    ep_len_mean           | 922          |
|    ep_rew_mean           | -331         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 797          |
|    total_timesteps       | 1077248      |
| train/                   |              |
|    approx_kl             | 0.0026627118 |
|    clip_fraction         | 0.0352       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.012       |
|    cost_value_loss       | 4.71e-06     |
|    cost_values           | -0.0121      |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0111       |
|    n_updates             | 5250         |
|    policy_gradient_loss  | -0.00307     |
|    std                   | 0.805        |
|    value_loss            | 0.0436       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.532        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.532        |
| reward                   | -0.43086988  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -328         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 819          |
|    total_timesteps       | 1079296      |
| train/                   |              |
|    approx_kl             | 0.0059026275 |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00112      |
|    cost_value_loss       | 1.05e-05     |
|    cost_values           | 0.00113      |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00851      |
|    n_updates             | 5260         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.807        |
|    value_loss            | 0.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.153        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.153        |
| reward                   | -0.523278    |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -327         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 841          |
|    total_timesteps       | 1081344      |
| train/                   |              |
|    approx_kl             | 0.0076283887 |
|    clip_fraction         | 0.0879       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000572     |
|    cost_value_loss       | 2.91e-05     |
|    cost_values           | 0.000372     |
|    entropy               | -2.4         |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.441        |
|    n_updates             | 5270         |
|    policy_gradient_loss  | -0.00493     |
|    std                   | 0.806        |
|    value_loss            | 0.836        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.232        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.232        |
| reward                   | -0.36821768  |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -329         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 863          |
|    total_timesteps       | 1083392      |
| train/                   |              |
|    approx_kl             | 0.0018109175 |
|    clip_fraction         | 0.0176       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00318      |
|    cost_value_loss       | 3.7e-05      |
|    cost_values           | 0.00369      |
|    entropy               | -2.4         |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0585       |
|    n_updates             | 5280         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.805        |
|    value_loss            | 0.561        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0672      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0672      |
| reward                   | -0.34436592 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -328        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 885         |
|    total_timesteps       | 1085440     |
| train/                   |             |
|    approx_kl             | 0.009415364 |
|    clip_fraction         | 0.0801      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00178    |
|    cost_value_loss       | 4.72e-06    |
|    cost_values           | -0.00167    |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0106      |
|    n_updates             | 5290        |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.804       |
|    value_loss            | 0.201       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0831      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0831      |
| reward                   | -0.37131408 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -328        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 908         |
|    total_timesteps       | 1087488     |
| train/                   |             |
|    approx_kl             | 0.005508546 |
|    clip_fraction         | 0.0516      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0241     |
|    cost_value_loss       | 1.42e-05    |
|    cost_values           | -0.0241     |
|    entropy               | -2.39       |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0415      |
|    n_updates             | 5300        |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 0.803       |
|    value_loss            | 0.156       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.114       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.114       |
| reward                   | -0.37968832 |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -333        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 930         |
|    total_timesteps       | 1089536     |
| train/                   |             |
|    approx_kl             | 0.005869627 |
|    clip_fraction         | 0.0345      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.011      |
|    cost_value_loss       | 3.8e-05     |
|    cost_values           | -0.011      |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.029       |
|    n_updates             | 5310        |
|    policy_gradient_loss  | -0.00207    |
|    std                   | 0.8         |
|    value_loss            | 0.0924      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.197        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.197        |
| reward                   | -0.32226393  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -331         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 952          |
|    total_timesteps       | 1091584      |
| train/                   |              |
|    approx_kl             | 0.0045784498 |
|    clip_fraction         | 0.0376       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00591     |
|    cost_value_loss       | 4.37e-05     |
|    cost_values           | -0.0062      |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.6          |
|    n_updates             | 5320         |
|    policy_gradient_loss  | -0.00473     |
|    std                   | 0.799        |
|    value_loss            | 0.939        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.193        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.193        |
| reward                   | -0.5127286   |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -332         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 974          |
|    total_timesteps       | 1093632      |
| train/                   |              |
|    approx_kl             | 0.0042420607 |
|    clip_fraction         | 0.0398       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0107      |
|    cost_value_loss       | 4.77e-05     |
|    cost_values           | -0.0106      |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0332       |
|    n_updates             | 5330         |
|    policy_gradient_loss  | -0.00516     |
|    std                   | 0.798        |
|    value_loss            | 0.0963       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.357       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.357       |
| reward                   | -0.4915094  |
| rollout/                 |             |
|    ep_len_mean           | 897         |
|    ep_rew_mean           | -321        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 996         |
|    total_timesteps       | 1095680     |
| train/                   |             |
|    approx_kl             | 0.007739018 |
|    clip_fraction         | 0.0533      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00265     |
|    cost_value_loss       | 2.6e-06     |
|    cost_values           | 0.0027      |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0141      |
|    n_updates             | 5340        |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.797       |
|    value_loss            | 0.0644      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0738       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0738       |
| reward                   | -0.41798306  |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -323         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1018         |
|    total_timesteps       | 1097728      |
| train/                   |              |
|    approx_kl             | 0.0038219825 |
|    clip_fraction         | 0.0479       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0253       |
|    cost_value_loss       | 6.33e-05     |
|    cost_values           | 0.0257       |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.821        |
|    n_updates             | 5350         |
|    policy_gradient_loss  | -0.00245     |
|    std                   | 0.795        |
|    value_loss            | 2.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.034        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.034        |
| reward                   | -0.39539734  |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -324         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1040         |
|    total_timesteps       | 1099776      |
| train/                   |              |
|    approx_kl             | 0.0049517076 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0118      |
|    cost_value_loss       | 5.59e-05     |
|    cost_values           | -0.0119      |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0538       |
|    n_updates             | 5360         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.792        |
|    value_loss            | 0.167        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.414        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.414        |
| reward                   | -0.20005435  |
| rollout/                 |              |
|    ep_len_mean           | 905          |
|    ep_rew_mean           | -326         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1063         |
|    total_timesteps       | 1101824      |
| train/                   |              |
|    approx_kl             | 0.0047682086 |
|    clip_fraction         | 0.0118       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0338      |
|    cost_value_loss       | 2.56e-05     |
|    cost_values           | -0.0349      |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0357       |
|    n_updates             | 5370         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.791        |
|    value_loss            | 0.347        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0077      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0077      |
| reward                   | -0.2824025  |
| rollout/                 |             |
|    ep_len_mean           | 902         |
|    ep_rew_mean           | -324        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1085        |
|    total_timesteps       | 1103872     |
| train/                   |             |
|    approx_kl             | 0.003787027 |
|    clip_fraction         | 0.0413      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000749    |
|    cost_value_loss       | 1.63e-05    |
|    cost_values           | 0.000511    |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.231       |
|    n_updates             | 5380        |
|    policy_gradient_loss  | -0.00314    |
|    std                   | 0.79        |
|    value_loss            | 0.705       |
------------------------------------------
Directory created: PPOL_New/models/seed-testing/tggzx3rw/model_epoch(10)
------------------------------------
| avg_speed          | 0.283       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.283       |
| reward             | -0.32605362 |
| rollout/           |             |
|    ep_len_mean     | 899         |
|    ep_rew_mean     | -323        |
| time/              |             |
|    fps             | 93          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1105920     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.254        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.254        |
| reward                   | -0.3655635   |
| rollout/                 |              |
|    ep_len_mean           | 899          |
|    ep_rew_mean           | -323         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 2            |
|    time_elapsed          | 44           |
|    total_timesteps       | 1107968      |
| train/                   |              |
|    approx_kl             | 0.0019626645 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0277       |
|    cost_value_loss       | 7.5e-05      |
|    cost_values           | 0.0277       |
|    entropy               | -2.37        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.903        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.303        |
|    n_updates             | 5400         |
|    policy_gradient_loss  | 8.99e-05     |
|    std                   | 0.79         |
|    value_loss            | 1.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00597     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00597     |
| reward                   | -0.27665603 |
| rollout/                 |             |
|    ep_len_mean           | 907         |
|    ep_rew_mean           | -326        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 1110016     |
| train/                   |             |
|    approx_kl             | 0.003011583 |
|    clip_fraction         | 0.00874     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00405    |
|    cost_value_loss       | 1.12e-05    |
|    cost_values           | -0.00379    |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0123      |
|    n_updates             | 5410        |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 0.788       |
|    value_loss            | 0.184       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.173        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.173        |
| reward                   | -0.36223683  |
| rollout/                 |              |
|    ep_len_mean           | 907          |
|    ep_rew_mean           | -327         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 1112064      |
| train/                   |              |
|    approx_kl             | 0.0083037615 |
|    clip_fraction         | 0.0807       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0203       |
|    cost_value_loss       | 3.82e-05     |
|    cost_values           | 0.0206       |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0547       |
|    n_updates             | 5420         |
|    policy_gradient_loss  | -0.00813     |
|    std                   | 0.786        |
|    value_loss            | 0.192        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.166       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.166       |
| reward                   | -0.4623175  |
| rollout/                 |             |
|    ep_len_mean           | 903         |
|    ep_rew_mean           | -323        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 1114112     |
| train/                   |             |
|    approx_kl             | 0.003054894 |
|    clip_fraction         | 0.00352     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000861   |
|    cost_value_loss       | 5.06e-05    |
|    cost_values           | -7.96e-05   |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.147       |
|    n_updates             | 5430        |
|    policy_gradient_loss  | -0.000389   |
|    std                   | 0.786       |
|    value_loss            | 1.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.694        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.694        |
| reward                   | -0.5388886   |
| rollout/                 |              |
|    ep_len_mean           | 903          |
|    ep_rew_mean           | -327         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 133          |
|    total_timesteps       | 1116160      |
| train/                   |              |
|    approx_kl             | 0.0055790744 |
|    clip_fraction         | 0.0462       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0125       |
|    cost_value_loss       | 3.46e-05     |
|    cost_values           | 0.0127       |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.288        |
|    n_updates             | 5440         |
|    policy_gradient_loss  | -0.00369     |
|    std                   | 0.784        |
|    value_loss            | 0.897        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0303       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0303       |
| reward                   | -0.3139839   |
| rollout/                 |              |
|    ep_len_mean           | 903          |
|    ep_rew_mean           | -327         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 155          |
|    total_timesteps       | 1118208      |
| train/                   |              |
|    approx_kl             | 0.0066599045 |
|    clip_fraction         | 0.0669       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00569     |
|    cost_value_loss       | 0.000699     |
|    cost_values           | -0.00109     |
|    entropy               | -2.34        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0129       |
|    n_updates             | 5450         |
|    policy_gradient_loss  | -0.00113     |
|    std                   | 0.782        |
|    value_loss            | 0.0758       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.153       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.153       |
| reward                   | -0.2817713  |
| rollout/                 |             |
|    ep_len_mean           | 891         |
|    ep_rew_mean           | -324        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 177         |
|    total_timesteps       | 1120256     |
| train/                   |             |
|    approx_kl             | 0.007449648 |
|    clip_fraction         | 0.0767      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0118      |
|    cost_value_loss       | 6.59e-05    |
|    cost_values           | 0.0129      |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0838      |
|    n_updates             | 5460        |
|    policy_gradient_loss  | -0.00711    |
|    std                   | 0.784       |
|    value_loss            | 0.461       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0223       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0223       |
| reward                   | -0.41360465  |
| rollout/                 |              |
|    ep_len_mean           | 891          |
|    ep_rew_mean           | -327         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 199          |
|    total_timesteps       | 1122304      |
| train/                   |              |
|    approx_kl             | 0.0051370477 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0239       |
|    cost_value_loss       | 0.000121     |
|    cost_values           | 0.0246       |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.604        |
|    n_updates             | 5470         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.785        |
|    value_loss            | 1.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.252        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.252        |
| reward                   | -0.28939563  |
| rollout/                 |              |
|    ep_len_mean           | 891          |
|    ep_rew_mean           | -330         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 221          |
|    total_timesteps       | 1124352      |
| train/                   |              |
|    approx_kl             | 0.0037983924 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0281       |
|    cost_value_loss       | 2.22e-05     |
|    cost_values           | 0.0285       |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00436      |
|    n_updates             | 5480         |
|    policy_gradient_loss  | -0.000956    |
|    std                   | 0.786        |
|    value_loss            | 0.0574       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0421       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0421       |
| reward                   | -0.38413575  |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -326         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 243          |
|    total_timesteps       | 1126400      |
| train/                   |              |
|    approx_kl             | 0.0056901854 |
|    clip_fraction         | 0.0436       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0181       |
|    cost_value_loss       | 5.37e-05     |
|    cost_values           | 0.0188       |
|    entropy               | -2.36        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0918       |
|    n_updates             | 5490         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.787        |
|    value_loss            | 0.369        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.5073433   |
| rollout/                 |              |
|    ep_len_mean           | 878          |
|    ep_rew_mean           | -320         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 266          |
|    total_timesteps       | 1128448      |
| train/                   |              |
|    approx_kl             | 0.0036200332 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00971      |
|    cost_value_loss       | 1.67e-05     |
|    cost_values           | 0.00981      |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.13         |
|    n_updates             | 5500         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.786        |
|    value_loss            | 0.359        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0954       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0954       |
| reward                   | -0.34997606  |
| rollout/                 |              |
|    ep_len_mean           | 871          |
|    ep_rew_mean           | -321         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 288          |
|    total_timesteps       | 1130496      |
| train/                   |              |
|    approx_kl             | 0.0021816376 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0297       |
|    cost_value_loss       | 5.77e-05     |
|    cost_values           | 0.0298       |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.798        |
|    n_updates             | 5510         |
|    policy_gradient_loss  | -0.000457    |
|    std                   | 0.785        |
|    value_loss            | 2.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.115        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.115        |
| reward                   | -0.24367324  |
| rollout/                 |              |
|    ep_len_mean           | 868          |
|    ep_rew_mean           | -320         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 311          |
|    total_timesteps       | 1132544      |
| train/                   |              |
|    approx_kl             | 0.0073926365 |
|    clip_fraction         | 0.0504       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0143       |
|    cost_value_loss       | 4.53e-05     |
|    cost_values           | 0.0141       |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.416        |
|    n_updates             | 5520         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 0.786        |
|    value_loss            | 0.763        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.283        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.283        |
| reward                   | -0.3115949   |
| rollout/                 |              |
|    ep_len_mean           | 866          |
|    ep_rew_mean           | -319         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 333          |
|    total_timesteps       | 1134592      |
| train/                   |              |
|    approx_kl             | 0.0027811879 |
|    clip_fraction         | 0.0253       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00587     |
|    cost_value_loss       | 3.63e-05     |
|    cost_values           | -0.00604     |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0856       |
|    n_updates             | 5530         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.785        |
|    value_loss            | 0.398        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.215        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.215        |
| reward                   | -0.4333731   |
| rollout/                 |              |
|    ep_len_mean           | 865          |
|    ep_rew_mean           | -321         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 356          |
|    total_timesteps       | 1136640      |
| train/                   |              |
|    approx_kl             | 0.0045915246 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0157      |
|    cost_value_loss       | 0.000128     |
|    cost_values           | -0.0139      |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.283        |
|    n_updates             | 5540         |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 0.785        |
|    value_loss            | 1.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.143       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.143       |
| reward                   | -0.284798   |
| rollout/                 |             |
|    ep_len_mean           | 869         |
|    ep_rew_mean           | -321        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 17          |
|    time_elapsed          | 378         |
|    total_timesteps       | 1138688     |
| train/                   |             |
|    approx_kl             | 0.002619999 |
|    clip_fraction         | 0.0313      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0147     |
|    cost_value_loss       | 2.63e-05    |
|    cost_values           | -0.0146     |
|    entropy               | -2.37       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.156       |
|    n_updates             | 5550        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.792       |
|    value_loss            | 0.663       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0452      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0452      |
| reward                   | -0.2678486  |
| rollout/                 |             |
|    ep_len_mean           | 875         |
|    ep_rew_mean           | -324        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 400         |
|    total_timesteps       | 1140736     |
| train/                   |             |
|    approx_kl             | 0.004084335 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0166     |
|    cost_value_loss       | 3.79e-05    |
|    cost_values           | -0.0171     |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.294       |
|    n_updates             | 5560        |
|    policy_gradient_loss  | -0.000281   |
|    std                   | 0.797       |
|    value_loss            | 0.896       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.37         |
| reward                   | -0.43791693  |
| rollout/                 |              |
|    ep_len_mean           | 871          |
|    ep_rew_mean           | -321         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 19           |
|    time_elapsed          | 423          |
|    total_timesteps       | 1142784      |
| train/                   |              |
|    approx_kl             | 0.0070297946 |
|    clip_fraction         | 0.0575       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00813      |
|    cost_value_loss       | 2.11e-05     |
|    cost_values           | 0.008        |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.228        |
|    n_updates             | 5570         |
|    policy_gradient_loss  | -0.00515     |
|    std                   | 0.795        |
|    value_loss            | 0.553        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.275        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.275        |
| reward                   | -0.31830236  |
| rollout/                 |              |
|    ep_len_mean           | 878          |
|    ep_rew_mean           | -324         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 20           |
|    time_elapsed          | 445          |
|    total_timesteps       | 1144832      |
| train/                   |              |
|    approx_kl             | 0.0036469838 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0125      |
|    cost_value_loss       | 6.9e-05      |
|    cost_values           | -0.0105      |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.377        |
|    n_updates             | 5580         |
|    policy_gradient_loss  | -0.00114     |
|    std                   | 0.794        |
|    value_loss            | 2.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.115       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.115       |
| reward                   | -0.5080212  |
| rollout/                 |             |
|    ep_len_mean           | 867         |
|    ep_rew_mean           | -320        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 21          |
|    time_elapsed          | 467         |
|    total_timesteps       | 1146880     |
| train/                   |             |
|    approx_kl             | 0.007874776 |
|    clip_fraction         | 0.0337      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0127     |
|    cost_value_loss       | 2.12e-05    |
|    cost_values           | -0.0129     |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.477       |
|    n_updates             | 5590        |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.794       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.129       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.129       |
| reward                   | -0.43288103 |
| rollout/                 |             |
|    ep_len_mean           | 864         |
|    ep_rew_mean           | -321        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 490         |
|    total_timesteps       | 1148928     |
| train/                   |             |
|    approx_kl             | 0.011262388 |
|    clip_fraction         | 0.0774      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00239     |
|    cost_value_loss       | 9.05e-05    |
|    cost_values           | 0.00263     |
|    entropy               | -2.36       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.707       |
|    n_updates             | 5600        |
|    policy_gradient_loss  | -0.000703   |
|    std                   | 0.79        |
|    value_loss            | 1.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.238       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.238       |
| reward                   | -0.47353396 |
| rollout/                 |             |
|    ep_len_mean           | 856         |
|    ep_rew_mean           | -316        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 512         |
|    total_timesteps       | 1150976     |
| train/                   |             |
|    approx_kl             | 0.005362577 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0099     |
|    cost_value_loss       | 3.78e-05    |
|    cost_values           | -0.0104     |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.189       |
|    n_updates             | 5610        |
|    policy_gradient_loss  | 0.000971    |
|    std                   | 0.79        |
|    value_loss            | 0.789       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.254       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.254       |
| reward                   | -0.40113676 |
| rollout/                 |             |
|    ep_len_mean           | 856         |
|    ep_rew_mean           | -315        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 534         |
|    total_timesteps       | 1153024     |
| train/                   |             |
|    approx_kl             | 0.008089813 |
|    clip_fraction         | 0.0617      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0189     |
|    cost_value_loss       | 3.83e-05    |
|    cost_values           | -0.0192     |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.649       |
|    n_updates             | 5620        |
|    policy_gradient_loss  | -0.00401    |
|    std                   | 0.789       |
|    value_loss            | 0.984       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.353       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.353       |
| reward                   | -0.42589536 |
| rollout/                 |             |
|    ep_len_mean           | 840         |
|    ep_rew_mean           | -310        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 25          |
|    time_elapsed          | 557         |
|    total_timesteps       | 1155072     |
| train/                   |             |
|    approx_kl             | 0.004444609 |
|    clip_fraction         | 0.041       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0196     |
|    cost_value_loss       | 3.26e-05    |
|    cost_values           | -0.02       |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0786      |
|    n_updates             | 5630        |
|    policy_gradient_loss  | -0.00324    |
|    std                   | 0.788       |
|    value_loss            | 0.391       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0259       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0259       |
| reward                   | -0.5304184   |
| rollout/                 |              |
|    ep_len_mean           | 838          |
|    ep_rew_mean           | -308         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 26           |
|    time_elapsed          | 579          |
|    total_timesteps       | 1157120      |
| train/                   |              |
|    approx_kl             | 0.0065402547 |
|    clip_fraction         | 0.0882       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0028       |
|    cost_value_loss       | 8.86e-05     |
|    cost_values           | 0.0039       |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.836        |
|    n_updates             | 5640         |
|    policy_gradient_loss  | -0.00374     |
|    std                   | 0.788        |
|    value_loss            | 2.94         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.41        |
| reward                   | -0.38313243 |
| rollout/                 |             |
|    ep_len_mean           | 835         |
|    ep_rew_mean           | -310        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 27          |
|    time_elapsed          | 601         |
|    total_timesteps       | 1159168     |
| train/                   |             |
|    approx_kl             | 0.007009571 |
|    clip_fraction         | 0.0328      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0101     |
|    cost_value_loss       | 8.99e-06    |
|    cost_values           | -0.0104     |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.277       |
|    n_updates             | 5650        |
|    policy_gradient_loss  | -0.00292    |
|    std                   | 0.787       |
|    value_loss            | 0.615       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.252        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.252        |
| reward                   | -0.33084255  |
| rollout/                 |              |
|    ep_len_mean           | 835          |
|    ep_rew_mean           | -312         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 28           |
|    time_elapsed          | 623          |
|    total_timesteps       | 1161216      |
| train/                   |              |
|    approx_kl             | 0.0062294914 |
|    clip_fraction         | 0.0563       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0111      |
|    cost_value_loss       | 2.84e-05     |
|    cost_values           | -0.0114      |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.138        |
|    n_updates             | 5660         |
|    policy_gradient_loss  | -0.00345     |
|    std                   | 0.783        |
|    value_loss            | 0.243        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.123        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.123        |
| reward                   | -0.32152376  |
| rollout/                 |              |
|    ep_len_mean           | 829          |
|    ep_rew_mean           | -308         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 29           |
|    time_elapsed          | 646          |
|    total_timesteps       | 1163264      |
| train/                   |              |
|    approx_kl             | 0.0040169978 |
|    clip_fraction         | 0.0473       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00489     |
|    cost_value_loss       | 5.63e-06     |
|    cost_values           | -0.00506     |
|    entropy               | -2.34        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00192      |
|    n_updates             | 5670         |
|    policy_gradient_loss  | -0.00427     |
|    std                   | 0.78         |
|    value_loss            | 0.0359       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.972        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.972        |
| reward                   | -0.46148607  |
| rollout/                 |              |
|    ep_len_mean           | 825          |
|    ep_rew_mean           | -307         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 30           |
|    time_elapsed          | 668          |
|    total_timesteps       | 1165312      |
| train/                   |              |
|    approx_kl             | 0.0063052964 |
|    clip_fraction         | 0.0871       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0139       |
|    cost_value_loss       | 5.2e-05      |
|    cost_values           | 0.0146       |
|    entropy               | -2.33        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.892        |
|    n_updates             | 5680         |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 0.779        |
|    value_loss            | 1.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.457        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.457        |
| reward                   | -0.2618644   |
| rollout/                 |              |
|    ep_len_mean           | 810          |
|    ep_rew_mean           | -304         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 31           |
|    time_elapsed          | 691          |
|    total_timesteps       | 1167360      |
| train/                   |              |
|    approx_kl             | 0.0041781184 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00456     |
|    cost_value_loss       | 0.000153     |
|    cost_values           | -0.00407     |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.955        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.01         |
|    n_updates             | 5690         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.778        |
|    value_loss            | 4.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.177        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.177        |
| reward                   | -0.37254643  |
| rollout/                 |              |
|    ep_len_mean           | 805          |
|    ep_rew_mean           | -302         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 32           |
|    time_elapsed          | 713          |
|    total_timesteps       | 1169408      |
| train/                   |              |
|    approx_kl             | 0.0046674283 |
|    clip_fraction         | 0.0713       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00787      |
|    cost_value_loss       | 6.93e-05     |
|    cost_values           | 0.00806      |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.404        |
|    n_updates             | 5700         |
|    policy_gradient_loss  | -0.005       |
|    std                   | 0.777        |
|    value_loss            | 1.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.269        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.269        |
| reward                   | -0.35545203  |
| rollout/                 |              |
|    ep_len_mean           | 795          |
|    ep_rew_mean           | -296         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 33           |
|    time_elapsed          | 735          |
|    total_timesteps       | 1171456      |
| train/                   |              |
|    approx_kl             | 0.0036548434 |
|    clip_fraction         | 0.0318       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0202      |
|    cost_value_loss       | 5.45e-05     |
|    cost_values           | -0.021       |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.425        |
|    n_updates             | 5710         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.776        |
|    value_loss            | 1.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0351       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0351       |
| reward                   | -0.5205934   |
| rollout/                 |              |
|    ep_len_mean           | 789          |
|    ep_rew_mean           | -292         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 34           |
|    time_elapsed          | 757          |
|    total_timesteps       | 1173504      |
| train/                   |              |
|    approx_kl             | 0.0030794423 |
|    clip_fraction         | 0.0193       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00996     |
|    cost_value_loss       | 8.15e-05     |
|    cost_values           | -0.0105      |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.242        |
|    n_updates             | 5720         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.776        |
|    value_loss            | 1.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0217      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0217      |
| reward                   | -0.169778   |
| rollout/                 |             |
|    ep_len_mean           | 805         |
|    ep_rew_mean           | -301        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 779         |
|    total_timesteps       | 1175552     |
| train/                   |             |
|    approx_kl             | 0.004708824 |
|    clip_fraction         | 0.0215      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0257     |
|    cost_value_loss       | 0.000278    |
|    cost_values           | -0.0263     |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.659       |
|    n_updates             | 5730        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.775       |
|    value_loss            | 3.93        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.31         |
| reward                   | -0.4499338   |
| rollout/                 |              |
|    ep_len_mean           | 798          |
|    ep_rew_mean           | -298         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 801          |
|    total_timesteps       | 1177600      |
| train/                   |              |
|    approx_kl             | 0.0060854936 |
|    clip_fraction         | 0.0565       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0289       |
|    cost_value_loss       | 6.2e-05      |
|    cost_values           | 0.0291       |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0191       |
|    n_updates             | 5740         |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.777        |
|    value_loss            | 0.0812       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.504       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.504       |
| reward                   | -0.48149842 |
| rollout/                 |             |
|    ep_len_mean           | 798         |
|    ep_rew_mean           | -298        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 823         |
|    total_timesteps       | 1179648     |
| train/                   |             |
|    approx_kl             | 0.004192524 |
|    clip_fraction         | 0.049       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0124     |
|    cost_value_loss       | 0.000237    |
|    cost_values           | -0.00957    |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.513       |
|    n_updates             | 5750        |
|    policy_gradient_loss  | -0.00255    |
|    std                   | 0.776       |
|    value_loss            | 1.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.468       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.468       |
| reward                   | -0.39460054 |
| rollout/                 |             |
|    ep_len_mean           | 793         |
|    ep_rew_mean           | -300        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 845         |
|    total_timesteps       | 1181696     |
| train/                   |             |
|    approx_kl             | 0.007980386 |
|    clip_fraction         | 0.0914      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.013       |
|    cost_value_loss       | 2.07e-05    |
|    cost_values           | 0.0125      |
|    entropy               | -2.32       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00668     |
|    n_updates             | 5760        |
|    policy_gradient_loss  | -0.00274    |
|    std                   | 0.773       |
|    value_loss            | 0.0448      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.164        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.164        |
| reward                   | -0.19171841  |
| rollout/                 |              |
|    ep_len_mean           | 789          |
|    ep_rew_mean           | -299         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 867          |
|    total_timesteps       | 1183744      |
| train/                   |              |
|    approx_kl             | 0.0044107046 |
|    clip_fraction         | 0.0722       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00963      |
|    cost_value_loss       | 4.02e-05     |
|    cost_values           | 0.00938      |
|    entropy               | -2.33        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0635       |
|    n_updates             | 5770         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.776        |
|    value_loss            | 0.682        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.469        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.469        |
| reward                   | -0.40191     |
| rollout/                 |              |
|    ep_len_mean           | 747          |
|    ep_rew_mean           | -283         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 889          |
|    total_timesteps       | 1185792      |
| train/                   |              |
|    approx_kl             | 0.0069698514 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.018       |
|    cost_value_loss       | 2.96e-05     |
|    cost_values           | -0.018       |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.36         |
|    n_updates             | 5780         |
|    policy_gradient_loss  | -0.000811    |
|    std                   | 0.777        |
|    value_loss            | 0.746        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.633        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.633        |
| reward                   | -0.41735694  |
| rollout/                 |              |
|    ep_len_mean           | 747          |
|    ep_rew_mean           | -284         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 911          |
|    total_timesteps       | 1187840      |
| train/                   |              |
|    approx_kl             | 0.0061218264 |
|    clip_fraction         | 0.0559       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0171      |
|    cost_value_loss       | 7.15e-05     |
|    cost_values           | -0.0172      |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.951        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.15         |
|    n_updates             | 5790         |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 0.777        |
|    value_loss            | 2.83         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.348       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.348       |
| reward                   | -0.43657625 |
| rollout/                 |             |
|    ep_len_mean           | 734         |
|    ep_rew_mean           | -276        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 933         |
|    total_timesteps       | 1189888     |
| train/                   |             |
|    approx_kl             | 0.00641582  |
|    clip_fraction         | 0.0821      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.011      |
|    cost_value_loss       | 1.93e-05    |
|    cost_values           | -0.0115     |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.123       |
|    n_updates             | 5800        |
|    policy_gradient_loss  | -0.00715    |
|    std                   | 0.777       |
|    value_loss            | 0.423       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0557       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0557       |
| reward                   | -0.517671    |
| rollout/                 |              |
|    ep_len_mean           | 730          |
|    ep_rew_mean           | -274         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 955          |
|    total_timesteps       | 1191936      |
| train/                   |              |
|    approx_kl             | 0.0046525924 |
|    clip_fraction         | 0.0253       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00495      |
|    cost_value_loss       | 2.66e-05     |
|    cost_values           | 0.00529      |
|    entropy               | -2.33        |
|    entropy_loss          | -2.33        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.42         |
|    n_updates             | 5810         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.775        |
|    value_loss            | 0.898        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0284       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0284       |
| reward                   | -0.5140197   |
| rollout/                 |              |
|    ep_len_mean           | 734          |
|    ep_rew_mean           | -276         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 977          |
|    total_timesteps       | 1193984      |
| train/                   |              |
|    approx_kl             | 0.0052885637 |
|    clip_fraction         | 0.0398       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00863     |
|    cost_value_loss       | 8.78e-05     |
|    cost_values           | -0.00837     |
|    entropy               | -2.32        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.259        |
|    n_updates             | 5820         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.773        |
|    value_loss            | 0.561        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.119        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.119        |
| reward                   | -0.539628    |
| rollout/                 |              |
|    ep_len_mean           | 734          |
|    ep_rew_mean           | -279         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 999          |
|    total_timesteps       | 1196032      |
| train/                   |              |
|    approx_kl             | 0.0062383087 |
|    clip_fraction         | 0.0242       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0151      |
|    cost_value_loss       | 5.99e-05     |
|    cost_values           | -0.0163      |
|    entropy               | -2.31        |
|    entropy_loss          | -2.32        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.142        |
|    n_updates             | 5830         |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.77         |
|    value_loss            | 0.495        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.706       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.706       |
| reward                   | -0.4172215  |
| rollout/                 |             |
|    ep_len_mean           | 731         |
|    ep_rew_mean           | -278        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1022        |
|    total_timesteps       | 1198080     |
| train/                   |             |
|    approx_kl             | 0.006180379 |
|    clip_fraction         | 0.0398      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00312    |
|    cost_value_loss       | 3.06e-06    |
|    cost_values           | -0.00314    |
|    entropy               | -2.29       |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0118      |
|    n_updates             | 5840        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.761       |
|    value_loss            | 0.0659      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.348        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.348        |
| reward                   | -0.2842288   |
| rollout/                 |              |
|    ep_len_mean           | 731          |
|    ep_rew_mean           | -278         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1044         |
|    total_timesteps       | 1200128      |
| train/                   |              |
|    approx_kl             | 0.0064355116 |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0053      |
|    cost_value_loss       | 2.73e-05     |
|    cost_values           | -0.00516     |
|    entropy               | -2.27        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.189        |
|    n_updates             | 5850         |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 0.754        |
|    value_loss            | 0.493        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.191       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.191       |
| reward                   | -0.505556   |
| rollout/                 |             |
|    ep_len_mean           | 717         |
|    ep_rew_mean           | -273        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1066        |
|    total_timesteps       | 1202176     |
| train/                   |             |
|    approx_kl             | 0.007376811 |
|    clip_fraction         | 0.0317      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00339    |
|    cost_value_loss       | 5.17e-05    |
|    cost_values           | -0.00335    |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.084       |
|    n_updates             | 5860        |
|    policy_gradient_loss  | -0.00134    |
|    std                   | 0.753       |
|    value_loss            | 0.785       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0813       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0813       |
| reward                   | -0.4431024   |
| rollout/                 |              |
|    ep_len_mean           | 713          |
|    ep_rew_mean           | -274         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 1204224      |
| train/                   |              |
|    approx_kl             | 0.0040772986 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00439     |
|    cost_value_loss       | 3.8e-05      |
|    cost_values           | -0.0043      |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.27         |
|    n_updates             | 5870         |
|    policy_gradient_loss  | -0.000537    |
|    std                   | 0.753        |
|    value_loss            | 2.18         |
-------------------------------------------
-----------------------------------
| avg_speed          | 0.25       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.25       |
| reward             | -0.3109166 |
| rollout/           |            |
|    ep_len_mean     | 711        |
|    ep_rew_mean     | -275       |
| time/              |            |
|    fps             | 93         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 1206272    |
-----------------------------------
------------------------------------------
| avg_speed                | 0.227       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.227       |
| reward                   | -0.3857129  |
| rollout/                 |             |
|    ep_len_mean           | 716         |
|    ep_rew_mean           | -274        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 1208320     |
| train/                   |             |
|    approx_kl             | 0.006295869 |
|    clip_fraction         | 0.0772      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00978    |
|    cost_value_loss       | 1.54e-05    |
|    cost_values           | -0.00976    |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.193       |
|    n_updates             | 5890        |
|    policy_gradient_loss  | -0.00362    |
|    std                   | 0.751       |
|    value_loss            | 0.434       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.489       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.489       |
| reward                   | -0.2664871  |
| rollout/                 |             |
|    ep_len_mean           | 700         |
|    ep_rew_mean           | -268        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 1210368     |
| train/                   |             |
|    approx_kl             | 0.004768617 |
|    clip_fraction         | 0.0597      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000137    |
|    cost_value_loss       | 4.6e-05     |
|    cost_values           | -9.2e-06    |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.363       |
|    n_updates             | 5900        |
|    policy_gradient_loss  | -0.0052     |
|    std                   | 0.751       |
|    value_loss            | 2.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.285       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.285       |
| reward                   | -0.32087922 |
| rollout/                 |             |
|    ep_len_mean           | 695         |
|    ep_rew_mean           | -268        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 4           |
|    time_elapsed          | 88          |
|    total_timesteps       | 1212416     |
| train/                   |             |
|    approx_kl             | 0.004225096 |
|    clip_fraction         | 0.0194      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00363    |
|    cost_value_loss       | 4.11e-05    |
|    cost_values           | -0.00378    |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.469       |
|    n_updates             | 5910        |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.751       |
|    value_loss            | 2           |
------------------------------------------
------------------------------------------
| avg_speed                | 0.157       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.157       |
| reward                   | -0.3441574  |
| rollout/                 |             |
|    ep_len_mean           | 698         |
|    ep_rew_mean           | -268        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 111         |
|    total_timesteps       | 1214464     |
| train/                   |             |
|    approx_kl             | 0.005030549 |
|    clip_fraction         | 0.0577      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00414    |
|    cost_value_loss       | 1.31e-05    |
|    cost_values           | -0.00418    |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.122       |
|    n_updates             | 5920        |
|    policy_gradient_loss  | -0.00382    |
|    std                   | 0.751       |
|    value_loss            | 0.263       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0462       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0462       |
| reward                   | -0.30576724  |
| rollout/                 |              |
|    ep_len_mean           | 709          |
|    ep_rew_mean           | -273         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 6            |
|    time_elapsed          | 133          |
|    total_timesteps       | 1216512      |
| train/                   |              |
|    approx_kl             | 0.0040444355 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00871     |
|    cost_value_loss       | 8.16e-06     |
|    cost_values           | -0.00933     |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.961        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.06         |
|    n_updates             | 5930         |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 0.751        |
|    value_loss            | 0.313        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0975       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0975       |
| reward                   | -0.3518268   |
| rollout/                 |              |
|    ep_len_mean           | 718          |
|    ep_rew_mean           | -275         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 7            |
|    time_elapsed          | 155          |
|    total_timesteps       | 1218560      |
| train/                   |              |
|    approx_kl             | 0.0073198713 |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000883    |
|    cost_value_loss       | 5.46e-05     |
|    cost_values           | -0.00126     |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.681        |
|    n_updates             | 5940         |
|    policy_gradient_loss  | -0.00446     |
|    std                   | 0.752        |
|    value_loss            | 1.7          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.302       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.302       |
| reward                   | -0.28579137 |
| rollout/                 |             |
|    ep_len_mean           | 721         |
|    ep_rew_mean           | -276        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 8           |
|    time_elapsed          | 178         |
|    total_timesteps       | 1220608     |
| train/                   |             |
|    approx_kl             | 0.007685914 |
|    clip_fraction         | 0.0408      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0145     |
|    cost_value_loss       | 5.87e-06    |
|    cost_values           | -0.0148     |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0451      |
|    n_updates             | 5950        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.753       |
|    value_loss            | 0.164       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00207      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00207      |
| reward                   | -0.5070277   |
| rollout/                 |              |
|    ep_len_mean           | 726          |
|    ep_rew_mean           | -277         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 200          |
|    total_timesteps       | 1222656      |
| train/                   |              |
|    approx_kl             | 0.0027098414 |
|    clip_fraction         | 0.00981      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00515      |
|    cost_value_loss       | 8.21e-06     |
|    cost_values           | 0.00498      |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00366      |
|    n_updates             | 5960         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.754        |
|    value_loss            | 0.073        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.283       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.283       |
| reward                   | -0.4920728  |
| rollout/                 |             |
|    ep_len_mean           | 717         |
|    ep_rew_mean           | -273        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 222         |
|    total_timesteps       | 1224704     |
| train/                   |             |
|    approx_kl             | 0.007392834 |
|    clip_fraction         | 0.0438      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.035       |
|    cost_value_loss       | 2.7e-05     |
|    cost_values           | 0.0356      |
|    entropy               | -2.26       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.162       |
|    n_updates             | 5970        |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.751       |
|    value_loss            | 0.414       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.246        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.246        |
| reward                   | -0.29030475  |
| rollout/                 |              |
|    ep_len_mean           | 723          |
|    ep_rew_mean           | -277         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 244          |
|    total_timesteps       | 1226752      |
| train/                   |              |
|    approx_kl             | 0.0075414535 |
|    clip_fraction         | 0.0595       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0267       |
|    cost_value_loss       | 5.49e-05     |
|    cost_values           | 0.0276       |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.236        |
|    n_updates             | 5980         |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 0.751        |
|    value_loss            | 0.755        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0815      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0815      |
| reward                   | -0.30476302 |
| rollout/                 |             |
|    ep_len_mean           | 728         |
|    ep_rew_mean           | -276        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 266         |
|    total_timesteps       | 1228800     |
| train/                   |             |
|    approx_kl             | 0.005827517 |
|    clip_fraction         | 0.0494      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00454     |
|    cost_value_loss       | 1.6e-05     |
|    cost_values           | 0.00468     |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0997      |
|    n_updates             | 5990        |
|    policy_gradient_loss  | -0.00389    |
|    std                   | 0.752       |
|    value_loss            | 0.546       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.814       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.814       |
| reward                   | -0.3026366  |
| rollout/                 |             |
|    ep_len_mean           | 722         |
|    ep_rew_mean           | -272        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 288         |
|    total_timesteps       | 1230848     |
| train/                   |             |
|    approx_kl             | 0.008611714 |
|    clip_fraction         | 0.0462      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00162    |
|    cost_value_loss       | 2.9e-05     |
|    cost_values           | -0.00186    |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.129       |
|    n_updates             | 6000        |
|    policy_gradient_loss  | -0.00271    |
|    std                   | 0.751       |
|    value_loss            | 0.5         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.46656108  |
| rollout/                 |              |
|    ep_len_mean           | 719          |
|    ep_rew_mean           | -271         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 310          |
|    total_timesteps       | 1232896      |
| train/                   |              |
|    approx_kl             | 0.0039776894 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00501      |
|    cost_value_loss       | 3.77e-05     |
|    cost_values           | 0.00524      |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.337        |
|    n_updates             | 6010         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.751        |
|    value_loss            | 1.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.06        |
| reward                   | -0.19582927 |
| rollout/                 |             |
|    ep_len_mean           | 719         |
|    ep_rew_mean           | -270        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 332         |
|    total_timesteps       | 1234944     |
| train/                   |             |
|    approx_kl             | 0.004400638 |
|    clip_fraction         | 0.0397      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0251      |
|    cost_value_loss       | 5.78e-05    |
|    cost_values           | 0.0257      |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.215       |
|    n_updates             | 6020        |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.751       |
|    value_loss            | 0.872       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.436       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.436       |
| reward                   | -0.21414009 |
| rollout/                 |             |
|    ep_len_mean           | 715         |
|    ep_rew_mean           | -267        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 354         |
|    total_timesteps       | 1236992     |
| train/                   |             |
|    approx_kl             | 0.010485587 |
|    clip_fraction         | 0.0838      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00441     |
|    cost_value_loss       | 4.58e-05    |
|    cost_values           | 0.00452     |
|    entropy               | -2.27       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.264       |
|    n_updates             | 6030        |
|    policy_gradient_loss  | -0.0043     |
|    std                   | 0.754       |
|    value_loss            | 0.759       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.137        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.137        |
| reward                   | -0.23520787  |
| rollout/                 |              |
|    ep_len_mean           | 720          |
|    ep_rew_mean           | -268         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 376          |
|    total_timesteps       | 1239040      |
| train/                   |              |
|    approx_kl             | 0.0057296148 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00749      |
|    cost_value_loss       | 2.3e-05      |
|    cost_values           | 0.00732      |
|    entropy               | -2.26        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.535        |
|    n_updates             | 6040         |
|    policy_gradient_loss  | -0.00167     |
|    std                   | 0.751        |
|    value_loss            | 1.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0948       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0948       |
| reward                   | -0.45588958  |
| rollout/                 |              |
|    ep_len_mean           | 723          |
|    ep_rew_mean           | -268         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 398          |
|    total_timesteps       | 1241088      |
| train/                   |              |
|    approx_kl             | 0.0072120694 |
|    clip_fraction         | 0.0566       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0105       |
|    cost_value_loss       | 3.15e-05     |
|    cost_values           | 0.0104       |
|    entropy               | -2.25        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.359        |
|    n_updates             | 6050         |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.748        |
|    value_loss            | 0.688        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.352        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.352        |
| reward                   | -0.3561628   |
| rollout/                 |              |
|    ep_len_mean           | 719          |
|    ep_rew_mean           | -267         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 421          |
|    total_timesteps       | 1243136      |
| train/                   |              |
|    approx_kl             | 0.0042870827 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0109      |
|    cost_value_loss       | 2.81e-05     |
|    cost_values           | -0.0107      |
|    entropy               | -2.25        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.183        |
|    n_updates             | 6060         |
|    policy_gradient_loss  | -0.00172     |
|    std                   | 0.748        |
|    value_loss            | 0.561        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0485       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0485       |
| reward                   | -0.46590135  |
| rollout/                 |              |
|    ep_len_mean           | 725          |
|    ep_rew_mean           | -269         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 443          |
|    total_timesteps       | 1245184      |
| train/                   |              |
|    approx_kl             | 0.0057850154 |
|    clip_fraction         | 0.0497       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0205      |
|    cost_value_loss       | 8.37e-06     |
|    cost_values           | -0.0204      |
|    entropy               | -2.26        |
|    entropy_loss          | -2.25        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.274        |
|    n_updates             | 6070         |
|    policy_gradient_loss  | -0.000864    |
|    std                   | 0.749        |
|    value_loss            | 0.541        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.48        |
| reward                   | -0.43514556 |
| rollout/                 |             |
|    ep_len_mean           | 720         |
|    ep_rew_mean           | -267        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 465         |
|    total_timesteps       | 1247232     |
| train/                   |             |
|    approx_kl             | 0.002121827 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00364    |
|    cost_value_loss       | 7.18e-06    |
|    cost_values           | -0.00382    |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0438      |
|    n_updates             | 6080        |
|    policy_gradient_loss  | -0.00252    |
|    std                   | 0.75        |
|    value_loss            | 0.345       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.481        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.481        |
| reward                   | -0.372832    |
| rollout/                 |              |
|    ep_len_mean           | 727          |
|    ep_rew_mean           | -268         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 487          |
|    total_timesteps       | 1249280      |
| train/                   |              |
|    approx_kl             | 0.0043989024 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00494      |
|    cost_value_loss       | 6.13e-05     |
|    cost_values           | 0.00482      |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.441        |
|    n_updates             | 6090         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.75         |
|    value_loss            | 1.37         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.186       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.186       |
| reward                   | -0.44847053 |
| rollout/                 |             |
|    ep_len_mean           | 718         |
|    ep_rew_mean           | -263        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 509         |
|    total_timesteps       | 1251328     |
| train/                   |             |
|    approx_kl             | 0.003045458 |
|    clip_fraction         | 0.031       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0183     |
|    cost_value_loss       | 3.75e-05    |
|    cost_values           | -0.0186     |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.249       |
|    n_updates             | 6100        |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.75        |
|    value_loss            | 0.804       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.241        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.241        |
| reward                   | -0.4881158   |
| rollout/                 |              |
|    ep_len_mean           | 717          |
|    ep_rew_mean           | -262         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 532          |
|    total_timesteps       | 1253376      |
| train/                   |              |
|    approx_kl             | 0.0028734682 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00713      |
|    cost_value_loss       | 3.02e-05     |
|    cost_values           | 0.00717      |
|    entropy               | -2.26        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.135        |
|    n_updates             | 6110         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.75         |
|    value_loss            | 0.534        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.128       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.128       |
| reward                   | -0.40117696 |
| rollout/                 |             |
|    ep_len_mean           | 725         |
|    ep_rew_mean           | -268        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 554         |
|    total_timesteps       | 1255424     |
| train/                   |             |
|    approx_kl             | 0.006331947 |
|    clip_fraction         | 0.0481      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0102      |
|    cost_value_loss       | 4.42e-06    |
|    cost_values           | 0.0102      |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.287       |
|    n_updates             | 6120        |
|    policy_gradient_loss  | 0.000397    |
|    std                   | 0.753       |
|    value_loss            | 0.535       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0138       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0138       |
| reward                   | -0.43241626  |
| rollout/                 |              |
|    ep_len_mean           | 722          |
|    ep_rew_mean           | -270         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 576          |
|    total_timesteps       | 1257472      |
| train/                   |              |
|    approx_kl             | 0.0042724474 |
|    clip_fraction         | 0.0486       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00247      |
|    cost_value_loss       | 5.79e-06     |
|    cost_values           | 0.00247      |
|    entropy               | -2.25        |
|    entropy_loss          | -2.26        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00687      |
|    n_updates             | 6130         |
|    policy_gradient_loss  | -0.00367     |
|    std                   | 0.749        |
|    value_loss            | 0.0724       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.56        |
| reward                   | -0.31088287 |
| rollout/                 |             |
|    ep_len_mean           | 743         |
|    ep_rew_mean           | -278        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 599         |
|    total_timesteps       | 1259520     |
| train/                   |             |
|    approx_kl             | 0.006624341 |
|    clip_fraction         | 0.0468      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00525     |
|    cost_value_loss       | 8.95e-06    |
|    cost_values           | 0.00527     |
|    entropy               | -2.24       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0287      |
|    n_updates             | 6140        |
|    policy_gradient_loss  | -0.00143    |
|    std                   | 0.744       |
|    value_loss            | 0.251       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.117       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.117       |
| reward                   | -0.22424473 |
| rollout/                 |             |
|    ep_len_mean           | 736         |
|    ep_rew_mean           | -274        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 621         |
|    total_timesteps       | 1261568     |
| train/                   |             |
|    approx_kl             | 0.007780874 |
|    clip_fraction         | 0.0821      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00319     |
|    cost_value_loss       | 1.9e-05     |
|    cost_values           | 0.0031      |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.103       |
|    n_updates             | 6150        |
|    policy_gradient_loss  | -0.00735    |
|    std                   | 0.742       |
|    value_loss            | 0.291       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.311        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.311        |
| reward                   | -0.438966    |
| rollout/                 |              |
|    ep_len_mean           | 733          |
|    ep_rew_mean           | -272         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 643          |
|    total_timesteps       | 1263616      |
| train/                   |              |
|    approx_kl             | 0.0073411055 |
|    clip_fraction         | 0.0903       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0044       |
|    cost_value_loss       | 2.66e-05     |
|    cost_values           | 0.00444      |
|    entropy               | -2.23        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.465        |
|    n_updates             | 6160         |
|    policy_gradient_loss  | -0.00483     |
|    std                   | 0.74         |
|    value_loss            | 1.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.248        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.248        |
| reward                   | -0.17886153  |
| rollout/                 |              |
|    ep_len_mean           | 735          |
|    ep_rew_mean           | -274         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 665          |
|    total_timesteps       | 1265664      |
| train/                   |              |
|    approx_kl             | 0.0073282514 |
|    clip_fraction         | 0.0772       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00482      |
|    cost_value_loss       | 8.96e-06     |
|    cost_values           | 0.00477      |
|    entropy               | -2.22        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.281        |
|    n_updates             | 6170         |
|    policy_gradient_loss  | -0.00438     |
|    std                   | 0.736        |
|    value_loss            | 0.586        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.445        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.445        |
| reward                   | -0.5078702   |
| rollout/                 |              |
|    ep_len_mean           | 727          |
|    ep_rew_mean           | -270         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 687          |
|    total_timesteps       | 1267712      |
| train/                   |              |
|    approx_kl             | 0.0076225577 |
|    clip_fraction         | 0.0539       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000841     |
|    cost_value_loss       | 1.31e-05     |
|    cost_values           | 0.000887     |
|    entropy               | -2.21        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0766       |
|    n_updates             | 6180         |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 0.733        |
|    value_loss            | 0.228        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.274        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.274        |
| reward                   | -0.2502204   |
| rollout/                 |              |
|    ep_len_mean           | 727          |
|    ep_rew_mean           | -270         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 710          |
|    total_timesteps       | 1269760      |
| train/                   |              |
|    approx_kl             | 0.0020570266 |
|    clip_fraction         | 0.00752      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000125     |
|    cost_value_loss       | 4.61e-05     |
|    cost_values           | 0.00119      |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.677        |
|    n_updates             | 6190         |
|    policy_gradient_loss  | -0.000808    |
|    std                   | 0.733        |
|    value_loss            | 3.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0985      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0985      |
| reward                   | -0.31684542 |
| rollout/                 |             |
|    ep_len_mean           | 734         |
|    ep_rew_mean           | -275        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 732         |
|    total_timesteps       | 1271808     |
| train/                   |             |
|    approx_kl             | 0.011655773 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0047      |
|    cost_value_loss       | 7.8e-06     |
|    cost_values           | 0.00477     |
|    entropy               | -2.2        |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00988     |
|    n_updates             | 6200        |
|    policy_gradient_loss  | -0.00469    |
|    std                   | 0.728       |
|    value_loss            | 0.0525      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0857       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0857       |
| reward                   | -0.46114153  |
| rollout/                 |              |
|    ep_len_mean           | 728          |
|    ep_rew_mean           | -272         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 754          |
|    total_timesteps       | 1273856      |
| train/                   |              |
|    approx_kl             | 0.0042161457 |
|    clip_fraction         | 0.125        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.011       |
|    cost_value_loss       | 5.45e-05     |
|    cost_values           | -0.011       |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.229        |
|    n_updates             | 6210         |
|    policy_gradient_loss  | 0.00293      |
|    std                   | 0.726        |
|    value_loss            | 1.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.341        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.341        |
| reward                   | -0.3999899   |
| rollout/                 |              |
|    ep_len_mean           | 726          |
|    ep_rew_mean           | -271         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 777          |
|    total_timesteps       | 1275904      |
| train/                   |              |
|    approx_kl             | 0.0032473085 |
|    clip_fraction         | 0.059        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00218     |
|    cost_value_loss       | 1.47e-05     |
|    cost_values           | -0.00227     |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.298        |
|    n_updates             | 6220         |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.726        |
|    value_loss            | 1.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.628       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.628       |
| reward                   | -0.25079483 |
| rollout/                 |             |
|    ep_len_mean           | 722         |
|    ep_rew_mean           | -267        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 799         |
|    total_timesteps       | 1277952     |
| train/                   |             |
|    approx_kl             | 0.003045398 |
|    clip_fraction         | 0.0241      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00764     |
|    cost_value_loss       | 6.45e-06    |
|    cost_values           | 0.00766     |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.532       |
|    n_updates             | 6230        |
|    policy_gradient_loss  | -0.000983   |
|    std                   | 0.726       |
|    value_loss            | 1.57        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.677        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.677        |
| reward                   | -0.28957444  |
| rollout/                 |              |
|    ep_len_mean           | 716          |
|    ep_rew_mean           | -266         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 821          |
|    total_timesteps       | 1280000      |
| train/                   |              |
|    approx_kl             | 0.0076498035 |
|    clip_fraction         | 0.0275       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00317      |
|    cost_value_loss       | 3.41e-05     |
|    cost_values           | 0.00387      |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.592        |
|    n_updates             | 6240         |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.726        |
|    value_loss            | 2.25         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.332        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.332        |
| reward                   | -0.29443035  |
| rollout/                 |              |
|    ep_len_mean           | 728          |
|    ep_rew_mean           | -271         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 844          |
|    total_timesteps       | 1282048      |
| train/                   |              |
|    approx_kl             | 0.0034186305 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000291    |
|    cost_value_loss       | 5.22e-05     |
|    cost_values           | 6.74e-05     |
|    entropy               | -2.19        |
|    entropy_loss          | -2.19        |
|    explained_variance    | 0.972        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.637        |
|    n_updates             | 6250         |
|    policy_gradient_loss  | -0.000887    |
|    std                   | 0.727        |
|    value_loss            | 2.26         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.169        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.169        |
| reward                   | -0.50846326  |
| rollout/                 |              |
|    ep_len_mean           | 725          |
|    ep_rew_mean           | -270         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 866          |
|    total_timesteps       | 1284096      |
| train/                   |              |
|    approx_kl             | 0.0032074093 |
|    clip_fraction         | 0.00366      |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00218     |
|    cost_value_loss       | 2.34e-05     |
|    cost_values           | -0.00226     |
|    entropy               | -2.19        |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.571        |
|    n_updates             | 6260         |
|    policy_gradient_loss  | -0.000578    |
|    std                   | 0.726        |
|    value_loss            | 2.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.202       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.202       |
| reward                   | -0.33202627 |
| rollout/                 |             |
|    ep_len_mean           | 725         |
|    ep_rew_mean           | -272        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 888         |
|    total_timesteps       | 1286144     |
| train/                   |             |
|    approx_kl             | 0.011027785 |
|    clip_fraction         | 0.0757      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0144      |
|    cost_value_loss       | 1.06e-05    |
|    cost_values           | 0.0143      |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.249       |
|    n_updates             | 6270        |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 0.724       |
|    value_loss            | 1.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0156      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0156      |
| reward                   | -0.46514508 |
| rollout/                 |             |
|    ep_len_mean           | 728         |
|    ep_rew_mean           | -274        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 910         |
|    total_timesteps       | 1288192     |
| train/                   |             |
|    approx_kl             | 0.008559462 |
|    clip_fraction         | 0.0779      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000994   |
|    cost_value_loss       | 6.79e-05    |
|    cost_values           | -0.00062    |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00953     |
|    n_updates             | 6280        |
|    policy_gradient_loss  | -0.00595    |
|    std                   | 0.723       |
|    value_loss            | 0.0723      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.323       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.323       |
| reward                   | -0.17462084 |
| rollout/                 |             |
|    ep_len_mean           | 728         |
|    ep_rew_mean           | -277        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 933         |
|    total_timesteps       | 1290240     |
| train/                   |             |
|    approx_kl             | 0.010969356 |
|    clip_fraction         | 0.0454      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0115     |
|    cost_value_loss       | 5.2e-05     |
|    cost_values           | -0.0115     |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00142     |
|    n_updates             | 6290        |
|    policy_gradient_loss  | -0.00224    |
|    std                   | 0.725       |
|    value_loss            | 0.0323      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0222      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0222      |
| reward                   | -0.5082051  |
| rollout/                 |             |
|    ep_len_mean           | 723         |
|    ep_rew_mean           | -274        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 955         |
|    total_timesteps       | 1292288     |
| train/                   |             |
|    approx_kl             | 0.009729677 |
|    clip_fraction         | 0.0642      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0102     |
|    cost_value_loss       | 2.9e-05     |
|    cost_values           | -0.0108     |
|    entropy               | -2.21       |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00668     |
|    n_updates             | 6300        |
|    policy_gradient_loss  | -0.00389    |
|    std                   | 0.733       |
|    value_loss            | 0.0416      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.219        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.219        |
| reward                   | -0.5367421   |
| rollout/                 |              |
|    ep_len_mean           | 727          |
|    ep_rew_mean           | -278         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 977          |
|    total_timesteps       | 1294336      |
| train/                   |              |
|    approx_kl             | 0.0077839196 |
|    clip_fraction         | 0.0726       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00899     |
|    cost_value_loss       | 3.37e-05     |
|    cost_values           | -0.0092      |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0924       |
|    n_updates             | 6310         |
|    policy_gradient_loss  | -0.0033      |
|    std                   | 0.737        |
|    value_loss            | 0.301        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0822      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0822      |
| reward                   | -0.46747094 |
| rollout/                 |             |
|    ep_len_mean           | 722         |
|    ep_rew_mean           | -277        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 1000        |
|    total_timesteps       | 1296384     |
| train/                   |             |
|    approx_kl             | 0.008358059 |
|    clip_fraction         | 0.0773      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00898    |
|    cost_value_loss       | 2.42e-06    |
|    cost_values           | -0.00933    |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00515     |
|    n_updates             | 6320        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.735       |
|    value_loss            | 0.0228      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.142        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.142        |
| reward                   | -0.3873477   |
| rollout/                 |              |
|    ep_len_mean           | 722          |
|    ep_rew_mean           | -278         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1022         |
|    total_timesteps       | 1298432      |
| train/                   |              |
|    approx_kl             | 0.0082863495 |
|    clip_fraction         | 0.0832       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00511     |
|    cost_value_loss       | 6.11e-06     |
|    cost_values           | -0.00512     |
|    entropy               | -2.21        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.295        |
|    n_updates             | 6330         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.734        |
|    value_loss            | 0.687        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0788       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0788       |
| reward                   | -0.46162856  |
| rollout/                 |              |
|    ep_len_mean           | 707          |
|    ep_rew_mean           | -277         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1045         |
|    total_timesteps       | 1300480      |
| train/                   |              |
|    approx_kl             | 0.0058553065 |
|    clip_fraction         | 0.0588       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00882     |
|    cost_value_loss       | 1.98e-06     |
|    cost_values           | -0.00892     |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00513      |
|    n_updates             | 6340         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 0.733        |
|    value_loss            | 0.0384       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.253       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.253       |
| reward                   | -0.5226885  |
| rollout/                 |             |
|    ep_len_mean           | 710         |
|    ep_rew_mean           | -279        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1067        |
|    total_timesteps       | 1302528     |
| train/                   |             |
|    approx_kl             | 0.009053359 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00528    |
|    cost_value_loss       | 2.97e-06    |
|    cost_values           | -0.00527    |
|    entropy               | -2.2        |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0633      |
|    n_updates             | 6350        |
|    policy_gradient_loss  | -0.00245    |
|    std                   | 0.729       |
|    value_loss            | 0.196       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.18         |
| reward                   | -0.26944792  |
| rollout/                 |              |
|    ep_len_mean           | 709          |
|    ep_rew_mean           | -279         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 1304576      |
| train/                   |              |
|    approx_kl             | 0.0046338215 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00388      |
|    cost_value_loss       | 1.26e-05     |
|    cost_values           | 0.00383      |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.106        |
|    n_updates             | 6360         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.729        |
|    value_loss            | 0.567        |
-------------------------------------------
------------------------------------
| avg_speed          | 0.256       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.256       |
| reward             | -0.48722556 |
| rollout/           |             |
|    ep_len_mean     | 717         |
|    ep_rew_mean     | -281        |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 1306624     |
------------------------------------
------------------------------------------
| avg_speed                | 0.116       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.116       |
| reward                   | -0.32792345 |
| rollout/                 |             |
|    ep_len_mean           | 720         |
|    ep_rew_mean           | -284        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 1308672     |
| train/                   |             |
|    approx_kl             | 0.003902284 |
|    clip_fraction         | 0.00801     |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0123     |
|    cost_value_loss       | 2.7e-05     |
|    cost_values           | -0.0131     |
|    entropy               | -2.21       |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0863      |
|    n_updates             | 6380        |
|    policy_gradient_loss  | -0.000329   |
|    std                   | 0.731       |
|    value_loss            | 0.289       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.5258795   |
| rollout/                 |              |
|    ep_len_mean           | 726          |
|    ep_rew_mean           | -286         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 3            |
|    time_elapsed          | 66           |
|    total_timesteps       | 1310720      |
| train/                   |              |
|    approx_kl             | 0.0057929065 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.013       |
|    cost_value_loss       | 1e-05        |
|    cost_values           | -0.0132      |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.203        |
|    n_updates             | 6390         |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 0.73         |
|    value_loss            | 0.308        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0725      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0725      |
| reward                   | -0.4844888  |
| rollout/                 |             |
|    ep_len_mean           | 724         |
|    ep_rew_mean           | -287        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 4           |
|    time_elapsed          | 88          |
|    total_timesteps       | 1312768     |
| train/                   |             |
|    approx_kl             | 0.008537385 |
|    clip_fraction         | 0.0668      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0098     |
|    cost_value_loss       | 2.74e-06    |
|    cost_values           | -0.00973    |
|    entropy               | -2.2        |
|    entropy_loss          | -2.2        |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00381     |
|    n_updates             | 6400        |
|    policy_gradient_loss  | -0.00491    |
|    std                   | 0.728       |
|    value_loss            | 0.022       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.101       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.101       |
| reward                   | -0.27416044 |
| rollout/                 |             |
|    ep_len_mean           | 733         |
|    ep_rew_mean           | -291        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 1314816     |
| train/                   |             |
|    approx_kl             | 0.00291512  |
|    clip_fraction         | 0.0144      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00514     |
|    cost_value_loss       | 1.27e-05    |
|    cost_values           | 0.00524     |
|    entropy               | -2.19       |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.139       |
|    n_updates             | 6410        |
|    policy_gradient_loss  | -0.00066    |
|    std                   | 0.727       |
|    value_loss            | 0.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.303        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.303        |
| reward                   | -0.34938908  |
| rollout/                 |              |
|    ep_len_mean           | 720          |
|    ep_rew_mean           | -287         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 1316864      |
| train/                   |              |
|    approx_kl             | 0.0028367282 |
|    clip_fraction         | 0.0363       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0022       |
|    cost_value_loss       | 3.42e-06     |
|    cost_values           | 0.00228      |
|    entropy               | -2.21        |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00347     |
|    n_updates             | 6420         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 0.732        |
|    value_loss            | 0.0262       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.27         |
| reward                   | -0.43187279  |
| rollout/                 |              |
|    ep_len_mean           | 726          |
|    ep_rew_mean           | -286         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 1318912      |
| train/                   |              |
|    approx_kl             | 0.0050347783 |
|    clip_fraction         | 0.0728       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00713     |
|    cost_value_loss       | 1.17e-05     |
|    cost_values           | -0.0071      |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.175        |
|    n_updates             | 6430         |
|    policy_gradient_loss  | -0.00142     |
|    std                   | 0.733        |
|    value_loss            | 0.444        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00749     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00749     |
| reward                   | -0.35077503 |
| rollout/                 |             |
|    ep_len_mean           | 708         |
|    ep_rew_mean           | -280        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 177         |
|    total_timesteps       | 1320960     |
| train/                   |             |
|    approx_kl             | 0.008955695 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0125     |
|    cost_value_loss       | 1.23e-05    |
|    cost_values           | -0.0127     |
|    entropy               | -2.2        |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.212       |
|    n_updates             | 6440        |
|    policy_gradient_loss  | -0.00541    |
|    std                   | 0.73        |
|    value_loss            | 0.784       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.179       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.179       |
| reward                   | -0.3399518  |
| rollout/                 |             |
|    ep_len_mean           | 717         |
|    ep_rew_mean           | -285        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 199         |
|    total_timesteps       | 1323008     |
| train/                   |             |
|    approx_kl             | 0.005759631 |
|    clip_fraction         | 0.0666      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0129     |
|    cost_value_loss       | 1.51e-05    |
|    cost_values           | -0.0126     |
|    entropy               | -2.2        |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.451       |
|    n_updates             | 6450        |
|    policy_gradient_loss  | -0.00316    |
|    std                   | 0.729       |
|    value_loss            | 0.957       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.165       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.165       |
| reward                   | -0.33254114 |
| rollout/                 |             |
|    ep_len_mean           | 724         |
|    ep_rew_mean           | -287        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 1325056     |
| train/                   |             |
|    approx_kl             | 0.006670758 |
|    clip_fraction         | 0.0603      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0141     |
|    cost_value_loss       | 7.18e-06    |
|    cost_values           | -0.0142     |
|    entropy               | -2.18       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00225     |
|    n_updates             | 6460        |
|    policy_gradient_loss  | -0.00408    |
|    std                   | 0.722       |
|    value_loss            | 0.0245      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.228        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.228        |
| reward                   | -0.3771342   |
| rollout/                 |              |
|    ep_len_mean           | 724          |
|    ep_rew_mean           | -286         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 243          |
|    total_timesteps       | 1327104      |
| train/                   |              |
|    approx_kl             | 0.0037735496 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00634     |
|    cost_value_loss       | 1.95e-05     |
|    cost_values           | -0.00558     |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.2          |
|    n_updates             | 6470         |
|    policy_gradient_loss  | -0.00309     |
|    std                   | 0.719        |
|    value_loss            | 0.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0132      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0132      |
| reward                   | -0.24058692 |
| rollout/                 |             |
|    ep_len_mean           | 721         |
|    ep_rew_mean           | -282        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 1329152     |
| train/                   |             |
|    approx_kl             | 0.004823327 |
|    clip_fraction         | 0.0161      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00564    |
|    cost_value_loss       | 6.48e-06    |
|    cost_values           | -0.0058     |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0173      |
|    n_updates             | 6480        |
|    policy_gradient_loss  | -0.000547   |
|    std                   | 0.718       |
|    value_loss            | 0.0755      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.107        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.107        |
| reward                   | -0.43399873  |
| rollout/                 |              |
|    ep_len_mean           | 717          |
|    ep_rew_mean           | -279         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 287          |
|    total_timesteps       | 1331200      |
| train/                   |              |
|    approx_kl             | 0.0029041423 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0145       |
|    cost_value_loss       | 0.000189     |
|    cost_values           | 0.0178       |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0719       |
|    n_updates             | 6490         |
|    policy_gradient_loss  | -0.000517    |
|    std                   | 0.717        |
|    value_loss            | 0.371        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.412        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.412        |
| reward                   | -0.33365127  |
| rollout/                 |              |
|    ep_len_mean           | 728          |
|    ep_rew_mean           | -285         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 309          |
|    total_timesteps       | 1333248      |
| train/                   |              |
|    approx_kl             | 0.0044328505 |
|    clip_fraction         | 0.02         |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0136      |
|    cost_value_loss       | 0.00223      |
|    cost_values           | -0.0187      |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.118        |
|    n_updates             | 6500         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.717        |
|    value_loss            | 0.342        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0387      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0387      |
| reward                   | -0.30587697 |
| rollout/                 |             |
|    ep_len_mean           | 735         |
|    ep_rew_mean           | -286        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 332         |
|    total_timesteps       | 1335296     |
| train/                   |             |
|    approx_kl             | 0.008227415 |
|    clip_fraction         | 0.0885      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00382     |
|    cost_value_loss       | 5.22e-06    |
|    cost_values           | 0.00388     |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.000625   |
|    n_updates             | 6510        |
|    policy_gradient_loss  | -0.00429    |
|    std                   | 0.72        |
|    value_loss            | 0.0191      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.472        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.472        |
| reward                   | -0.4441648   |
| rollout/                 |              |
|    ep_len_mean           | 751          |
|    ep_rew_mean           | -291         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 354          |
|    total_timesteps       | 1337344      |
| train/                   |              |
|    approx_kl             | 0.0046311505 |
|    clip_fraction         | 0.126        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0138      |
|    cost_value_loss       | 9.95e-06     |
|    cost_values           | -0.0144      |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0788       |
|    n_updates             | 6520         |
|    policy_gradient_loss  | 0.0017       |
|    std                   | 0.72         |
|    value_loss            | 0.654        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.149        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.149        |
| reward                   | -0.4287883   |
| rollout/                 |              |
|    ep_len_mean           | 757          |
|    ep_rew_mean           | -293         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 376          |
|    total_timesteps       | 1339392      |
| train/                   |              |
|    approx_kl             | 0.0019734588 |
|    clip_fraction         | 0.0251       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00354     |
|    cost_value_loss       | 2.6e-06      |
|    cost_values           | -0.00353     |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0067       |
|    n_updates             | 6530         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.718        |
|    value_loss            | 0.0623       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.12        |
| reward                   | -0.46870655 |
| rollout/                 |             |
|    ep_len_mean           | 758         |
|    ep_rew_mean           | -291        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 398         |
|    total_timesteps       | 1341440     |
| train/                   |             |
|    approx_kl             | 0.00831045  |
|    clip_fraction         | 0.0621      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00271     |
|    cost_value_loss       | 7.14e-06    |
|    cost_values           | 0.00303     |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0644      |
|    n_updates             | 6540        |
|    policy_gradient_loss  | -0.00315    |
|    std                   | 0.717       |
|    value_loss            | 0.253       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0945      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0945      |
| reward                   | -0.19649862 |
| rollout/                 |             |
|    ep_len_mean           | 764         |
|    ep_rew_mean           | -296        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 420         |
|    total_timesteps       | 1343488     |
| train/                   |             |
|    approx_kl             | 0.007512995 |
|    clip_fraction         | 0.0414      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00131     |
|    cost_value_loss       | 8.63e-06    |
|    cost_values           | 0.00153     |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0405      |
|    n_updates             | 6550        |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 0.717       |
|    value_loss            | 0.204       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.296        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.296        |
| reward                   | -0.2786847   |
| rollout/                 |              |
|    ep_len_mean           | 766          |
|    ep_rew_mean           | -295         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 443          |
|    total_timesteps       | 1345536      |
| train/                   |              |
|    approx_kl             | 0.0055688317 |
|    clip_fraction         | 0.086        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000137     |
|    cost_value_loss       | 5.45e-06     |
|    cost_values           | 0.000112     |
|    entropy               | -2.15        |
|    entropy_loss          | -2.16        |
|    explained_variance    | 1            |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.000517    |
|    n_updates             | 6560         |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 0.71         |
|    value_loss            | 0.0106       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.375        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.375        |
| reward                   | -0.44006333  |
| rollout/                 |              |
|    ep_len_mean           | 762          |
|    ep_rew_mean           | -289         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 465          |
|    total_timesteps       | 1347584      |
| train/                   |              |
|    approx_kl             | 0.0058618635 |
|    clip_fraction         | 0.0372       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0108      |
|    cost_value_loss       | 4.9e-06      |
|    cost_values           | -0.0108      |
|    entropy               | -2.13        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.154        |
|    n_updates             | 6570         |
|    policy_gradient_loss  | -0.000709    |
|    std                   | 0.706        |
|    value_loss            | 0.568        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0348      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0348      |
| reward                   | -0.4645716  |
| rollout/                 |             |
|    ep_len_mean           | 757         |
|    ep_rew_mean           | -287        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 487         |
|    total_timesteps       | 1349632     |
| train/                   |             |
|    approx_kl             | 0.009426971 |
|    clip_fraction         | 0.045       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00949    |
|    cost_value_loss       | 1.5e-05     |
|    cost_values           | -0.00933    |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.225       |
|    n_updates             | 6580        |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 0.705       |
|    value_loss            | 0.465       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.853       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.853       |
| reward                   | -0.3523347  |
| rollout/                 |             |
|    ep_len_mean           | 770         |
|    ep_rew_mean           | -291        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 509         |
|    total_timesteps       | 1351680     |
| train/                   |             |
|    approx_kl             | 0.003932015 |
|    clip_fraction         | 0.0309      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00684     |
|    cost_value_loss       | 1.89e-05    |
|    cost_values           | 0.00678     |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.225       |
|    n_updates             | 6590        |
|    policy_gradient_loss  | -0.00136    |
|    std                   | 0.704       |
|    value_loss            | 0.423       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.151        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.151        |
| reward                   | -0.45010865  |
| rollout/                 |              |
|    ep_len_mean           | 781          |
|    ep_rew_mean           | -296         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 531          |
|    total_timesteps       | 1353728      |
| train/                   |              |
|    approx_kl             | 0.0059412373 |
|    clip_fraction         | 0.0502       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00524      |
|    cost_value_loss       | 4.46e-06     |
|    cost_values           | 0.00538      |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0716       |
|    n_updates             | 6600         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.701        |
|    value_loss            | 0.266        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0965      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0965      |
| reward                   | -0.46663278 |
| rollout/                 |             |
|    ep_len_mean           | 795         |
|    ep_rew_mean           | -303        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 554         |
|    total_timesteps       | 1355776     |
| train/                   |             |
|    approx_kl             | 0.011905176 |
|    clip_fraction         | 0.08        |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00545    |
|    cost_value_loss       | 9.7e-06     |
|    cost_values           | -0.00535    |
|    entropy               | -2.11       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0463      |
|    n_updates             | 6610        |
|    policy_gradient_loss  | -0.00535    |
|    std                   | 0.699       |
|    value_loss            | 0.132       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0343       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0343       |
| reward                   | -0.27639684  |
| rollout/                 |              |
|    ep_len_mean           | 789          |
|    ep_rew_mean           | -301         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 576          |
|    total_timesteps       | 1357824      |
| train/                   |              |
|    approx_kl             | 0.0051663322 |
|    clip_fraction         | 0.0483       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00422     |
|    cost_value_loss       | 7.02e-06     |
|    cost_values           | -0.00417     |
|    entropy               | -2.12        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0343       |
|    n_updates             | 6620         |
|    policy_gradient_loss  | -0.00251     |
|    std                   | 0.7          |
|    value_loss            | 0.0835       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.324       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.324       |
| reward                   | -0.3700501  |
| rollout/                 |             |
|    ep_len_mean           | 796         |
|    ep_rew_mean           | -304        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 598         |
|    total_timesteps       | 1359872     |
| train/                   |             |
|    approx_kl             | 0.008462017 |
|    clip_fraction         | 0.0609      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0165     |
|    cost_value_loss       | 2.66e-05    |
|    cost_values           | -0.0172     |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.143       |
|    n_updates             | 6630        |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 0.702       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0655      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0655      |
| reward                   | -0.46932963 |
| rollout/                 |             |
|    ep_len_mean           | 798         |
|    ep_rew_mean           | -303        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 620         |
|    total_timesteps       | 1361920     |
| train/                   |             |
|    approx_kl             | 0.005198381 |
|    clip_fraction         | 0.0285      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00334     |
|    cost_value_loss       | 8.92e-06    |
|    cost_values           | 0.00354     |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0644      |
|    n_updates             | 6640        |
|    policy_gradient_loss  | -0.00219    |
|    std                   | 0.701       |
|    value_loss            | 0.201       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.245       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.245       |
| reward                   | -0.3785866  |
| rollout/                 |             |
|    ep_len_mean           | 786         |
|    ep_rew_mean           | -298        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 642         |
|    total_timesteps       | 1363968     |
| train/                   |             |
|    approx_kl             | 0.005050218 |
|    clip_fraction         | 0.0315      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0042     |
|    cost_value_loss       | 1.88e-05    |
|    cost_values           | -0.00408    |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.445       |
|    n_updates             | 6650        |
|    policy_gradient_loss  | -0.00315    |
|    std                   | 0.701       |
|    value_loss            | 1.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.455        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.455        |
| reward                   | -0.36204928  |
| rollout/                 |              |
|    ep_len_mean           | 759          |
|    ep_rew_mean           | -284         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 664          |
|    total_timesteps       | 1366016      |
| train/                   |              |
|    approx_kl             | 0.0044378904 |
|    clip_fraction         | 0.0565       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00624      |
|    cost_value_loss       | 1.46e-05     |
|    cost_values           | 0.00635      |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.244        |
|    n_updates             | 6660         |
|    policy_gradient_loss  | -0.00364     |
|    std                   | 0.701        |
|    value_loss            | 0.646        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.122       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.122       |
| reward                   | -0.50477815 |
| rollout/                 |             |
|    ep_len_mean           | 752         |
|    ep_rew_mean           | -280        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 687         |
|    total_timesteps       | 1368064     |
| train/                   |             |
|    approx_kl             | 0.011637149 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00298    |
|    cost_value_loss       | 1.95e-05    |
|    cost_values           | -0.00305    |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.365       |
|    n_updates             | 6670        |
|    policy_gradient_loss  | -0.00445    |
|    std                   | 0.701       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0404      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0404      |
| reward                   | -0.513814   |
| rollout/                 |             |
|    ep_len_mean           | 745         |
|    ep_rew_mean           | -275        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 709         |
|    total_timesteps       | 1370112     |
| train/                   |             |
|    approx_kl             | 0.005024107 |
|    clip_fraction         | 0.0323      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00907    |
|    cost_value_loss       | 1.65e-05    |
|    cost_values           | -0.0093     |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.141       |
|    n_updates             | 6680        |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 0.701       |
|    value_loss            | 0.595       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.592       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.592       |
| reward                   | -0.46305773 |
| rollout/                 |             |
|    ep_len_mean           | 759         |
|    ep_rew_mean           | -282        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 731         |
|    total_timesteps       | 1372160     |
| train/                   |             |
|    approx_kl             | 0.007917898 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00367    |
|    cost_value_loss       | 1.57e-05    |
|    cost_values           | -0.00361    |
|    entropy               | -2.11       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0543      |
|    n_updates             | 6690        |
|    policy_gradient_loss  | -0.00716    |
|    std                   | 0.699       |
|    value_loss            | 0.145       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.123        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.123        |
| reward                   | -0.4423475   |
| rollout/                 |              |
|    ep_len_mean           | 753          |
|    ep_rew_mean           | -277         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 754          |
|    total_timesteps       | 1374208      |
| train/                   |              |
|    approx_kl             | 0.0059695193 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000688    |
|    cost_value_loss       | 3.24e-06     |
|    cost_values           | -0.000694    |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0115       |
|    n_updates             | 6700         |
|    policy_gradient_loss  | -0.00361     |
|    std                   | 0.699        |
|    value_loss            | 0.0309       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0134      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0134      |
| reward                   | -0.28117013 |
| rollout/                 |             |
|    ep_len_mean           | 763         |
|    ep_rew_mean           | -281        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 776         |
|    total_timesteps       | 1376256     |
| train/                   |             |
|    approx_kl             | 0.008399229 |
|    clip_fraction         | 0.056       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00879    |
|    cost_value_loss       | 1.83e-05    |
|    cost_values           | -0.00886    |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.104       |
|    n_updates             | 6710        |
|    policy_gradient_loss  | -0.000492   |
|    std                   | 0.7         |
|    value_loss            | 0.254       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.349        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.349        |
| reward                   | -0.33102512  |
| rollout/                 |              |
|    ep_len_mean           | 767          |
|    ep_rew_mean           | -280         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 799          |
|    total_timesteps       | 1378304      |
| train/                   |              |
|    approx_kl             | 0.0044894656 |
|    clip_fraction         | 0.0277       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00946     |
|    cost_value_loss       | 5.03e-06     |
|    cost_values           | -0.00953     |
|    entropy               | -2.12        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.00818      |
|    n_updates             | 6720         |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 0.7          |
|    value_loss            | 0.117        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0547       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0547       |
| reward                   | -0.3776333   |
| rollout/                 |              |
|    ep_len_mean           | 778          |
|    ep_rew_mean           | -284         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 821          |
|    total_timesteps       | 1380352      |
| train/                   |              |
|    approx_kl             | 0.0056443433 |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00416     |
|    cost_value_loss       | 2.26e-05     |
|    cost_values           | -0.00419     |
|    entropy               | -2.11        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.103        |
|    n_updates             | 6730         |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 0.7          |
|    value_loss            | 0.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.328       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.328       |
| reward                   | -0.4199514  |
| rollout/                 |             |
|    ep_len_mean           | 771         |
|    ep_rew_mean           | -280        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 843         |
|    total_timesteps       | 1382400     |
| train/                   |             |
|    approx_kl             | 0.004865874 |
|    clip_fraction         | 0.0522      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000848   |
|    cost_value_loss       | 2.86e-05    |
|    cost_values           | -0.000632   |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0998      |
|    n_updates             | 6740        |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.7         |
|    value_loss            | 0.837       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0263      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0263      |
| reward                   | -0.26132455 |
| rollout/                 |             |
|    ep_len_mean           | 773         |
|    ep_rew_mean           | -280        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 866         |
|    total_timesteps       | 1384448     |
| train/                   |             |
|    approx_kl             | 0.00634165  |
|    clip_fraction         | 0.0578      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000575   |
|    cost_value_loss       | 6.89e-06    |
|    cost_values           | -0.000475   |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.281       |
|    n_updates             | 6750        |
|    policy_gradient_loss  | -0.00287    |
|    std                   | 0.7         |
|    value_loss            | 0.708       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.149        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.149        |
| reward                   | -0.37688294  |
| rollout/                 |              |
|    ep_len_mean           | 771          |
|    ep_rew_mean           | -279         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 888          |
|    total_timesteps       | 1386496      |
| train/                   |              |
|    approx_kl             | 0.0040290426 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00808      |
|    cost_value_loss       | 1.96e-05     |
|    cost_values           | 0.00838      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0801       |
|    n_updates             | 6760         |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 0.7          |
|    value_loss            | 0.277        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.778       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.778       |
| reward                   | -0.18813929 |
| rollout/                 |             |
|    ep_len_mean           | 771         |
|    ep_rew_mean           | -278        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 910         |
|    total_timesteps       | 1388544     |
| train/                   |             |
|    approx_kl             | 0.002591765 |
|    clip_fraction         | 0.0475      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00498     |
|    cost_value_loss       | 1.04e-05    |
|    cost_values           | 0.00485     |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0891      |
|    n_updates             | 6770        |
|    policy_gradient_loss  | -0.00204    |
|    std                   | 0.704       |
|    value_loss            | 0.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.274        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.274        |
| reward                   | -0.22772649  |
| rollout/                 |              |
|    ep_len_mean           | 774          |
|    ep_rew_mean           | -277         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 932          |
|    total_timesteps       | 1390592      |
| train/                   |              |
|    approx_kl             | 0.0071623195 |
|    clip_fraction         | 0.0588       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0034      |
|    cost_value_loss       | 9.58e-06     |
|    cost_values           | -0.0035      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.12        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0113       |
|    n_updates             | 6780         |
|    policy_gradient_loss  | -0.00615     |
|    std                   | 0.701        |
|    value_loss            | 0.0687       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.38290793 |
| rollout/                 |             |
|    ep_len_mean           | 771         |
|    ep_rew_mean           | -275        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 954         |
|    total_timesteps       | 1392640     |
| train/                   |             |
|    approx_kl             | 0.003704381 |
|    clip_fraction         | 0.06        |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0149     |
|    cost_value_loss       | 2e-05       |
|    cost_values           | -0.0151     |
|    entropy               | -2.11       |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.175       |
|    n_updates             | 6790        |
|    policy_gradient_loss  | -0.00306    |
|    std                   | 0.7         |
|    value_loss            | 0.575       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.287        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.287        |
| reward                   | -0.17026204  |
| rollout/                 |              |
|    ep_len_mean           | 772          |
|    ep_rew_mean           | -275         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 977          |
|    total_timesteps       | 1394688      |
| train/                   |              |
|    approx_kl             | 0.0034932601 |
|    clip_fraction         | 0.0361       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0154      |
|    cost_value_loss       | 1.4e-05      |
|    cost_values           | -0.0157      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.045        |
|    n_updates             | 6800         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.7          |
|    value_loss            | 0.312        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.154        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.154        |
| reward                   | -0.21393916  |
| rollout/                 |              |
|    ep_len_mean           | 765          |
|    ep_rew_mean           | -272         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 999          |
|    total_timesteps       | 1396736      |
| train/                   |              |
|    approx_kl             | 0.0026267897 |
|    clip_fraction         | 0.0411       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0136      |
|    cost_value_loss       | 1.24e-05     |
|    cost_values           | -0.0139      |
|    entropy               | -2.11        |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.398        |
|    n_updates             | 6810         |
|    policy_gradient_loss  | -0.000716    |
|    std                   | 0.699        |
|    value_loss            | 0.782        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.559        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.559        |
| reward                   | -0.26701003  |
| rollout/                 |              |
|    ep_len_mean           | 767          |
|    ep_rew_mean           | -272         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1021         |
|    total_timesteps       | 1398784      |
| train/                   |              |
|    approx_kl             | 0.0018317876 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00737     |
|    cost_value_loss       | 8.37e-06     |
|    cost_values           | -0.00727     |
|    entropy               | -2.1         |
|    entropy_loss          | -2.11        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.543        |
|    n_updates             | 6820         |
|    policy_gradient_loss  | -0.00182     |
|    std                   | 0.698        |
|    value_loss            | 1.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.665       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.665       |
| reward                   | -0.26257738 |
| rollout/                 |             |
|    ep_len_mean           | 744         |
|    ep_rew_mean           | -259        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1044        |
|    total_timesteps       | 1400832     |
| train/                   |             |
|    approx_kl             | 0.005527308 |
|    clip_fraction         | 0.0542      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00239    |
|    cost_value_loss       | 2.76e-06    |
|    cost_values           | -0.00241    |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0233      |
|    n_updates             | 6830        |
|    policy_gradient_loss  | -0.00395    |
|    std                   | 0.697       |
|    value_loss            | 0.0804      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0543      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0543      |
| reward                   | -0.50802064 |
| rollout/                 |             |
|    ep_len_mean           | 739         |
|    ep_rew_mean           | -255        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1066        |
|    total_timesteps       | 1402880     |
| train/                   |             |
|    approx_kl             | 0.006557922 |
|    clip_fraction         | 0.0552      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000227    |
|    cost_value_loss       | 1.56e-05    |
|    cost_values           | 0.000186    |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.276       |
|    n_updates             | 6840        |
|    policy_gradient_loss  | -0.00386    |
|    std                   | 0.697       |
|    value_loss            | 0.861       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.233        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.233        |
| reward                   | -0.47943124  |
| rollout/                 |              |
|    ep_len_mean           | 739          |
|    ep_rew_mean           | -257         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1088         |
|    total_timesteps       | 1404928      |
| train/                   |              |
|    approx_kl             | 0.0054268194 |
|    clip_fraction         | 0.0491       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00311      |
|    cost_value_loss       | 4.73e-06     |
|    cost_values           | 0.00314      |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0313       |
|    n_updates             | 6850         |
|    policy_gradient_loss  | -0.00422     |
|    std                   | 0.694        |
|    value_loss            | 0.1          |
-------------------------------------------
----------------------------------
| avg_speed          | 0.328     |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 0.328     |
| reward             | -0.485969 |
| rollout/           |           |
|    ep_len_mean     | 739       |
|    ep_rew_mean     | -256      |
| time/              |           |
|    fps             | 94        |
|    iterations      | 1         |
|    time_elapsed    | 21        |
|    total_timesteps | 1406976   |
----------------------------------
-------------------------------------------
| avg_speed                | 0.792        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.792        |
| reward                   | -0.26324356  |
| rollout/                 |              |
|    ep_len_mean           | 737          |
|    ep_rew_mean           | -256         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 2            |
|    time_elapsed          | 44           |
|    total_timesteps       | 1409024      |
| train/                   |              |
|    approx_kl             | 0.0064565567 |
|    clip_fraction         | 0.0525       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00344      |
|    cost_value_loss       | 4.83e-06     |
|    cost_values           | 0.00373      |
|    entropy               | -2.09        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0456       |
|    n_updates             | 6870         |
|    policy_gradient_loss  | -0.00283     |
|    std                   | 0.69         |
|    value_loss            | 0.395        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0152      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0152      |
| reward                   | -0.50012684 |
| rollout/                 |             |
|    ep_len_mean           | 733         |
|    ep_rew_mean           | -255        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 1411072     |
| train/                   |             |
|    approx_kl             | 0.007825319 |
|    clip_fraction         | 0.0233      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00852    |
|    cost_value_loss       | 8.48e-06    |
|    cost_values           | -0.00854    |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0729      |
|    n_updates             | 6880        |
|    policy_gradient_loss  | -0.00178    |
|    std                   | 0.69        |
|    value_loss            | 0.31        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.236      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.236      |
| reward                   | -0.4239051 |
| rollout/                 |            |
|    ep_len_mean           | 728        |
|    ep_rew_mean           | -253       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 4          |
|    time_elapsed          | 88         |
|    total_timesteps       | 1413120    |
| train/                   |            |
|    approx_kl             | 0.00493009 |
|    clip_fraction         | 0.0346     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.01       |
|    cost_value_loss       | 2.48e-05   |
|    cost_values           | 0.0111     |
|    entropy               | -2.08      |
|    entropy_loss          | -2.08      |
|    explained_variance    | 0.963      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.338      |
|    n_updates             | 6890       |
|    policy_gradient_loss  | -0.00248   |
|    std                   | 0.689      |
|    value_loss            | 2.21       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.183        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.183        |
| reward                   | -0.38277474  |
| rollout/                 |              |
|    ep_len_mean           | 720          |
|    ep_rew_mean           | -248         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 1415168      |
| train/                   |              |
|    approx_kl             | 0.0045986925 |
|    clip_fraction         | 0.0465       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00225     |
|    cost_value_loss       | 9.25e-06     |
|    cost_values           | -0.00226     |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.241        |
|    n_updates             | 6900         |
|    policy_gradient_loss  | -0.00454     |
|    std                   | 0.689        |
|    value_loss            | 0.719        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.465        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.465        |
| reward                   | -0.29220593  |
| rollout/                 |              |
|    ep_len_mean           | 720          |
|    ep_rew_mean           | -249         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 1417216      |
| train/                   |              |
|    approx_kl             | 0.0019355735 |
|    clip_fraction         | 0.0564       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.013        |
|    cost_value_loss       | 1.81e-05     |
|    cost_values           | 0.0126       |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.167        |
|    n_updates             | 6910         |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.687        |
|    value_loss            | 0.334        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.241        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.241        |
| reward                   | -0.3790895   |
| rollout/                 |              |
|    ep_len_mean           | 710          |
|    ep_rew_mean           | -245         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 1419264      |
| train/                   |              |
|    approx_kl             | 0.0060226982 |
|    clip_fraction         | 0.0662       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00227      |
|    cost_value_loss       | 1.01e-05     |
|    cost_values           | 0.00263      |
|    entropy               | -2.07        |
|    entropy_loss          | -2.07        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0156       |
|    n_updates             | 6920         |
|    policy_gradient_loss  | -0.00557     |
|    std                   | 0.684        |
|    value_loss            | 0.104        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.404       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.404       |
| reward                   | -0.27707008 |
| rollout/                 |             |
|    ep_len_mean           | 707         |
|    ep_rew_mean           | -243        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 176         |
|    total_timesteps       | 1421312     |
| train/                   |             |
|    approx_kl             | 0.010830146 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0057      |
|    cost_value_loss       | 1.14e-05    |
|    cost_values           | 0.00557     |
|    entropy               | -2.06       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.133       |
|    n_updates             | 6930        |
|    policy_gradient_loss  | -0.00753    |
|    std                   | 0.682       |
|    value_loss            | 0.358       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.217       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.217       |
| reward                   | -0.29706025 |
| rollout/                 |             |
|    ep_len_mean           | 714         |
|    ep_rew_mean           | -245        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 199         |
|    total_timesteps       | 1423360     |
| train/                   |             |
|    approx_kl             | 0.005883011 |
|    clip_fraction         | 0.0644      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00581     |
|    cost_value_loss       | 1.77e-05    |
|    cost_values           | 0.00582     |
|    entropy               | -2.06       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.084       |
|    n_updates             | 6940        |
|    policy_gradient_loss  | -0.00405    |
|    std                   | 0.68        |
|    value_loss            | 0.229       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0462      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0462      |
| reward                   | -0.34027913 |
| rollout/                 |             |
|    ep_len_mean           | 715         |
|    ep_rew_mean           | -246        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 1425408     |
| train/                   |             |
|    approx_kl             | 0.004466543 |
|    clip_fraction         | 0.014       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00109     |
|    cost_value_loss       | 6.71e-06    |
|    cost_values           | 0.00155     |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0173      |
|    n_updates             | 6950        |
|    policy_gradient_loss  | -0.000487   |
|    std                   | 0.677       |
|    value_loss            | 0.0891      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.266        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.266        |
| reward                   | -0.47126377  |
| rollout/                 |              |
|    ep_len_mean           | 714          |
|    ep_rew_mean           | -243         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 243          |
|    total_timesteps       | 1427456      |
| train/                   |              |
|    approx_kl             | 0.0073701376 |
|    clip_fraction         | 0.0829       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00431      |
|    cost_value_loss       | 2.97e-05     |
|    cost_values           | 0.0045       |
|    entropy               | -2.05        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0128       |
|    n_updates             | 6960         |
|    policy_gradient_loss  | -0.00518     |
|    std                   | 0.677        |
|    value_loss            | 0.0547       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0554       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0554       |
| reward                   | -0.2749477   |
| rollout/                 |              |
|    ep_len_mean           | 724          |
|    ep_rew_mean           | -247         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 265          |
|    total_timesteps       | 1429504      |
| train/                   |              |
|    approx_kl             | 0.0035749716 |
|    clip_fraction         | 0.0182       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0101       |
|    cost_value_loss       | 1.32e-05     |
|    cost_values           | 0.0108       |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.967        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.411        |
|    n_updates             | 6970         |
|    policy_gradient_loss  | -0.000672    |
|    std                   | 0.676        |
|    value_loss            | 1.78         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0243      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0243      |
| reward                   | -0.4679573  |
| rollout/                 |             |
|    ep_len_mean           | 713         |
|    ep_rew_mean           | -242        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 287         |
|    total_timesteps       | 1431552     |
| train/                   |             |
|    approx_kl             | 0.005549772 |
|    clip_fraction         | 0.0374      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00111     |
|    cost_value_loss       | 2.2e-05     |
|    cost_values           | 0.00112     |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0339      |
|    n_updates             | 6980        |
|    policy_gradient_loss  | -0.00528    |
|    std                   | 0.676       |
|    value_loss            | 0.336       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.711        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.711        |
| reward                   | -0.28472388  |
| rollout/                 |              |
|    ep_len_mean           | 718          |
|    ep_rew_mean           | -246         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 309          |
|    total_timesteps       | 1433600      |
| train/                   |              |
|    approx_kl             | 0.0043029203 |
|    clip_fraction         | 0.0789       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00264      |
|    cost_value_loss       | 7.31e-06     |
|    cost_values           | 0.00263      |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.179        |
|    n_updates             | 6990         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.676        |
|    value_loss            | 0.52         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.143        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.143        |
| reward                   | -0.315592    |
| rollout/                 |              |
|    ep_len_mean           | 722          |
|    ep_rew_mean           | -247         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 331          |
|    total_timesteps       | 1435648      |
| train/                   |              |
|    approx_kl             | 0.0057943994 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00352     |
|    cost_value_loss       | 2.12e-05     |
|    cost_values           | -0.00391     |
|    entropy               | -2.04        |
|    entropy_loss          | -2.04        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.285        |
|    n_updates             | 7000         |
|    policy_gradient_loss  | -0.00364     |
|    std                   | 0.674        |
|    value_loss            | 1.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.829        |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 0.829        |
| reward                   | -0.102410145 |
| rollout/                 |              |
|    ep_len_mean           | 724          |
|    ep_rew_mean           | -248         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 353          |
|    total_timesteps       | 1437696      |
| train/                   |              |
|    approx_kl             | 0.0057134456 |
|    clip_fraction         | 0.0525       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0093      |
|    cost_value_loss       | 1.77e-05     |
|    cost_values           | -0.00945     |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.185        |
|    n_updates             | 7010         |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.673        |
|    value_loss            | 0.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0451       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0451       |
| reward                   | -0.45995557  |
| rollout/                 |              |
|    ep_len_mean           | 736          |
|    ep_rew_mean           | -254         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 375          |
|    total_timesteps       | 1439744      |
| train/                   |              |
|    approx_kl             | 0.0034651854 |
|    clip_fraction         | 0.0388       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00204      |
|    cost_value_loss       | 1.08e-05     |
|    cost_values           | 0.002        |
|    entropy               | -2.02        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.135        |
|    n_updates             | 7020         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.669        |
|    value_loss            | 0.497        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0762       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0762       |
| reward                   | -0.46357974  |
| rollout/                 |              |
|    ep_len_mean           | 739          |
|    ep_rew_mean           | -258         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 397          |
|    total_timesteps       | 1441792      |
| train/                   |              |
|    approx_kl             | 0.0024565724 |
|    clip_fraction         | 0.0374       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00682     |
|    cost_value_loss       | 1.24e-05     |
|    cost_values           | -0.00681     |
|    entropy               | -2           |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0258       |
|    n_updates             | 7030         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.663        |
|    value_loss            | 0.0746       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.036        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.036        |
| reward                   | -0.29701167  |
| rollout/                 |              |
|    ep_len_mean           | 736          |
|    ep_rew_mean           | -256         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 419          |
|    total_timesteps       | 1443840      |
| train/                   |              |
|    approx_kl             | 0.0068085864 |
|    clip_fraction         | 0.0671       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00171      |
|    cost_value_loss       | 1.34e-05     |
|    cost_values           | 0.00171      |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.185        |
|    n_updates             | 7040         |
|    policy_gradient_loss  | -0.00193     |
|    std                   | 0.663        |
|    value_loss            | 0.401        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0647       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0647       |
| reward                   | -0.4253984   |
| rollout/                 |              |
|    ep_len_mean           | 734          |
|    ep_rew_mean           | -253         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 442          |
|    total_timesteps       | 1445888      |
| train/                   |              |
|    approx_kl             | 0.0029316815 |
|    clip_fraction         | 0.0337       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00634     |
|    cost_value_loss       | 5.1e-06      |
|    cost_values           | -0.00632     |
|    entropy               | -2           |
|    entropy_loss          | -2           |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0463       |
|    n_updates             | 7050         |
|    policy_gradient_loss  | -0.00111     |
|    std                   | 0.662        |
|    value_loss            | 0.195        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.531       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.531       |
| reward                   | -0.3736544  |
| rollout/                 |             |
|    ep_len_mean           | 735         |
|    ep_rew_mean           | -254        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 463         |
|    total_timesteps       | 1447936     |
| train/                   |             |
|    approx_kl             | 0.011243648 |
|    clip_fraction         | 0.042       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00162     |
|    cost_value_loss       | 5.53e-06    |
|    cost_values           | 0.00161     |
|    entropy               | -1.99       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.101       |
|    n_updates             | 7060        |
|    policy_gradient_loss  | 0.000761    |
|    std                   | 0.658       |
|    value_loss            | 0.142       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.655        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.655        |
| reward                   | -0.1534189   |
| rollout/                 |              |
|    ep_len_mean           | 725          |
|    ep_rew_mean           | -251         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 485          |
|    total_timesteps       | 1449984      |
| train/                   |              |
|    approx_kl             | 0.0034752144 |
|    clip_fraction         | 0.0695       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00268      |
|    cost_value_loss       | 5.87e-06     |
|    cost_values           | 0.00273      |
|    entropy               | -1.99        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0286       |
|    n_updates             | 7070         |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 0.659        |
|    value_loss            | 0.0817       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.281        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.281        |
| reward                   | -0.32240686  |
| rollout/                 |              |
|    ep_len_mean           | 708          |
|    ep_rew_mean           | -244         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 508          |
|    total_timesteps       | 1452032      |
| train/                   |              |
|    approx_kl             | 0.0075855157 |
|    clip_fraction         | 0.0651       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00219      |
|    cost_value_loss       | 1.97e-05     |
|    cost_values           | 0.00193      |
|    entropy               | -1.99        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.127        |
|    n_updates             | 7080         |
|    policy_gradient_loss  | -0.000193    |
|    std                   | 0.657        |
|    value_loss            | 0.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0694       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0694       |
| reward                   | -0.46441412  |
| rollout/                 |              |
|    ep_len_mean           | 717          |
|    ep_rew_mean           | -248         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 530          |
|    total_timesteps       | 1454080      |
| train/                   |              |
|    approx_kl             | 0.0071288776 |
|    clip_fraction         | 0.0626       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00795     |
|    cost_value_loss       | 1.92e-05     |
|    cost_values           | -0.0078      |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.144        |
|    n_updates             | 7090         |
|    policy_gradient_loss  | -0.00275     |
|    std                   | 0.656        |
|    value_loss            | 0.321        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0577       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0577       |
| reward                   | -0.27998075  |
| rollout/                 |              |
|    ep_len_mean           | 705          |
|    ep_rew_mean           | -245         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 552          |
|    total_timesteps       | 1456128      |
| train/                   |              |
|    approx_kl             | 0.0016352726 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0134      |
|    cost_value_loss       | 2.52e-05     |
|    cost_values           | -0.0135      |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.266        |
|    n_updates             | 7100         |
|    policy_gradient_loss  | 0.000538     |
|    std                   | 0.656        |
|    value_loss            | 1.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.707       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.707       |
| reward                   | -0.4107445  |
| rollout/                 |             |
|    ep_len_mean           | 694         |
|    ep_rew_mean           | -239        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 574         |
|    total_timesteps       | 1458176     |
| train/                   |             |
|    approx_kl             | 0.006416992 |
|    clip_fraction         | 0.0973      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00797    |
|    cost_value_loss       | 2.62e-05    |
|    cost_values           | -0.00799    |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.134       |
|    n_updates             | 7110        |
|    policy_gradient_loss  | -0.00484    |
|    std                   | 0.656       |
|    value_loss            | 0.473       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.334        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.334        |
| reward                   | -0.27712154  |
| rollout/                 |              |
|    ep_len_mean           | 692          |
|    ep_rew_mean           | -240         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 596          |
|    total_timesteps       | 1460224      |
| train/                   |              |
|    approx_kl             | 0.0033377202 |
|    clip_fraction         | 0.0316       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00753     |
|    cost_value_loss       | 2.14e-05     |
|    cost_values           | -0.0076      |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.23         |
|    n_updates             | 7120         |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 0.654        |
|    value_loss            | 0.439        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.062       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.062       |
| reward                   | -0.36654964 |
| rollout/                 |             |
|    ep_len_mean           | 684         |
|    ep_rew_mean           | -237        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 618         |
|    total_timesteps       | 1462272     |
| train/                   |             |
|    approx_kl             | 0.006271829 |
|    clip_fraction         | 0.0488      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00332    |
|    cost_value_loss       | 3.4e-05     |
|    cost_values           | -0.0034     |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0729      |
|    n_updates             | 7130        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.655       |
|    value_loss            | 0.185       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00831     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00831     |
| reward                   | -0.4236042  |
| rollout/                 |             |
|    ep_len_mean           | 679         |
|    ep_rew_mean           | -235        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 641         |
|    total_timesteps       | 1464320     |
| train/                   |             |
|    approx_kl             | 0.008324977 |
|    clip_fraction         | 0.0814      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000193   |
|    cost_value_loss       | 3.55e-05    |
|    cost_values           | -0.000155   |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.112       |
|    n_updates             | 7140        |
|    policy_gradient_loss  | -0.00546    |
|    std                   | 0.657       |
|    value_loss            | 0.276       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.551        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.551        |
| reward                   | -0.37335354  |
| rollout/                 |              |
|    ep_len_mean           | 678          |
|    ep_rew_mean           | -237         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 662          |
|    total_timesteps       | 1466368      |
| train/                   |              |
|    approx_kl             | 0.0047670715 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00981     |
|    cost_value_loss       | 1.65e-05     |
|    cost_values           | -0.0102      |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.187        |
|    n_updates             | 7150         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.656        |
|    value_loss            | 0.86         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.113        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.113        |
| reward                   | -0.2560128   |
| rollout/                 |              |
|    ep_len_mean           | 686          |
|    ep_rew_mean           | -240         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 684          |
|    total_timesteps       | 1468416      |
| train/                   |              |
|    approx_kl             | 0.0059657125 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000342    |
|    cost_value_loss       | 1.87e-05     |
|    cost_values           | -0.000372    |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0458       |
|    n_updates             | 7160         |
|    policy_gradient_loss  | -0.00713     |
|    std                   | 0.655        |
|    value_loss            | 0.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.12         |
| reward                   | -0.33535978  |
| rollout/                 |              |
|    ep_len_mean           | 692          |
|    ep_rew_mean           | -243         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 706          |
|    total_timesteps       | 1470464      |
| train/                   |              |
|    approx_kl             | 0.0059801685 |
|    clip_fraction         | 0.0635       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0155      |
|    cost_value_loss       | 2.58e-05     |
|    cost_values           | -0.0158      |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.956        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.447        |
|    n_updates             | 7170         |
|    policy_gradient_loss  | -0.000836    |
|    std                   | 0.654        |
|    value_loss            | 2.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0766       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0766       |
| reward                   | -0.32188338  |
| rollout/                 |              |
|    ep_len_mean           | 697          |
|    ep_rew_mean           | -246         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 729          |
|    total_timesteps       | 1472512      |
| train/                   |              |
|    approx_kl             | 0.0068804976 |
|    clip_fraction         | 0.0814       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00132      |
|    cost_value_loss       | 2.24e-05     |
|    cost_values           | 0.00131      |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.082        |
|    n_updates             | 7180         |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 0.653        |
|    value_loss            | 0.267        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.129       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.129       |
| reward                   | -0.45989397 |
| rollout/                 |             |
|    ep_len_mean           | 695         |
|    ep_rew_mean           | -245        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 751         |
|    total_timesteps       | 1474560     |
| train/                   |             |
|    approx_kl             | 0.007730458 |
|    clip_fraction         | 0.0761      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00298     |
|    cost_value_loss       | 9.52e-06    |
|    cost_values           | 0.00294     |
|    entropy               | -1.97       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.0124     |
|    n_updates             | 7190        |
|    policy_gradient_loss  | -0.00721    |
|    std                   | 0.65        |
|    value_loss            | 0.0223      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.398       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.398       |
| reward                   | -0.40085953 |
| rollout/                 |             |
|    ep_len_mean           | 695         |
|    ep_rew_mean           | -246        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 773         |
|    total_timesteps       | 1476608     |
| train/                   |             |
|    approx_kl             | 0.006468991 |
|    clip_fraction         | 0.0574      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00101    |
|    cost_value_loss       | 1.05e-05    |
|    cost_values           | -0.00105    |
|    entropy               | -1.97       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0538      |
|    n_updates             | 7200        |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 0.651       |
|    value_loss            | 0.291       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.248      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.248      |
| reward                   | -0.4408921 |
| rollout/                 |            |
|    ep_len_mean           | 684        |
|    ep_rew_mean           | -243       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 36         |
|    time_elapsed          | 794        |
|    total_timesteps       | 1478656    |
| train/                   |            |
|    approx_kl             | 0.00391291 |
|    clip_fraction         | 0.0483     |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00559   |
|    cost_value_loss       | 6.32e-06   |
|    cost_values           | -0.00565   |
|    entropy               | -1.95      |
|    entropy_loss          | -1.96      |
|    explained_variance    | 0.996      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.000884   |
|    n_updates             | 7210       |
|    policy_gradient_loss  | -0.00386   |
|    std                   | 0.646      |
|    value_loss            | 0.0197     |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.0888      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0888      |
| reward                   | -0.18258573 |
| rollout/                 |             |
|    ep_len_mean           | 684         |
|    ep_rew_mean           | -243        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 816         |
|    total_timesteps       | 1480704     |
| train/                   |             |
|    approx_kl             | 0.008212645 |
|    clip_fraction         | 0.0639      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00406    |
|    cost_value_loss       | 2.55e-05    |
|    cost_values           | -0.00367    |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.125       |
|    n_updates             | 7220        |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.645       |
|    value_loss            | 0.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.605       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.605       |
| reward                   | -0.19399136 |
| rollout/                 |             |
|    ep_len_mean           | 675         |
|    ep_rew_mean           | -238        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 838         |
|    total_timesteps       | 1482752     |
| train/                   |             |
|    approx_kl             | 0.004485276 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0131     |
|    cost_value_loss       | 1.99e-05    |
|    cost_values           | -0.0134     |
|    entropy               | -1.96       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.108       |
|    n_updates             | 7230        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.646       |
|    value_loss            | 0.464       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.497       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.497       |
| reward                   | -0.32332838 |
| rollout/                 |             |
|    ep_len_mean           | 662         |
|    ep_rew_mean           | -235        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 860         |
|    total_timesteps       | 1484800     |
| train/                   |             |
|    approx_kl             | 0.005299208 |
|    clip_fraction         | 0.0334      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00858    |
|    cost_value_loss       | 9.57e-05    |
|    cost_values           | -0.00892    |
|    entropy               | -1.96       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.211       |
|    n_updates             | 7240        |
|    policy_gradient_loss  | -0.00208    |
|    std                   | 0.646       |
|    value_loss            | 0.837       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.063        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.063        |
| reward                   | -0.3751745   |
| rollout/                 |              |
|    ep_len_mean           | 661          |
|    ep_rew_mean           | -234         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 883          |
|    total_timesteps       | 1486848      |
| train/                   |              |
|    approx_kl             | 0.0049869716 |
|    clip_fraction         | 0.0386       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000345    |
|    cost_value_loss       | 7.26e-05     |
|    cost_values           | -0.00157     |
|    entropy               | -1.95        |
|    entropy_loss          | -1.96        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.16         |
|    n_updates             | 7250         |
|    policy_gradient_loss  | -0.00347     |
|    std                   | 0.644        |
|    value_loss            | 0.392        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.511        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.511        |
| reward                   | -0.15869582  |
| rollout/                 |              |
|    ep_len_mean           | 657          |
|    ep_rew_mean           | -233         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 905          |
|    total_timesteps       | 1488896      |
| train/                   |              |
|    approx_kl             | 0.0065891724 |
|    clip_fraction         | 0.0663       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00366      |
|    cost_value_loss       | 9.28e-06     |
|    cost_values           | 0.00389      |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.26         |
|    n_updates             | 7260         |
|    policy_gradient_loss  | -0.00381     |
|    std                   | 0.644        |
|    value_loss            | 0.606        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0419      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0419      |
| reward                   | -0.3813768  |
| rollout/                 |             |
|    ep_len_mean           | 657         |
|    ep_rew_mean           | -232        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 927         |
|    total_timesteps       | 1490944     |
| train/                   |             |
|    approx_kl             | 0.005486679 |
|    clip_fraction         | 0.0302      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000124   |
|    cost_value_loss       | 5.54e-06    |
|    cost_values           | 7.83e-05    |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0439      |
|    n_updates             | 7270        |
|    policy_gradient_loss  | 0.00011     |
|    std                   | 0.644       |
|    value_loss            | 0.584       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.274       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.274       |
| reward                   | -0.3184265  |
| rollout/                 |             |
|    ep_len_mean           | 661         |
|    ep_rew_mean           | -235        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 950         |
|    total_timesteps       | 1492992     |
| train/                   |             |
|    approx_kl             | 0.004349013 |
|    clip_fraction         | 0.0167      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0053      |
|    cost_value_loss       | 9.17e-06    |
|    cost_values           | 0.00548     |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0345      |
|    n_updates             | 7280        |
|    policy_gradient_loss  | 0.000219    |
|    std                   | 0.644       |
|    value_loss            | 0.308       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.389        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.389        |
| reward                   | -0.46941143  |
| rollout/                 |              |
|    ep_len_mean           | 638          |
|    ep_rew_mean           | -224         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 972          |
|    total_timesteps       | 1495040      |
| train/                   |              |
|    approx_kl             | 0.0041399514 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0026      |
|    cost_value_loss       | 2.58e-05     |
|    cost_values           | -0.00234     |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0.957        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.568        |
|    n_updates             | 7290         |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 0.643        |
|    value_loss            | 2.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.223       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.223       |
| reward                   | -0.37795222 |
| rollout/                 |             |
|    ep_len_mean           | 651         |
|    ep_rew_mean           | -231        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 994         |
|    total_timesteps       | 1497088     |
| train/                   |             |
|    approx_kl             | 0.004596266 |
|    clip_fraction         | 0.0225      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000417   |
|    cost_value_loss       | 1.13e-05    |
|    cost_values           | -0.000683   |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.672       |
|    n_updates             | 7300        |
|    policy_gradient_loss  | -0.00255    |
|    std                   | 0.644       |
|    value_loss            | 2.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.8          |
| reward                   | -0.2514734   |
| rollout/                 |              |
|    ep_len_mean           | 640          |
|    ep_rew_mean           | -226         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1016         |
|    total_timesteps       | 1499136      |
| train/                   |              |
|    approx_kl             | 0.0046302145 |
|    clip_fraction         | 0.0357       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00167      |
|    cost_value_loss       | 1.29e-05     |
|    cost_values           | 0.00154      |
|    entropy               | -1.96        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0.955        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0666       |
|    n_updates             | 7310         |
|    policy_gradient_loss  | -0.0034      |
|    std                   | 0.647        |
|    value_loss            | 0.339        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.21        |
| reward                   | -0.22427246 |
| rollout/                 |             |
|    ep_len_mean           | 645         |
|    ep_rew_mean           | -230        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1038        |
|    total_timesteps       | 1501184     |
| train/                   |             |
|    approx_kl             | 0.009626487 |
|    clip_fraction         | 0.0612      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00437     |
|    cost_value_loss       | 5.35e-06    |
|    cost_values           | 0.00436     |
|    entropy               | -1.96       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.139       |
|    n_updates             | 7320        |
|    policy_gradient_loss  | -0.00384    |
|    std                   | 0.647       |
|    value_loss            | 0.325       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.735       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.735       |
| reward                   | -0.3078899  |
| rollout/                 |             |
|    ep_len_mean           | 643         |
|    ep_rew_mean           | -226        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1060        |
|    total_timesteps       | 1503232     |
| train/                   |             |
|    approx_kl             | 0.008209607 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000526   |
|    cost_value_loss       | 1.15e-05    |
|    cost_values           | -0.000395   |
|    entropy               | -1.96       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.259       |
|    n_updates             | 7330        |
|    policy_gradient_loss  | -0.00632    |
|    std                   | 0.647       |
|    value_loss            | 0.748       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0192       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0192       |
| reward                   | -0.45552403  |
| rollout/                 |              |
|    ep_len_mean           | 638          |
|    ep_rew_mean           | -224         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1082         |
|    total_timesteps       | 1505280      |
| train/                   |              |
|    approx_kl             | 0.0043320707 |
|    clip_fraction         | 0.0236       |
|    clip_range            | 0.2          |
|    cost_returns          | -7.18e-05    |
|    cost_value_loss       | 3.51e-06     |
|    cost_values           | -0.000202    |
|    entropy               | -1.96        |
|    entropy_loss          | -1.96        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0914       |
|    n_updates             | 7340         |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 0.647        |
|    value_loss            | 0.476        |
-------------------------------------------
------------------------------------
| avg_speed          | 0.579       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.579       |
| reward             | -0.26186863 |
| rollout/           |             |
|    ep_len_mean     | 638         |
|    ep_rew_mean     | -224        |
| time/              |             |
|    fps             | 94          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1507328     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.18         |
| reward                   | -0.30337572  |
| rollout/                 |              |
|    ep_len_mean           | 644          |
|    ep_rew_mean           | -225         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 1509376      |
| train/                   |              |
|    approx_kl             | 0.0066944137 |
|    clip_fraction         | 0.0357       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0042      |
|    cost_value_loss       | 2.91e-06     |
|    cost_values           | -0.00433     |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0306       |
|    n_updates             | 7360         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.645        |
|    value_loss            | 0.209        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.421       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.421       |
| reward                   | -0.46455252 |
| rollout/                 |             |
|    ep_len_mean           | 650         |
|    ep_rew_mean           | -228        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 1511424     |
| train/                   |             |
|    approx_kl             | 0.005237478 |
|    clip_fraction         | 0.029       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00397    |
|    cost_value_loss       | 3.93e-06    |
|    cost_values           | -0.0041     |
|    entropy               | -1.96       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00435     |
|    n_updates             | 7370        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.646       |
|    value_loss            | 0.0793      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.242        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.242        |
| reward                   | -0.2667642   |
| rollout/                 |              |
|    ep_len_mean           | 642          |
|    ep_rew_mean           | -223         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 1513472      |
| train/                   |              |
|    approx_kl             | 0.0051621245 |
|    clip_fraction         | 0.0742       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00588      |
|    cost_value_loss       | 7.54e-06     |
|    cost_values           | 0.00589      |
|    entropy               | -1.97        |
|    entropy_loss          | -1.96        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | -0.00232     |
|    n_updates             | 7380         |
|    policy_gradient_loss  | -0.00413     |
|    std                   | 0.65         |
|    value_loss            | 0.00994      |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.24611066  |
| rollout/                 |              |
|    ep_len_mean           | 652          |
|    ep_rew_mean           | -226         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 1515520      |
| train/                   |              |
|    approx_kl             | 0.0067480085 |
|    clip_fraction         | 0.0929       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00245     |
|    cost_value_loss       | 9.48e-06     |
|    cost_values           | -0.00257     |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.222        |
|    n_updates             | 7390         |
|    policy_gradient_loss  | -0.00558     |
|    std                   | 0.65         |
|    value_loss            | 0.697        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.586       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.586       |
| reward                   | -0.2533486  |
| rollout/                 |             |
|    ep_len_mean           | 658         |
|    ep_rew_mean           | -226        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 1517568     |
| train/                   |             |
|    approx_kl             | 0.006518526 |
|    clip_fraction         | 0.0426      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00736    |
|    cost_value_loss       | 1.24e-05    |
|    cost_values           | -0.00682    |
|    entropy               | -1.96       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0735      |
|    n_updates             | 7400        |
|    policy_gradient_loss  | -0.00483    |
|    std                   | 0.648       |
|    value_loss            | 0.278       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.292       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.292       |
| reward                   | -0.42520866 |
| rollout/                 |             |
|    ep_len_mean           | 644         |
|    ep_rew_mean           | -221        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 153         |
|    total_timesteps       | 1519616     |
| train/                   |             |
|    approx_kl             | 0.010235218 |
|    clip_fraction         | 0.096       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0088     |
|    cost_value_loss       | 0.000346    |
|    cost_values           | -0.012      |
|    entropy               | -1.96       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0234      |
|    n_updates             | 7410        |
|    policy_gradient_loss  | -0.00349    |
|    std                   | 0.647       |
|    value_loss            | 0.102       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.919        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.919        |
| reward                   | -0.45506746  |
| rollout/                 |              |
|    ep_len_mean           | 658          |
|    ep_rew_mean           | -228         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 8            |
|    time_elapsed          | 175          |
|    total_timesteps       | 1521664      |
| train/                   |              |
|    approx_kl             | 0.0071856272 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00152     |
|    cost_value_loss       | 2.2e-05      |
|    cost_values           | -0.00176     |
|    entropy               | -1.95        |
|    entropy_loss          | -1.96        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.242        |
|    n_updates             | 7420         |
|    policy_gradient_loss  | -0.00469     |
|    std                   | 0.646        |
|    value_loss            | 0.747        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.152        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.152        |
| reward                   | -0.22116882  |
| rollout/                 |              |
|    ep_len_mean           | 664          |
|    ep_rew_mean           | -232         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 9            |
|    time_elapsed          | 197          |
|    total_timesteps       | 1523712      |
| train/                   |              |
|    approx_kl             | 0.0058066244 |
|    clip_fraction         | 0.0689       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00445      |
|    cost_value_loss       | 1.88e-05     |
|    cost_values           | 0.00442      |
|    entropy               | -1.95        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0236       |
|    n_updates             | 7430         |
|    policy_gradient_loss  | -0.00538     |
|    std                   | 0.644        |
|    value_loss            | 0.102        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.276        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.276        |
| reward                   | -0.4950884   |
| rollout/                 |              |
|    ep_len_mean           | 666          |
|    ep_rew_mean           | -233         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 219          |
|    total_timesteps       | 1525760      |
| train/                   |              |
|    approx_kl             | 0.0035399203 |
|    clip_fraction         | 0.0358       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0116      |
|    cost_value_loss       | 4.1e-05      |
|    cost_values           | -0.0124      |
|    entropy               | -1.94        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.611        |
|    n_updates             | 7440         |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.643        |
|    value_loss            | 2.6          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.447       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.447       |
| reward                   | -0.31781092 |
| rollout/                 |             |
|    ep_len_mean           | 665         |
|    ep_rew_mean           | -235        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 11          |
|    time_elapsed          | 241         |
|    total_timesteps       | 1527808     |
| train/                   |             |
|    approx_kl             | 0.007752206 |
|    clip_fraction         | 0.0856      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00429     |
|    cost_value_loss       | 1.8e-05     |
|    cost_values           | 0.00437     |
|    entropy               | -1.94       |
|    entropy_loss          | -1.94       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.127       |
|    n_updates             | 7450        |
|    policy_gradient_loss  | -0.00392    |
|    std                   | 0.641       |
|    value_loss            | 0.352       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.041        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.041        |
| reward                   | -0.25619492  |
| rollout/                 |              |
|    ep_len_mean           | 670          |
|    ep_rew_mean           | -237         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 12           |
|    time_elapsed          | 263          |
|    total_timesteps       | 1529856      |
| train/                   |              |
|    approx_kl             | 0.0035925505 |
|    clip_fraction         | 0.0294       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00633     |
|    cost_value_loss       | 1.76e-05     |
|    cost_values           | -0.00639     |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0886       |
|    n_updates             | 7460         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.638        |
|    value_loss            | 0.294        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.577        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.577        |
| reward                   | -0.2720818   |
| rollout/                 |              |
|    ep_len_mean           | 674          |
|    ep_rew_mean           | -241         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 13           |
|    time_elapsed          | 285          |
|    total_timesteps       | 1531904      |
| train/                   |              |
|    approx_kl             | 0.0048326673 |
|    clip_fraction         | 0.0614       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00445     |
|    cost_value_loss       | 1.48e-05     |
|    cost_values           | -0.00447     |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.129        |
|    n_updates             | 7470         |
|    policy_gradient_loss  | -0.00454     |
|    std                   | 0.638        |
|    value_loss            | 0.289        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.581        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.581        |
| reward                   | -0.30310747  |
| rollout/                 |              |
|    ep_len_mean           | 674          |
|    ep_rew_mean           | -241         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 307          |
|    total_timesteps       | 1533952      |
| train/                   |              |
|    approx_kl             | 0.0048850183 |
|    clip_fraction         | 0.0537       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000437    |
|    cost_value_loss       | 1.6e-05      |
|    cost_values           | -0.000336    |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.127        |
|    n_updates             | 7480         |
|    policy_gradient_loss  | -0.00437     |
|    std                   | 0.637        |
|    value_loss            | 0.267        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0129       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0129       |
| reward                   | -0.29445493  |
| rollout/                 |              |
|    ep_len_mean           | 679          |
|    ep_rew_mean           | -244         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 15           |
|    time_elapsed          | 329          |
|    total_timesteps       | 1536000      |
| train/                   |              |
|    approx_kl             | 0.0044932254 |
|    clip_fraction         | 0.0336       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00594     |
|    cost_value_loss       | 3.69e-05     |
|    cost_values           | -0.00662     |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0256       |
|    n_updates             | 7490         |
|    policy_gradient_loss  | -0.00306     |
|    std                   | 0.636        |
|    value_loss            | 0.121        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.121       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.121       |
| reward                   | -0.2378955  |
| rollout/                 |             |
|    ep_len_mean           | 676         |
|    ep_rew_mean           | -243        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 16          |
|    time_elapsed          | 351         |
|    total_timesteps       | 1538048     |
| train/                   |             |
|    approx_kl             | 0.002679693 |
|    clip_fraction         | 0.0229      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00185     |
|    cost_value_loss       | 0.000122    |
|    cost_values           | 0.00268     |
|    entropy               | -1.92       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00969     |
|    n_updates             | 7500        |
|    policy_gradient_loss  | -0.000911   |
|    std                   | 0.635       |
|    value_loss            | 0.0866      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.142        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.142        |
| reward                   | -0.45683098  |
| rollout/                 |              |
|    ep_len_mean           | 668          |
|    ep_rew_mean           | -241         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 17           |
|    time_elapsed          | 373          |
|    total_timesteps       | 1540096      |
| train/                   |              |
|    approx_kl             | 0.0048970776 |
|    clip_fraction         | 0.0133       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0102      |
|    cost_value_loss       | 0.000502     |
|    cost_values           | -0.0153      |
|    entropy               | -1.92        |
|    entropy_loss          | -1.92        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0926       |
|    n_updates             | 7510         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.634        |
|    value_loss            | 0.306        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.55        |
| reward                   | -0.20798035 |
| rollout/                 |             |
|    ep_len_mean           | 678         |
|    ep_rew_mean           | -246        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 18          |
|    time_elapsed          | 394         |
|    total_timesteps       | 1542144     |
| train/                   |             |
|    approx_kl             | 0.005973952 |
|    clip_fraction         | 0.0462      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0104     |
|    cost_value_loss       | 2.56e-05    |
|    cost_values           | -0.0102     |
|    entropy               | -1.92       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.135       |
|    n_updates             | 7520        |
|    policy_gradient_loss  | -0.00362    |
|    std                   | 0.634       |
|    value_loss            | 0.279       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.69        |
| reward                   | -0.519539   |
| rollout/                 |             |
|    ep_len_mean           | 672         |
|    ep_rew_mean           | -240        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 19          |
|    time_elapsed          | 416         |
|    total_timesteps       | 1544192     |
| train/                   |             |
|    approx_kl             | 0.005055911 |
|    clip_fraction         | 0.0643      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00324    |
|    cost_value_loss       | 1.58e-05    |
|    cost_values           | -0.00324    |
|    entropy               | -1.9        |
|    entropy_loss          | -1.91       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.038       |
|    n_updates             | 7530        |
|    policy_gradient_loss  | -0.00392    |
|    std                   | 0.628       |
|    value_loss            | 0.134       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.189        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.189        |
| reward                   | -0.20074959  |
| rollout/                 |              |
|    ep_len_mean           | 671          |
|    ep_rew_mean           | -241         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 20           |
|    time_elapsed          | 438          |
|    total_timesteps       | 1546240      |
| train/                   |              |
|    approx_kl             | 0.0048811957 |
|    clip_fraction         | 0.0754       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0133      |
|    cost_value_loss       | 1.88e-05     |
|    cost_values           | -0.0133      |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.349        |
|    n_updates             | 7540         |
|    policy_gradient_loss  | -0.000113    |
|    std                   | 0.626        |
|    value_loss            | 1.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.306        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.306        |
| reward                   | -0.34942162  |
| rollout/                 |              |
|    ep_len_mean           | 682          |
|    ep_rew_mean           | -245         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 21           |
|    time_elapsed          | 460          |
|    total_timesteps       | 1548288      |
| train/                   |              |
|    approx_kl             | 0.0068060784 |
|    clip_fraction         | 0.0377       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0103      |
|    cost_value_loss       | 1.9e-05      |
|    cost_values           | -0.0105      |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.316        |
|    n_updates             | 7550         |
|    policy_gradient_loss  | -0.0034      |
|    std                   | 0.626        |
|    value_loss            | 0.967        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.29        |
| reward                   | -0.417383   |
| rollout/                 |             |
|    ep_len_mean           | 680         |
|    ep_rew_mean           | -248        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 22          |
|    time_elapsed          | 482         |
|    total_timesteps       | 1550336     |
| train/                   |             |
|    approx_kl             | 0.005867172 |
|    clip_fraction         | 0.0352      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00591    |
|    cost_value_loss       | 1.23e-05    |
|    cost_values           | -0.00586    |
|    entropy               | -1.89       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | -0.00108    |
|    n_updates             | 7560        |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 0.624       |
|    value_loss            | 0.116       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0181      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0181      |
| reward                   | -0.37506288 |
| rollout/                 |             |
|    ep_len_mean           | 695         |
|    ep_rew_mean           | -252        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 23          |
|    time_elapsed          | 505         |
|    total_timesteps       | 1552384     |
| train/                   |             |
|    approx_kl             | 0.007927472 |
|    clip_fraction         | 0.0553      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00304     |
|    cost_value_loss       | 1.92e-05    |
|    cost_values           | 0.00308     |
|    entropy               | -1.89       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0726      |
|    n_updates             | 7570        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.625       |
|    value_loss            | 0.148       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.565        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.565        |
| reward                   | -0.19964577  |
| rollout/                 |              |
|    ep_len_mean           | 697          |
|    ep_rew_mean           | -251         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 24           |
|    time_elapsed          | 527          |
|    total_timesteps       | 1554432      |
| train/                   |              |
|    approx_kl             | 0.0038195138 |
|    clip_fraction         | 0.0408       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00795     |
|    cost_value_loss       | 2.04e-05     |
|    cost_values           | -0.00812     |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.177        |
|    n_updates             | 7580         |
|    policy_gradient_loss  | -0.00448     |
|    std                   | 0.625        |
|    value_loss            | 0.527        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.288        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.288        |
| reward                   | -0.4045893   |
| rollout/                 |              |
|    ep_len_mean           | 701          |
|    ep_rew_mean           | -252         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 25           |
|    time_elapsed          | 550          |
|    total_timesteps       | 1556480      |
| train/                   |              |
|    approx_kl             | 0.0061229304 |
|    clip_fraction         | 0.0565       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00437     |
|    cost_value_loss       | 1.3e-05      |
|    cost_values           | -0.00443     |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0812       |
|    n_updates             | 7590         |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 0.626        |
|    value_loss            | 0.247        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0924      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0924      |
| reward                   | -0.46588668 |
| rollout/                 |             |
|    ep_len_mean           | 701         |
|    ep_rew_mean           | -253        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 26          |
|    time_elapsed          | 572         |
|    total_timesteps       | 1558528     |
| train/                   |             |
|    approx_kl             | 0.006681239 |
|    clip_fraction         | 0.0565      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000322    |
|    cost_value_loss       | 1.63e-05    |
|    cost_values           | 0.000387    |
|    entropy               | -1.89       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0335      |
|    n_updates             | 7600        |
|    policy_gradient_loss  | -0.00569    |
|    std                   | 0.627       |
|    value_loss            | 0.145       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.34        |
| reward                   | -0.56883156 |
| rollout/                 |             |
|    ep_len_mean           | 693         |
|    ep_rew_mean           | -251        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 27          |
|    time_elapsed          | 594         |
|    total_timesteps       | 1560576     |
| train/                   |             |
|    approx_kl             | 0.008589779 |
|    clip_fraction         | 0.0993      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000794    |
|    cost_value_loss       | 2.61e-05    |
|    cost_values           | 0.000723    |
|    entropy               | -1.89       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.141       |
|    n_updates             | 7610        |
|    policy_gradient_loss  | -0.00733    |
|    std                   | 0.627       |
|    value_loss            | 0.494       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0642       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0642       |
| reward                   | -0.38987103  |
| rollout/                 |              |
|    ep_len_mean           | 693          |
|    ep_rew_mean           | -253         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 28           |
|    time_elapsed          | 616          |
|    total_timesteps       | 1562624      |
| train/                   |              |
|    approx_kl             | 0.0062773344 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00494     |
|    cost_value_loss       | 2.59e-05     |
|    cost_values           | -0.00491     |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.51         |
|    n_updates             | 7620         |
|    policy_gradient_loss  | 7.87e-05     |
|    std                   | 0.627        |
|    value_loss            | 1.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.443        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.443        |
| reward                   | -0.31664348  |
| rollout/                 |              |
|    ep_len_mean           | 703          |
|    ep_rew_mean           | -258         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 29           |
|    time_elapsed          | 638          |
|    total_timesteps       | 1564672      |
| train/                   |              |
|    approx_kl             | 0.0047839647 |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00299     |
|    cost_value_loss       | 0.000326     |
|    cost_values           | -0.00289     |
|    entropy               | -1.9         |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0.937        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.203        |
|    n_updates             | 7630         |
|    policy_gradient_loss  | -0.0056      |
|    std                   | 0.628        |
|    value_loss            | 1.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.437       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.437       |
| reward                   | -0.27958217 |
| rollout/                 |             |
|    ep_len_mean           | 716         |
|    ep_rew_mean           | -263        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 30          |
|    time_elapsed          | 660         |
|    total_timesteps       | 1566720     |
| train/                   |             |
|    approx_kl             | 0.003482905 |
|    clip_fraction         | 0.0301      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0183      |
|    cost_value_loss       | 6.66e-05    |
|    cost_values           | 0.0183      |
|    entropy               | -1.9        |
|    entropy_loss          | -1.9        |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0126      |
|    n_updates             | 7640        |
|    policy_gradient_loss  | -0.0017     |
|    std                   | 0.628       |
|    value_loss            | 0.0678      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.149        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.149        |
| reward                   | -0.307289    |
| rollout/                 |              |
|    ep_len_mean           | 708          |
|    ep_rew_mean           | -258         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 31           |
|    time_elapsed          | 682          |
|    total_timesteps       | 1568768      |
| train/                   |              |
|    approx_kl             | 0.0036125048 |
|    clip_fraction         | 0.0253       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0205       |
|    cost_value_loss       | 3.38e-05     |
|    cost_values           | 0.0216       |
|    entropy               | -1.89        |
|    entropy_loss          | -1.9         |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0438       |
|    n_updates             | 7650         |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 0.626        |
|    value_loss            | 0.234        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.888       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.888       |
| reward                   | -0.32194608 |
| rollout/                 |             |
|    ep_len_mean           | 715         |
|    ep_rew_mean           | -259        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 704         |
|    total_timesteps       | 1570816     |
| train/                   |             |
|    approx_kl             | 0.007839335 |
|    clip_fraction         | 0.061       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0252      |
|    cost_value_loss       | 2.75e-05    |
|    cost_values           | 0.0254      |
|    entropy               | -1.9        |
|    entropy_loss          | -1.9        |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.171       |
|    n_updates             | 7660        |
|    policy_gradient_loss  | -0.000838   |
|    std                   | 0.629       |
|    value_loss            | 0.496       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.112       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.112       |
| reward                   | -0.31003726 |
| rollout/                 |             |
|    ep_len_mean           | 709         |
|    ep_rew_mean           | -257        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 726         |
|    total_timesteps       | 1572864     |
| train/                   |             |
|    approx_kl             | 0.008883901 |
|    clip_fraction         | 0.0908      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0252      |
|    cost_value_loss       | 3.01e-05    |
|    cost_values           | 0.0253      |
|    entropy               | -1.89       |
|    entropy_loss          | -1.9        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.161       |
|    n_updates             | 7670        |
|    policy_gradient_loss  | -0.00419    |
|    std                   | 0.626       |
|    value_loss            | 0.455       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.441       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.441       |
| reward                   | -0.3534841  |
| rollout/                 |             |
|    ep_len_mean           | 716         |
|    ep_rew_mean           | -260        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 748         |
|    total_timesteps       | 1574912     |
| train/                   |             |
|    approx_kl             | 0.003470169 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00693    |
|    cost_value_loss       | 3.12e-05    |
|    cost_values           | -0.00716    |
|    entropy               | -1.89       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.176       |
|    n_updates             | 7680        |
|    policy_gradient_loss  | -0.000748   |
|    std                   | 0.625       |
|    value_loss            | 0.539       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.123        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.123        |
| reward                   | -0.30946147  |
| rollout/                 |              |
|    ep_len_mean           | 723          |
|    ep_rew_mean           | -263         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 771          |
|    total_timesteps       | 1576960      |
| train/                   |              |
|    approx_kl             | 0.0053201914 |
|    clip_fraction         | 0.0608       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0159       |
|    cost_value_loss       | 1.18e-05     |
|    cost_values           | 0.0159       |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0129       |
|    n_updates             | 7690         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 0.624        |
|    value_loss            | 0.0284       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.197        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.197        |
| reward                   | -0.4908875   |
| rollout/                 |              |
|    ep_len_mean           | 733          |
|    ep_rew_mean           | -265         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 793          |
|    total_timesteps       | 1579008      |
| train/                   |              |
|    approx_kl             | 0.0058582514 |
|    clip_fraction         | 0.0449       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00742     |
|    cost_value_loss       | 3.32e-05     |
|    cost_values           | -0.00707     |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0444       |
|    n_updates             | 7700         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.625        |
|    value_loss            | 0.198        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.129       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.129       |
| reward                   | -0.40865064 |
| rollout/                 |             |
|    ep_len_mean           | 733         |
|    ep_rew_mean           | -267        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 815         |
|    total_timesteps       | 1581056     |
| train/                   |             |
|    approx_kl             | 0.005341666 |
|    clip_fraction         | 0.0692      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00489     |
|    cost_value_loss       | 1.57e-05    |
|    cost_values           | 0.00487     |
|    entropy               | -1.87       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00699     |
|    n_updates             | 7710        |
|    policy_gradient_loss  | -0.00515    |
|    std                   | 0.621       |
|    value_loss            | 0.0273      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.345       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.345       |
| reward                   | -0.4249232  |
| rollout/                 |             |
|    ep_len_mean           | 733         |
|    ep_rew_mean           | -270        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 38          |
|    time_elapsed          | 836         |
|    total_timesteps       | 1583104     |
| train/                   |             |
|    approx_kl             | 0.015909053 |
|    clip_fraction         | 0.0886      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00144    |
|    cost_value_loss       | 1.16e-05    |
|    cost_values           | -0.00138    |
|    entropy               | -1.86       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 1           |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00877     |
|    n_updates             | 7720        |
|    policy_gradient_loss  | -0.00529    |
|    std                   | 0.617       |
|    value_loss            | 0.0233      |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0181      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0181      |
| reward                   | -0.2382441  |
| rollout/                 |             |
|    ep_len_mean           | 723         |
|    ep_rew_mean           | -265        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 858         |
|    total_timesteps       | 1585152     |
| train/                   |             |
|    approx_kl             | 0.006574153 |
|    clip_fraction         | 0.0538      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.003       |
|    cost_value_loss       | 1.18e-05    |
|    cost_values           | 0.00283     |
|    entropy               | -1.85       |
|    entropy_loss          | -1.86       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0077      |
|    n_updates             | 7730        |
|    policy_gradient_loss  | -0.00246    |
|    std                   | 0.615       |
|    value_loss            | 0.0336      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.384        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.384        |
| reward                   | -0.4821716   |
| rollout/                 |              |
|    ep_len_mean           | 730          |
|    ep_rew_mean           | -269         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 880          |
|    total_timesteps       | 1587200      |
| train/                   |              |
|    approx_kl             | 0.0045415903 |
|    clip_fraction         | 0.0587       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00301      |
|    cost_value_loss       | 1.54e-05     |
|    cost_values           | 0.00343      |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0983       |
|    n_updates             | 7740         |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 0.614        |
|    value_loss            | 0.505        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.249       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.249       |
| reward                   | -0.41062814 |
| rollout/                 |             |
|    ep_len_mean           | 713         |
|    ep_rew_mean           | -266        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 903         |
|    total_timesteps       | 1589248     |
| train/                   |             |
|    approx_kl             | 0.004017201 |
|    clip_fraction         | 0.0366      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.32e-05    |
|    cost_value_loss       | 1.04e-05    |
|    cost_values           | 0.000124    |
|    entropy               | -1.85       |
|    entropy_loss          | -1.85       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0497      |
|    n_updates             | 7750        |
|    policy_gradient_loss  | -0.00155    |
|    std                   | 0.613       |
|    value_loss            | 0.121       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.228        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.228        |
| reward                   | -0.27488053  |
| rollout/                 |              |
|    ep_len_mean           | 723          |
|    ep_rew_mean           | -270         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 925          |
|    total_timesteps       | 1591296      |
| train/                   |              |
|    approx_kl             | 0.0046860925 |
|    clip_fraction         | 0.0531       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00486      |
|    cost_value_loss       | 2.56e-05     |
|    cost_values           | 0.00488      |
|    entropy               | -1.85        |
|    entropy_loss          | -1.85        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.18         |
|    n_updates             | 7760         |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 0.613        |
|    value_loss            | 0.453        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.372       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.372       |
| reward                   | -0.36801922 |
| rollout/                 |             |
|    ep_len_mean           | 728         |
|    ep_rew_mean           | -272        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 947         |
|    total_timesteps       | 1593344     |
| train/                   |             |
|    approx_kl             | 0.008032206 |
|    clip_fraction         | 0.0827      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00458    |
|    cost_value_loss       | 1e-05       |
|    cost_values           | -0.00468    |
|    entropy               | -1.84       |
|    entropy_loss          | -1.85       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0199      |
|    n_updates             | 7770        |
|    policy_gradient_loss  | -0.00495    |
|    std                   | 0.612       |
|    value_loss            | 0.099       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.3          |
| reward                   | -0.3771773   |
| rollout/                 |              |
|    ep_len_mean           | 718          |
|    ep_rew_mean           | -266         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 970          |
|    total_timesteps       | 1595392      |
| train/                   |              |
|    approx_kl             | 0.0055208756 |
|    clip_fraction         | 0.0472       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0016       |
|    cost_value_loss       | 1.52e-05     |
|    cost_values           | 0.00181      |
|    entropy               | -1.83        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0183       |
|    n_updates             | 7780         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.609        |
|    value_loss            | 0.0584       |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.41        |
| reward                   | -0.38444608 |
| rollout/                 |             |
|    ep_len_mean           | 726         |
|    ep_rew_mean           | -268        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 992         |
|    total_timesteps       | 1597440     |
| train/                   |             |
|    approx_kl             | 0.009849848 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0066      |
|    cost_value_loss       | 3.03e-05    |
|    cost_values           | 0.007       |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0978      |
|    n_updates             | 7790        |
|    policy_gradient_loss  | -0.00823    |
|    std                   | 0.606       |
|    value_loss            | 0.392       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0305      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0305      |
| reward                   | -0.73204774 |
| rollout/                 |             |
|    ep_len_mean           | 716         |
|    ep_rew_mean           | -261        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1014        |
|    total_timesteps       | 1599488     |
| train/                   |             |
|    approx_kl             | 0.016446806 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00197     |
|    cost_value_loss       | 3.52e-06    |
|    cost_values           | 0.00197     |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.00955     |
|    n_updates             | 7800        |
|    policy_gradient_loss  | -0.00943    |
|    std                   | 0.606       |
|    value_loss            | 0.0605      |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.214        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.214        |
| reward                   | -0.33023995  |
| rollout/                 |              |
|    ep_len_mean           | 722          |
|    ep_rew_mean           | -271         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1036         |
|    total_timesteps       | 1601536      |
| train/                   |              |
|    approx_kl             | 0.0060405284 |
|    clip_fraction         | 0.0462       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0291       |
|    cost_value_loss       | 0.0589       |
|    cost_values           | 0.0277       |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.81         |
|    n_updates             | 7810         |
|    policy_gradient_loss  | -0.00169     |
|    std                   | 0.607        |
|    value_loss            | 2.9          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.176       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.176       |
| reward                   | -0.28732347 |
| rollout/                 |             |
|    ep_len_mean           | 728         |
|    ep_rew_mean           | -272        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1058        |
|    total_timesteps       | 1603584     |
| train/                   |             |
|    approx_kl             | 0.004356386 |
|    clip_fraction         | 0.00996     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.813       |
|    cost_value_loss       | 3.37        |
|    cost_values           | 0.718       |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.88        |
|    n_updates             | 7820        |
|    policy_gradient_loss  | -0.00163    |
|    std                   | 0.607       |
|    value_loss            | 14.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.722       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.722       |
| reward                   | -0.27069268 |
| rollout/                 |             |
|    ep_len_mean           | 734         |
|    ep_rew_mean           | -273        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1080        |
|    total_timesteps       | 1605632     |
| train/                   |             |
|    approx_kl             | 0.008257721 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.267       |
|    cost_value_loss       | 0.000968    |
|    cost_values           | 0.268       |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0234      |
|    n_updates             | 7830        |
|    policy_gradient_loss  | -0.00677    |
|    std                   | 0.606       |
|    value_loss            | 0.121       |
------------------------------------------
Directory created: PPOL_New/models/seed-testing/tggzx3rw/model_epoch(15)
------------------------------------
| avg_speed          | 0.218       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.218       |
| reward             | -0.20671122 |
| rollout/           |             |
|    ep_len_mean     | 723         |
|    ep_rew_mean     | -268        |
| time/              |             |
|    fps             | 94          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1607680     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.556        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.556        |
| reward                   | -0.3983631   |
| rollout/                 |              |
|    ep_len_mean           | 711          |
|    ep_rew_mean           | -263         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 2            |
|    time_elapsed          | 44           |
|    total_timesteps       | 1609728      |
| train/                   |              |
|    approx_kl             | 0.0053956723 |
|    clip_fraction         | 0.0411       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.208        |
|    cost_value_loss       | 0.0145       |
|    cost_values           | 0.224        |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.03         |
|    n_updates             | 7850         |
|    policy_gradient_loss  | -0.00137     |
|    std                   | 0.607        |
|    value_loss            | 3.05         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.03         |
| reward                   | -0.19069651  |
| rollout/                 |              |
|    ep_len_mean           | 718          |
|    ep_rew_mean           | -268         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 3            |
|    time_elapsed          | 66           |
|    total_timesteps       | 1611776      |
| train/                   |              |
|    approx_kl             | 0.0070339134 |
|    clip_fraction         | 0.0401       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0308      |
|    cost_value_loss       | 0.000638     |
|    cost_values           | -0.0361      |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.881        |
|    n_updates             | 7860         |
|    policy_gradient_loss  | -0.00233     |
|    std                   | 0.606        |
|    value_loss            | 2.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.407       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.407       |
| reward                   | -0.4345478  |
| rollout/                 |             |
|    ep_len_mean           | 697         |
|    ep_rew_mean           | -259        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 1613824     |
| train/                   |             |
|    approx_kl             | 0.008021461 |
|    clip_fraction         | 0.0607      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.384       |
|    cost_value_loss       | 0.018       |
|    cost_values           | 0.397       |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.15        |
|    n_updates             | 7870        |
|    policy_gradient_loss  | -0.00418    |
|    std                   | 0.605       |
|    value_loss            | 3.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.418       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.418       |
| reward                   | -0.24930458 |
| rollout/                 |             |
|    ep_len_mean           | 701         |
|    ep_rew_mean           | -260        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 5           |
|    time_elapsed          | 111         |
|    total_timesteps       | 1615872     |
| train/                   |             |
|    approx_kl             | 0.006246681 |
|    clip_fraction         | 0.0611      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0562      |
|    cost_value_loss       | 0.000437    |
|    cost_values           | 0.0551      |
|    entropy               | -1.83       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.308       |
|    n_updates             | 7880        |
|    policy_gradient_loss  | -0.00338    |
|    std                   | 0.607       |
|    value_loss            | 1.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0537       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0537       |
| reward                   | -0.24224709  |
| rollout/                 |              |
|    ep_len_mean           | 701          |
|    ep_rew_mean           | -258         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 6            |
|    time_elapsed          | 133          |
|    total_timesteps       | 1617920      |
| train/                   |              |
|    approx_kl             | 0.0041024364 |
|    clip_fraction         | 0.0421       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0115      |
|    cost_value_loss       | 7.47e-05     |
|    cost_values           | -0.0122      |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.454        |
|    n_updates             | 7890         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.607        |
|    value_loss            | 0.913        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.399        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.399        |
| reward                   | -0.4142317   |
| rollout/                 |              |
|    ep_len_mean           | 701          |
|    ep_rew_mean           | -255         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 7            |
|    time_elapsed          | 156          |
|    total_timesteps       | 1619968      |
| train/                   |              |
|    approx_kl             | 0.0069672028 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00565     |
|    cost_value_loss       | 1.75e-05     |
|    cost_values           | -0.00653     |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.928        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.185        |
|    n_updates             | 7900         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.607        |
|    value_loss            | 0.665        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.41         |
| reward                   | -0.24721605  |
| rollout/                 |              |
|    ep_len_mean           | 694          |
|    ep_rew_mean           | -254         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 8            |
|    time_elapsed          | 178          |
|    total_timesteps       | 1622016      |
| train/                   |              |
|    approx_kl             | 0.0075260624 |
|    clip_fraction         | 0.0408       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00707      |
|    cost_value_loss       | 7.67e-05     |
|    cost_values           | 0.00661      |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0816       |
|    n_updates             | 7910         |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 0.608        |
|    value_loss            | 0.228        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.16         |
| reward                   | -0.42347455  |
| rollout/                 |              |
|    ep_len_mean           | 670          |
|    ep_rew_mean           | -247         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 200          |
|    total_timesteps       | 1624064      |
| train/                   |              |
|    approx_kl             | 0.0068981554 |
|    clip_fraction         | 0.0971       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0308       |
|    cost_value_loss       | 0.000176     |
|    cost_values           | 0.0308       |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.34         |
|    n_updates             | 7920         |
|    policy_gradient_loss  | -0.0065      |
|    std                   | 0.606        |
|    value_loss            | 0.865        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0804      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0804      |
| reward                   | -0.40003324 |
| rollout/                 |             |
|    ep_len_mean           | 679         |
|    ep_rew_mean           | -251        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 222         |
|    total_timesteps       | 1626112     |
| train/                   |             |
|    approx_kl             | 0.005862411 |
|    clip_fraction         | 0.0702      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.148       |
|    cost_value_loss       | 0.00503     |
|    cost_values           | 0.158       |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.22        |
|    n_updates             | 7930        |
|    policy_gradient_loss  | -0.000448   |
|    std                   | 0.605       |
|    value_loss            | 3.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.238       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.238       |
| reward                   | -0.4245348  |
| rollout/                 |             |
|    ep_len_mean           | 687         |
|    ep_rew_mean           | -252        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 244         |
|    total_timesteps       | 1628160     |
| train/                   |             |
|    approx_kl             | 0.012945396 |
|    clip_fraction         | 0.0827      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0441     |
|    cost_value_loss       | 0.000116    |
|    cost_values           | -0.0457     |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.113       |
|    n_updates             | 7940        |
|    policy_gradient_loss  | -0.00458    |
|    std                   | 0.604       |
|    value_loss            | 0.291       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0516      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0516      |
| reward                   | -0.24775895 |
| rollout/                 |             |
|    ep_len_mean           | 680         |
|    ep_rew_mean           | -249        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 266         |
|    total_timesteps       | 1630208     |
| train/                   |             |
|    approx_kl             | 0.0041396   |
|    clip_fraction         | 0.0128      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0309     |
|    cost_value_loss       | 0.000124    |
|    cost_values           | -0.0323     |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0916      |
|    n_updates             | 7950        |
|    policy_gradient_loss  | -0.000268   |
|    std                   | 0.604       |
|    value_loss            | 0.462       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.456       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.456       |
| reward                   | -0.2661944  |
| rollout/                 |             |
|    ep_len_mean           | 680         |
|    ep_rew_mean           | -248        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 287         |
|    total_timesteps       | 1632256     |
| train/                   |             |
|    approx_kl             | 0.005497341 |
|    clip_fraction         | 0.0307      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.028       |
|    cost_value_loss       | 0.00235     |
|    cost_values           | 0.0301      |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.42        |
|    n_updates             | 7960        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 0.603       |
|    value_loss            | 1.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0285      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0285      |
| reward                   | -0.35977122 |
| rollout/                 |             |
|    ep_len_mean           | 680         |
|    ep_rew_mean           | -248        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 1634304     |
| train/                   |             |
|    approx_kl             | 0.007729533 |
|    clip_fraction         | 0.0861      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.012      |
|    cost_value_loss       | 5.7e-05     |
|    cost_values           | -0.0123     |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0497      |
|    n_updates             | 7970        |
|    policy_gradient_loss  | -0.00487    |
|    std                   | 0.601       |
|    value_loss            | 0.157       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.088        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.088        |
| reward                   | -0.3317175   |
| rollout/                 |              |
|    ep_len_mean           | 673          |
|    ep_rew_mean           | -246         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 332          |
|    total_timesteps       | 1636352      |
| train/                   |              |
|    approx_kl             | 0.0054595373 |
|    clip_fraction         | 0.0467       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0247      |
|    cost_value_loss       | 4.72e-05     |
|    cost_values           | -0.0252      |
|    entropy               | -1.79        |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0162       |
|    n_updates             | 7980         |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 0.595        |
|    value_loss            | 0.0386       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.075       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.075       |
| reward                   | -0.4316654  |
| rollout/                 |             |
|    ep_len_mean           | 676         |
|    ep_rew_mean           | -248        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 354         |
|    total_timesteps       | 1638400     |
| train/                   |             |
|    approx_kl             | 0.004103806 |
|    clip_fraction         | 0.0639      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0369     |
|    cost_value_loss       | 5.32e-05    |
|    cost_values           | -0.0371     |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.068       |
|    n_updates             | 7990        |
|    policy_gradient_loss  | -0.0042     |
|    std                   | 0.591       |
|    value_loss            | 0.235       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.79         |
| reward                   | -0.47594678  |
| rollout/                 |              |
|    ep_len_mean           | 676          |
|    ep_rew_mean           | -248         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 376          |
|    total_timesteps       | 1640448      |
| train/                   |              |
|    approx_kl             | 0.0033437116 |
|    clip_fraction         | 0.0848       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0127      |
|    cost_value_loss       | 6.43e-05     |
|    cost_values           | -0.0136      |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0.967        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.368        |
|    n_updates             | 8000         |
|    policy_gradient_loss  | 0.00192      |
|    std                   | 0.591        |
|    value_loss            | 0.969        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.306       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.306       |
| reward                   | -0.3629137  |
| rollout/                 |             |
|    ep_len_mean           | 674         |
|    ep_rew_mean           | -248        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 399         |
|    total_timesteps       | 1642496     |
| train/                   |             |
|    approx_kl             | 0.011551434 |
|    clip_fraction         | 0.087       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0808      |
|    cost_value_loss       | 0.00258     |
|    cost_values           | 0.0845      |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.82        |
|    n_updates             | 8010        |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 0.591       |
|    value_loss            | 1.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.251        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.251        |
| reward                   | -0.33598772  |
| rollout/                 |              |
|    ep_len_mean           | 676          |
|    ep_rew_mean           | -247         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 421          |
|    total_timesteps       | 1644544      |
| train/                   |              |
|    approx_kl             | 0.0064216796 |
|    clip_fraction         | 0.0495       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00631      |
|    cost_value_loss       | 0.00147      |
|    cost_values           | 0.00764      |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.261        |
|    n_updates             | 8020         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 0.589        |
|    value_loss            | 0.636        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.207        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.207        |
| reward                   | -0.41466454  |
| rollout/                 |              |
|    ep_len_mean           | 662          |
|    ep_rew_mean           | -240         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 443          |
|    total_timesteps       | 1646592      |
| train/                   |              |
|    approx_kl             | 0.0036488618 |
|    clip_fraction         | 0.0212       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0169      |
|    cost_value_loss       | 3.65e-05     |
|    cost_values           | -0.0164      |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.121        |
|    n_updates             | 8030         |
|    policy_gradient_loss  | -0.000333    |
|    std                   | 0.588        |
|    value_loss            | 0.322        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.375       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.375       |
| reward                   | -0.23578683 |
| rollout/                 |             |
|    ep_len_mean           | 655         |
|    ep_rew_mean           | -237        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 466         |
|    total_timesteps       | 1648640     |
| train/                   |             |
|    approx_kl             | 0.008818914 |
|    clip_fraction         | 0.0526      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00153     |
|    cost_value_loss       | 3.68e-05    |
|    cost_values           | 0.0016      |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.38        |
|    n_updates             | 8040        |
|    policy_gradient_loss  | -0.00414    |
|    std                   | 0.588       |
|    value_loss            | 1.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.3          |
| reward                   | -0.38418645  |
| rollout/                 |              |
|    ep_len_mean           | 656          |
|    ep_rew_mean           | -235         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 488          |
|    total_timesteps       | 1650688      |
| train/                   |              |
|    approx_kl             | 0.0047530774 |
|    clip_fraction         | 0.0795       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0217       |
|    cost_value_loss       | 0.000898     |
|    cost_values           | 0.0224       |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.144        |
|    n_updates             | 8050         |
|    policy_gradient_loss  | -0.00493     |
|    std                   | 0.589        |
|    value_loss            | 0.483        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -0.2555444   |
| rollout/                 |              |
|    ep_len_mean           | 662          |
|    ep_rew_mean           | -238         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 510          |
|    total_timesteps       | 1652736      |
| train/                   |              |
|    approx_kl             | 0.0072928993 |
|    clip_fraction         | 0.0621       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00162     |
|    cost_value_loss       | 2.64e-05     |
|    cost_values           | -0.0016      |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.126        |
|    n_updates             | 8060         |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 0.589        |
|    value_loss            | 0.396        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.41         |
| reward                   | -0.21522522  |
| rollout/                 |              |
|    ep_len_mean           | 669          |
|    ep_rew_mean           | -241         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 532          |
|    total_timesteps       | 1654784      |
| train/                   |              |
|    approx_kl             | 0.0017891619 |
|    clip_fraction         | 0.0356       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00347     |
|    cost_value_loss       | 1.08e-05     |
|    cost_values           | -0.00368     |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.136        |
|    n_updates             | 8070         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.589        |
|    value_loss            | 0.373        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.38        |
| reward                   | -0.30346015 |
| rollout/                 |             |
|    ep_len_mean           | 669         |
|    ep_rew_mean           | -242        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 554         |
|    total_timesteps       | 1656832     |
| train/                   |             |
|    approx_kl             | 0.00822489  |
|    clip_fraction         | 0.099       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0131      |
|    cost_value_loss       | 3.94e-05    |
|    cost_values           | 0.0132      |
|    entropy               | -1.78       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.231       |
|    n_updates             | 8080        |
|    policy_gradient_loss  | -0.00681    |
|    std                   | 0.591       |
|    value_loss            | 0.665       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.67         |
| reward                   | -0.35605007  |
| rollout/                 |              |
|    ep_len_mean           | 647          |
|    ep_rew_mean           | -231         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 577          |
|    total_timesteps       | 1658880      |
| train/                   |              |
|    approx_kl             | 0.0057852995 |
|    clip_fraction         | 0.0572       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0608       |
|    cost_value_loss       | 0.00112      |
|    cost_values           | 0.0643       |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.669        |
|    n_updates             | 8090         |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.592        |
|    value_loss            | 2.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00747     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00747     |
| reward                   | -0.26000258 |
| rollout/                 |             |
|    ep_len_mean           | 649         |
|    ep_rew_mean           | -232        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 599         |
|    total_timesteps       | 1660928     |
| train/                   |             |
|    approx_kl             | 0.004985895 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00882     |
|    cost_value_loss       | 1.62e-05    |
|    cost_values           | 0.009       |
|    entropy               | -1.77       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.288       |
|    n_updates             | 8100        |
|    policy_gradient_loss  | -0.00263    |
|    std                   | 0.591       |
|    value_loss            | 0.658       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.04        |
| reward                   | -0.4142411  |
| rollout/                 |             |
|    ep_len_mean           | 650         |
|    ep_rew_mean           | -233        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 621         |
|    total_timesteps       | 1662976     |
| train/                   |             |
|    approx_kl             | 0.006454014 |
|    clip_fraction         | 0.0661      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0126     |
|    cost_value_loss       | 3.35e-05    |
|    cost_values           | -0.0126     |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.292       |
|    n_updates             | 8110        |
|    policy_gradient_loss  | -0.00439    |
|    std                   | 0.591       |
|    value_loss            | 0.784       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.36        |
| reward                   | -0.32538763 |
| rollout/                 |             |
|    ep_len_mean           | 659         |
|    ep_rew_mean           | -237        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 643         |
|    total_timesteps       | 1665024     |
| train/                   |             |
|    approx_kl             | 0.005386427 |
|    clip_fraction         | 0.0538      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0105     |
|    cost_value_loss       | 3.48e-05    |
|    cost_values           | -0.0107     |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.4         |
|    n_updates             | 8120        |
|    policy_gradient_loss  | -0.0048     |
|    std                   | 0.591       |
|    value_loss            | 1.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.367        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.367        |
| reward                   | -0.45478994  |
| rollout/                 |              |
|    ep_len_mean           | 667          |
|    ep_rew_mean           | -237         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 665          |
|    total_timesteps       | 1667072      |
| train/                   |              |
|    approx_kl             | 0.0069459644 |
|    clip_fraction         | 0.0705       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0294       |
|    cost_value_loss       | 0.000599     |
|    cost_values           | 0.0302       |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.123        |
|    n_updates             | 8130         |
|    policy_gradient_loss  | -0.00704     |
|    std                   | 0.592        |
|    value_loss            | 0.404        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.256        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.256        |
| reward                   | -0.47537774  |
| rollout/                 |              |
|    ep_len_mean           | 668          |
|    ep_rew_mean           | -234         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 687          |
|    total_timesteps       | 1669120      |
| train/                   |              |
|    approx_kl             | 0.0035966518 |
|    clip_fraction         | 0.0469       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0192      |
|    cost_value_loss       | 2.14e-05     |
|    cost_values           | -0.0193      |
|    entropy               | -1.77        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.138        |
|    n_updates             | 8140         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 0.59         |
|    value_loss            | 0.276        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.314       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.314       |
| reward                   | -0.25198495 |
| rollout/                 |             |
|    ep_len_mean           | 660         |
|    ep_rew_mean           | -233        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 710         |
|    total_timesteps       | 1671168     |
| train/                   |             |
|    approx_kl             | 0.007594024 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00237    |
|    cost_value_loss       | 3.03e-05    |
|    cost_values           | -0.0024     |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.155       |
|    n_updates             | 8150        |
|    policy_gradient_loss  | -0.00617    |
|    std                   | 0.588       |
|    value_loss            | 0.468       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0577      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0577      |
| reward                   | -0.4201121  |
| rollout/                 |             |
|    ep_len_mean           | 656         |
|    ep_rew_mean           | -229        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 732         |
|    total_timesteps       | 1673216     |
| train/                   |             |
|    approx_kl             | 0.009645093 |
|    clip_fraction         | 0.0795      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0152     |
|    cost_value_loss       | 2.42e-05    |
|    cost_values           | -0.0153     |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.155       |
|    n_updates             | 8160        |
|    policy_gradient_loss  | -0.00279    |
|    std                   | 0.591       |
|    value_loss            | 0.342       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.786       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.786       |
| reward                   | -0.3276757  |
| rollout/                 |             |
|    ep_len_mean           | 649         |
|    ep_rew_mean           | -226        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 754         |
|    total_timesteps       | 1675264     |
| train/                   |             |
|    approx_kl             | 0.004151917 |
|    clip_fraction         | 0.0694      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0112      |
|    cost_value_loss       | 1.76e-05    |
|    cost_values           | 0.0115      |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.278       |
|    n_updates             | 8170        |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 0.589       |
|    value_loss            | 0.702       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.198       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.198       |
| reward                   | -0.42255867 |
| rollout/                 |             |
|    ep_len_mean           | 657         |
|    ep_rew_mean           | -227        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 777         |
|    total_timesteps       | 1677312     |
| train/                   |             |
|    approx_kl             | 0.005342479 |
|    clip_fraction         | 0.0436      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00352    |
|    cost_value_loss       | 1.77e-05    |
|    cost_values           | -0.00367    |
|    entropy               | -1.76       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.316       |
|    n_updates             | 8180        |
|    policy_gradient_loss  | -0.00399    |
|    std                   | 0.587       |
|    value_loss            | 0.794       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.35        |
| reward                   | -0.2589997  |
| rollout/                 |             |
|    ep_len_mean           | 654         |
|    ep_rew_mean           | -226        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 799         |
|    total_timesteps       | 1679360     |
| train/                   |             |
|    approx_kl             | 0.006884587 |
|    clip_fraction         | 0.0618      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00434     |
|    cost_value_loss       | 0.000152    |
|    cost_values           | 0.00532     |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.418       |
|    n_updates             | 8190        |
|    policy_gradient_loss  | -0.0048     |
|    std                   | 0.587       |
|    value_loss            | 1.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.482       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.482       |
| reward                   | -0.31184626 |
| rollout/                 |             |
|    ep_len_mean           | 654         |
|    ep_rew_mean           | -225        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 821         |
|    total_timesteps       | 1681408     |
| train/                   |             |
|    approx_kl             | 0.006318641 |
|    clip_fraction         | 0.094       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00333     |
|    cost_value_loss       | 2.72e-05    |
|    cost_values           | 0.0034      |
|    entropy               | -1.77       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.451       |
|    n_updates             | 8200        |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 0.589       |
|    value_loss            | 1.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.406       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.406       |
| reward                   | -0.46313497 |
| rollout/                 |             |
|    ep_len_mean           | 635         |
|    ep_rew_mean           | -223        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 844         |
|    total_timesteps       | 1683456     |
| train/                   |             |
|    approx_kl             | 0.005662846 |
|    clip_fraction         | 0.0621      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00516    |
|    cost_value_loss       | 1.49e-05    |
|    cost_values           | -0.00523    |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.094       |
|    n_updates             | 8210        |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 0.589       |
|    value_loss            | 0.262       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.423       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.423       |
| reward                   | -0.36292866 |
| rollout/                 |             |
|    ep_len_mean           | 636         |
|    ep_rew_mean           | -222        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 866         |
|    total_timesteps       | 1685504     |
| train/                   |             |
|    approx_kl             | 0.009033624 |
|    clip_fraction         | 0.072       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0144     |
|    cost_value_loss       | 2.17e-05    |
|    cost_values           | -0.0144     |
|    entropy               | -1.78       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.418       |
|    n_updates             | 8220        |
|    policy_gradient_loss  | -0.00393    |
|    std                   | 0.591       |
|    value_loss            | 0.717       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.771        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.771        |
| reward                   | -0.39760843  |
| rollout/                 |              |
|    ep_len_mean           | 643          |
|    ep_rew_mean           | -225         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 888          |
|    total_timesteps       | 1687552      |
| train/                   |              |
|    approx_kl             | 0.0053460235 |
|    clip_fraction         | 0.0561       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00953     |
|    cost_value_loss       | 1.81e-05     |
|    cost_values           | -0.0098      |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.031        |
|    n_updates             | 8230         |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.591        |
|    value_loss            | 0.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.552        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.552        |
| reward                   | -0.20268673  |
| rollout/                 |              |
|    ep_len_mean           | 660          |
|    ep_rew_mean           | -232         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 910          |
|    total_timesteps       | 1689600      |
| train/                   |              |
|    approx_kl             | 0.0027100425 |
|    clip_fraction         | 0.0378       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0143      |
|    cost_value_loss       | 1.03e-05     |
|    cost_values           | -0.0144      |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0366       |
|    n_updates             | 8240         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.592        |
|    value_loss            | 0.191        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.382        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.382        |
| reward                   | -0.43367586  |
| rollout/                 |              |
|    ep_len_mean           | 668          |
|    ep_rew_mean           | -232         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 933          |
|    total_timesteps       | 1691648      |
| train/                   |              |
|    approx_kl             | 0.0049875234 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.012       |
|    cost_value_loss       | 1.75e-05     |
|    cost_values           | -0.0127      |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0238       |
|    n_updates             | 8250         |
|    policy_gradient_loss  | -0.00042     |
|    std                   | 0.591        |
|    value_loss            | 0.171        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.243        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.243        |
| reward                   | -0.4771486   |
| rollout/                 |              |
|    ep_len_mean           | 657          |
|    ep_rew_mean           | -229         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 955          |
|    total_timesteps       | 1693696      |
| train/                   |              |
|    approx_kl             | 0.0064816996 |
|    clip_fraction         | 0.0728       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0126      |
|    cost_value_loss       | 1.31e-05     |
|    cost_values           | -0.0127      |
|    entropy               | -1.79        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0656       |
|    n_updates             | 8260         |
|    policy_gradient_loss  | -0.00368     |
|    std                   | 0.595        |
|    value_loss            | 0.141        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.08         |
| reward                   | -0.26367494  |
| rollout/                 |              |
|    ep_len_mean           | 654          |
|    ep_rew_mean           | -227         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 977          |
|    total_timesteps       | 1695744      |
| train/                   |              |
|    approx_kl             | 0.0045164633 |
|    clip_fraction         | 0.0423       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00031     |
|    cost_value_loss       | 1.8e-05      |
|    cost_values           | -0.000301    |
|    entropy               | -1.81        |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0842       |
|    n_updates             | 8270         |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.601        |
|    value_loss            | 0.193        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.201       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.201       |
| reward                   | -0.42559925 |
| rollout/                 |             |
|    ep_len_mean           | 642         |
|    ep_rew_mean           | -224        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 999         |
|    total_timesteps       | 1697792     |
| train/                   |             |
|    approx_kl             | 0.00672918  |
|    clip_fraction         | 0.0632      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00605    |
|    cost_value_loss       | 2.05e-05    |
|    cost_values           | -0.00607    |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0725      |
|    n_updates             | 8280        |
|    policy_gradient_loss  | -0.00485    |
|    std                   | 0.602       |
|    value_loss            | 0.272       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.306       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.306       |
| reward                   | -0.19113055 |
| rollout/                 |             |
|    ep_len_mean           | 642         |
|    ep_rew_mean           | -225        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1021        |
|    total_timesteps       | 1699840     |
| train/                   |             |
|    approx_kl             | 0.00503847  |
|    clip_fraction         | 0.0708      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00668     |
|    cost_value_loss       | 0.000363    |
|    cost_values           | 0.00759     |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.325       |
|    n_updates             | 8290        |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 0.603       |
|    value_loss            | 1.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0316       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0316       |
| reward                   | -0.3636302   |
| rollout/                 |              |
|    ep_len_mean           | 649          |
|    ep_rew_mean           | -226         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1043         |
|    total_timesteps       | 1701888      |
| train/                   |              |
|    approx_kl             | 0.0050399993 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000703    |
|    cost_value_loss       | 2.06e-05     |
|    cost_values           | -0.000535    |
|    entropy               | -1.81        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0227       |
|    n_updates             | 8300         |
|    policy_gradient_loss  | -0.0031      |
|    std                   | 0.602        |
|    value_loss            | 0.119        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.132        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.132        |
| reward                   | -0.39160195  |
| rollout/                 |              |
|    ep_len_mean           | 655          |
|    ep_rew_mean           | -229         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1064         |
|    total_timesteps       | 1703936      |
| train/                   |              |
|    approx_kl             | 0.0030810644 |
|    clip_fraction         | 0.0419       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00166     |
|    cost_value_loss       | 0.000155     |
|    cost_values           | -0.0021      |
|    entropy               | -1.81        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.189        |
|    n_updates             | 8310         |
|    policy_gradient_loss  | -0.00116     |
|    std                   | 0.602        |
|    value_loss            | 0.874        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.115       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.115       |
| reward                   | -0.25704375 |
| rollout/                 |             |
|    ep_len_mean           | 662         |
|    ep_rew_mean           | -232        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1086        |
|    total_timesteps       | 1705984     |
| train/                   |             |
|    approx_kl             | 0.008536518 |
|    clip_fraction         | 0.0958      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0117     |
|    cost_value_loss       | 8.72e-06    |
|    cost_values           | -0.0116     |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0185      |
|    n_updates             | 8320        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.603       |
|    value_loss            | 0.0374      |
------------------------------------------
------------------------------------
| avg_speed          | 0.181       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.181       |
| reward             | -0.51602393 |
| rollout/           |             |
|    ep_len_mean     | 670         |
|    ep_rew_mean     | -235        |
| time/              |             |
|    fps             | 96          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1708032     |
------------------------------------
------------------------------------------
| avg_speed                | 0.146       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.146       |
| reward                   | -0.39042926 |
| rollout/                 |             |
|    ep_len_mean           | 670         |
|    ep_rew_mean           | -236        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 1710080     |
| train/                   |             |
|    approx_kl             | 0.008804031 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00816    |
|    cost_value_loss       | 2.37e-05    |
|    cost_values           | -0.00817    |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.127       |
|    n_updates             | 8340        |
|    policy_gradient_loss  | -0.00773    |
|    std                   | 0.6         |
|    value_loss            | 0.476       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.492       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.492       |
| reward                   | -0.30035502 |
| rollout/                 |             |
|    ep_len_mean           | 661         |
|    ep_rew_mean           | -234        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 1712128     |
| train/                   |             |
|    approx_kl             | 0.006818623 |
|    clip_fraction         | 0.044       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0118      |
|    cost_value_loss       | 0.000245    |
|    cost_values           | 0.0127      |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.162       |
|    n_updates             | 8350        |
|    policy_gradient_loss  | -0.000889   |
|    std                   | 0.601       |
|    value_loss            | 0.897       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.24         |
| reward                   | -0.36218527  |
| rollout/                 |              |
|    ep_len_mean           | 668          |
|    ep_rew_mean           | -234         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 1714176      |
| train/                   |              |
|    approx_kl             | 0.0077974484 |
|    clip_fraction         | 0.073        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00274     |
|    cost_value_loss       | 1.89e-05     |
|    cost_values           | -0.00287     |
|    entropy               | -1.82        |
|    entropy_loss          | -1.81        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.38         |
|    n_updates             | 8360         |
|    policy_gradient_loss  | -0.00416     |
|    std                   | 0.602        |
|    value_loss            | 1.35         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.253        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.253        |
| reward                   | -0.2209559   |
| rollout/                 |              |
|    ep_len_mean           | 669          |
|    ep_rew_mean           | -235         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 1716224      |
| train/                   |              |
|    approx_kl             | 0.0027283183 |
|    clip_fraction         | 0.0241       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00625      |
|    cost_value_loss       | 3.05e-06     |
|    cost_values           | 0.00648      |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0327       |
|    n_updates             | 8370         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.604        |
|    value_loss            | 0.136        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.662       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.662       |
| reward                   | -0.4450787  |
| rollout/                 |             |
|    ep_len_mean           | 656         |
|    ep_rew_mean           | -231        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 1718272     |
| train/                   |             |
|    approx_kl             | 0.007028995 |
|    clip_fraction         | 0.0526      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000339   |
|    cost_value_loss       | 0.000118    |
|    cost_values           | -5.99e-05   |
|    entropy               | -1.82       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.343       |
|    n_updates             | 8380        |
|    policy_gradient_loss  | -0.00432    |
|    std                   | 0.605       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.23468149 |
| rollout/                 |             |
|    ep_len_mean           | 668         |
|    ep_rew_mean           | -236        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 1720320     |
| train/                   |             |
|    approx_kl             | 0.004289895 |
|    clip_fraction         | 0.0336      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0118     |
|    cost_value_loss       | 1.76e-05    |
|    cost_values           | -0.0121     |
|    entropy               | -1.83       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.342       |
|    n_updates             | 8390        |
|    policy_gradient_loss  | -0.00292    |
|    std                   | 0.606       |
|    value_loss            | 1.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.339        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.339        |
| reward                   | -0.29643652  |
| rollout/                 |              |
|    ep_len_mean           | 668          |
|    ep_rew_mean           | -236         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 1722368      |
| train/                   |              |
|    approx_kl             | 0.0072784824 |
|    clip_fraction         | 0.061        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0125      |
|    cost_value_loss       | 8.05e-06     |
|    cost_values           | -0.0125      |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0195       |
|    n_updates             | 8400         |
|    policy_gradient_loss  | -0.0059      |
|    std                   | 0.607        |
|    value_loss            | 0.101        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.697        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.697        |
| reward                   | -0.4989062   |
| rollout/                 |              |
|    ep_len_mean           | 676          |
|    ep_rew_mean           | -237         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 1724416      |
| train/                   |              |
|    approx_kl             | 0.0031550354 |
|    clip_fraction         | 0.0407       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00859     |
|    cost_value_loss       | 5.93e-05     |
|    cost_values           | -0.00922     |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.019        |
|    n_updates             | 8410         |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 0.606        |
|    value_loss            | 0.0819       |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.548        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.548        |
| reward                   | -0.36675945  |
| rollout/                 |              |
|    ep_len_mean           | 675          |
|    ep_rew_mean           | -239         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 220          |
|    total_timesteps       | 1726464      |
| train/                   |              |
|    approx_kl             | 0.0039625824 |
|    clip_fraction         | 0.0476       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0178       |
|    cost_value_loss       | 3.43e-05     |
|    cost_values           | 0.0187       |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0327       |
|    n_updates             | 8420         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.606        |
|    value_loss            | 0.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.104       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.104       |
| reward                   | -0.34985375 |
| rollout/                 |             |
|    ep_len_mean           | 689         |
|    ep_rew_mean           | -243        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 242         |
|    total_timesteps       | 1728512     |
| train/                   |             |
|    approx_kl             | 0.008409286 |
|    clip_fraction         | 0.0927      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00421     |
|    cost_value_loss       | 2.1e-05     |
|    cost_values           | 0.00374     |
|    entropy               | -1.82       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.126       |
|    n_updates             | 8430        |
|    policy_gradient_loss  | -0.00606    |
|    std                   | 0.603       |
|    value_loss            | 0.226       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.697       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.697       |
| reward                   | -0.3790959  |
| rollout/                 |             |
|    ep_len_mean           | 681         |
|    ep_rew_mean           | -239        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 264         |
|    total_timesteps       | 1730560     |
| train/                   |             |
|    approx_kl             | 0.005395645 |
|    clip_fraction         | 0.0715      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00852     |
|    cost_value_loss       | 1.13e-05    |
|    cost_values           | 0.00866     |
|    entropy               | -1.81       |
|    entropy_loss          | -1.82       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0433      |
|    n_updates             | 8440        |
|    policy_gradient_loss  | -0.00382    |
|    std                   | 0.601       |
|    value_loss            | 0.128       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.643       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.643       |
| reward                   | -0.31491682 |
| rollout/                 |             |
|    ep_len_mean           | 675         |
|    ep_rew_mean           | -236        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 286         |
|    total_timesteps       | 1732608     |
| train/                   |             |
|    approx_kl             | 0.011711605 |
|    clip_fraction         | 0.0928      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0112      |
|    cost_value_loss       | 1.05e-05    |
|    cost_values           | 0.0114      |
|    entropy               | -1.8        |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.1         |
|    n_updates             | 8450        |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 0.598       |
|    value_loss            | 0.226       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.397        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.397        |
| reward                   | -0.17807049  |
| rollout/                 |              |
|    ep_len_mean           | 667          |
|    ep_rew_mean           | -232         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 14           |
|    time_elapsed          | 308          |
|    total_timesteps       | 1734656      |
| train/                   |              |
|    approx_kl             | 0.0067167827 |
|    clip_fraction         | 0.0754       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00104      |
|    cost_value_loss       | 1.39e-05     |
|    cost_values           | 0.00098      |
|    entropy               | -1.8         |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.293        |
|    n_updates             | 8460         |
|    policy_gradient_loss  | -0.00438     |
|    std                   | 0.596        |
|    value_loss            | 0.678        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.67        |
| reward                   | -0.25977212 |
| rollout/                 |             |
|    ep_len_mean           | 661         |
|    ep_rew_mean           | -230        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 15          |
|    time_elapsed          | 330         |
|    total_timesteps       | 1736704     |
| train/                   |             |
|    approx_kl             | 0.00448235  |
|    clip_fraction         | 0.074       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00364     |
|    cost_value_loss       | 1.76e-05    |
|    cost_values           | 0.00371     |
|    entropy               | -1.8        |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0726      |
|    n_updates             | 8470        |
|    policy_gradient_loss  | -0.0047     |
|    std                   | 0.596       |
|    value_loss            | 0.307       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.18         |
| reward                   | -0.22828183  |
| rollout/                 |              |
|    ep_len_mean           | 662          |
|    ep_rew_mean           | -229         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 16           |
|    time_elapsed          | 352          |
|    total_timesteps       | 1738752      |
| train/                   |              |
|    approx_kl             | 0.0046231253 |
|    clip_fraction         | 0.0511       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00592      |
|    cost_value_loss       | 1.09e-05     |
|    cost_values           | 0.00603      |
|    entropy               | -1.79        |
|    entropy_loss          | -1.8         |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.233        |
|    n_updates             | 8480         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.595        |
|    value_loss            | 0.501        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.236       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.236       |
| reward                   | -0.16821368 |
| rollout/                 |             |
|    ep_len_mean           | 669         |
|    ep_rew_mean           | -230        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 17          |
|    time_elapsed          | 374         |
|    total_timesteps       | 1740800     |
| train/                   |             |
|    approx_kl             | 0.006382973 |
|    clip_fraction         | 0.049       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000843    |
|    cost_value_loss       | 1.5e-05     |
|    cost_values           | 0.000842    |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.225       |
|    n_updates             | 8490        |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.595       |
|    value_loss            | 0.538       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.37        |
| reward                   | -0.27003393 |
| rollout/                 |             |
|    ep_len_mean           | 684         |
|    ep_rew_mean           | -234        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 18          |
|    time_elapsed          | 396         |
|    total_timesteps       | 1742848     |
| train/                   |             |
|    approx_kl             | 0.007859727 |
|    clip_fraction         | 0.0523      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00201     |
|    cost_value_loss       | 1.23e-05    |
|    cost_values           | 0.00199     |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.145       |
|    n_updates             | 8500        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.595       |
|    value_loss            | 0.531       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.946       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.946       |
| reward                   | -0.20576422 |
| rollout/                 |             |
|    ep_len_mean           | 684         |
|    ep_rew_mean           | -234        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 418         |
|    total_timesteps       | 1744896     |
| train/                   |             |
|    approx_kl             | 0.005306529 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00362     |
|    cost_value_loss       | 1.02e-05    |
|    cost_values           | 0.00364     |
|    entropy               | -1.79       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.356       |
|    n_updates             | 8510        |
|    policy_gradient_loss  | -0.0018     |
|    std                   | 0.594       |
|    value_loss            | 0.931       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.149        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.149        |
| reward                   | -0.3096252   |
| rollout/                 |              |
|    ep_len_mean           | 676          |
|    ep_rew_mean           | -231         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 440          |
|    total_timesteps       | 1746944      |
| train/                   |              |
|    approx_kl             | 0.0066475086 |
|    clip_fraction         | 0.0738       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0017       |
|    cost_value_loss       | 9.67e-06     |
|    cost_values           | 0.00166      |
|    entropy               | -1.78        |
|    entropy_loss          | -1.79        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.177        |
|    n_updates             | 8520         |
|    policy_gradient_loss  | -0.00428     |
|    std                   | 0.592        |
|    value_loss            | 0.423        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.613       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.613       |
| reward                   | -0.23530588 |
| rollout/                 |             |
|    ep_len_mean           | 669         |
|    ep_rew_mean           | -229        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 462         |
|    total_timesteps       | 1748992     |
| train/                   |             |
|    approx_kl             | 0.007276032 |
|    clip_fraction         | 0.0716      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00758     |
|    cost_value_loss       | 0.000172    |
|    cost_values           | 0.00818     |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.774       |
|    n_updates             | 8530        |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 0.591       |
|    value_loss            | 2.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.398       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.398       |
| reward                   | -0.39055178 |
| rollout/                 |             |
|    ep_len_mean           | 689         |
|    ep_rew_mean           | -234        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 485         |
|    total_timesteps       | 1751040     |
| train/                   |             |
|    approx_kl             | 0.00439522  |
|    clip_fraction         | 0.0416      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00126     |
|    cost_value_loss       | 1.5e-05     |
|    cost_values           | 0.0014      |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.234       |
|    n_updates             | 8540        |
|    policy_gradient_loss  | -0.00503    |
|    std                   | 0.592       |
|    value_loss            | 0.747       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.521       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.521       |
| reward                   | -0.41894147 |
| rollout/                 |             |
|    ep_len_mean           | 687         |
|    ep_rew_mean           | -231        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 507         |
|    total_timesteps       | 1753088     |
| train/                   |             |
|    approx_kl             | 0.008356227 |
|    clip_fraction         | 0.0933      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00393     |
|    cost_value_loss       | 1.17e-05    |
|    cost_values           | 0.00393     |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.121       |
|    n_updates             | 8550        |
|    policy_gradient_loss  | -0.00796    |
|    std                   | 0.592       |
|    value_loss            | 0.332       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.794       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.794       |
| reward                   | -0.2900341  |
| rollout/                 |             |
|    ep_len_mean           | 672         |
|    ep_rew_mean           | -226        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 529         |
|    total_timesteps       | 1755136     |
| train/                   |             |
|    approx_kl             | 0.004610272 |
|    clip_fraction         | 0.0445      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00396    |
|    cost_value_loss       | 1.35e-05    |
|    cost_values           | -0.00414    |
|    entropy               | -1.78       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0864      |
|    n_updates             | 8560        |
|    policy_gradient_loss  | -0.00235    |
|    std                   | 0.591       |
|    value_loss            | 0.396       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.194       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.194       |
| reward                   | -0.2360352  |
| rollout/                 |             |
|    ep_len_mean           | 668         |
|    ep_rew_mean           | -225        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 552         |
|    total_timesteps       | 1757184     |
| train/                   |             |
|    approx_kl             | 0.008651286 |
|    clip_fraction         | 0.096       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0038     |
|    cost_value_loss       | 1.57e-05    |
|    cost_values           | -0.00375    |
|    entropy               | -1.77       |
|    entropy_loss          | -1.78       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.333       |
|    n_updates             | 8570        |
|    policy_gradient_loss  | -0.00556    |
|    std                   | 0.589       |
|    value_loss            | 0.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.268       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.268       |
| reward                   | -0.2849603  |
| rollout/                 |             |
|    ep_len_mean           | 665         |
|    ep_rew_mean           | -222        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 574         |
|    total_timesteps       | 1759232     |
| train/                   |             |
|    approx_kl             | 0.004828212 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0039      |
|    cost_value_loss       | 1.12e-05    |
|    cost_values           | 0.00389     |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.176       |
|    n_updates             | 8580        |
|    policy_gradient_loss  | -0.00212    |
|    std                   | 0.588       |
|    value_loss            | 0.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.17         |
| reward                   | -0.46572614  |
| rollout/                 |              |
|    ep_len_mean           | 672          |
|    ep_rew_mean           | -225         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 596          |
|    total_timesteps       | 1761280      |
| train/                   |              |
|    approx_kl             | 0.0037289227 |
|    clip_fraction         | 0.0498       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00207      |
|    cost_value_loss       | 1.23e-05     |
|    cost_values           | 0.0022       |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.128        |
|    n_updates             | 8590         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.588        |
|    value_loss            | 0.436        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.125        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.125        |
| reward                   | -0.23545074  |
| rollout/                 |              |
|    ep_len_mean           | 672          |
|    ep_rew_mean           | -226         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 618          |
|    total_timesteps       | 1763328      |
| train/                   |              |
|    approx_kl             | 0.0037337136 |
|    clip_fraction         | 0.0291       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000197    |
|    cost_value_loss       | 3.55e-05     |
|    cost_values           | -0.00177     |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.18         |
|    n_updates             | 8600         |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 0.588        |
|    value_loss            | 1.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.399       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.399       |
| reward                   | -0.3382029  |
| rollout/                 |             |
|    ep_len_mean           | 665         |
|    ep_rew_mean           | -221        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 641         |
|    total_timesteps       | 1765376     |
| train/                   |             |
|    approx_kl             | 0.010660378 |
|    clip_fraction         | 0.0617      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0156      |
|    cost_value_loss       | 0.000116    |
|    cost_values           | 0.0161      |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0913      |
|    n_updates             | 8610        |
|    policy_gradient_loss  | -0.00551    |
|    std                   | 0.588       |
|    value_loss            | 0.426       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.11         |
| reward                   | -0.16677481  |
| rollout/                 |              |
|    ep_len_mean           | 665          |
|    ep_rew_mean           | -223         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 663          |
|    total_timesteps       | 1767424      |
| train/                   |              |
|    approx_kl             | 0.0038652015 |
|    clip_fraction         | 0.0583       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000506     |
|    cost_value_loss       | 1.86e-05     |
|    cost_values           | 0.000511     |
|    entropy               | -1.76        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.283        |
|    n_updates             | 8620         |
|    policy_gradient_loss  | -0.001       |
|    std                   | 0.587        |
|    value_loss            | 0.764        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.339        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.339        |
| reward                   | -0.20314585  |
| rollout/                 |              |
|    ep_len_mean           | 657          |
|    ep_rew_mean           | -216         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 686          |
|    total_timesteps       | 1769472      |
| train/                   |              |
|    approx_kl             | 0.0059973085 |
|    clip_fraction         | 0.0479       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00437      |
|    cost_value_loss       | 9.6e-06      |
|    cost_values           | 0.00441      |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0271       |
|    n_updates             | 8630         |
|    policy_gradient_loss  | -0.00186     |
|    std                   | 0.586        |
|    value_loss            | 0.0672       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.135       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.135       |
| reward                   | -0.42229077 |
| rollout/                 |             |
|    ep_len_mean           | 648         |
|    ep_rew_mean           | -212        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 708         |
|    total_timesteps       | 1771520     |
| train/                   |             |
|    approx_kl             | 0.007651048 |
|    clip_fraction         | 0.0516      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00075    |
|    cost_value_loss       | 1.08e-05    |
|    cost_values           | -0.000654   |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.29        |
|    n_updates             | 8640        |
|    policy_gradient_loss  | -0.00191    |
|    std                   | 0.586       |
|    value_loss            | 0.621       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.64        |
| reward                   | -0.43238097 |
| rollout/                 |             |
|    ep_len_mean           | 654         |
|    ep_rew_mean           | -214        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 730         |
|    total_timesteps       | 1773568     |
| train/                   |             |
|    approx_kl             | 0.005776568 |
|    clip_fraction         | 0.0804      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000355   |
|    cost_value_loss       | 1.38e-05    |
|    cost_values           | -0.000372   |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.165       |
|    n_updates             | 8650        |
|    policy_gradient_loss  | -0.00337    |
|    std                   | 0.586       |
|    value_loss            | 0.402       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.705       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.705       |
| reward                   | -0.44530994 |
| rollout/                 |             |
|    ep_len_mean           | 650         |
|    ep_rew_mean           | -211        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 753         |
|    total_timesteps       | 1775616     |
| train/                   |             |
|    approx_kl             | 0.009087654 |
|    clip_fraction         | 0.0928      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000615    |
|    cost_value_loss       | 1.61e-05    |
|    cost_values           | 0.000694    |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.0389      |
|    n_updates             | 8660        |
|    policy_gradient_loss  | -0.00507    |
|    std                   | 0.584       |
|    value_loss            | 0.113       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.14        |
| reward                   | -0.53878385 |
| rollout/                 |             |
|    ep_len_mean           | 648         |
|    ep_rew_mean           | -211        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 775         |
|    total_timesteps       | 1777664     |
| train/                   |             |
|    approx_kl             | 0.007728231 |
|    clip_fraction         | 0.0703      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000762   |
|    cost_value_loss       | 1.55e-05    |
|    cost_values           | -0.000812   |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.284       |
|    n_updates             | 8670        |
|    policy_gradient_loss  | -0.0042     |
|    std                   | 0.583       |
|    value_loss            | 0.614       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0428       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0428       |
| reward                   | -0.23979641  |
| rollout/                 |              |
|    ep_len_mean           | 637          |
|    ep_rew_mean           | -208         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 797          |
|    total_timesteps       | 1779712      |
| train/                   |              |
|    approx_kl             | 0.0066700545 |
|    clip_fraction         | 0.0499       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00164      |
|    cost_value_loss       | 1.03e-05     |
|    cost_values           | 0.00171      |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.146        |
|    n_updates             | 8680         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 0.581        |
|    value_loss            | 0.361        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.726        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.726        |
| reward                   | -0.14702314  |
| rollout/                 |              |
|    ep_len_mean           | 633          |
|    ep_rew_mean           | -207         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 819          |
|    total_timesteps       | 1781760      |
| train/                   |              |
|    approx_kl             | 0.0074318657 |
|    clip_fraction         | 0.0813       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0012       |
|    cost_value_loss       | 1.58e-05     |
|    cost_values           | 0.00126      |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.127        |
|    n_updates             | 8690         |
|    policy_gradient_loss  | -0.00402     |
|    std                   | 0.581        |
|    value_loss            | 0.282        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.698       |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 0.698       |
| reward                   | -0.1083224  |
| rollout/                 |             |
|    ep_len_mean           | 638         |
|    ep_rew_mean           | -207        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 842         |
|    total_timesteps       | 1783808     |
| train/                   |             |
|    approx_kl             | 0.006312415 |
|    clip_fraction         | 0.0926      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00233    |
|    cost_value_loss       | 1.88e-05    |
|    cost_values           | -0.00253    |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.202       |
|    n_updates             | 8700        |
|    policy_gradient_loss  | -0.0051     |
|    std                   | 0.582       |
|    value_loss            | 0.503       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.35        |
| reward                   | -0.32659724 |
| rollout/                 |             |
|    ep_len_mean           | 619         |
|    ep_rew_mean           | -200        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 864         |
|    total_timesteps       | 1785856     |
| train/                   |             |
|    approx_kl             | 0.006419724 |
|    clip_fraction         | 0.0822      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00191     |
|    cost_value_loss       | 2.07e-05    |
|    cost_values           | 0.00189     |
|    entropy               | -1.74       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.142       |
|    n_updates             | 8710        |
|    policy_gradient_loss  | -0.00511    |
|    std                   | 0.58        |
|    value_loss            | 0.368       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.868       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.868       |
| reward                   | -0.39456907 |
| rollout/                 |             |
|    ep_len_mean           | 619         |
|    ep_rew_mean           | -199        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 887         |
|    total_timesteps       | 1787904     |
| train/                   |             |
|    approx_kl             | 0.00718485  |
|    clip_fraction         | 0.0414      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00768    |
|    cost_value_loss       | 1.7e-05     |
|    cost_values           | -0.00783    |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.353       |
|    n_updates             | 8720        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.581       |
|    value_loss            | 1.32        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.572        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.572        |
| reward                   | -0.2267357   |
| rollout/                 |              |
|    ep_len_mean           | 619          |
|    ep_rew_mean           | -199         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 909          |
|    total_timesteps       | 1789952      |
| train/                   |              |
|    approx_kl             | 0.0036800117 |
|    clip_fraction         | 0.0416       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.012        |
|    cost_value_loss       | 0.000155     |
|    cost_values           | 0.0125       |
|    entropy               | -1.74        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.246        |
|    n_updates             | 8730         |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 0.58         |
|    value_loss            | 0.921        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.06         |
| reward                   | -0.2592537   |
| rollout/                 |              |
|    ep_len_mean           | 623          |
|    ep_rew_mean           | -200         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 931          |
|    total_timesteps       | 1792000      |
| train/                   |              |
|    approx_kl             | 0.0025812543 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00337      |
|    cost_value_loss       | 1.77e-05     |
|    cost_values           | 0.00324      |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0.967        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.331        |
|    n_updates             | 8740         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.578        |
|    value_loss            | 0.968        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.995        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.995        |
| reward                   | -0.23298661  |
| rollout/                 |              |
|    ep_len_mean           | 623          |
|    ep_rew_mean           | -200         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 953          |
|    total_timesteps       | 1794048      |
| train/                   |              |
|    approx_kl             | 0.0054188897 |
|    clip_fraction         | 0.0634       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00341      |
|    cost_value_loss       | 2.33e-05     |
|    cost_values           | 0.00358      |
|    entropy               | -1.73        |
|    entropy_loss          | -1.73        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.25         |
|    n_updates             | 8750         |
|    policy_gradient_loss  | -0.00487     |
|    std                   | 0.577        |
|    value_loss            | 0.835        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.643       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.643       |
| reward                   | -0.43128124 |
| rollout/                 |             |
|    ep_len_mean           | 615         |
|    ep_rew_mean           | -197        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 975         |
|    total_timesteps       | 1796096     |
| train/                   |             |
|    approx_kl             | 0.006444061 |
|    clip_fraction         | 0.0885      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00286     |
|    cost_value_loss       | 3.01e-05    |
|    cost_values           | 0.00282     |
|    entropy               | -1.72       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.269       |
|    n_updates             | 8760        |
|    policy_gradient_loss  | -0.00654    |
|    std                   | 0.574       |
|    value_loss            | 0.856       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.175       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.175       |
| reward                   | -0.2415381  |
| rollout/                 |             |
|    ep_len_mean           | 623         |
|    ep_rew_mean           | -199        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 997         |
|    total_timesteps       | 1798144     |
| train/                   |             |
|    approx_kl             | 0.006512909 |
|    clip_fraction         | 0.0773      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00282    |
|    cost_value_loss       | 5.38e-05    |
|    cost_values           | -0.00283    |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.593       |
|    n_updates             | 8770        |
|    policy_gradient_loss  | -0.00607    |
|    std                   | 0.573       |
|    value_loss            | 1.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.15        |
| reward                   | -0.35157815 |
| rollout/                 |             |
|    ep_len_mean           | 607         |
|    ep_rew_mean           | -194        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1020        |
|    total_timesteps       | 1800192     |
| train/                   |             |
|    approx_kl             | 0.010290949 |
|    clip_fraction         | 0.0932      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00273    |
|    cost_value_loss       | 1.99e-05    |
|    cost_values           | -0.00272    |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.355       |
|    n_updates             | 8780        |
|    policy_gradient_loss  | -0.00517    |
|    std                   | 0.573       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0285      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0285      |
| reward                   | -0.24645594 |
| rollout/                 |             |
|    ep_len_mean           | 603         |
|    ep_rew_mean           | -193        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1042        |
|    total_timesteps       | 1802240     |
| train/                   |             |
|    approx_kl             | 0.007770665 |
|    clip_fraction         | 0.0583      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00254    |
|    cost_value_loss       | 1.72e-05    |
|    cost_values           | -0.00267    |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.37        |
|    n_updates             | 8790        |
|    policy_gradient_loss  | -0.00443    |
|    std                   | 0.572       |
|    value_loss            | 0.985       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.27        |
| reward                   | -0.17233835 |
| rollout/                 |             |
|    ep_len_mean           | 590         |
|    ep_rew_mean           | -191        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1064        |
|    total_timesteps       | 1804288     |
| train/                   |             |
|    approx_kl             | 0.006575171 |
|    clip_fraction         | 0.0567      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00078     |
|    cost_value_loss       | 1.16e-05    |
|    cost_values           | 0.000794    |
|    entropy               | -1.71       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.324       |
|    n_updates             | 8800        |
|    policy_gradient_loss  | -0.00196    |
|    std                   | 0.571       |
|    value_loss            | 0.757       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.34034124 |
| rollout/                 |             |
|    ep_len_mean           | 596         |
|    ep_rew_mean           | -191        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1086        |
|    total_timesteps       | 1806336     |
| train/                   |             |
|    approx_kl             | 0.007770764 |
|    clip_fraction         | 0.0881      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00246    |
|    cost_value_loss       | 1.54e-05    |
|    cost_values           | -0.00242    |
|    entropy               | -1.71       |
|    entropy_loss          | -1.71       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.303       |
|    n_updates             | 8810        |
|    policy_gradient_loss  | -0.00479    |
|    std                   | 0.57        |
|    value_loss            | 0.846       |
------------------------------------------
------------------------------------
| avg_speed          | 0.89        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.89        |
| reward             | -0.25823608 |
| rollout/           |             |
|    ep_len_mean     | 587         |
|    ep_rew_mean     | -189        |
| time/              |             |
|    fps             | 94          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1808384     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.964        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.964        |
| reward                   | -0.23830308  |
| rollout/                 |              |
|    ep_len_mean           | 580          |
|    ep_rew_mean           | -187         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 1810432      |
| train/                   |              |
|    approx_kl             | 0.0048674583 |
|    clip_fraction         | 0.0731       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00345     |
|    cost_value_loss       | 8.33e-06     |
|    cost_values           | -0.00348     |
|    entropy               | -1.72        |
|    entropy_loss          | -1.72        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.158        |
|    n_updates             | 8830         |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 0.572        |
|    value_loss            | 0.408        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.769        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.769        |
| reward                   | -0.16477709  |
| rollout/                 |              |
|    ep_len_mean           | 579          |
|    ep_rew_mean           | -187         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 1812480      |
| train/                   |              |
|    approx_kl             | 0.0041901567 |
|    clip_fraction         | 0.0257       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00163     |
|    cost_value_loss       | 8.88e-06     |
|    cost_values           | -0.00184     |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.353        |
|    n_updates             | 8840         |
|    policy_gradient_loss  | -0.00143     |
|    std                   | 0.57         |
|    value_loss            | 0.827        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.03        |
| reward                   | -0.3816384  |
| rollout/                 |             |
|    ep_len_mean           | 590         |
|    ep_rew_mean           | -191        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 1814528     |
| train/                   |             |
|    approx_kl             | 0.004106231 |
|    clip_fraction         | 0.0832      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000579   |
|    cost_value_loss       | 8.85e-06    |
|    cost_values           | -0.000587   |
|    entropy               | -1.7        |
|    entropy_loss          | -1.71       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.105       |
|    n_updates             | 8850        |
|    policy_gradient_loss  | -0.004      |
|    std                   | 0.568       |
|    value_loss            | 0.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.843        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.843        |
| reward                   | -0.31581703  |
| rollout/                 |              |
|    ep_len_mean           | 580          |
|    ep_rew_mean           | -189         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 1816576      |
| train/                   |              |
|    approx_kl             | 0.0058726165 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000398     |
|    cost_value_loss       | 1.27e-05     |
|    cost_values           | 0.000354     |
|    entropy               | -1.69        |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.133        |
|    n_updates             | 8860         |
|    policy_gradient_loss  | -0.00228     |
|    std                   | 0.565        |
|    value_loss            | 0.294        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.754        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.754        |
| reward                   | -0.37151468  |
| rollout/                 |              |
|    ep_len_mean           | 567          |
|    ep_rew_mean           | -183         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 6            |
|    time_elapsed          | 131          |
|    total_timesteps       | 1818624      |
| train/                   |              |
|    approx_kl             | 0.0052619586 |
|    clip_fraction         | 0.0592       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000178     |
|    cost_value_loss       | 1.14e-05     |
|    cost_values           | 0.000205     |
|    entropy               | -1.7         |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.145        |
|    n_updates             | 8870         |
|    policy_gradient_loss  | -0.00333     |
|    std                   | 0.567        |
|    value_loss            | 0.35         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.958       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.958       |
| reward                   | -0.17772934 |
| rollout/                 |             |
|    ep_len_mean           | 563         |
|    ep_rew_mean           | -182        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 1820672     |
| train/                   |             |
|    approx_kl             | 0.006268803 |
|    clip_fraction         | 0.0677      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000875   |
|    cost_value_loss       | 1.2e-05     |
|    cost_values           | -0.000904   |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.211       |
|    n_updates             | 8880        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.568       |
|    value_loss            | 0.454       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.827        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.827        |
| reward                   | -0.39474997  |
| rollout/                 |              |
|    ep_len_mean           | 560          |
|    ep_rew_mean           | -178         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 1822720      |
| train/                   |              |
|    approx_kl             | 0.0044637504 |
|    clip_fraction         | 0.0392       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00204      |
|    cost_value_loss       | 1.4e-05      |
|    cost_values           | 0.00209      |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.242        |
|    n_updates             | 8890         |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 0.566        |
|    value_loss            | 0.729        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.404        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.404        |
| reward                   | -0.25996628  |
| rollout/                 |              |
|    ep_len_mean           | 548          |
|    ep_rew_mean           | -176         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 1824768      |
| train/                   |              |
|    approx_kl             | 0.0042511234 |
|    clip_fraction         | 0.0187       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000561    |
|    cost_value_loss       | 2.28e-05     |
|    cost_values           | -0.000564    |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.366        |
|    n_updates             | 8900         |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.565        |
|    value_loss            | 1.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00286     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00286     |
| reward                   | -0.28568697 |
| rollout/                 |             |
|    ep_len_mean           | 534         |
|    ep_rew_mean           | -170        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 1826816     |
| train/                   |             |
|    approx_kl             | 0.006053538 |
|    clip_fraction         | 0.0683      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000658   |
|    cost_value_loss       | 1.04e-05    |
|    cost_values           | -0.00062    |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.275       |
|    n_updates             | 8910        |
|    policy_gradient_loss  | -0.00379    |
|    std                   | 0.563       |
|    value_loss            | 0.576       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.15        |
| reward                   | -0.39515838 |
| rollout/                 |             |
|    ep_len_mean           | 521         |
|    ep_rew_mean           | -165        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 1828864     |
| train/                   |             |
|    approx_kl             | 0.010794991 |
|    clip_fraction         | 0.0518      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0019     |
|    cost_value_loss       | 1.14e-05    |
|    cost_values           | -0.00193    |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.322       |
|    n_updates             | 8920        |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.564       |
|    value_loss            | 0.985       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.577       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.577       |
| reward                   | -0.3605273  |
| rollout/                 |             |
|    ep_len_mean           | 521         |
|    ep_rew_mean           | -165        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 1830912     |
| train/                   |             |
|    approx_kl             | 0.009328246 |
|    clip_fraction         | 0.0903      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000643   |
|    cost_value_loss       | 2.08e-05    |
|    cost_values           | -0.000595   |
|    entropy               | -1.68       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.298       |
|    n_updates             | 8930        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.563       |
|    value_loss            | 0.779       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.89        |
| reward                   | -0.24066769 |
| rollout/                 |             |
|    ep_len_mean           | 507         |
|    ep_rew_mean           | -161        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 287         |
|    total_timesteps       | 1832960     |
| train/                   |             |
|    approx_kl             | 0.011630801 |
|    clip_fraction         | 0.0952      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00208    |
|    cost_value_loss       | 1.34e-05    |
|    cost_values           | -0.00215    |
|    entropy               | -1.68       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.295       |
|    n_updates             | 8940        |
|    policy_gradient_loss  | -0.00611    |
|    std                   | 0.56        |
|    value_loss            | 0.708       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.393       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.393       |
| reward                   | -0.35484505 |
| rollout/                 |             |
|    ep_len_mean           | 474         |
|    ep_rew_mean           | -147        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 1835008     |
| train/                   |             |
|    approx_kl             | 0.004952387 |
|    clip_fraction         | 0.059       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00393    |
|    cost_value_loss       | 1.19e-05    |
|    cost_values           | -0.00414    |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.393       |
|    n_updates             | 8950        |
|    policy_gradient_loss  | -0.00389    |
|    std                   | 0.56        |
|    value_loss            | 1.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.182        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.182        |
| reward                   | -0.25760868  |
| rollout/                 |              |
|    ep_len_mean           | 476          |
|    ep_rew_mean           | -147         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 332          |
|    total_timesteps       | 1837056      |
| train/                   |              |
|    approx_kl             | 0.0056429664 |
|    clip_fraction         | 0.0432       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00393     |
|    cost_value_loss       | 8.52e-06     |
|    cost_values           | -0.00398     |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.668        |
|    n_updates             | 8960         |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 0.559        |
|    value_loss            | 1.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.2          |
| reward                   | -0.30161265  |
| rollout/                 |              |
|    ep_len_mean           | 457          |
|    ep_rew_mean           | -141         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 354          |
|    total_timesteps       | 1839104      |
| train/                   |              |
|    approx_kl             | 0.0059777014 |
|    clip_fraction         | 0.0474       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00555     |
|    cost_value_loss       | 1.77e-05     |
|    cost_values           | -0.00567     |
|    entropy               | -1.66        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.485        |
|    n_updates             | 8970         |
|    policy_gradient_loss  | -0.00422     |
|    std                   | 0.557        |
|    value_loss            | 1.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.24        |
| reward                   | -0.18146287 |
| rollout/                 |             |
|    ep_len_mean           | 448         |
|    ep_rew_mean           | -139        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 377         |
|    total_timesteps       | 1841152     |
| train/                   |             |
|    approx_kl             | 0.005809564 |
|    clip_fraction         | 0.0526      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00144    |
|    cost_value_loss       | 1.57e-05    |
|    cost_values           | -0.00144    |
|    entropy               | -1.65       |
|    entropy_loss          | -1.66       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.333       |
|    n_updates             | 8980        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.555       |
|    value_loss            | 0.771       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.27        |
| reward                   | -0.38220438 |
| rollout/                 |             |
|    ep_len_mean           | 444         |
|    ep_rew_mean           | -138        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 399         |
|    total_timesteps       | 1843200     |
| train/                   |             |
|    approx_kl             | 0.008698779 |
|    clip_fraction         | 0.0691      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.001       |
|    cost_value_loss       | 2.15e-05    |
|    cost_values           | 0.00102     |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.44        |
|    n_updates             | 8990        |
|    policy_gradient_loss  | -0.00626    |
|    std                   | 0.553       |
|    value_loss            | 0.848       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.272        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.272        |
| reward                   | -0.39657837  |
| rollout/                 |              |
|    ep_len_mean           | 449          |
|    ep_rew_mean           | -141         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 421          |
|    total_timesteps       | 1845248      |
| train/                   |              |
|    approx_kl             | 0.0028699506 |
|    clip_fraction         | 0.0374       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000376     |
|    cost_value_loss       | 2.4e-05      |
|    cost_values           | 0.00044      |
|    entropy               | -1.64        |
|    entropy_loss          | -1.65        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.38         |
|    n_updates             | 9000         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.551        |
|    value_loss            | 0.988        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.13         |
| reward                   | -0.8012078   |
| rollout/                 |              |
|    ep_len_mean           | 455          |
|    ep_rew_mean           | -143         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 443          |
|    total_timesteps       | 1847296      |
| train/                   |              |
|    approx_kl             | 0.0077642924 |
|    clip_fraction         | 0.057        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00657      |
|    cost_value_loss       | 9.27e-05     |
|    cost_values           | 0.00684      |
|    entropy               | -1.64        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.358        |
|    n_updates             | 9010         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.55         |
|    value_loss            | 1.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.3          |
| reward                   | -0.25555208  |
| rollout/                 |              |
|    ep_len_mean           | 460          |
|    ep_rew_mean           | -148         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 464          |
|    total_timesteps       | 1849344      |
| train/                   |              |
|    approx_kl             | 0.0067927064 |
|    clip_fraction         | 0.082        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00171      |
|    cost_value_loss       | 6.14e-05     |
|    cost_values           | 0.00205      |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.502        |
|    n_updates             | 9020         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.548        |
|    value_loss            | 1.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.6          |
| reward                   | -0.50874305  |
| rollout/                 |              |
|    ep_len_mean           | 453          |
|    ep_rew_mean           | -146         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 486          |
|    total_timesteps       | 1851392      |
| train/                   |              |
|    approx_kl             | 0.0043702214 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00979      |
|    cost_value_loss       | 6.32e-05     |
|    cost_values           | 0.00991      |
|    entropy               | -1.63        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.6          |
|    n_updates             | 9030         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.547        |
|    value_loss            | 1.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.34         |
| reward                   | -0.32271945  |
| rollout/                 |              |
|    ep_len_mean           | 449          |
|    ep_rew_mean           | -144         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 508          |
|    total_timesteps       | 1853440      |
| train/                   |              |
|    approx_kl             | 0.0059323874 |
|    clip_fraction         | 0.055        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000864     |
|    cost_value_loss       | 9.11e-06     |
|    cost_values           | 0.000919     |
|    entropy               | -1.62        |
|    entropy_loss          | -1.63        |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.726        |
|    n_updates             | 9040         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.546        |
|    value_loss            | 1.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.19         |
| reward                   | -0.38621762  |
| rollout/                 |              |
|    ep_len_mean           | 445          |
|    ep_rew_mean           | -144         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 531          |
|    total_timesteps       | 1855488      |
| train/                   |              |
|    approx_kl             | 0.0067927926 |
|    clip_fraction         | 0.0501       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00457      |
|    cost_value_loss       | 1.93e-05     |
|    cost_values           | 0.00461      |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.801        |
|    n_updates             | 9050         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.546        |
|    value_loss            | 1.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.89        |
| reward                   | -0.24935576 |
| rollout/                 |             |
|    ep_len_mean           | 429         |
|    ep_rew_mean           | -137        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 553         |
|    total_timesteps       | 1857536     |
| train/                   |             |
|    approx_kl             | 0.006492686 |
|    clip_fraction         | 0.0699      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000354    |
|    cost_value_loss       | 1.23e-05    |
|    cost_values           | 0.000369    |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.338       |
|    n_updates             | 9060        |
|    policy_gradient_loss  | -0.00353    |
|    std                   | 0.547       |
|    value_loss            | 0.902       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.42        |
| reward                   | -0.46920723 |
| rollout/                 |             |
|    ep_len_mean           | 428         |
|    ep_rew_mean           | -136        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 575         |
|    total_timesteps       | 1859584     |
| train/                   |             |
|    approx_kl             | 0.004999429 |
|    clip_fraction         | 0.0329      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00346    |
|    cost_value_loss       | 1.01e-05    |
|    cost_values           | -0.00348    |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.801       |
|    n_updates             | 9070        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.547       |
|    value_loss            | 1.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.14        |
| reward                   | -0.51423526 |
| rollout/                 |             |
|    ep_len_mean           | 439         |
|    ep_rew_mean           | -142        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 597         |
|    total_timesteps       | 1861632     |
| train/                   |             |
|    approx_kl             | 0.008280896 |
|    clip_fraction         | 0.0923      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0036      |
|    cost_value_loss       | 2.46e-05    |
|    cost_values           | 0.00376     |
|    entropy               | -1.62       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.52        |
|    n_updates             | 9080        |
|    policy_gradient_loss  | -0.00505    |
|    std                   | 0.547       |
|    value_loss            | 1.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.386        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.386        |
| reward                   | -0.26962352  |
| rollout/                 |              |
|    ep_len_mean           | 440          |
|    ep_rew_mean           | -143         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 619          |
|    total_timesteps       | 1863680      |
| train/                   |              |
|    approx_kl             | 0.0052769543 |
|    clip_fraction         | 0.0535       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00297      |
|    cost_value_loss       | 6.45e-05     |
|    cost_values           | 0.00336      |
|    entropy               | -1.62        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.271        |
|    n_updates             | 9090         |
|    policy_gradient_loss  | -0.00297     |
|    std                   | 0.546        |
|    value_loss            | 1.38         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.39097545 |
| rollout/                 |             |
|    ep_len_mean           | 422         |
|    ep_rew_mean           | -138        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 641         |
|    total_timesteps       | 1865728     |
| train/                   |             |
|    approx_kl             | 0.004574476 |
|    clip_fraction         | 0.0532      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000791    |
|    cost_value_loss       | 1.57e-05    |
|    cost_values           | 0.000641    |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.37        |
|    n_updates             | 9100        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.544       |
|    value_loss            | 0.902       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0652      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0652      |
| reward                   | -0.3623581  |
| rollout/                 |             |
|    ep_len_mean           | 426         |
|    ep_rew_mean           | -142        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 663         |
|    total_timesteps       | 1867776     |
| train/                   |             |
|    approx_kl             | 0.007313175 |
|    clip_fraction         | 0.0702      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00432     |
|    cost_value_loss       | 2e-05       |
|    cost_values           | 0.00432     |
|    entropy               | -1.6        |
|    entropy_loss          | -1.61       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.299       |
|    n_updates             | 9110        |
|    policy_gradient_loss  | -0.00555    |
|    std                   | 0.54        |
|    value_loss            | 0.762       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.191        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.191        |
| reward                   | -0.3330026   |
| rollout/                 |              |
|    ep_len_mean           | 424          |
|    ep_rew_mean           | -140         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 686          |
|    total_timesteps       | 1869824      |
| train/                   |              |
|    approx_kl             | 0.0064276066 |
|    clip_fraction         | 0.0409       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00456      |
|    cost_value_loss       | 4.51e-05     |
|    cost_values           | 0.00462      |
|    entropy               | -1.59        |
|    entropy_loss          | -1.6         |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.439        |
|    n_updates             | 9120         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.538        |
|    value_loss            | 1.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.351        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.351        |
| reward                   | -0.28522494  |
| rollout/                 |              |
|    ep_len_mean           | 421          |
|    ep_rew_mean           | -140         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 708          |
|    total_timesteps       | 1871872      |
| train/                   |              |
|    approx_kl             | 0.0052167084 |
|    clip_fraction         | 0.0526       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00184      |
|    cost_value_loss       | 8.22e-06     |
|    cost_values           | 0.00194      |
|    entropy               | -1.58        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.571        |
|    n_updates             | 9130         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.535        |
|    value_loss            | 1.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.36        |
| reward                   | -0.17297813 |
| rollout/                 |             |
|    ep_len_mean           | 421         |
|    ep_rew_mean           | -140        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 730         |
|    total_timesteps       | 1873920     |
| train/                   |             |
|    approx_kl             | 0.012380219 |
|    clip_fraction         | 0.0786      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00164     |
|    cost_value_loss       | 1.16e-05    |
|    cost_values           | 0.00165     |
|    entropy               | -1.57       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.293       |
|    n_updates             | 9140        |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 0.532       |
|    value_loss            | 0.732       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.113        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.113        |
| reward                   | -0.47125867  |
| rollout/                 |              |
|    ep_len_mean           | 426          |
|    ep_rew_mean           | -143         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 752          |
|    total_timesteps       | 1875968      |
| train/                   |              |
|    approx_kl             | 0.0062081814 |
|    clip_fraction         | 0.0534       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00466      |
|    cost_value_loss       | 3.02e-05     |
|    cost_values           | 0.0047       |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.292        |
|    n_updates             | 9150         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.531        |
|    value_loss            | 0.652        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.86         |
| reward                   | -0.25507578  |
| rollout/                 |              |
|    ep_len_mean           | 437          |
|    ep_rew_mean           | -148         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 774          |
|    total_timesteps       | 1878016      |
| train/                   |              |
|    approx_kl             | 0.0060512135 |
|    clip_fraction         | 0.0789       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00399      |
|    cost_value_loss       | 5.06e-05     |
|    cost_values           | 0.00446      |
|    entropy               | -1.57        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.579        |
|    n_updates             | 9160         |
|    policy_gradient_loss  | -0.00359     |
|    std                   | 0.532        |
|    value_loss            | 1.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.341       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.341       |
| reward                   | -0.337692   |
| rollout/                 |             |
|    ep_len_mean           | 428         |
|    ep_rew_mean           | -146        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 797         |
|    total_timesteps       | 1880064     |
| train/                   |             |
|    approx_kl             | 0.006898073 |
|    clip_fraction         | 0.0692      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00423     |
|    cost_value_loss       | 1.4e-05     |
|    cost_values           | 0.00421     |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.224       |
|    n_updates             | 9170        |
|    policy_gradient_loss  | -0.00354    |
|    std                   | 0.531       |
|    value_loss            | 0.588       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.55         |
| reward                   | -0.19852458  |
| rollout/                 |              |
|    ep_len_mean           | 424          |
|    ep_rew_mean           | -144         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 819          |
|    total_timesteps       | 1882112      |
| train/                   |              |
|    approx_kl             | 0.0047032405 |
|    clip_fraction         | 0.063        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00302      |
|    cost_value_loss       | 1.14e-05     |
|    cost_values           | 0.00315      |
|    entropy               | -1.56        |
|    entropy_loss          | -1.57        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.419        |
|    n_updates             | 9180         |
|    policy_gradient_loss  | -0.00282     |
|    std                   | 0.53         |
|    value_loss            | 1.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.235       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.235       |
| reward                   | -0.5071813  |
| rollout/                 |             |
|    ep_len_mean           | 437         |
|    ep_rew_mean           | -149        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 841         |
|    total_timesteps       | 1884160     |
| train/                   |             |
|    approx_kl             | 0.006857205 |
|    clip_fraction         | 0.0795      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000317    |
|    cost_value_loss       | 1.31e-05    |
|    cost_values           | 0.000259    |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.697       |
|    n_updates             | 9190        |
|    policy_gradient_loss  | -0.00597    |
|    std                   | 0.529       |
|    value_loss            | 1.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.431       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.431       |
| reward                   | -0.4073827  |
| rollout/                 |             |
|    ep_len_mean           | 440         |
|    ep_rew_mean           | -153        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 863         |
|    total_timesteps       | 1886208     |
| train/                   |             |
|    approx_kl             | 0.008102117 |
|    clip_fraction         | 0.0569      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00862     |
|    cost_value_loss       | 1.63e-05    |
|    cost_values           | 0.00889     |
|    entropy               | -1.56       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.293       |
|    n_updates             | 9200        |
|    policy_gradient_loss  | -0.00264    |
|    std                   | 0.529       |
|    value_loss            | 1.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.838        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.838        |
| reward                   | -0.20482843  |
| rollout/                 |              |
|    ep_len_mean           | 440          |
|    ep_rew_mean           | -152         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 885          |
|    total_timesteps       | 1888256      |
| train/                   |              |
|    approx_kl             | 0.0051913504 |
|    clip_fraction         | 0.0744       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00753      |
|    cost_value_loss       | 6.26e-05     |
|    cost_values           | 0.00781      |
|    entropy               | -1.55        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.623        |
|    n_updates             | 9210         |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.528        |
|    value_loss            | 2.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.54        |
| reward                   | -0.34637937 |
| rollout/                 |             |
|    ep_len_mean           | 422         |
|    ep_rew_mean           | -143        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 908         |
|    total_timesteps       | 1890304     |
| train/                   |             |
|    approx_kl             | 0.007528547 |
|    clip_fraction         | 0.0616      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00113    |
|    cost_value_loss       | 9.72e-06    |
|    cost_values           | -0.00113    |
|    entropy               | -1.55       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.854       |
|    n_updates             | 9220        |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.528       |
|    value_loss            | 1.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.643       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.643       |
| reward                   | -0.4461111  |
| rollout/                 |             |
|    ep_len_mean           | 409         |
|    ep_rew_mean           | -138        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 929         |
|    total_timesteps       | 1892352     |
| train/                   |             |
|    approx_kl             | 0.008211306 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00268     |
|    cost_value_loss       | 1.22e-05    |
|    cost_values           | 0.00265     |
|    entropy               | -1.55       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.337       |
|    n_updates             | 9230        |
|    policy_gradient_loss  | -0.00679    |
|    std                   | 0.527       |
|    value_loss            | 0.828       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0279      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0279      |
| reward                   | -0.17977932 |
| rollout/                 |             |
|    ep_len_mean           | 416         |
|    ep_rew_mean           | -141        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 951         |
|    total_timesteps       | 1894400     |
| train/                   |             |
|    approx_kl             | 0.004932124 |
|    clip_fraction         | 0.057       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00111    |
|    cost_value_loss       | 7.68e-06    |
|    cost_values           | -0.00112    |
|    entropy               | -1.54       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.522       |
|    n_updates             | 9240        |
|    policy_gradient_loss  | -0.00022    |
|    std                   | 0.525       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.3740891  |
| rollout/                 |             |
|    ep_len_mean           | 411         |
|    ep_rew_mean           | -138        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 973         |
|    total_timesteps       | 1896448     |
| train/                   |             |
|    approx_kl             | 0.006109356 |
|    clip_fraction         | 0.0542      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000973   |
|    cost_value_loss       | 2.9e-05     |
|    cost_values           | -0.000933   |
|    entropy               | -1.54       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.689       |
|    n_updates             | 9250        |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 0.524       |
|    value_loss            | 1.83        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.57         |
| reward                   | -0.38489184  |
| rollout/                 |              |
|    ep_len_mean           | 412          |
|    ep_rew_mean           | -140         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 995          |
|    total_timesteps       | 1898496      |
| train/                   |              |
|    approx_kl             | 0.0038822591 |
|    clip_fraction         | 0.0559       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000922    |
|    cost_value_loss       | 7.33e-06     |
|    cost_values           | -0.000837    |
|    entropy               | -1.54        |
|    entropy_loss          | -1.54        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.532        |
|    n_updates             | 9260         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.522        |
|    value_loss            | 1.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.115       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.115       |
| reward                   | -0.35694328 |
| rollout/                 |             |
|    ep_len_mean           | 418         |
|    ep_rew_mean           | -143        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1017        |
|    total_timesteps       | 1900544     |
| train/                   |             |
|    approx_kl             | 0.00490069  |
|    clip_fraction         | 0.0684      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000293   |
|    cost_value_loss       | 5.27e-06    |
|    cost_values           | -0.000272   |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.389       |
|    n_updates             | 9270        |
|    policy_gradient_loss  | -0.0042     |
|    std                   | 0.522       |
|    value_loss            | 0.912       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.38        |
| reward                   | -0.25444615 |
| rollout/                 |             |
|    ep_len_mean           | 397         |
|    ep_rew_mean           | -133        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1039        |
|    total_timesteps       | 1902592     |
| train/                   |             |
|    approx_kl             | 0.007837534 |
|    clip_fraction         | 0.0846      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0017     |
|    cost_value_loss       | 2.61e-05    |
|    cost_values           | -0.00158    |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.292       |
|    n_updates             | 9280        |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 0.522       |
|    value_loss            | 1.04        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.21       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.21       |
| reward                   | -0.4770646 |
| rollout/                 |            |
|    ep_len_mean           | 401        |
|    ep_rew_mean           | -134       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 48         |
|    time_elapsed          | 1061       |
|    total_timesteps       | 1904640    |
| train/                   |            |
|    approx_kl             | 0.0071494  |
|    clip_fraction         | 0.0806     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.0068     |
|    cost_value_loss       | 2.16e-05   |
|    cost_values           | 0.00692    |
|    entropy               | -1.53      |
|    entropy_loss          | -1.53      |
|    explained_variance    | 0.989      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.483      |
|    n_updates             | 9290       |
|    policy_gradient_loss  | -0.00293   |
|    std                   | 0.52       |
|    value_loss            | 0.987      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.878       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.878       |
| reward                   | -0.28195375 |
| rollout/                 |             |
|    ep_len_mean           | 394         |
|    ep_rew_mean           | -131        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1084        |
|    total_timesteps       | 1906688     |
| train/                   |             |
|    approx_kl             | 0.009198754 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00082     |
|    cost_value_loss       | 6.16e-06    |
|    cost_values           | 0.000823    |
|    entropy               | -1.52       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.392       |
|    n_updates             | 9300        |
|    policy_gradient_loss  | -0.00662    |
|    std                   | 0.518       |
|    value_loss            | 0.863       |
------------------------------------------
------------------------------------
| avg_speed          | 1.07        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 1.07        |
| reward             | -0.18209472 |
| rollout/           |             |
|    ep_len_mean     | 392         |
|    ep_rew_mean     | -131        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 1908736     |
------------------------------------
------------------------------------------
| avg_speed                | 0.0187      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0187      |
| reward                   | -0.21789354 |
| rollout/                 |             |
|    ep_len_mean           | 394         |
|    ep_rew_mean           | -131        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 1910784     |
| train/                   |             |
|    approx_kl             | 0.005291404 |
|    clip_fraction         | 0.0711      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00142    |
|    cost_value_loss       | 4.08e-06    |
|    cost_values           | -0.00149    |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.358       |
|    n_updates             | 9320        |
|    policy_gradient_loss  | -0.00292    |
|    std                   | 0.516       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00912     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00912     |
| reward                   | -0.38003036 |
| rollout/                 |             |
|    ep_len_mean           | 397         |
|    ep_rew_mean           | -131        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 1912832     |
| train/                   |             |
|    approx_kl             | 0.005290428 |
|    clip_fraction         | 0.0734      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00143     |
|    cost_value_loss       | 8.03e-06    |
|    cost_values           | 0.00133     |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.239       |
|    n_updates             | 9330        |
|    policy_gradient_loss  | -0.0039     |
|    std                   | 0.516       |
|    value_loss            | 0.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.493       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.493       |
| reward                   | -0.37868536 |
| rollout/                 |             |
|    ep_len_mean           | 389         |
|    ep_rew_mean           | -127        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 1914880     |
| train/                   |             |
|    approx_kl             | 0.009310266 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00243     |
|    cost_value_loss       | 1.04e-05    |
|    cost_values           | 0.00241     |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.168       |
|    n_updates             | 9340        |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 0.516       |
|    value_loss            | 0.379       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.5          |
| reward                   | -0.34552258  |
| rollout/                 |              |
|    ep_len_mean           | 382          |
|    ep_rew_mean           | -124         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 1916928      |
| train/                   |              |
|    approx_kl             | 0.0069392775 |
|    clip_fraction         | 0.0777       |
|    clip_range            | 0.2          |
|    cost_returns          | -4.41e-05    |
|    cost_value_loss       | 1.53e-05     |
|    cost_values           | -9.85e-05    |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.387        |
|    n_updates             | 9350         |
|    policy_gradient_loss  | -0.00358     |
|    std                   | 0.516        |
|    value_loss            | 0.824        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.07        |
| reward                   | -0.39103335 |
| rollout/                 |             |
|    ep_len_mean           | 386         |
|    ep_rew_mean           | -127        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 1918976     |
| train/                   |             |
|    approx_kl             | 0.009155326 |
|    clip_fraction         | 0.0838      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0012     |
|    cost_value_loss       | 7.9e-06     |
|    cost_values           | -0.00123    |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.255       |
|    n_updates             | 9360        |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 0.514       |
|    value_loss            | 0.618       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.38466504 |
| rollout/                 |             |
|    ep_len_mean           | 379         |
|    ep_rew_mean           | -125        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 1921024     |
| train/                   |             |
|    approx_kl             | 0.007685502 |
|    clip_fraction         | 0.068       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00766     |
|    cost_value_loss       | 6.81e-05    |
|    cost_values           | 0.00808     |
|    entropy               | -1.49       |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.39        |
|    n_updates             | 9370        |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 0.512       |
|    value_loss            | 1.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.09         |
| reward                   | -0.4594634   |
| rollout/                 |              |
|    ep_len_mean           | 364          |
|    ep_rew_mean           | -117         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 177          |
|    total_timesteps       | 1923072      |
| train/                   |              |
|    approx_kl             | 0.0055710897 |
|    clip_fraction         | 0.0612       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00628      |
|    cost_value_loss       | 1.84e-05     |
|    cost_values           | 0.00634      |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.303        |
|    n_updates             | 9380         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 0.513        |
|    value_loss            | 0.768        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.635       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.635       |
| reward                   | -0.29215223 |
| rollout/                 |             |
|    ep_len_mean           | 368         |
|    ep_rew_mean           | -121        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 199         |
|    total_timesteps       | 1925120     |
| train/                   |             |
|    approx_kl             | 0.006150375 |
|    clip_fraction         | 0.087       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00388     |
|    cost_value_loss       | 1.41e-05    |
|    cost_values           | 0.00392     |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.644       |
|    n_updates             | 9390        |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.515       |
|    value_loss            | 1.58        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.31         |
| reward                   | -0.36181372  |
| rollout/                 |              |
|    ep_len_mean           | 371          |
|    ep_rew_mean           | -124         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 221          |
|    total_timesteps       | 1927168      |
| train/                   |              |
|    approx_kl             | 0.0085171955 |
|    clip_fraction         | 0.0879       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0119       |
|    cost_value_loss       | 4.05e-05     |
|    cost_values           | 0.012        |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.283        |
|    n_updates             | 9400         |
|    policy_gradient_loss  | -0.00573     |
|    std                   | 0.516        |
|    value_loss            | 0.668        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.51         |
| reward                   | -0.33060807  |
| rollout/                 |              |
|    ep_len_mean           | 373          |
|    ep_rew_mean           | -124         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 244          |
|    total_timesteps       | 1929216      |
| train/                   |              |
|    approx_kl             | 0.0076789497 |
|    clip_fraction         | 0.0991       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00514      |
|    cost_value_loss       | 3.2e-05      |
|    cost_values           | 0.00497      |
|    entropy               | -1.51        |
|    entropy_loss          | -1.51        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.846        |
|    n_updates             | 9410         |
|    policy_gradient_loss  | -0.00462     |
|    std                   | 0.516        |
|    value_loss            | 1.75         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 1.59       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.59       |
| reward                   | -0.2953922 |
| rollout/                 |            |
|    ep_len_mean           | 366        |
|    ep_rew_mean           | -121       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 12         |
|    time_elapsed          | 266        |
|    total_timesteps       | 1931264    |
| train/                   |            |
|    approx_kl             | 0.00957473 |
|    clip_fraction         | 0.0897     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00133    |
|    cost_value_loss       | 1.03e-05   |
|    cost_values           | 0.00139    |
|    entropy               | -1.5       |
|    entropy_loss          | -1.51      |
|    explained_variance    | 0.983      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.434      |
|    n_updates             | 9420       |
|    policy_gradient_loss  | -0.00491   |
|    std                   | 0.515      |
|    value_loss            | 1.08       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 1.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.29         |
| reward                   | -0.683213    |
| rollout/                 |              |
|    ep_len_mean           | 364          |
|    ep_rew_mean           | -121         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 288          |
|    total_timesteps       | 1933312      |
| train/                   |              |
|    approx_kl             | 0.0070676534 |
|    clip_fraction         | 0.0625       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00255      |
|    cost_value_loss       | 1.78e-05     |
|    cost_values           | 0.00247      |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.866        |
|    n_updates             | 9430         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 0.515        |
|    value_loss            | 1.72         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.19         |
| reward                   | -0.19698898  |
| rollout/                 |              |
|    ep_len_mean           | 365          |
|    ep_rew_mean           | -123         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 311          |
|    total_timesteps       | 1935360      |
| train/                   |              |
|    approx_kl             | 0.0069510853 |
|    clip_fraction         | 0.0858       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00217      |
|    cost_value_loss       | 2.82e-05     |
|    cost_values           | 0.00245      |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.04         |
|    n_updates             | 9440         |
|    policy_gradient_loss  | -0.0062      |
|    std                   | 0.514        |
|    value_loss            | 2.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.21         |
| reward                   | -0.19402878  |
| rollout/                 |              |
|    ep_len_mean           | 361          |
|    ep_rew_mean           | -120         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 333          |
|    total_timesteps       | 1937408      |
| train/                   |              |
|    approx_kl             | 0.0063181818 |
|    clip_fraction         | 0.0396       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00379      |
|    cost_value_loss       | 1.27e-05     |
|    cost_values           | 0.00383      |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.872        |
|    n_updates             | 9450         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.513        |
|    value_loss            | 2.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.595       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.595       |
| reward                   | -0.44347537 |
| rollout/                 |             |
|    ep_len_mean           | 362         |
|    ep_rew_mean           | -121        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 355         |
|    total_timesteps       | 1939456     |
| train/                   |             |
|    approx_kl             | 0.005950187 |
|    clip_fraction         | 0.0249      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000985   |
|    cost_value_loss       | 6.05e-06    |
|    cost_values           | -0.001      |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.629       |
|    n_updates             | 9460        |
|    policy_gradient_loss  | -0.00151    |
|    std                   | 0.514       |
|    value_loss            | 1.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.42        |
| reward                   | -0.34468275 |
| rollout/                 |             |
|    ep_len_mean           | 361         |
|    ep_rew_mean           | -119        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 377         |
|    total_timesteps       | 1941504     |
| train/                   |             |
|    approx_kl             | 0.005088896 |
|    clip_fraction         | 0.0521      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00224     |
|    cost_value_loss       | 1.69e-05    |
|    cost_values           | 0.00224     |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.694       |
|    n_updates             | 9470        |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.513       |
|    value_loss            | 1.6         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.788        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.788        |
| reward                   | -0.39803758  |
| rollout/                 |              |
|    ep_len_mean           | 358          |
|    ep_rew_mean           | -119         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 399          |
|    total_timesteps       | 1943552      |
| train/                   |              |
|    approx_kl             | 0.0074082557 |
|    clip_fraction         | 0.0832       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000209    |
|    cost_value_loss       | 1.21e-05     |
|    cost_values           | -0.000284    |
|    entropy               | -1.49        |
|    entropy_loss          | -1.49        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.338        |
|    n_updates             | 9480         |
|    policy_gradient_loss  | -0.0053      |
|    std                   | 0.511        |
|    value_loss            | 0.834        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.341       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.341       |
| reward                   | -0.33686417 |
| rollout/                 |             |
|    ep_len_mean           | 347         |
|    ep_rew_mean           | -116        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 421         |
|    total_timesteps       | 1945600     |
| train/                   |             |
|    approx_kl             | 0.008030551 |
|    clip_fraction         | 0.0609      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000131    |
|    cost_value_loss       | 7.05e-06    |
|    cost_values           | 6.16e-05    |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.382       |
|    n_updates             | 9490        |
|    policy_gradient_loss  | -0.00229    |
|    std                   | 0.508       |
|    value_loss            | 0.843       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.35        |
| reward                   | -0.4316854  |
| rollout/                 |             |
|    ep_len_mean           | 339         |
|    ep_rew_mean           | -113        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 443         |
|    total_timesteps       | 1947648     |
| train/                   |             |
|    approx_kl             | 0.003413008 |
|    clip_fraction         | 0.0528      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000447   |
|    cost_value_loss       | 9.29e-06    |
|    cost_values           | -0.000341   |
|    entropy               | -1.47       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.362       |
|    n_updates             | 9500        |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.507       |
|    value_loss            | 0.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.33        |
| reward                   | -0.38063452 |
| rollout/                 |             |
|    ep_len_mean           | 342         |
|    ep_rew_mean           | -115        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 466         |
|    total_timesteps       | 1949696     |
| train/                   |             |
|    approx_kl             | 0.008873936 |
|    clip_fraction         | 0.09        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000461    |
|    cost_value_loss       | 1.56e-05    |
|    cost_values           | 0.000489    |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.402       |
|    n_updates             | 9510        |
|    policy_gradient_loss  | -0.00495    |
|    std                   | 0.506       |
|    value_loss            | 0.885       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.936        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.936        |
| reward                   | -0.32083115  |
| rollout/                 |              |
|    ep_len_mean           | 338          |
|    ep_rew_mean           | -112         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 488          |
|    total_timesteps       | 1951744      |
| train/                   |              |
|    approx_kl             | 0.0068764966 |
|    clip_fraction         | 0.0836       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00036      |
|    cost_value_loss       | 1.03e-05     |
|    cost_values           | 0.000385     |
|    entropy               | -1.46        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.184        |
|    n_updates             | 9520         |
|    policy_gradient_loss  | -0.00163     |
|    std                   | 0.504        |
|    value_loss            | 0.512        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.895        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.895        |
| reward                   | -0.37664357  |
| rollout/                 |              |
|    ep_len_mean           | 338          |
|    ep_rew_mean           | -112         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 510          |
|    total_timesteps       | 1953792      |
| train/                   |              |
|    approx_kl             | 0.0069700475 |
|    clip_fraction         | 0.0752       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000521    |
|    cost_value_loss       | 8.36e-06     |
|    cost_values           | -0.000492    |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.347        |
|    n_updates             | 9530         |
|    policy_gradient_loss  | -0.00417     |
|    std                   | 0.504        |
|    value_loss            | 0.698        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.4          |
| reward                   | -0.18826357  |
| rollout/                 |              |
|    ep_len_mean           | 338          |
|    ep_rew_mean           | -112         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 533          |
|    total_timesteps       | 1955840      |
| train/                   |              |
|    approx_kl             | 0.0052410536 |
|    clip_fraction         | 0.0524       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.98e-05     |
|    cost_value_loss       | 9.99e-06     |
|    cost_values           | 0.000133     |
|    entropy               | -1.46        |
|    entropy_loss          | -1.46        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.282        |
|    n_updates             | 9540         |
|    policy_gradient_loss  | -0.00311     |
|    std                   | 0.504        |
|    value_loss            | 0.802        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.103       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.103       |
| reward                   | -0.48567894 |
| rollout/                 |             |
|    ep_len_mean           | 338         |
|    ep_rew_mean           | -111        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 555         |
|    total_timesteps       | 1957888     |
| train/                   |             |
|    approx_kl             | 0.004755859 |
|    clip_fraction         | 0.0361      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00138    |
|    cost_value_loss       | 4.68e-06    |
|    cost_values           | -0.00144    |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.323       |
|    n_updates             | 9550        |
|    policy_gradient_loss  | -0.00284    |
|    std                   | 0.503       |
|    value_loss            | 0.796       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.41        |
| reward                   | -0.34417668 |
| rollout/                 |             |
|    ep_len_mean           | 333         |
|    ep_rew_mean           | -107        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 577         |
|    total_timesteps       | 1959936     |
| train/                   |             |
|    approx_kl             | 0.007946076 |
|    clip_fraction         | 0.0519      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00687     |
|    cost_value_loss       | 4.09e-05    |
|    cost_values           | 0.00686     |
|    entropy               | -1.45       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.511       |
|    n_updates             | 9560        |
|    policy_gradient_loss  | -0.00197    |
|    std                   | 0.502       |
|    value_loss            | 1.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.31        |
| reward                   | -0.47309035 |
| rollout/                 |             |
|    ep_len_mean           | 331         |
|    ep_rew_mean           | -108        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 600         |
|    total_timesteps       | 1961984     |
| train/                   |             |
|    approx_kl             | 0.00565576  |
|    clip_fraction         | 0.053       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000695   |
|    cost_value_loss       | 5.45e-06    |
|    cost_values           | -0.000697   |
|    entropy               | -1.44       |
|    entropy_loss          | -1.45       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.302       |
|    n_updates             | 9570        |
|    policy_gradient_loss  | -0.00226    |
|    std                   | 0.499       |
|    value_loss            | 0.754       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.36        |
| reward                   | -0.24392074 |
| rollout/                 |             |
|    ep_len_mean           | 331         |
|    ep_rew_mean           | -108        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 622         |
|    total_timesteps       | 1964032     |
| train/                   |             |
|    approx_kl             | 0.011751082 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00131     |
|    cost_value_loss       | 1.1e-05     |
|    cost_values           | 0.00131     |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.163       |
|    n_updates             | 9580        |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 0.498       |
|    value_loss            | 0.489       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.71         |
| reward                   | -0.27194527  |
| rollout/                 |              |
|    ep_len_mean           | 337          |
|    ep_rew_mean           | -111         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 29           |
|    time_elapsed          | 645          |
|    total_timesteps       | 1966080      |
| train/                   |              |
|    approx_kl             | 0.0078001134 |
|    clip_fraction         | 0.0707       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00111      |
|    cost_value_loss       | 8.65e-06     |
|    cost_values           | 0.00123      |
|    entropy               | -1.43        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.216        |
|    n_updates             | 9590         |
|    policy_gradient_loss  | -0.00369     |
|    std                   | 0.495        |
|    value_loss            | 0.584        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.229       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.229       |
| reward                   | -0.32617027 |
| rollout/                 |             |
|    ep_len_mean           | 334         |
|    ep_rew_mean           | -108        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 667         |
|    total_timesteps       | 1968128     |
| train/                   |             |
|    approx_kl             | 0.005671253 |
|    clip_fraction         | 0.0864      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00793     |
|    cost_value_loss       | 2.91e-05    |
|    cost_values           | 0.00798     |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.336       |
|    n_updates             | 9600        |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 0.495       |
|    value_loss            | 1.37        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1            |
| reward                   | -0.50210375  |
| rollout/                 |              |
|    ep_len_mean           | 342          |
|    ep_rew_mean           | -111         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 689          |
|    total_timesteps       | 1970176      |
| train/                   |              |
|    approx_kl             | 0.0067633954 |
|    clip_fraction         | 0.0793       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00125      |
|    cost_value_loss       | 4.62e-06     |
|    cost_values           | 0.00161      |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.277        |
|    n_updates             | 9610         |
|    policy_gradient_loss  | -0.00349     |
|    std                   | 0.496        |
|    value_loss            | 0.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.23         |
| reward                   | -0.25316066  |
| rollout/                 |              |
|    ep_len_mean           | 348          |
|    ep_rew_mean           | -112         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 712          |
|    total_timesteps       | 1972224      |
| train/                   |              |
|    approx_kl             | 0.0068864296 |
|    clip_fraction         | 0.067        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000348     |
|    cost_value_loss       | 4.02e-06     |
|    cost_values           | 0.000357     |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.509        |
|    n_updates             | 9620         |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 0.496        |
|    value_loss            | 1.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.754       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.754       |
| reward                   | -0.23393656 |
| rollout/                 |             |
|    ep_len_mean           | 346         |
|    ep_rew_mean           | -111        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 734         |
|    total_timesteps       | 1974272     |
| train/                   |             |
|    approx_kl             | 0.003950308 |
|    clip_fraction         | 0.0353      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000686   |
|    cost_value_loss       | 4.93e-06    |
|    cost_values           | -0.0012     |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.353       |
|    n_updates             | 9630        |
|    policy_gradient_loss  | -0.00111    |
|    std                   | 0.495       |
|    value_loss            | 1.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.955        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.955        |
| reward                   | -0.42142555  |
| rollout/                 |              |
|    ep_len_mean           | 345          |
|    ep_rew_mean           | -111         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 756          |
|    total_timesteps       | 1976320      |
| train/                   |              |
|    approx_kl             | 0.0068814973 |
|    clip_fraction         | 0.0971       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000472    |
|    cost_value_loss       | 3e-06        |
|    cost_values           | -0.000467    |
|    entropy               | -1.43        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.328        |
|    n_updates             | 9640         |
|    policy_gradient_loss  | -0.00403     |
|    std                   | 0.496        |
|    value_loss            | 0.675        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.145        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.145        |
| reward                   | -0.21036449  |
| rollout/                 |              |
|    ep_len_mean           | 344          |
|    ep_rew_mean           | -110         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 778          |
|    total_timesteps       | 1978368      |
| train/                   |              |
|    approx_kl             | 0.0077833286 |
|    clip_fraction         | 0.0764       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000176    |
|    cost_value_loss       | 7.54e-06     |
|    cost_values           | -0.000155    |
|    entropy               | -1.44        |
|    entropy_loss          | -1.43        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.192        |
|    n_updates             | 9650         |
|    policy_gradient_loss  | -0.00349     |
|    std                   | 0.497        |
|    value_loss            | 0.628        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.832       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.832       |
| reward                   | -0.8284415  |
| rollout/                 |             |
|    ep_len_mean           | 348         |
|    ep_rew_mean           | -110        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 800         |
|    total_timesteps       | 1980416     |
| train/                   |             |
|    approx_kl             | 0.013181269 |
|    clip_fraction         | 0.0926      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000529    |
|    cost_value_loss       | 4.51e-06    |
|    cost_values           | 0.000548    |
|    entropy               | -1.43       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.449       |
|    n_updates             | 9660        |
|    policy_gradient_loss  | -0.00547    |
|    std                   | 0.497       |
|    value_loss            | 1.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.802       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.802       |
| reward                   | -0.35011303 |
| rollout/                 |             |
|    ep_len_mean           | 359         |
|    ep_rew_mean           | -115        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 822         |
|    total_timesteps       | 1982464     |
| train/                   |             |
|    approx_kl             | 0.012145092 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00537     |
|    cost_value_loss       | 2.37e-05    |
|    cost_values           | 0.00544     |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.49        |
|    n_updates             | 9670        |
|    policy_gradient_loss  | -0.00389    |
|    std                   | 0.495       |
|    value_loss            | 1.6         |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.57       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.57       |
| reward                   | -0.2077017 |
| rollout/                 |            |
|    ep_len_mean           | 359        |
|    ep_rew_mean           | -114       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 38         |
|    time_elapsed          | 845        |
|    total_timesteps       | 1984512    |
| train/                   |            |
|    approx_kl             | 0.00478579 |
|    clip_fraction         | 0.0477     |
|    clip_range            | 0.2        |
|    cost_returns          | -0.000189  |
|    cost_value_loss       | 7.05e-06   |
|    cost_values           | -0.000259  |
|    entropy               | -1.42      |
|    entropy_loss          | -1.43      |
|    explained_variance    | 0.986      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.567      |
|    n_updates             | 9680       |
|    policy_gradient_loss  | -0.00308   |
|    std                   | 0.494      |
|    value_loss            | 1.37       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.24        |
| reward                   | -0.26755586 |
| rollout/                 |             |
|    ep_len_mean           | 363         |
|    ep_rew_mean           | -114        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 867         |
|    total_timesteps       | 1986560     |
| train/                   |             |
|    approx_kl             | 0.00748266  |
|    clip_fraction         | 0.097       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.36e-05    |
|    cost_value_loss       | 3.17e-06    |
|    cost_values           | 1.99e-05    |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.568       |
|    n_updates             | 9690        |
|    policy_gradient_loss  | -0.00725    |
|    std                   | 0.493       |
|    value_loss            | 1.24        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.364        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.364        |
| reward                   | -0.2389222   |
| rollout/                 |              |
|    ep_len_mean           | 366          |
|    ep_rew_mean           | -115         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 889          |
|    total_timesteps       | 1988608      |
| train/                   |              |
|    approx_kl             | 0.0037350622 |
|    clip_fraction         | 0.0436       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00134     |
|    cost_value_loss       | 2.2e-06      |
|    cost_values           | -0.00146     |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.539        |
|    n_updates             | 9700         |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 0.492        |
|    value_loss            | 1.81         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.415        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.415        |
| reward                   | -0.26990333  |
| rollout/                 |              |
|    ep_len_mean           | 372          |
|    ep_rew_mean           | -116         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 912          |
|    total_timesteps       | 1990656      |
| train/                   |              |
|    approx_kl             | 0.0057219863 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0022       |
|    cost_value_loss       | 5.19e-06     |
|    cost_values           | 0.00219      |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.274        |
|    n_updates             | 9710         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.492        |
|    value_loss            | 0.93         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.17        |
| reward                   | -0.32307178 |
| rollout/                 |             |
|    ep_len_mean           | 366         |
|    ep_rew_mean           | -115        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 934         |
|    total_timesteps       | 1992704     |
| train/                   |             |
|    approx_kl             | 0.008050174 |
|    clip_fraction         | 0.0917      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000434    |
|    cost_value_loss       | 2.09e-06    |
|    cost_values           | 0.000421    |
|    entropy               | -1.41       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.36        |
|    n_updates             | 9720        |
|    policy_gradient_loss  | -0.00433    |
|    std                   | 0.491       |
|    value_loss            | 0.903       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.769        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.769        |
| reward                   | -0.3808134   |
| rollout/                 |              |
|    ep_len_mean           | 357          |
|    ep_rew_mean           | -110         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 956          |
|    total_timesteps       | 1994752      |
| train/                   |              |
|    approx_kl             | 0.0057367175 |
|    clip_fraction         | 0.0621       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00298      |
|    cost_value_loss       | 7.93e-06     |
|    cost_values           | 0.00301      |
|    entropy               | -1.41        |
|    entropy_loss          | -1.41        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.346        |
|    n_updates             | 9730         |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 0.491        |
|    value_loss            | 0.861        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.2          |
| reward                   | -0.19847345  |
| rollout/                 |              |
|    ep_len_mean           | 356          |
|    ep_rew_mean           | -110         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 979          |
|    total_timesteps       | 1996800      |
| train/                   |              |
|    approx_kl             | 0.0063072937 |
|    clip_fraction         | 0.0695       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000957     |
|    cost_value_loss       | 5.22e-06     |
|    cost_values           | 0.000936     |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.291        |
|    n_updates             | 9740         |
|    policy_gradient_loss  | -0.0038      |
|    std                   | 0.493        |
|    value_loss            | 0.683        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.75         |
| reward                   | -0.15819907  |
| rollout/                 |              |
|    ep_len_mean           | 356          |
|    ep_rew_mean           | -108         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 1001         |
|    total_timesteps       | 1998848      |
| train/                   |              |
|    approx_kl             | 0.0066024074 |
|    clip_fraction         | 0.057        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00196      |
|    cost_value_loss       | 8.99e-06     |
|    cost_values           | 0.00242      |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.321        |
|    n_updates             | 9750         |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.493        |
|    value_loss            | 0.821        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.235       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.235       |
| reward                   | -0.43041405 |
| rollout/                 |             |
|    ep_len_mean           | 348         |
|    ep_rew_mean           | -104        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1023        |
|    total_timesteps       | 2000896     |
| train/                   |             |
|    approx_kl             | 0.007787813 |
|    clip_fraction         | 0.0691      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000998    |
|    cost_value_loss       | 5.83e-06    |
|    cost_values           | 0.000914    |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.347       |
|    n_updates             | 9760        |
|    policy_gradient_loss  | -0.00362    |
|    std                   | 0.493       |
|    value_loss            | 0.982       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.931       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.931       |
| reward                   | -0.22796333 |
| rollout/                 |             |
|    ep_len_mean           | 355         |
|    ep_rew_mean           | -106        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1045        |
|    total_timesteps       | 2002944     |
| train/                   |             |
|    approx_kl             | 0.008076903 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00125    |
|    cost_value_loss       | 1.21e-05    |
|    cost_values           | -0.00148    |
|    entropy               | -1.41       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.24        |
|    n_updates             | 9770        |
|    policy_gradient_loss  | -0.00586    |
|    std                   | 0.492       |
|    value_loss            | 0.547       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.881       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.881       |
| reward                   | -0.24562769 |
| rollout/                 |             |
|    ep_len_mean           | 346         |
|    ep_rew_mean           | -104        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1068        |
|    total_timesteps       | 2004992     |
| train/                   |             |
|    approx_kl             | 0.009300651 |
|    clip_fraction         | 0.0747      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00051     |
|    cost_value_loss       | 5.07e-06    |
|    cost_values           | 0.000459    |
|    entropy               | -1.41       |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.331       |
|    n_updates             | 9780        |
|    policy_gradient_loss  | -0.00267    |
|    std                   | 0.491       |
|    value_loss            | 0.955       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.17        |
| reward                   | -0.22826815 |
| rollout/                 |             |
|    ep_len_mean           | 342         |
|    ep_rew_mean           | -105        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1090        |
|    total_timesteps       | 2007040     |
| train/                   |             |
|    approx_kl             | 0.013462124 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.86e-06    |
|    cost_value_loss       | 2.46e-06    |
|    cost_values           | -7.15e-05   |
|    entropy               | -1.4        |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.377       |
|    n_updates             | 9790        |
|    policy_gradient_loss  | -0.00655    |
|    std                   | 0.489       |
|    value_loss            | 0.867       |
------------------------------------------
-----------------------------------
| avg_speed          | 1.41       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 1.41       |
| reward             | -0.7323396 |
| rollout/           |            |
|    ep_len_mean     | 339        |
|    ep_rew_mean     | -104       |
| time/              |            |
|    fps             | 93         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 2009088    |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.243        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.243        |
| reward                   | -0.20941925  |
| rollout/                 |              |
|    ep_len_mean           | 343          |
|    ep_rew_mean           | -107         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 2011136      |
| train/                   |              |
|    approx_kl             | 0.0058375495 |
|    clip_fraction         | 0.0506       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00121      |
|    cost_value_loss       | 1.97e-05     |
|    cost_values           | 0.00109      |
|    entropy               | -1.4         |
|    entropy_loss          | -1.4         |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.398        |
|    n_updates             | 9810         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 0.487        |
|    value_loss            | 1.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -0.4690259   |
| rollout/                 |              |
|    ep_len_mean           | 342          |
|    ep_rew_mean           | -108         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 2013184      |
| train/                   |              |
|    approx_kl             | 0.0062398165 |
|    clip_fraction         | 0.11         |
|    clip_range            | 0.2          |
|    cost_returns          | 4.5e-05      |
|    cost_value_loss       | 6.53e-06     |
|    cost_values           | 3.59e-05     |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.39         |
|    n_updates             | 9820         |
|    policy_gradient_loss  | -0.00557     |
|    std                   | 0.485        |
|    value_loss            | 1.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.25        |
| reward                   | -0.20462024 |
| rollout/                 |             |
|    ep_len_mean           | 330         |
|    ep_rew_mean           | -103        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 2015232     |
| train/                   |             |
|    approx_kl             | 0.005949458 |
|    clip_fraction         | 0.0543      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000198   |
|    cost_value_loss       | 1.06e-05    |
|    cost_values           | -0.00015    |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.196       |
|    n_updates             | 9830        |
|    policy_gradient_loss  | -0.00136    |
|    std                   | 0.485       |
|    value_loss            | 0.479       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.06        |
| reward                   | -0.21638538 |
| rollout/                 |             |
|    ep_len_mean           | 331         |
|    ep_rew_mean           | -104        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 2017280     |
| train/                   |             |
|    approx_kl             | 0.006365331 |
|    clip_fraction         | 0.0561      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00181    |
|    cost_value_loss       | 4.55e-06    |
|    cost_values           | -0.00185    |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.323       |
|    n_updates             | 9840        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.484       |
|    value_loss            | 0.872       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.22         |
| reward                   | -0.1799536   |
| rollout/                 |              |
|    ep_len_mean           | 317          |
|    ep_rew_mean           | -101         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 6            |
|    time_elapsed          | 131          |
|    total_timesteps       | 2019328      |
| train/                   |              |
|    approx_kl             | 0.0060841097 |
|    clip_fraction         | 0.0833       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000112     |
|    cost_value_loss       | 4.07e-06     |
|    cost_values           | 3e-05        |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.373        |
|    n_updates             | 9850         |
|    policy_gradient_loss  | -0.00454     |
|    std                   | 0.483        |
|    value_loss            | 0.798        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.417       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.417       |
| reward                   | -0.35671183 |
| rollout/                 |             |
|    ep_len_mean           | 311         |
|    ep_rew_mean           | -99.2       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 153         |
|    total_timesteps       | 2021376     |
| train/                   |             |
|    approx_kl             | 0.007981462 |
|    clip_fraction         | 0.0955      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000662   |
|    cost_value_loss       | 6.83e-06    |
|    cost_values           | -0.000615   |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.214       |
|    n_updates             | 9860        |
|    policy_gradient_loss  | -0.00379    |
|    std                   | 0.484       |
|    value_loss            | 0.522       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0132      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0132      |
| reward                   | -0.33385685 |
| rollout/                 |             |
|    ep_len_mean           | 306         |
|    ep_rew_mean           | -97.6       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 176         |
|    total_timesteps       | 2023424     |
| train/                   |             |
|    approx_kl             | 0.011531478 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000932   |
|    cost_value_loss       | 5.8e-06     |
|    cost_values           | -0.00114    |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.294       |
|    n_updates             | 9870        |
|    policy_gradient_loss  | -0.00509    |
|    std                   | 0.484       |
|    value_loss            | 0.687       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.77        |
| reward                   | -0.40978497 |
| rollout/                 |             |
|    ep_len_mean           | 300         |
|    ep_rew_mean           | -96.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 198         |
|    total_timesteps       | 2025472     |
| train/                   |             |
|    approx_kl             | 0.007605306 |
|    clip_fraction         | 0.0895      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00326    |
|    cost_value_loss       | 6.47e-06    |
|    cost_values           | -0.00352    |
|    entropy               | -1.37       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.305       |
|    n_updates             | 9880        |
|    policy_gradient_loss  | -0.00526    |
|    std                   | 0.481       |
|    value_loss            | 0.758       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.393       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.393       |
| reward                   | -0.52065027 |
| rollout/                 |             |
|    ep_len_mean           | 296         |
|    ep_rew_mean           | -97.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 220         |
|    total_timesteps       | 2027520     |
| train/                   |             |
|    approx_kl             | 0.008791249 |
|    clip_fraction         | 0.09        |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0025     |
|    cost_value_loss       | 4.24e-06    |
|    cost_values           | -0.00247    |
|    entropy               | -1.38       |
|    entropy_loss          | -1.37       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.326       |
|    n_updates             | 9890        |
|    policy_gradient_loss  | -0.00485    |
|    std                   | 0.482       |
|    value_loss            | 0.765       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.37        |
| reward                   | -0.28334904 |
| rollout/                 |             |
|    ep_len_mean           | 304         |
|    ep_rew_mean           | -102        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 242         |
|    total_timesteps       | 2029568     |
| train/                   |             |
|    approx_kl             | 0.007199577 |
|    clip_fraction         | 0.0797      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00436     |
|    cost_value_loss       | 1.63e-05    |
|    cost_values           | 0.00435     |
|    entropy               | -1.38       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.762       |
|    n_updates             | 9900        |
|    policy_gradient_loss  | -0.000571   |
|    std                   | 0.483       |
|    value_loss            | 2.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.6          |
| reward                   | -0.28783077  |
| rollout/                 |              |
|    ep_len_mean           | 304          |
|    ep_rew_mean           | -102         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 12           |
|    time_elapsed          | 265          |
|    total_timesteps       | 2031616      |
| train/                   |              |
|    approx_kl             | 0.0071678017 |
|    clip_fraction         | 0.0888       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000873     |
|    cost_value_loss       | 1.7e-05      |
|    cost_values           | 0.000846     |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.598        |
|    n_updates             | 9910         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 0.483        |
|    value_loss            | 1.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.00602      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00602      |
| reward                   | -0.17453907  |
| rollout/                 |              |
|    ep_len_mean           | 297          |
|    ep_rew_mean           | -100         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 287          |
|    total_timesteps       | 2033664      |
| train/                   |              |
|    approx_kl             | 0.0068636406 |
|    clip_fraction         | 0.0779       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000985    |
|    cost_value_loss       | 7.38e-06     |
|    cost_values           | -0.00102     |
|    entropy               | -1.37        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.55         |
|    n_updates             | 9920         |
|    policy_gradient_loss  | -0.00513     |
|    std                   | 0.48         |
|    value_loss            | 1.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.729       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.729       |
| reward                   | -0.48633334 |
| rollout/                 |             |
|    ep_len_mean           | 289         |
|    ep_rew_mean           | -95.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 2035712     |
| train/                   |             |
|    approx_kl             | 0.00664641  |
|    clip_fraction         | 0.0728      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00188    |
|    cost_value_loss       | 4.5e-06     |
|    cost_values           | -0.00187    |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.635       |
|    n_updates             | 9930        |
|    policy_gradient_loss  | -0.00413    |
|    std                   | 0.479       |
|    value_loss            | 1.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.362       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.362       |
| reward                   | -0.29338533 |
| rollout/                 |             |
|    ep_len_mean           | 277         |
|    ep_rew_mean           | -90.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 332         |
|    total_timesteps       | 2037760     |
| train/                   |             |
|    approx_kl             | 0.00934403  |
|    clip_fraction         | 0.0801      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000802   |
|    cost_value_loss       | 4.62e-06    |
|    cost_values           | -0.000825   |
|    entropy               | -1.37       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.43        |
|    n_updates             | 9940        |
|    policy_gradient_loss  | -0.00522    |
|    std                   | 0.48        |
|    value_loss            | 1.12        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.98         |
| reward                   | -0.45687285  |
| rollout/                 |              |
|    ep_len_mean           | 271          |
|    ep_rew_mean           | -87.7        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 354          |
|    total_timesteps       | 2039808      |
| train/                   |              |
|    approx_kl             | 0.0049876045 |
|    clip_fraction         | 0.0561       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00134     |
|    cost_value_loss       | 7.53e-06     |
|    cost_values           | -0.00141     |
|    entropy               | -1.36        |
|    entropy_loss          | -1.37        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.428        |
|    n_updates             | 9950         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 0.479        |
|    value_loss            | 0.874        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.75         |
| reward                   | -0.48087215  |
| rollout/                 |              |
|    ep_len_mean           | 261          |
|    ep_rew_mean           | -83.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 377          |
|    total_timesteps       | 2041856      |
| train/                   |              |
|    approx_kl             | 0.0064131003 |
|    clip_fraction         | 0.0622       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00107     |
|    cost_value_loss       | 3.97e-06     |
|    cost_values           | -0.00105     |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.333        |
|    n_updates             | 9960         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.478        |
|    value_loss            | 0.789        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.67        |
| reward                   | -0.17512359 |
| rollout/                 |             |
|    ep_len_mean           | 259         |
|    ep_rew_mean           | -82.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 399         |
|    total_timesteps       | 2043904     |
| train/                   |             |
|    approx_kl             | 0.005152146 |
|    clip_fraction         | 0.0664      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000572   |
|    cost_value_loss       | 4.08e-06    |
|    cost_values           | -0.000544   |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.429       |
|    n_updates             | 9970        |
|    policy_gradient_loss  | -0.00359    |
|    std                   | 0.477       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.41        |
| reward                   | -0.34971032 |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -83.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 422         |
|    total_timesteps       | 2045952     |
| train/                   |             |
|    approx_kl             | 0.008708149 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0011      |
|    cost_value_loss       | 4.63e-06    |
|    cost_values           | 0.00115     |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.249       |
|    n_updates             | 9980        |
|    policy_gradient_loss  | -0.00673    |
|    std                   | 0.477       |
|    value_loss            | 0.579       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.922       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.922       |
| reward                   | -0.17180577 |
| rollout/                 |             |
|    ep_len_mean           | 260         |
|    ep_rew_mean           | -82.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 444         |
|    total_timesteps       | 2048000     |
| train/                   |             |
|    approx_kl             | 0.006011269 |
|    clip_fraction         | 0.086       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000797    |
|    cost_value_loss       | 5.07e-06    |
|    cost_values           | 0.000793    |
|    entropy               | -1.34       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.289       |
|    n_updates             | 9990        |
|    policy_gradient_loss  | -0.00438    |
|    std                   | 0.475       |
|    value_loss            | 0.639       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.42        |
| reward                   | -0.6376423  |
| rollout/                 |             |
|    ep_len_mean           | 264         |
|    ep_rew_mean           | -83.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 467         |
|    total_timesteps       | 2050048     |
| train/                   |             |
|    approx_kl             | 0.005404788 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000916   |
|    cost_value_loss       | 5.36e-06    |
|    cost_values           | -0.000791   |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.359       |
|    n_updates             | 10000       |
|    policy_gradient_loss  | -0.00528    |
|    std                   | 0.475       |
|    value_loss            | 0.807       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.859       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.859       |
| reward                   | -0.33448735 |
| rollout/                 |             |
|    ep_len_mean           | 277         |
|    ep_rew_mean           | -88.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 489         |
|    total_timesteps       | 2052096     |
| train/                   |             |
|    approx_kl             | 0.004638913 |
|    clip_fraction         | 0.0782      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000114   |
|    cost_value_loss       | 1.86e-05    |
|    cost_values           | -9.96e-05   |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.512       |
|    n_updates             | 10010       |
|    policy_gradient_loss  | -0.00359    |
|    std                   | 0.475       |
|    value_loss            | 1.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.21         |
| reward                   | -0.22769478  |
| rollout/                 |              |
|    ep_len_mean           | 285          |
|    ep_rew_mean           | -92.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 511          |
|    total_timesteps       | 2054144      |
| train/                   |              |
|    approx_kl             | 0.0068844934 |
|    clip_fraction         | 0.0545       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000626    |
|    cost_value_loss       | 8.85e-06     |
|    cost_values           | -0.00066     |
|    entropy               | -1.34        |
|    entropy_loss          | -1.34        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.488        |
|    n_updates             | 10020        |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 0.473        |
|    value_loss            | 1.81         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.17        |
| reward                   | -0.334749   |
| rollout/                 |             |
|    ep_len_mean           | 277         |
|    ep_rew_mean           | -86.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 533         |
|    total_timesteps       | 2056192     |
| train/                   |             |
|    approx_kl             | 0.005072698 |
|    clip_fraction         | 0.0571      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.003       |
|    cost_value_loss       | 1.58e-05    |
|    cost_values           | 0.00296     |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.383       |
|    n_updates             | 10030       |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.471       |
|    value_loss            | 0.913       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.46         |
| reward                   | -0.25148982  |
| rollout/                 |              |
|    ep_len_mean           | 276          |
|    ep_rew_mean           | -85.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 555          |
|    total_timesteps       | 2058240      |
| train/                   |              |
|    approx_kl             | 0.0063295346 |
|    clip_fraction         | 0.0709       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00101      |
|    cost_value_loss       | 5.04e-06     |
|    cost_values           | 0.000905     |
|    entropy               | -1.32        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.373        |
|    n_updates             | 10040        |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.469        |
|    value_loss            | 1.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.75        |
| reward                   | -0.3629421  |
| rollout/                 |             |
|    ep_len_mean           | 279         |
|    ep_rew_mean           | -87.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 577         |
|    total_timesteps       | 2060288     |
| train/                   |             |
|    approx_kl             | 0.009258527 |
|    clip_fraction         | 0.0623      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00182     |
|    cost_value_loss       | 6.02e-06    |
|    cost_values           | 0.00202     |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.221       |
|    n_updates             | 10050       |
|    policy_gradient_loss  | -0.000746   |
|    std                   | 0.47        |
|    value_loss            | 0.699       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.62        |
| reward                   | -0.39211082 |
| rollout/                 |             |
|    ep_len_mean           | 276         |
|    ep_rew_mean           | -87.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 600         |
|    total_timesteps       | 2062336     |
| train/                   |             |
|    approx_kl             | 0.008368395 |
|    clip_fraction         | 0.0982      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000972    |
|    cost_value_loss       | 7.6e-06     |
|    cost_values           | 0.000872    |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.247       |
|    n_updates             | 10060       |
|    policy_gradient_loss  | -0.00304    |
|    std                   | 0.471       |
|    value_loss            | 0.592       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.185        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.185        |
| reward                   | -0.5422785   |
| rollout/                 |              |
|    ep_len_mean           | 278          |
|    ep_rew_mean           | -87.3        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 622          |
|    total_timesteps       | 2064384      |
| train/                   |              |
|    approx_kl             | 0.0040894155 |
|    clip_fraction         | 0.0651       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000886     |
|    cost_value_loss       | 6.45e-06     |
|    cost_values           | 0.00103      |
|    entropy               | -1.33        |
|    entropy_loss          | -1.33        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.377        |
|    n_updates             | 10070        |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.471        |
|    value_loss            | 0.946        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.625       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.625       |
| reward                   | -0.6945678  |
| rollout/                 |             |
|    ep_len_mean           | 285         |
|    ep_rew_mean           | -91.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 644         |
|    total_timesteps       | 2066432     |
| train/                   |             |
|    approx_kl             | 0.005579221 |
|    clip_fraction         | 0.04        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000307    |
|    cost_value_loss       | 8.42e-06    |
|    cost_values           | 0.000306    |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.557       |
|    n_updates             | 10080       |
|    policy_gradient_loss  | -0.00121    |
|    std                   | 0.471       |
|    value_loss            | 1.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.65        |
| reward                   | -0.35785717 |
| rollout/                 |             |
|    ep_len_mean           | 292         |
|    ep_rew_mean           | -96         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 666         |
|    total_timesteps       | 2068480     |
| train/                   |             |
|    approx_kl             | 0.007013577 |
|    clip_fraction         | 0.0745      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00672     |
|    cost_value_loss       | 2.34e-05    |
|    cost_values           | 0.00677     |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.803       |
|    n_updates             | 10090       |
|    policy_gradient_loss  | -0.00487    |
|    std                   | 0.469       |
|    value_loss            | 1.58        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.38         |
| reward                   | -0.43699068  |
| rollout/                 |              |
|    ep_len_mean           | 293          |
|    ep_rew_mean           | -96.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 31           |
|    time_elapsed          | 688          |
|    total_timesteps       | 2070528      |
| train/                   |              |
|    approx_kl             | 0.0076340474 |
|    clip_fraction         | 0.0527       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00187      |
|    cost_value_loss       | 3.8e-06      |
|    cost_values           | 0.00187      |
|    entropy               | -1.31        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.656        |
|    n_updates             | 10100        |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 0.468        |
|    value_loss            | 1.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.66         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.66         |
| reward                   | -0.3363679   |
| rollout/                 |              |
|    ep_len_mean           | 311          |
|    ep_rew_mean           | -106         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 711          |
|    total_timesteps       | 2072576      |
| train/                   |              |
|    approx_kl             | 0.0045644986 |
|    clip_fraction         | 0.0481       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.000519    |
|    cost_value_loss       | 3.32e-06     |
|    cost_values           | -0.000512    |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.853        |
|    n_updates             | 10110        |
|    policy_gradient_loss  | -0.00125     |
|    std                   | 0.468        |
|    value_loss            | 1.85         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.568        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.568        |
| reward                   | -0.7722894   |
| rollout/                 |              |
|    ep_len_mean           | 309          |
|    ep_rew_mean           | -105         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 733          |
|    total_timesteps       | 2074624      |
| train/                   |              |
|    approx_kl             | 0.0074991984 |
|    clip_fraction         | 0.0694       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00392      |
|    cost_value_loss       | 2.63e-05     |
|    cost_values           | 0.00378      |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.353        |
|    n_updates             | 10120        |
|    policy_gradient_loss  | -0.00345     |
|    std                   | 0.466        |
|    value_loss            | 1.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.62        |
| reward                   | -0.18892013 |
| rollout/                 |             |
|    ep_len_mean           | 317         |
|    ep_rew_mean           | -110        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 755         |
|    total_timesteps       | 2076672     |
| train/                   |             |
|    approx_kl             | 0.008043754 |
|    clip_fraction         | 0.0911      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00557     |
|    cost_value_loss       | 2.11e-05    |
|    cost_values           | 0.00591     |
|    entropy               | -1.31       |
|    entropy_loss          | -1.31       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.44        |
|    n_updates             | 10130       |
|    policy_gradient_loss  | -0.00496    |
|    std                   | 0.467       |
|    value_loss            | 1.34        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.153        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.153        |
| reward                   | -0.3940968   |
| rollout/                 |              |
|    ep_len_mean           | 324          |
|    ep_rew_mean           | -114         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 777          |
|    total_timesteps       | 2078720      |
| train/                   |              |
|    approx_kl             | 0.0088700345 |
|    clip_fraction         | 0.0884       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00341      |
|    cost_value_loss       | 1.01e-05     |
|    cost_values           | 0.00276      |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.624        |
|    n_updates             | 10140        |
|    policy_gradient_loss  | -0.00333     |
|    std                   | 0.467        |
|    value_loss            | 1.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.16         |
| reward                   | -0.42443797  |
| rollout/                 |              |
|    ep_len_mean           | 332          |
|    ep_rew_mean           | -120         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 800          |
|    total_timesteps       | 2080768      |
| train/                   |              |
|    approx_kl             | 0.0045142453 |
|    clip_fraction         | 0.0857       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00184      |
|    cost_value_loss       | 1.38e-05     |
|    cost_values           | 0.00183      |
|    entropy               | -1.32        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.789        |
|    n_updates             | 10150        |
|    policy_gradient_loss  | -0.00607     |
|    std                   | 0.469        |
|    value_loss            | 1.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.58         |
| reward                   | -0.26854327  |
| rollout/                 |              |
|    ep_len_mean           | 334          |
|    ep_rew_mean           | -122         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 822          |
|    total_timesteps       | 2082816      |
| train/                   |              |
|    approx_kl             | 0.0066545024 |
|    clip_fraction         | 0.0862       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00172      |
|    cost_value_loss       | 1.99e-05     |
|    cost_values           | 0.00173      |
|    entropy               | -1.33        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.33         |
|    n_updates             | 10160        |
|    policy_gradient_loss  | -0.00242     |
|    std                   | 0.47         |
|    value_loss            | 1.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.52        |
| reward                   | -0.21654153 |
| rollout/                 |             |
|    ep_len_mean           | 317         |
|    ep_rew_mean           | -114        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 844         |
|    total_timesteps       | 2084864     |
| train/                   |             |
|    approx_kl             | 0.005341484 |
|    clip_fraction         | 0.062       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00166     |
|    cost_value_loss       | 2.33e-05    |
|    cost_values           | 0.000991    |
|    entropy               | -1.32       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.532       |
|    n_updates             | 10170       |
|    policy_gradient_loss  | -0.00178    |
|    std                   | 0.469       |
|    value_loss            | 1.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.22         |
| reward                   | -0.1950988   |
| rollout/                 |              |
|    ep_len_mean           | 315          |
|    ep_rew_mean           | -113         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 866          |
|    total_timesteps       | 2086912      |
| train/                   |              |
|    approx_kl             | 0.0051309424 |
|    clip_fraction         | 0.0475       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00223      |
|    cost_value_loss       | 1.14e-05     |
|    cost_values           | 0.00251      |
|    entropy               | -1.31        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.302        |
|    n_updates             | 10180        |
|    policy_gradient_loss  | -0.00245     |
|    std                   | 0.467        |
|    value_loss            | 0.846        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.53        |
| reward                   | -0.47138295 |
| rollout/                 |             |
|    ep_len_mean           | 311         |
|    ep_rew_mean           | -113        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 888         |
|    total_timesteps       | 2088960     |
| train/                   |             |
|    approx_kl             | 0.010378675 |
|    clip_fraction         | 0.0888      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00474     |
|    cost_value_loss       | 8.35e-06    |
|    cost_values           | 0.00473     |
|    entropy               | -1.3        |
|    entropy_loss          | -1.31       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.261       |
|    n_updates             | 10190       |
|    policy_gradient_loss  | -0.00442    |
|    std                   | 0.465       |
|    value_loss            | 0.672       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.27        |
| reward                   | -0.32793468 |
| rollout/                 |             |
|    ep_len_mean           | 307         |
|    ep_rew_mean           | -111        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 910         |
|    total_timesteps       | 2091008     |
| train/                   |             |
|    approx_kl             | 0.008774983 |
|    clip_fraction         | 0.0606      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00362     |
|    cost_value_loss       | 5.81e-06    |
|    cost_values           | 0.00368     |
|    entropy               | -1.29       |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.378       |
|    n_updates             | 10200       |
|    policy_gradient_loss  | -0.00181    |
|    std                   | 0.463       |
|    value_loss            | 0.814       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.25485048 |
| rollout/                 |             |
|    ep_len_mean           | 307         |
|    ep_rew_mean           | -112        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 932         |
|    total_timesteps       | 2093056     |
| train/                   |             |
|    approx_kl             | 0.008377524 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00298     |
|    cost_value_loss       | 1.01e-05    |
|    cost_values           | 0.00284     |
|    entropy               | -1.28       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.218       |
|    n_updates             | 10210       |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 0.461       |
|    value_loss            | 0.484       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.479       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.479       |
| reward                   | -0.43662512 |
| rollout/                 |             |
|    ep_len_mean           | 302         |
|    ep_rew_mean           | -108        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 954         |
|    total_timesteps       | 2095104     |
| train/                   |             |
|    approx_kl             | 0.009810242 |
|    clip_fraction         | 0.0863      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00262     |
|    cost_value_loss       | 7.24e-06    |
|    cost_values           | 0.00286     |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.291       |
|    n_updates             | 10220       |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 0.461       |
|    value_loss            | 0.715       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.39        |
| reward                   | -0.21999672 |
| rollout/                 |             |
|    ep_len_mean           | 299         |
|    ep_rew_mean           | -105        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 976         |
|    total_timesteps       | 2097152     |
| train/                   |             |
|    approx_kl             | 0.005175937 |
|    clip_fraction         | 0.0306      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00263     |
|    cost_value_loss       | 5.51e-06    |
|    cost_values           | 0.00255     |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.377       |
|    n_updates             | 10230       |
|    policy_gradient_loss  | -0.000909   |
|    std                   | 0.46        |
|    value_loss            | 0.902       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.84        |
| reward                   | -0.46296877 |
| rollout/                 |             |
|    ep_len_mean           | 298         |
|    ep_rew_mean           | -105        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 998         |
|    total_timesteps       | 2099200     |
| train/                   |             |
|    approx_kl             | 0.006134224 |
|    clip_fraction         | 0.0569      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00198     |
|    cost_value_loss       | 7.95e-06    |
|    cost_values           | 0.00212     |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.488       |
|    n_updates             | 10240       |
|    policy_gradient_loss  | -0.00365    |
|    std                   | 0.46        |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.948       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.948       |
| reward                   | -0.3755676  |
| rollout/                 |             |
|    ep_len_mean           | 281         |
|    ep_rew_mean           | -96.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1020        |
|    total_timesteps       | 2101248     |
| train/                   |             |
|    approx_kl             | 0.009897223 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000477    |
|    cost_value_loss       | 9.33e-06    |
|    cost_values           | 0.000408    |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.286       |
|    n_updates             | 10250       |
|    policy_gradient_loss  | -0.00584    |
|    std                   | 0.46        |
|    value_loss            | 0.741       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.854      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.854      |
| reward                   | -0.3279102 |
| rollout/                 |            |
|    ep_len_mean           | 274        |
|    ep_rew_mean           | -92.1      |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 47         |
|    time_elapsed          | 1043       |
|    total_timesteps       | 2103296    |
| train/                   |            |
|    approx_kl             | 0.01269312 |
|    clip_fraction         | 0.0971     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00294    |
|    cost_value_loss       | 1.18e-05   |
|    cost_values           | 0.003      |
|    entropy               | -1.28      |
|    entropy_loss          | -1.28      |
|    explained_variance    | 0.992      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.349      |
|    n_updates             | 10260      |
|    policy_gradient_loss  | -0.00412   |
|    std                   | 0.459      |
|    value_loss            | 0.814      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.572       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.572       |
| reward                   | -0.47240958 |
| rollout/                 |             |
|    ep_len_mean           | 263         |
|    ep_rew_mean           | -85.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1065        |
|    total_timesteps       | 2105344     |
| train/                   |             |
|    approx_kl             | 0.006434682 |
|    clip_fraction         | 0.0705      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00125     |
|    cost_value_loss       | 9.47e-06    |
|    cost_values           | 0.00127     |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.269       |
|    n_updates             | 10270       |
|    policy_gradient_loss  | -0.00434    |
|    std                   | 0.457       |
|    value_loss            | 0.688       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.377        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.377        |
| reward                   | -0.32248917  |
| rollout/                 |              |
|    ep_len_mean           | 262          |
|    ep_rew_mean           | -85.1        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1087         |
|    total_timesteps       | 2107392      |
| train/                   |              |
|    approx_kl             | 0.0073705963 |
|    clip_fraction         | 0.0881       |
|    clip_range            | 0.2          |
|    cost_returns          | -9.79e-05    |
|    cost_value_loss       | 6.93e-06     |
|    cost_values           | -0.000114    |
|    entropy               | -1.27        |
|    entropy_loss          | -1.27        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.494        |
|    n_updates             | 10280        |
|    policy_gradient_loss  | -0.00481     |
|    std                   | 0.457        |
|    value_loss            | 1.52         |
-------------------------------------------
Directory created: PPOL_New/models/seed-testing/tggzx3rw/model_epoch(20)
------------------------------------
| avg_speed          | 0.681       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.681       |
| reward             | -0.27563035 |
| rollout/           |             |
|    ep_len_mean     | 262         |
|    ep_rew_mean     | -83.9       |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2109440     |
------------------------------------
------------------------------------------
| avg_speed                | 1.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.22        |
| reward                   | -0.22730614 |
| rollout/                 |             |
|    ep_len_mean           | 256         |
|    ep_rew_mean           | -82.3       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 2111488     |
| train/                   |             |
|    approx_kl             | 0.006619414 |
|    clip_fraction         | 0.0685      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00152     |
|    cost_value_loss       | 9.67e-06    |
|    cost_values           | 0.002       |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.381       |
|    n_updates             | 10300       |
|    policy_gradient_loss  | -0.0025     |
|    std                   | 0.457       |
|    value_loss            | 0.859       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.42        |
| reward                   | -0.5107635  |
| rollout/                 |             |
|    ep_len_mean           | 266         |
|    ep_rew_mean           | -86.4       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 2113536     |
| train/                   |             |
|    approx_kl             | 0.011905236 |
|    clip_fraction         | 0.0868      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00207     |
|    cost_value_loss       | 4.67e-06    |
|    cost_values           | 0.00208     |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.531       |
|    n_updates             | 10310       |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.456       |
|    value_loss            | 0.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.25        |
| reward                   | -0.3516355  |
| rollout/                 |             |
|    ep_len_mean           | 270         |
|    ep_rew_mean           | -88         |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 88          |
|    total_timesteps       | 2115584     |
| train/                   |             |
|    approx_kl             | 0.005935358 |
|    clip_fraction         | 0.0857      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00497     |
|    cost_value_loss       | 1.92e-05    |
|    cost_values           | 0.00508     |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.483       |
|    n_updates             | 10320       |
|    policy_gradient_loss  | -0.00191    |
|    std                   | 0.457       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.53        |
| reward                   | -0.34803483 |
| rollout/                 |             |
|    ep_len_mean           | 274         |
|    ep_rew_mean           | -89         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 2117632     |
| train/                   |             |
|    approx_kl             | 0.00566476  |
|    clip_fraction         | 0.0362      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00238     |
|    cost_value_loss       | 6.97e-06    |
|    cost_values           | 0.00243     |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.42        |
|    n_updates             | 10330       |
|    policy_gradient_loss  | -0.00108    |
|    std                   | 0.457       |
|    value_loss            | 0.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.42        |
| reward                   | -0.38354823 |
| rollout/                 |             |
|    ep_len_mean           | 279         |
|    ep_rew_mean           | -93.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 2119680     |
| train/                   |             |
|    approx_kl             | 0.004133627 |
|    clip_fraction         | 0.0587      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00176     |
|    cost_value_loss       | 7.02e-06    |
|    cost_values           | 0.00184     |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.304       |
|    n_updates             | 10340       |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.457       |
|    value_loss            | 0.757       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.25639492  |
| rollout/                 |              |
|    ep_len_mean           | 279          |
|    ep_rew_mean           | -93.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 2121728      |
| train/                   |              |
|    approx_kl             | 0.0052362056 |
|    clip_fraction         | 0.0633       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00597      |
|    cost_value_loss       | 1.48e-05     |
|    cost_values           | 0.00582      |
|    entropy               | -1.27        |
|    entropy_loss          | -1.27        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.464        |
|    n_updates             | 10350        |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 0.456        |
|    value_loss            | 1.91         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.19        |
| reward                   | -0.27273878 |
| rollout/                 |             |
|    ep_len_mean           | 277         |
|    ep_rew_mean           | -93.2       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 8           |
|    time_elapsed          | 175         |
|    total_timesteps       | 2123776     |
| train/                   |             |
|    approx_kl             | 0.009775612 |
|    clip_fraction         | 0.0886      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000233    |
|    cost_value_loss       | 5.18e-06    |
|    cost_values           | 0.000163    |
|    entropy               | -1.26       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.424       |
|    n_updates             | 10360       |
|    policy_gradient_loss  | -0.00208    |
|    std                   | 0.454       |
|    value_loss            | 0.928       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.25        |
| reward                   | -0.19193874 |
| rollout/                 |             |
|    ep_len_mean           | 276         |
|    ep_rew_mean           | -93.4       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 9           |
|    time_elapsed          | 197         |
|    total_timesteps       | 2125824     |
| train/                   |             |
|    approx_kl             | 0.008401506 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000133   |
|    cost_value_loss       | 5.12e-06    |
|    cost_values           | -0.000145   |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.247       |
|    n_updates             | 10370       |
|    policy_gradient_loss  | -0.00331    |
|    std                   | 0.452       |
|    value_loss            | 0.619       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.569        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.569        |
| reward                   | -0.21416119  |
| rollout/                 |              |
|    ep_len_mean           | 274          |
|    ep_rew_mean           | -92.1        |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 10           |
|    time_elapsed          | 220          |
|    total_timesteps       | 2127872      |
| train/                   |              |
|    approx_kl             | 0.0077281957 |
|    clip_fraction         | 0.0952       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54e-05     |
|    cost_value_loss       | 7.12e-06     |
|    cost_values           | 1.08e-06     |
|    entropy               | -1.24        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.357        |
|    n_updates             | 10380        |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.451        |
|    value_loss            | 0.868        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.332        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.332        |
| reward                   | -0.31726316  |
| rollout/                 |              |
|    ep_len_mean           | 273          |
|    ep_rew_mean           | -91.4        |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 11           |
|    time_elapsed          | 242          |
|    total_timesteps       | 2129920      |
| train/                   |              |
|    approx_kl             | 0.0069041084 |
|    clip_fraction         | 0.0423       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000296     |
|    cost_value_loss       | 4.83e-06     |
|    cost_values           | 0.00035      |
|    entropy               | -1.25        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.376        |
|    n_updates             | 10390        |
|    policy_gradient_loss  | -0.0034      |
|    std                   | 0.452        |
|    value_loss            | 0.974        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.75        |
| reward                   | -0.36717746 |
| rollout/                 |             |
|    ep_len_mean           | 273         |
|    ep_rew_mean           | -92.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 264         |
|    total_timesteps       | 2131968     |
| train/                   |             |
|    approx_kl             | 0.007828174 |
|    clip_fraction         | 0.0662      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00167     |
|    cost_value_loss       | 5.89e-06    |
|    cost_values           | 0.00172     |
|    entropy               | -1.23       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.244       |
|    n_updates             | 10400       |
|    policy_gradient_loss  | -0.00322    |
|    std                   | 0.449       |
|    value_loss            | 0.539       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.812       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.812       |
| reward                   | -0.30268207 |
| rollout/                 |             |
|    ep_len_mean           | 266         |
|    ep_rew_mean           | -88.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 286         |
|    total_timesteps       | 2134016     |
| train/                   |             |
|    approx_kl             | 0.011452022 |
|    clip_fraction         | 0.0861      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00151     |
|    cost_value_loss       | 6.09e-06    |
|    cost_values           | 0.00146     |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.24        |
|    n_updates             | 10410       |
|    policy_gradient_loss  | -0.00266    |
|    std                   | 0.451       |
|    value_loss            | 0.522       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.65        |
| reward                   | -0.25740817 |
| rollout/                 |             |
|    ep_len_mean           | 263         |
|    ep_rew_mean           | -87.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 309         |
|    total_timesteps       | 2136064     |
| train/                   |             |
|    approx_kl             | 0.005868756 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000899    |
|    cost_value_loss       | 8.47e-06    |
|    cost_values           | 0.00111     |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.291       |
|    n_updates             | 10420       |
|    policy_gradient_loss  | -0.00213    |
|    std                   | 0.453       |
|    value_loss            | 0.951       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.497       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.497       |
| reward                   | -0.38163728 |
| rollout/                 |             |
|    ep_len_mean           | 265         |
|    ep_rew_mean           | -88.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 331         |
|    total_timesteps       | 2138112     |
| train/                   |             |
|    approx_kl             | 0.009366322 |
|    clip_fraction         | 0.0889      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00226     |
|    cost_value_loss       | 8.78e-06    |
|    cost_values           | 0.00216     |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.581       |
|    n_updates             | 10430       |
|    policy_gradient_loss  | -0.0024     |
|    std                   | 0.452       |
|    value_loss            | 1.34        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.26         |
| reward                   | -0.2614112   |
| rollout/                 |              |
|    ep_len_mean           | 257          |
|    ep_rew_mean           | -87.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 353          |
|    total_timesteps       | 2140160      |
| train/                   |              |
|    approx_kl             | 0.0053888853 |
|    clip_fraction         | 0.0608       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000442     |
|    cost_value_loss       | 1.59e-05     |
|    cost_values           | 0.000641     |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.497        |
|    n_updates             | 10440        |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.453        |
|    value_loss            | 1.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.79        |
| reward                   | -0.17343885 |
| rollout/                 |             |
|    ep_len_mean           | 255         |
|    ep_rew_mean           | -86         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 375         |
|    total_timesteps       | 2142208     |
| train/                   |             |
|    approx_kl             | 0.011163281 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000806    |
|    cost_value_loss       | 4.68e-05    |
|    cost_values           | -0.000228   |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.908       |
|    n_updates             | 10450       |
|    policy_gradient_loss  | -0.0057     |
|    std                   | 0.454       |
|    value_loss            | 2.82        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.11       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.11       |
| reward                   | -0.2810804 |
| rollout/                 |            |
|    ep_len_mean           | 242        |
|    ep_rew_mean           | -79.1      |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 18         |
|    time_elapsed          | 397        |
|    total_timesteps       | 2144256    |
| train/                   |            |
|    approx_kl             | 0.00466526 |
|    clip_fraction         | 0.0471     |
|    clip_range            | 0.2        |
|    cost_returns          | -0.002     |
|    cost_value_loss       | 1.07e-05   |
|    cost_values           | -0.00157   |
|    entropy               | -1.25      |
|    entropy_loss          | -1.25      |
|    explained_variance    | 0.976      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.419      |
|    n_updates             | 10460      |
|    policy_gradient_loss  | -0.00255   |
|    std                   | 0.453      |
|    value_loss            | 1.09       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.35        |
| reward                   | -0.5062539  |
| rollout/                 |             |
|    ep_len_mean           | 236         |
|    ep_rew_mean           | -77.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 418         |
|    total_timesteps       | 2146304     |
| train/                   |             |
|    approx_kl             | 0.006077517 |
|    clip_fraction         | 0.0605      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00138    |
|    cost_value_loss       | 5e-06       |
|    cost_values           | -0.00146    |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.63        |
|    n_updates             | 10470       |
|    policy_gradient_loss  | -0.00422    |
|    std                   | 0.453       |
|    value_loss            | 1.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.38         |
| reward                   | -0.28419283  |
| rollout/                 |              |
|    ep_len_mean           | 243          |
|    ep_rew_mean           | -80.8        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 440          |
|    total_timesteps       | 2148352      |
| train/                   |              |
|    approx_kl             | 0.0041975216 |
|    clip_fraction         | 0.0353       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00342     |
|    cost_value_loss       | 9.53e-06     |
|    cost_values           | -0.0033      |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.581        |
|    n_updates             | 10480        |
|    policy_gradient_loss  | -0.000807    |
|    std                   | 0.453        |
|    value_loss            | 1.55         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.662        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.662        |
| reward                   | -0.25066072  |
| rollout/                 |              |
|    ep_len_mean           | 242          |
|    ep_rew_mean           | -80.6        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 462          |
|    total_timesteps       | 2150400      |
| train/                   |              |
|    approx_kl             | 0.0067834435 |
|    clip_fraction         | 0.0613       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00749     |
|    cost_value_loss       | 3.42e-05     |
|    cost_values           | -0.00744     |
|    entropy               | -1.25        |
|    entropy_loss          | -1.25        |
|    explained_variance    | 0.947        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.658        |
|    n_updates             | 10490        |
|    policy_gradient_loss  | -0.00424     |
|    std                   | 0.453        |
|    value_loss            | 2.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.914       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.914       |
| reward                   | -0.32336232 |
| rollout/                 |             |
|    ep_len_mean           | 244         |
|    ep_rew_mean           | -81.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 485         |
|    total_timesteps       | 2152448     |
| train/                   |             |
|    approx_kl             | 0.007538316 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00345    |
|    cost_value_loss       | 1.21e-05    |
|    cost_values           | -0.0036     |
|    entropy               | -1.24       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.817       |
|    n_updates             | 10500       |
|    policy_gradient_loss  | -0.00616    |
|    std                   | 0.452       |
|    value_loss            | 1.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.965       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.965       |
| reward                   | -0.53231    |
| rollout/                 |             |
|    ep_len_mean           | 243         |
|    ep_rew_mean           | -81.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 506         |
|    total_timesteps       | 2154496     |
| train/                   |             |
|    approx_kl             | 0.006702287 |
|    clip_fraction         | 0.0843      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0024     |
|    cost_value_loss       | 9.87e-06    |
|    cost_values           | -0.00245    |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.275       |
|    n_updates             | 10510       |
|    policy_gradient_loss  | -0.00336    |
|    std                   | 0.451       |
|    value_loss            | 0.832       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.23647617 |
| rollout/                 |             |
|    ep_len_mean           | 250         |
|    ep_rew_mean           | -85.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 528         |
|    total_timesteps       | 2156544     |
| train/                   |             |
|    approx_kl             | 0.011441173 |
|    clip_fraction         | 0.0834      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00357    |
|    cost_value_loss       | 1.29e-05    |
|    cost_values           | -0.00363    |
|    entropy               | -1.23       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.701       |
|    n_updates             | 10520       |
|    policy_gradient_loss  | -0.00603    |
|    std                   | 0.45        |
|    value_loss            | 2.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.52        |
| reward                   | -0.23068428 |
| rollout/                 |             |
|    ep_len_mean           | 258         |
|    ep_rew_mean           | -87.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 550         |
|    total_timesteps       | 2158592     |
| train/                   |             |
|    approx_kl             | 0.008047568 |
|    clip_fraction         | 0.0811      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00574     |
|    cost_value_loss       | 1.38e-05    |
|    cost_values           | 0.00576     |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.491       |
|    n_updates             | 10530       |
|    policy_gradient_loss  | -0.00577    |
|    std                   | 0.448       |
|    value_loss            | 1.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.04        |
| reward                   | -0.3451225  |
| rollout/                 |             |
|    ep_len_mean           | 255         |
|    ep_rew_mean           | -89.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 572         |
|    total_timesteps       | 2160640     |
| train/                   |             |
|    approx_kl             | 0.008721091 |
|    clip_fraction         | 0.089       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00232    |
|    cost_value_loss       | 6.93e-06    |
|    cost_values           | -0.00239    |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.489       |
|    n_updates             | 10540       |
|    policy_gradient_loss  | -0.0063     |
|    std                   | 0.448       |
|    value_loss            | 1.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.19        |
| reward                   | -0.26859364 |
| rollout/                 |             |
|    ep_len_mean           | 255         |
|    ep_rew_mean           | -89.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 594         |
|    total_timesteps       | 2162688     |
| train/                   |             |
|    approx_kl             | 0.008531503 |
|    clip_fraction         | 0.0703      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00428     |
|    cost_value_loss       | 1.78e-05    |
|    cost_values           | 0.00446     |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.13        |
|    n_updates             | 10550       |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.447       |
|    value_loss            | 2.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.722       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.722       |
| reward                   | -0.3276132  |
| rollout/                 |             |
|    ep_len_mean           | 251         |
|    ep_rew_mean           | -84.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 617         |
|    total_timesteps       | 2164736     |
| train/                   |             |
|    approx_kl             | 0.006763799 |
|    clip_fraction         | 0.0937      |
|    clip_range            | 0.2         |
|    cost_returns          | -3.31e-05   |
|    cost_value_loss       | 4.68e-06    |
|    cost_values           | 2.12e-05    |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.437       |
|    n_updates             | 10560       |
|    policy_gradient_loss  | -0.0077     |
|    std                   | 0.446       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.56        |
| reward                   | -0.22650757 |
| rollout/                 |             |
|    ep_len_mean           | 256         |
|    ep_rew_mean           | -85.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 639         |
|    total_timesteps       | 2166784     |
| train/                   |             |
|    approx_kl             | 0.008671936 |
|    clip_fraction         | 0.0935      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000454    |
|    cost_value_loss       | 3.22e-06    |
|    cost_values           | 0.000417    |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.592       |
|    n_updates             | 10570       |
|    policy_gradient_loss  | -0.00199    |
|    std                   | 0.444       |
|    value_loss            | 1.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.07        |
| reward                   | -0.24028336 |
| rollout/                 |             |
|    ep_len_mean           | 255         |
|    ep_rew_mean           | -84.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 662         |
|    total_timesteps       | 2168832     |
| train/                   |             |
|    approx_kl             | 0.006218496 |
|    clip_fraction         | 0.0569      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000653   |
|    cost_value_loss       | 3.86e-06    |
|    cost_values           | -0.000706   |
|    entropy               | -1.2        |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.776       |
|    n_updates             | 10580       |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.442       |
|    value_loss            | 1.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.862       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.862       |
| reward                   | -0.3757321  |
| rollout/                 |             |
|    ep_len_mean           | 258         |
|    ep_rew_mean           | -86.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 684         |
|    total_timesteps       | 2170880     |
| train/                   |             |
|    approx_kl             | 0.008353425 |
|    clip_fraction         | 0.0727      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000397   |
|    cost_value_loss       | 7.13e-06    |
|    cost_values           | -0.000487   |
|    entropy               | -1.19       |
|    entropy_loss          | -1.19       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.363       |
|    n_updates             | 10590       |
|    policy_gradient_loss  | -0.00439    |
|    std                   | 0.439       |
|    value_loss            | 0.922       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.48         |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 1.48         |
| reward                   | -0.08487479  |
| rollout/                 |              |
|    ep_len_mean           | 253          |
|    ep_rew_mean           | -83          |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 706          |
|    total_timesteps       | 2172928      |
| train/                   |              |
|    approx_kl             | 0.0040595816 |
|    clip_fraction         | 0.0504       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0101      |
|    cost_value_loss       | 4.35e-05     |
|    cost_values           | -0.0101      |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0.915        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.615        |
|    n_updates             | 10600        |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 0.438        |
|    value_loss            | 2.92         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.748        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.748        |
| reward                   | -0.2043372   |
| rollout/                 |              |
|    ep_len_mean           | 256          |
|    ep_rew_mean           | -84.6        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 728          |
|    total_timesteps       | 2174976      |
| train/                   |              |
|    approx_kl             | 0.0073688496 |
|    clip_fraction         | 0.094        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00138     |
|    cost_value_loss       | 6.13e-06     |
|    cost_values           | -0.00139     |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.707        |
|    n_updates             | 10610        |
|    policy_gradient_loss  | -0.00569     |
|    std                   | 0.438        |
|    value_loss            | 1.5          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.245       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.245       |
| reward                   | -0.22119926 |
| rollout/                 |             |
|    ep_len_mean           | 255         |
|    ep_rew_mean           | -84.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 750         |
|    total_timesteps       | 2177024     |
| train/                   |             |
|    approx_kl             | 0.005932885 |
|    clip_fraction         | 0.0569      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00198    |
|    cost_value_loss       | 8.74e-06    |
|    cost_values           | -0.00202    |
|    entropy               | -1.18       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.472       |
|    n_updates             | 10620       |
|    policy_gradient_loss  | -0.00284    |
|    std                   | 0.438       |
|    value_loss            | 1.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.934        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.934        |
| reward                   | -0.21226807  |
| rollout/                 |              |
|    ep_len_mean           | 258          |
|    ep_rew_mean           | -85.1        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 772          |
|    total_timesteps       | 2179072      |
| train/                   |              |
|    approx_kl             | 0.0051343543 |
|    clip_fraction         | 0.0699       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00111     |
|    cost_value_loss       | 7.24e-06     |
|    cost_values           | -0.00106     |
|    entropy               | -1.18        |
|    entropy_loss          | -1.18        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.365        |
|    n_updates             | 10630        |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 0.437        |
|    value_loss            | 0.805        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.475       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.475       |
| reward                   | -0.28310448 |
| rollout/                 |             |
|    ep_len_mean           | 252         |
|    ep_rew_mean           | -80.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 794         |
|    total_timesteps       | 2181120     |
| train/                   |             |
|    approx_kl             | 0.00814976  |
|    clip_fraction         | 0.0836      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00159    |
|    cost_value_loss       | 7.56e-06    |
|    cost_values           | -0.00168    |
|    entropy               | -1.18       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.416       |
|    n_updates             | 10640       |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.437       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.55        |
| reward                   | -0.35639974 |
| rollout/                 |             |
|    ep_len_mean           | 248         |
|    ep_rew_mean           | -82.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 816         |
|    total_timesteps       | 2183168     |
| train/                   |             |
|    approx_kl             | 0.006494564 |
|    clip_fraction         | 0.0747      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0008     |
|    cost_value_loss       | 4.74e-06    |
|    cost_values           | -0.000826   |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.415       |
|    n_updates             | 10650       |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.435       |
|    value_loss            | 0.903       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.14         |
| reward                   | -0.32853928  |
| rollout/                 |              |
|    ep_len_mean           | 248          |
|    ep_rew_mean           | -83.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 38           |
|    time_elapsed          | 838          |
|    total_timesteps       | 2185216      |
| train/                   |              |
|    approx_kl             | 0.0050151628 |
|    clip_fraction         | 0.077        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00139      |
|    cost_value_loss       | 1.52e-05     |
|    cost_values           | 0.00143      |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.69         |
|    n_updates             | 10660        |
|    policy_gradient_loss  | -0.000869    |
|    std                   | 0.433        |
|    value_loss            | 2.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.05        |
| reward                   | -0.31123382 |
| rollout/                 |             |
|    ep_len_mean           | 252         |
|    ep_rew_mean           | -85.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 860         |
|    total_timesteps       | 2187264     |
| train/                   |             |
|    approx_kl             | 0.010762187 |
|    clip_fraction         | 0.0791      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00167     |
|    cost_value_loss       | 1.42e-05    |
|    cost_values           | 0.00168     |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.08        |
|    n_updates             | 10670       |
|    policy_gradient_loss  | -0.00635    |
|    std                   | 0.433       |
|    value_loss            | 5.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.56        |
| reward                   | -1.1691444  |
| rollout/                 |             |
|    ep_len_mean           | 250         |
|    ep_rew_mean           | -84.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 882         |
|    total_timesteps       | 2189312     |
| train/                   |             |
|    approx_kl             | 0.007784306 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000202    |
|    cost_value_loss       | 5.17e-06    |
|    cost_values           | 0.000214    |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.465       |
|    n_updates             | 10680       |
|    policy_gradient_loss  | -0.00576    |
|    std                   | 0.433       |
|    value_loss            | 1.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.78         |
| reward                   | -0.2964316   |
| rollout/                 |              |
|    ep_len_mean           | 252          |
|    ep_rew_mean           | -90.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 904          |
|    total_timesteps       | 2191360      |
| train/                   |              |
|    approx_kl             | 0.0065869275 |
|    clip_fraction         | 0.0893       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00149      |
|    cost_value_loss       | 1.66e-05     |
|    cost_values           | 0.00153      |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.48         |
|    n_updates             | 10690        |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 0.432        |
|    value_loss            | 3.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.04         |
| reward                   | -0.26165578  |
| rollout/                 |              |
|    ep_len_mean           | 257          |
|    ep_rew_mean           | -94.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 926          |
|    total_timesteps       | 2193408      |
| train/                   |              |
|    approx_kl             | 0.0086305635 |
|    clip_fraction         | 0.068        |
|    clip_range            | 0.2          |
|    cost_returns          | -9.36e-05    |
|    cost_value_loss       | 6.85e-06     |
|    cost_values           | -9.45e-05    |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.342        |
|    n_updates             | 10700        |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.431        |
|    value_loss            | 0.929        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.808        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.808        |
| reward                   | -0.31143016  |
| rollout/                 |              |
|    ep_len_mean           | 250          |
|    ep_rew_mean           | -90.6        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 948          |
|    total_timesteps       | 2195456      |
| train/                   |              |
|    approx_kl             | 0.0061451374 |
|    clip_fraction         | 0.0995       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0002       |
|    cost_value_loss       | 1.24e-05     |
|    cost_values           | 0.000271     |
|    entropy               | -1.15        |
|    entropy_loss          | -1.15        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.731        |
|    n_updates             | 10710        |
|    policy_gradient_loss  | -0.0047      |
|    std                   | 0.431        |
|    value_loss            | 1.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.38        |
| reward                   | -0.23323932 |
| rollout/                 |             |
|    ep_len_mean           | 251         |
|    ep_rew_mean           | -91.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 970         |
|    total_timesteps       | 2197504     |
| train/                   |             |
|    approx_kl             | 0.005256948 |
|    clip_fraction         | 0.0497      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0028      |
|    cost_value_loss       | 5.33e-06    |
|    cost_values           | 0.00276     |
|    entropy               | -1.14       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.862       |
|    n_updates             | 10720       |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 0.429       |
|    value_loss            | 1.98        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.336        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.336        |
| reward                   | -0.47036615  |
| rollout/                 |              |
|    ep_len_mean           | 248          |
|    ep_rew_mean           | -90.6        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 992          |
|    total_timesteps       | 2199552      |
| train/                   |              |
|    approx_kl             | 0.0073703863 |
|    clip_fraction         | 0.0777       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00157      |
|    cost_value_loss       | 7.35e-06     |
|    cost_values           | 0.00158      |
|    entropy               | -1.14        |
|    entropy_loss          | -1.14        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.244        |
|    n_updates             | 10730        |
|    policy_gradient_loss  | -0.00406     |
|    std                   | 0.428        |
|    value_loss            | 0.722        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.01        |
| reward                   | -0.34733495 |
| rollout/                 |             |
|    ep_len_mean           | 246         |
|    ep_rew_mean           | -89.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1014        |
|    total_timesteps       | 2201600     |
| train/                   |             |
|    approx_kl             | 0.006986315 |
|    clip_fraction         | 0.0758      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000681    |
|    cost_value_loss       | 7.35e-06    |
|    cost_values           | 0.000674    |
|    entropy               | -1.13       |
|    entropy_loss          | -1.13       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.312       |
|    n_updates             | 10740       |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.426       |
|    value_loss            | 0.921       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.533       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.533       |
| reward                   | -0.23845123 |
| rollout/                 |             |
|    ep_len_mean           | 245         |
|    ep_rew_mean           | -89.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1036        |
|    total_timesteps       | 2203648     |
| train/                   |             |
|    approx_kl             | 0.006830437 |
|    clip_fraction         | 0.0812      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.000487    |
|    cost_value_loss       | 5.37e-06    |
|    cost_values           | 0.000495    |
|    entropy               | -1.12       |
|    entropy_loss          | -1.13       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.567       |
|    n_updates             | 10750       |
|    policy_gradient_loss  | -0.00395    |
|    std                   | 0.425       |
|    value_loss            | 1.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.77         |
| reward                   | -0.29334146  |
| rollout/                 |              |
|    ep_len_mean           | 246          |
|    ep_rew_mean           | -89          |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1058         |
|    total_timesteps       | 2205696      |
| train/                   |              |
|    approx_kl             | 0.0073163053 |
|    clip_fraction         | 0.0676       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000326     |
|    cost_value_loss       | 5.65e-06     |
|    cost_values           | 0.000375     |
|    entropy               | -1.13        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.448        |
|    n_updates             | 10760        |
|    policy_gradient_loss  | -0.00248     |
|    std                   | 0.427        |
|    value_loss            | 0.993        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.57         |
| reward                   | -0.43803346  |
| rollout/                 |              |
|    ep_len_mean           | 244          |
|    ep_rew_mean           | -85.3        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1080         |
|    total_timesteps       | 2207744      |
| train/                   |              |
|    approx_kl             | 0.0068320907 |
|    clip_fraction         | 0.075        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.000949     |
|    cost_value_loss       | 3.48e-06     |
|    cost_values           | 0.000904     |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.509        |
|    n_updates             | 10770        |
|    policy_gradient_loss  | -0.00421     |
|    std                   | 0.426        |
|    value_loss            | 1.3          |
-------------------------------------------
------------------------------------
| avg_speed          | 1.96        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 1.96        |
| reward             | -0.42698476 |
| rollout/           |             |
|    ep_len_mean     | 246         |
|    ep_rew_mean     | -86.3       |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2209792     |
------------------------------------
------------------------------------------
| avg_speed                | 0.744       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.744       |
| reward                   | -0.6946882  |
| rollout/                 |             |
|    ep_len_mean           | 243         |
|    ep_rew_mean           | -85.2       |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 2211840     |
| train/                   |             |
|    approx_kl             | 0.008009551 |
|    clip_fraction         | 0.055       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.778       |
|    cost_value_loss       | 5.44        |
|    cost_values           | 0.665       |
|    entropy               | -1.13       |
|    entropy_loss          | -1.13       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.65        |
|    n_updates             | 10790       |
|    policy_gradient_loss  | -0.00528    |
|    std                   | 0.427       |
|    value_loss            | 6.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.08         |
| reward                   | -0.29888952  |
| rollout/                 |              |
|    ep_len_mean           | 245          |
|    ep_rew_mean           | -85.3        |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 65           |
|    total_timesteps       | 2213888      |
| train/                   |              |
|    approx_kl             | 0.0044689337 |
|    clip_fraction         | 0.0633       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.102        |
|    cost_value_loss       | 0.00675      |
|    cost_values           | 0.109        |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0.986        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.835        |
|    n_updates             | 10800        |
|    policy_gradient_loss  | -0.00381     |
|    std                   | 0.427        |
|    value_loss            | 2.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.215        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.215        |
| reward                   | -0.3049564   |
| rollout/                 |              |
|    ep_len_mean           | 252          |
|    ep_rew_mean           | -90.1        |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 2215936      |
| train/                   |              |
|    approx_kl             | 0.0063771363 |
|    clip_fraction         | 0.0978       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.456        |
|    cost_value_loss       | 0.0313       |
|    cost_values           | 0.459        |
|    entropy               | -1.14        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0.999        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.294        |
|    n_updates             | 10810        |
|    policy_gradient_loss  | -0.00401     |
|    std                   | 0.428        |
|    value_loss            | 0.805        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.84         |
| reward                   | -0.1883243   |
| rollout/                 |              |
|    ep_len_mean           | 245          |
|    ep_rew_mean           | -85.8        |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 109          |
|    total_timesteps       | 2217984      |
| train/                   |              |
|    approx_kl             | 0.0087878825 |
|    clip_fraction         | 0.106        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.394        |
|    cost_value_loss       | 0.0267       |
|    cost_values           | 0.419        |
|    entropy               | -1.13        |
|    entropy_loss          | -1.14        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.605        |
|    n_updates             | 10820        |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 0.428        |
|    value_loss            | 2.24         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.687       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.687       |
| reward                   | -0.36736137 |
| rollout/                 |             |
|    ep_len_mean           | 245         |
|    ep_rew_mean           | -85.5       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 2220032     |
| train/                   |             |
|    approx_kl             | 0.005628147 |
|    clip_fraction         | 0.0647      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0109      |
|    cost_value_loss       | 0.000989    |
|    cost_values           | 0.0131      |
|    entropy               | -1.12       |
|    entropy_loss          | -1.13       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.374       |
|    n_updates             | 10830       |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.426       |
|    value_loss            | 1.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.891        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.891        |
| reward                   | -1.0140923   |
| rollout/                 |              |
|    ep_len_mean           | 245          |
|    ep_rew_mean           | -85.8        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 154          |
|    total_timesteps       | 2222080      |
| train/                   |              |
|    approx_kl             | 0.0060389363 |
|    clip_fraction         | 0.0738       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0204       |
|    cost_value_loss       | 0.000188     |
|    cost_values           | 0.0209       |
|    entropy               | -1.13        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.753        |
|    n_updates             | 10840        |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.426        |
|    value_loss            | 1.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.6          |
| reward                   | -0.3177728   |
| rollout/                 |              |
|    ep_len_mean           | 252          |
|    ep_rew_mean           | -90.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 2224128      |
| train/                   |              |
|    approx_kl             | 0.0060854233 |
|    clip_fraction         | 0.0866       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.31         |
|    cost_value_loss       | 0.00518      |
|    cost_values           | 0.321        |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.664        |
|    n_updates             | 10850        |
|    policy_gradient_loss  | -0.00418     |
|    std                   | 0.427        |
|    value_loss            | 2.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.412       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.412       |
| reward                   | -0.735806   |
| rollout/                 |             |
|    ep_len_mean           | 247         |
|    ep_rew_mean           | -88.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 199         |
|    total_timesteps       | 2226176     |
| train/                   |             |
|    approx_kl             | 0.005767242 |
|    clip_fraction         | 0.059       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00188    |
|    cost_value_loss       | 0.0101      |
|    cost_values           | -0.00118    |
|    entropy               | -1.13       |
|    entropy_loss          | -1.13       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.71        |
|    n_updates             | 10860       |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 0.427       |
|    value_loss            | 1.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.69         |
| reward                   | -0.3994343   |
| rollout/                 |              |
|    ep_len_mean           | 256          |
|    ep_rew_mean           | -93.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 10           |
|    time_elapsed          | 221          |
|    total_timesteps       | 2228224      |
| train/                   |              |
|    approx_kl             | 0.0069041625 |
|    clip_fraction         | 0.0972       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.061        |
|    cost_value_loss       | 0.00121      |
|    cost_values           | 0.0607       |
|    entropy               | -1.13        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.706        |
|    n_updates             | 10870        |
|    policy_gradient_loss  | -0.00415     |
|    std                   | 0.426        |
|    value_loss            | 2.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.53        |
| reward                   | -0.29804805 |
| rollout/                 |             |
|    ep_len_mean           | 266         |
|    ep_rew_mean           | -96.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 2230272     |
| train/                   |             |
|    approx_kl             | 0.00701511  |
|    clip_fraction         | 0.0595      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0755      |
|    cost_value_loss       | 0.00786     |
|    cost_values           | 0.08        |
|    entropy               | -1.12       |
|    entropy_loss          | -1.12       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.476       |
|    n_updates             | 10880       |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.424       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.69        |
| reward                   | -0.33408388 |
| rollout/                 |             |
|    ep_len_mean           | 270         |
|    ep_rew_mean           | -101        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 266         |
|    total_timesteps       | 2232320     |
| train/                   |             |
|    approx_kl             | 0.010729707 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0172     |
|    cost_value_loss       | 0.000158    |
|    cost_values           | -0.0168     |
|    entropy               | -1.11       |
|    entropy_loss          | -1.11       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.363       |
|    n_updates             | 10890       |
|    policy_gradient_loss  | -0.00667    |
|    std                   | 0.423       |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.96        |
| reward                   | -0.47886297 |
| rollout/                 |             |
|    ep_len_mean           | 272         |
|    ep_rew_mean           | -103        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 288         |
|    total_timesteps       | 2234368     |
| train/                   |             |
|    approx_kl             | 0.010159196 |
|    clip_fraction         | 0.0704      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.145       |
|    cost_value_loss       | 0.00787     |
|    cost_values           | 0.151       |
|    entropy               | -1.11       |
|    entropy_loss          | -1.11       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.741       |
|    n_updates             | 10900       |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 0.424       |
|    value_loss            | 2.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.89         |
| reward                   | -0.87492675  |
| rollout/                 |              |
|    ep_len_mean           | 278          |
|    ep_rew_mean           | -105         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 310          |
|    total_timesteps       | 2236416      |
| train/                   |              |
|    approx_kl             | 0.0053635314 |
|    clip_fraction         | 0.0708       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0599      |
|    cost_value_loss       | 0.000767     |
|    cost_values           | -0.0568      |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0.854        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.03         |
|    n_updates             | 10910        |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.424        |
|    value_loss            | 4.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.4          |
| reward                   | -0.30675703  |
| rollout/                 |              |
|    ep_len_mean           | 281          |
|    ep_rew_mean           | -104         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 333          |
|    total_timesteps       | 2238464      |
| train/                   |              |
|    approx_kl             | 0.0065518105 |
|    clip_fraction         | 0.0713       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.102        |
|    cost_value_loss       | 0.0364       |
|    cost_values           | 0.101        |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.09         |
|    n_updates             | 10920        |
|    policy_gradient_loss  | -0.00441     |
|    std                   | 0.424        |
|    value_loss            | 3.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.632       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.632       |
| reward                   | -0.3544414  |
| rollout/                 |             |
|    ep_len_mean           | 290         |
|    ep_rew_mean           | -110        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 355         |
|    total_timesteps       | 2240512     |
| train/                   |             |
|    approx_kl             | 0.008277263 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0175     |
|    cost_value_loss       | 0.00509     |
|    cost_values           | -0.016      |
|    entropy               | -1.1        |
|    entropy_loss          | -1.11       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.806       |
|    n_updates             | 10930       |
|    policy_gradient_loss  | -0.00421    |
|    std                   | 0.421       |
|    value_loss            | 1.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.24        |
| reward                   | -0.1754026  |
| rollout/                 |             |
|    ep_len_mean           | 283         |
|    ep_rew_mean           | -104        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 377         |
|    total_timesteps       | 2242560     |
| train/                   |             |
|    approx_kl             | 0.008407279 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.125       |
|    cost_value_loss       | 0.00424     |
|    cost_values           | 0.129       |
|    entropy               | -1.1        |
|    entropy_loss          | -1.1        |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.597       |
|    n_updates             | 10940       |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 0.42        |
|    value_loss            | 1.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.616       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.616       |
| reward                   | -0.35456294 |
| rollout/                 |             |
|    ep_len_mean           | 279         |
|    ep_rew_mean           | -99.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 400         |
|    total_timesteps       | 2244608     |
| train/                   |             |
|    approx_kl             | 0.008195989 |
|    clip_fraction         | 0.0961      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0101      |
|    cost_value_loss       | 0.000109    |
|    cost_values           | 0.0116      |
|    entropy               | -1.1        |
|    entropy_loss          | -1.1        |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.772       |
|    n_updates             | 10950       |
|    policy_gradient_loss  | -0.00435    |
|    std                   | 0.42        |
|    value_loss            | 2           |
------------------------------------------
------------------------------------------
| avg_speed                | 0.816       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.816       |
| reward                   | -0.6138065  |
| rollout/                 |             |
|    ep_len_mean           | 279         |
|    ep_rew_mean           | -99.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 422         |
|    total_timesteps       | 2246656     |
| train/                   |             |
|    approx_kl             | 0.006548688 |
|    clip_fraction         | 0.063       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00823    |
|    cost_value_loss       | 0.000157    |
|    cost_values           | -0.0089     |
|    entropy               | -1.09       |
|    entropy_loss          | -1.09       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.611       |
|    n_updates             | 10960       |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.418       |
|    value_loss            | 1.37        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.457        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.457        |
| reward                   | -0.23990802  |
| rollout/                 |              |
|    ep_len_mean           | 290          |
|    ep_rew_mean           | -105         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 444          |
|    total_timesteps       | 2248704      |
| train/                   |              |
|    approx_kl             | 0.0048915506 |
|    clip_fraction         | 0.0601       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00652      |
|    cost_value_loss       | 0.000125     |
|    cost_values           | 0.00647      |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.547        |
|    n_updates             | 10970        |
|    policy_gradient_loss  | -0.002       |
|    std                   | 0.417        |
|    value_loss            | 1.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.691        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.691        |
| reward                   | -0.31211987  |
| rollout/                 |              |
|    ep_len_mean           | 284          |
|    ep_rew_mean           | -100         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 21           |
|    time_elapsed          | 466          |
|    total_timesteps       | 2250752      |
| train/                   |              |
|    approx_kl             | 0.0074936566 |
|    clip_fraction         | 0.0687       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0241       |
|    cost_value_loss       | 0.00166      |
|    cost_values           | 0.025        |
|    entropy               | -1.08        |
|    entropy_loss          | -1.08        |
|    explained_variance    | 0.998        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.198        |
|    n_updates             | 10980        |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 0.417        |
|    value_loss            | 0.574        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.326       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.326       |
| reward                   | -0.35423544 |
| rollout/                 |             |
|    ep_len_mean           | 285         |
|    ep_rew_mean           | -99.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 489         |
|    total_timesteps       | 2252800     |
| train/                   |             |
|    approx_kl             | 0.007868026 |
|    clip_fraction         | 0.0744      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0138     |
|    cost_value_loss       | 0.00015     |
|    cost_values           | -0.0146     |
|    entropy               | -1.08       |
|    entropy_loss          | -1.08       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.393       |
|    n_updates             | 10990       |
|    policy_gradient_loss  | -0.00353    |
|    std                   | 0.416       |
|    value_loss            | 0.948       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.02        |
| reward                   | -0.2722299  |
| rollout/                 |             |
|    ep_len_mean           | 295         |
|    ep_rew_mean           | -106        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 511         |
|    total_timesteps       | 2254848     |
| train/                   |             |
|    approx_kl             | 0.007769725 |
|    clip_fraction         | 0.0717      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00837    |
|    cost_value_loss       | 0.000112    |
|    cost_values           | -0.00865    |
|    entropy               | -1.08       |
|    entropy_loss          | -1.08       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.387       |
|    n_updates             | 11000       |
|    policy_gradient_loss  | -0.00336    |
|    std                   | 0.415       |
|    value_loss            | 0.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.14         |
| reward                   | -0.3581447   |
| rollout/                 |              |
|    ep_len_mean           | 286          |
|    ep_rew_mean           | -101         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 533          |
|    total_timesteps       | 2256896      |
| train/                   |              |
|    approx_kl             | 0.0069238762 |
|    clip_fraction         | 0.0828       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.101        |
|    cost_value_loss       | 0.00321      |
|    cost_values           | 0.105        |
|    entropy               | -1.08        |
|    entropy_loss          | -1.08        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.26         |
|    n_updates             | 11010        |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.416        |
|    value_loss            | 2.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.76        |
| reward                   | -0.22315668 |
| rollout/                 |             |
|    ep_len_mean           | 285         |
|    ep_rew_mean           | -104        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 555         |
|    total_timesteps       | 2258944     |
| train/                   |             |
|    approx_kl             | 0.010682333 |
|    clip_fraction         | 0.096       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0065     |
|    cost_value_loss       | 0.000105    |
|    cost_values           | -0.00708    |
|    entropy               | -1.08       |
|    entropy_loss          | -1.08       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.255       |
|    n_updates             | 11020       |
|    policy_gradient_loss  | -0.00753    |
|    std                   | 0.416       |
|    value_loss            | 0.737       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.86        |
| reward                   | -0.23186754 |
| rollout/                 |             |
|    ep_len_mean           | 296         |
|    ep_rew_mean           | -109        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 577         |
|    total_timesteps       | 2260992     |
| train/                   |             |
|    approx_kl             | 0.012162849 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0585      |
|    cost_value_loss       | 0.00229     |
|    cost_values           | 0.0602      |
|    entropy               | -1.08       |
|    entropy_loss          | -1.08       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.434       |
|    n_updates             | 11030       |
|    policy_gradient_loss  | -0.00502    |
|    std                   | 0.415       |
|    value_loss            | 1.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.96         |
| reward                   | -1.0118928   |
| rollout/                 |              |
|    ep_len_mean           | 279          |
|    ep_rew_mean           | -99.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 599          |
|    total_timesteps       | 2263040      |
| train/                   |              |
|    approx_kl             | 0.0046740645 |
|    clip_fraction         | 0.0642       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.037        |
|    cost_value_loss       | 0.00175      |
|    cost_values           | 0.0398       |
|    entropy               | -1.08        |
|    entropy_loss          | -1.08        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.646        |
|    n_updates             | 11040        |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 0.415        |
|    value_loss            | 2.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.07        |
| reward                   | -0.36965927 |
| rollout/                 |             |
|    ep_len_mean           | 282         |
|    ep_rew_mean           | -105        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 621         |
|    total_timesteps       | 2265088     |
| train/                   |             |
|    approx_kl             | 0.007460846 |
|    clip_fraction         | 0.0723      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0708      |
|    cost_value_loss       | 0.000675    |
|    cost_values           | 0.0717      |
|    entropy               | -1.08       |
|    entropy_loss          | -1.08       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.796       |
|    n_updates             | 11050       |
|    policy_gradient_loss  | -0.00414    |
|    std                   | 0.415       |
|    value_loss            | 1.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.89        |
| reward                   | -0.27731854 |
| rollout/                 |             |
|    ep_len_mean           | 289         |
|    ep_rew_mean           | -117        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 643         |
|    total_timesteps       | 2267136     |
| train/                   |             |
|    approx_kl             | 0.010697828 |
|    clip_fraction         | 0.094       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0709      |
|    cost_value_loss       | 0.00241     |
|    cost_values           | 0.0729      |
|    entropy               | -1.08       |
|    entropy_loss          | -1.08       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.776       |
|    n_updates             | 11060       |
|    policy_gradient_loss  | -0.00394    |
|    std                   | 0.415       |
|    value_loss            | 2.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.13         |
| reward                   | -0.27386537  |
| rollout/                 |              |
|    ep_len_mean           | 284          |
|    ep_rew_mean           | -113         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 666          |
|    total_timesteps       | 2269184      |
| train/                   |              |
|    approx_kl             | 0.0055408305 |
|    clip_fraction         | 0.0385       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.34         |
|    cost_value_loss       | 42.9         |
|    cost_values           | 1.25         |
|    entropy               | -1.07        |
|    entropy_loss          | -1.07        |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0.000696     |
|    learning_rate         | 0.0003       |
|    loss                  | 41.2         |
|    n_updates             | 11070        |
|    policy_gradient_loss  | -0.00387     |
|    std                   | 0.415        |
|    value_loss            | 78.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.31        |
| reward                   | -0.43995783 |
| rollout/                 |             |
|    ep_len_mean           | 282         |
|    ep_rew_mean           | -113        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 688         |
|    total_timesteps       | 2271232     |
| train/                   |             |
|    approx_kl             | 0.006309476 |
|    clip_fraction         | 0.0388      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.784       |
|    cost_value_loss       | 0.0492      |
|    cost_values           | 0.856       |
|    entropy               | -1.07       |
|    entropy_loss          | -1.07       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.768       |
|    n_updates             | 11080       |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 0.414       |
|    value_loss            | 3.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.77        |
| reward                   | -0.18976337 |
| rollout/                 |             |
|    ep_len_mean           | 278         |
|    ep_rew_mean           | -112        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 711         |
|    total_timesteps       | 2273280     |
| train/                   |             |
|    approx_kl             | 0.010204131 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.679       |
|    cost_value_loss       | 0.0428      |
|    cost_values           | 0.742       |
|    entropy               | -1.07       |
|    entropy_loss          | -1.07       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.609       |
|    n_updates             | 11090       |
|    policy_gradient_loss  | -0.0028     |
|    std                   | 0.413       |
|    value_loss            | 1.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.697       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.697       |
| reward                   | -0.43586123 |
| rollout/                 |             |
|    ep_len_mean           | 263         |
|    ep_rew_mean           | -106        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 733         |
|    total_timesteps       | 2275328     |
| train/                   |             |
|    approx_kl             | 0.006094058 |
|    clip_fraction         | 0.0534      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.628       |
|    cost_value_loss       | 0.0262      |
|    cost_values           | 0.7         |
|    entropy               | -1.07       |
|    entropy_loss          | -1.07       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.682       |
|    n_updates             | 11100       |
|    policy_gradient_loss  | -0.0024     |
|    std                   | 0.413       |
|    value_loss            | 1.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.322       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.322       |
| reward                   | -0.4321315  |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -106        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 755         |
|    total_timesteps       | 2277376     |
| train/                   |             |
|    approx_kl             | 0.007188403 |
|    clip_fraction         | 0.0702      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.453       |
|    cost_value_loss       | 0.0169      |
|    cost_values           | 0.497       |
|    entropy               | -1.05       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.533       |
|    n_updates             | 11110       |
|    policy_gradient_loss  | -0.00219    |
|    std                   | 0.41        |
|    value_loss            | 1.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.87         |
| reward                   | -0.27316526  |
| rollout/                 |              |
|    ep_len_mean           | 251          |
|    ep_rew_mean           | -100         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 777          |
|    total_timesteps       | 2279424      |
| train/                   |              |
|    approx_kl             | 0.0070136627 |
|    clip_fraction         | 0.083        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.288        |
|    cost_value_loss       | 0.00768      |
|    cost_values           | 0.316        |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.854        |
|    n_updates             | 11120        |
|    policy_gradient_loss  | -0.00505     |
|    std                   | 0.409        |
|    value_loss            | 1.75         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.23         |
| reward                   | -0.83043575  |
| rollout/                 |              |
|    ep_len_mean           | 249          |
|    ep_rew_mean           | -99.2        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 799          |
|    total_timesteps       | 2281472      |
| train/                   |              |
|    approx_kl             | 0.0059667407 |
|    clip_fraction         | 0.0559       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.211        |
|    cost_value_loss       | 0.00606      |
|    cost_values           | 0.25         |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.582        |
|    n_updates             | 11130        |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.409        |
|    value_loss            | 1.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.819        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.819        |
| reward                   | -0.5525564   |
| rollout/                 |              |
|    ep_len_mean           | 249          |
|    ep_rew_mean           | -98.2        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 821          |
|    total_timesteps       | 2283520      |
| train/                   |              |
|    approx_kl             | 0.0077284873 |
|    clip_fraction         | 0.053        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.444        |
|    cost_value_loss       | 0.00959      |
|    cost_values           | 0.485        |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.518        |
|    n_updates             | 11140        |
|    policy_gradient_loss  | -0.00147     |
|    std                   | 0.41         |
|    value_loss            | 1.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.36        |
| reward                   | -0.32243505 |
| rollout/                 |             |
|    ep_len_mean           | 262         |
|    ep_rew_mean           | -108        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 843         |
|    total_timesteps       | 2285568     |
| train/                   |             |
|    approx_kl             | 0.010425328 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.133       |
|    cost_value_loss       | 0.0122      |
|    cost_values           | 0.151       |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.22        |
|    n_updates             | 11150       |
|    policy_gradient_loss  | -0.00644    |
|    std                   | 0.41        |
|    value_loss            | 3.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.563       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.563       |
| reward                   | -0.26331657 |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -110        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 865         |
|    total_timesteps       | 2287616     |
| train/                   |             |
|    approx_kl             | 0.010679476 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.697       |
|    cost_value_loss       | 0.0436      |
|    cost_values           | 0.755       |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.413       |
|    n_updates             | 11160       |
|    policy_gradient_loss  | -0.00563    |
|    std                   | 0.409       |
|    value_loss            | 1.71        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.95         |
| reward                   | -0.29251274  |
| rollout/                 |              |
|    ep_len_mean           | 277          |
|    ep_rew_mean           | -118         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 40           |
|    time_elapsed          | 887          |
|    total_timesteps       | 2289664      |
| train/                   |              |
|    approx_kl             | 0.0058377176 |
|    clip_fraction         | 0.122        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 9.07         |
|    cost_values           | 0.564        |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0.00854      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.26         |
|    n_updates             | 11170        |
|    policy_gradient_loss  | 0.000291     |
|    std                   | 0.409        |
|    value_loss            | 3.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.42703155  |
| rollout/                 |              |
|    ep_len_mean           | 282          |
|    ep_rew_mean           | -116         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 909          |
|    total_timesteps       | 2291712      |
| train/                   |              |
|    approx_kl             | 0.0059269452 |
|    clip_fraction         | 0.0356       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.03         |
|    cost_value_loss       | 50.6         |
|    cost_values           | 0.247        |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | -1.13        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.6         |
|    n_updates             | 11180        |
|    policy_gradient_loss  | -0.0038      |
|    std                   | 0.409        |
|    value_loss            | 34.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.65         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.65         |
| reward                   | -0.43820256  |
| rollout/                 |              |
|    ep_len_mean           | 259          |
|    ep_rew_mean           | -96.8        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 931          |
|    total_timesteps       | 2293760      |
| train/                   |              |
|    approx_kl             | 0.0053541004 |
|    clip_fraction         | 0.0488       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.889        |
|    cost_value_loss       | 0.138        |
|    cost_values           | 1.2          |
|    entropy               | -1.04        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.839        |
|    n_updates             | 11190        |
|    policy_gradient_loss  | -0.00496     |
|    std                   | 0.408        |
|    value_loss            | 3.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1            |
| reward                   | -0.71614087  |
| rollout/                 |              |
|    ep_len_mean           | 268          |
|    ep_rew_mean           | -102         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 953          |
|    total_timesteps       | 2295808      |
| train/                   |              |
|    approx_kl             | 0.0073776655 |
|    clip_fraction         | 0.0964       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.779        |
|    cost_value_loss       | 0.0273       |
|    cost_values           | 0.858        |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0.969        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.05         |
|    n_updates             | 11200        |
|    policy_gradient_loss  | -0.00718     |
|    std                   | 0.408        |
|    value_loss            | 2.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.81        |
| reward                   | -0.88905907 |
| rollout/                 |             |
|    ep_len_mean           | 276         |
|    ep_rew_mean           | -107        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 976         |
|    total_timesteps       | 2297856     |
| train/                   |             |
|    approx_kl             | 0.006052778 |
|    clip_fraction         | 0.0662      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.739       |
|    cost_value_loss       | 0.0439      |
|    cost_values           | 0.857       |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.848       |
|    n_updates             | 11210       |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 0.408       |
|    value_loss            | 5.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.76        |
| reward                   | -0.49460167 |
| rollout/                 |             |
|    ep_len_mean           | 291         |
|    ep_rew_mean           | -120        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 998         |
|    total_timesteps       | 2299904     |
| train/                   |             |
|    approx_kl             | 0.005596051 |
|    clip_fraction         | 0.064       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.624       |
|    cost_value_loss       | 0.0401      |
|    cost_values           | 0.732       |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.1         |
|    n_updates             | 11220       |
|    policy_gradient_loss  | -0.00445    |
|    std                   | 0.407       |
|    value_loss            | 3.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.495        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.495        |
| reward                   | -0.501856    |
| rollout/                 |              |
|    ep_len_mean           | 298          |
|    ep_rew_mean           | -123         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1020         |
|    total_timesteps       | 2301952      |
| train/                   |              |
|    approx_kl             | 0.0063150954 |
|    clip_fraction         | 0.0906       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 5.52         |
|    cost_values           | 0.703        |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.02         |
|    n_updates             | 11230        |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.408        |
|    value_loss            | 22.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.04        |
| reward                   | -0.25694624 |
| rollout/                 |             |
|    ep_len_mean           | 313         |
|    ep_rew_mean           | -134        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1041        |
|    total_timesteps       | 2304000     |
| train/                   |             |
|    approx_kl             | 0.009497121 |
|    clip_fraction         | 0.0863      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.72        |
|    cost_value_loss       | 0.0417      |
|    cost_values           | 0.876       |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.16        |
|    n_updates             | 11240       |
|    policy_gradient_loss  | -0.0037     |
|    std                   | 0.408       |
|    value_loss            | 3.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.98        |
| reward                   | -0.78220147 |
| rollout/                 |             |
|    ep_len_mean           | 314         |
|    ep_rew_mean           | -133        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1064        |
|    total_timesteps       | 2306048     |
| train/                   |             |
|    approx_kl             | 0.012748186 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.872       |
|    cost_value_loss       | 0.0449      |
|    cost_values           | 0.953       |
|    entropy               | -1.05       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.615       |
|    n_updates             | 11250       |
|    policy_gradient_loss  | -0.0072     |
|    std                   | 0.409       |
|    value_loss            | 1.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0925       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0925       |
| reward                   | -0.400989    |
| rollout/                 |              |
|    ep_len_mean           | 334          |
|    ep_rew_mean           | -146         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1085         |
|    total_timesteps       | 2308096      |
| train/                   |              |
|    approx_kl             | 0.0116018485 |
|    clip_fraction         | 0.1          |
|    clip_range            | 0.2          |
|    cost_returns          | 0.429        |
|    cost_value_loss       | 0.00988      |
|    cost_values           | 0.505        |
|    entropy               | -1.05        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.9          |
|    n_updates             | 11260        |
|    policy_gradient_loss  | -0.00323     |
|    std                   | 0.409        |
|    value_loss            | 5.48         |
-------------------------------------------
------------------------------------
| avg_speed          | 0.888       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.888       |
| reward             | -0.25235146 |
| rollout/           |             |
|    ep_len_mean     | 345         |
|    ep_rew_mean     | -154        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2310144     |
------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.25190514 |
| rollout/                 |             |
|    ep_len_mean           | 360         |
|    ep_rew_mean           | -167        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 2312192     |
| train/                   |             |
|    approx_kl             | 0.004655305 |
|    clip_fraction         | 0.035       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 3.98        |
|    cost_values           | 1.08        |
|    entropy               | -1.04       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.97        |
|    n_updates             | 11280       |
|    policy_gradient_loss  | -0.00444    |
|    std                   | 0.409       |
|    value_loss            | 17          |
------------------------------------------
------------------------------------------
| avg_speed                | 1.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.7         |
| reward                   | -0.31204632 |
| rollout/                 |             |
|    ep_len_mean           | 367         |
|    ep_rew_mean           | -172        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 2314240     |
| train/                   |             |
|    approx_kl             | 0.007477346 |
|    clip_fraction         | 0.0495      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.67        |
|    cost_value_loss       | 18.7        |
|    cost_values           | 1.91        |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00469     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.86        |
|    n_updates             | 11290       |
|    policy_gradient_loss  | -0.00549    |
|    std                   | 0.409       |
|    value_loss            | 20          |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.99         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.99         |
| reward                   | -1.1362203   |
| rollout/                 |              |
|    ep_len_mean           | 372          |
|    ep_rew_mean           | -174         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 87           |
|    total_timesteps       | 2316288      |
| train/                   |              |
|    approx_kl             | 0.0048533864 |
|    clip_fraction         | 0.0586       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 0.0888       |
|    cost_values           | 1.38         |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.1          |
|    n_updates             | 11300        |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 0.409        |
|    value_loss            | 4.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.43         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.43         |
| reward                   | -0.85302234  |
| rollout/                 |              |
|    ep_len_mean           | 380          |
|    ep_rew_mean           | -182         |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 2318336      |
| train/                   |              |
|    approx_kl             | 0.0049937563 |
|    clip_fraction         | 0.0408       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 7.53         |
|    cost_values           | 1.03         |
|    entropy               | -1.05        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.98         |
|    n_updates             | 11310        |
|    policy_gradient_loss  | -0.00279     |
|    std                   | 0.409        |
|    value_loss            | 10.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.91        |
| reward                   | -0.5776401  |
| rollout/                 |             |
|    ep_len_mean           | 397         |
|    ep_rew_mean           | -196        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 2320384     |
| train/                   |             |
|    approx_kl             | 0.005916954 |
|    clip_fraction         | 0.0503      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.05        |
|    cost_value_loss       | 7.47        |
|    cost_values           | 1.7         |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.917       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.1        |
|    n_updates             | 11320       |
|    policy_gradient_loss  | -0.00678    |
|    std                   | 0.409       |
|    value_loss            | 26.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.3         |
| reward                   | -0.3060601  |
| rollout/                 |             |
|    ep_len_mean           | 404         |
|    ep_rew_mean           | -201        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 2322432     |
| train/                   |             |
|    approx_kl             | 0.006938818 |
|    clip_fraction         | 0.0451      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 0.338       |
|    cost_values           | 1.88        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.19        |
|    n_updates             | 11330       |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 0.409       |
|    value_loss            | 9.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.36        |
| reward                   | -0.15240252 |
| rollout/                 |             |
|    ep_len_mean           | 391         |
|    ep_rew_mean           | -195        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 176         |
|    total_timesteps       | 2324480     |
| train/                   |             |
|    approx_kl             | 0.01044477  |
|    clip_fraction         | 0.0872      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 0.112       |
|    cost_values           | 1.63        |
|    entropy               | -1.04       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.68        |
|    n_updates             | 11340       |
|    policy_gradient_loss  | -0.00448    |
|    std                   | 0.408       |
|    value_loss            | 4.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.93        |
| reward                   | -0.25890088 |
| rollout/                 |             |
|    ep_len_mean           | 368         |
|    ep_rew_mean           | -187        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 198         |
|    total_timesteps       | 2326528     |
| train/                   |             |
|    approx_kl             | 0.008589123 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 0.606       |
|    cost_values           | 1.16        |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.57        |
|    n_updates             | 11350       |
|    policy_gradient_loss  | -0.00338    |
|    std                   | 0.409       |
|    value_loss            | 8.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.63        |
| reward                   | -0.8735351  |
| rollout/                 |             |
|    ep_len_mean           | 375         |
|    ep_rew_mean           | -192        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 2328576     |
| train/                   |             |
|    approx_kl             | 0.006879031 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.36        |
|    cost_value_loss       | 39.7        |
|    cost_values           | 1.35        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.6        |
|    n_updates             | 11360       |
|    policy_gradient_loss  | -0.0054     |
|    std                   | 0.409       |
|    value_loss            | 32.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.86        |
| reward                   | -0.5261491  |
| rollout/                 |             |
|    ep_len_mean           | 391         |
|    ep_rew_mean           | -203        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 2330624     |
| train/                   |             |
|    approx_kl             | 0.007610701 |
|    clip_fraction         | 0.057       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 9.68        |
|    cost_values           | 1.98        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.87        |
|    n_updates             | 11370       |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.41        |
|    value_loss            | 10.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.03        |
| reward                   | -0.25162223 |
| rollout/                 |             |
|    ep_len_mean           | 405         |
|    ep_rew_mean           | -211        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 2332672     |
| train/                   |             |
|    approx_kl             | 0.015142347 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.46        |
|    cost_value_loss       | 0.0993      |
|    cost_values           | 1.61        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.09        |
|    n_updates             | 11380       |
|    policy_gradient_loss  | -0.00656    |
|    std                   | 0.409       |
|    value_loss            | 2.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.596       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.596       |
| reward                   | -0.207816   |
| rollout/                 |             |
|    ep_len_mean           | 410         |
|    ep_rew_mean           | -214        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 288         |
|    total_timesteps       | 2334720     |
| train/                   |             |
|    approx_kl             | 0.006756898 |
|    clip_fraction         | 0.0952      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 0.0893      |
|    cost_values           | 1.53        |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.16        |
|    n_updates             | 11390       |
|    policy_gradient_loss  | -0.00208    |
|    std                   | 0.408       |
|    value_loss            | 9.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.23        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.23        |
| reward                   | -0.5564133  |
| rollout/                 |             |
|    ep_len_mean           | 393         |
|    ep_rew_mean           | -204        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 2336768     |
| train/                   |             |
|    approx_kl             | 0.008552623 |
|    clip_fraction         | 0.0687      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.783       |
|    cost_value_loss       | 0.0486      |
|    cost_values           | 0.924       |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.46        |
|    n_updates             | 11400       |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.408       |
|    value_loss            | 4.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.11         |
| reward                   | -0.3644453   |
| rollout/                 |              |
|    ep_len_mean           | 387          |
|    ep_rew_mean           | -198         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 332          |
|    total_timesteps       | 2338816      |
| train/                   |              |
|    approx_kl             | 0.0088474015 |
|    clip_fraction         | 0.106        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.538        |
|    cost_value_loss       | 0.0218       |
|    cost_values           | 0.638        |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0.927        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.75         |
|    n_updates             | 11410        |
|    policy_gradient_loss  | -0.00764     |
|    std                   | 0.408        |
|    value_loss            | 9.84         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.83        |
| reward                   | -0.21911022 |
| rollout/                 |             |
|    ep_len_mean           | 393         |
|    ep_rew_mean           | -199        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 355         |
|    total_timesteps       | 2340864     |
| train/                   |             |
|    approx_kl             | 0.006560337 |
|    clip_fraction         | 0.0619      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.811       |
|    cost_value_loss       | 0.0612      |
|    cost_values           | 0.934       |
|    entropy               | -1.03       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.872       |
|    n_updates             | 11420       |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.406       |
|    value_loss            | 3.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.42         |
| reward                   | -0.36906314  |
| rollout/                 |              |
|    ep_len_mean           | 388          |
|    ep_rew_mean           | -196         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 377          |
|    total_timesteps       | 2342912      |
| train/                   |              |
|    approx_kl             | 0.0066891187 |
|    clip_fraction         | 0.0883       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.659        |
|    cost_value_loss       | 0.0249       |
|    cost_values           | 0.755        |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 0.966        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.02         |
|    n_updates             | 11430        |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.405        |
|    value_loss            | 2.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.54        |
| reward                   | -0.3433243  |
| rollout/                 |             |
|    ep_len_mean           | 389         |
|    ep_rew_mean           | -196        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 399         |
|    total_timesteps       | 2344960     |
| train/                   |             |
|    approx_kl             | 0.005224536 |
|    clip_fraction         | 0.0775      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.755       |
|    cost_value_loss       | 0.0838      |
|    cost_values           | 0.834       |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.85        |
|    n_updates             | 11440       |
|    policy_gradient_loss  | -0.00301    |
|    std                   | 0.404       |
|    value_loss            | 12.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.25        |
| reward                   | -0.26103505 |
| rollout/                 |             |
|    ep_len_mean           | 387         |
|    ep_rew_mean           | -196        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 422         |
|    total_timesteps       | 2347008     |
| train/                   |             |
|    approx_kl             | 0.005768525 |
|    clip_fraction         | 0.076       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0894      |
|    cost_value_loss       | 0.0015      |
|    cost_values           | 0.107       |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.61        |
|    n_updates             | 11450       |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 0.404       |
|    value_loss            | 3.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.12         |
| reward                   | -0.29173186  |
| rollout/                 |              |
|    ep_len_mean           | 395          |
|    ep_rew_mean           | -202         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 444          |
|    total_timesteps       | 2349056      |
| train/                   |              |
|    approx_kl             | 0.0069474485 |
|    clip_fraction         | 0.112        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.88         |
|    cost_value_loss       | 38.9         |
|    cost_values           | 0.914        |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0.001        |
|    learning_rate         | 0.0003       |
|    loss                  | 25.7         |
|    n_updates             | 11460        |
|    policy_gradient_loss  | -0.00883     |
|    std                   | 0.404        |
|    value_loss            | 47.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.14        |
| reward                   | -0.5174003  |
| rollout/                 |             |
|    ep_len_mean           | 368         |
|    ep_rew_mean           | -182        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 467         |
|    total_timesteps       | 2351104     |
| train/                   |             |
|    approx_kl             | 0.005277721 |
|    clip_fraction         | 0.0557      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.47        |
|    cost_value_loss       | 53.9        |
|    cost_values           | 1.43        |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.00651     |
|    learning_rate         | 0.0003      |
|    loss                  | 13.2        |
|    n_updates             | 11470       |
|    policy_gradient_loss  | -0.00807    |
|    std                   | 0.403       |
|    value_loss            | 53.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.05         |
| reward                   | -0.9030892   |
| rollout/                 |              |
|    ep_len_mean           | 377          |
|    ep_rew_mean           | -187         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 489          |
|    total_timesteps       | 2353152      |
| train/                   |              |
|    approx_kl             | 0.0061720195 |
|    clip_fraction         | 0.068        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.656        |
|    cost_value_loss       | 0.0349       |
|    cost_values           | 0.811        |
|    entropy               | -1.01        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.62         |
|    n_updates             | 11480        |
|    policy_gradient_loss  | -0.00451     |
|    std                   | 0.402        |
|    value_loss            | 6.76         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.8          |
| reward                   | -0.46512464  |
| rollout/                 |              |
|    ep_len_mean           | 376          |
|    ep_rew_mean           | -184         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 511          |
|    total_timesteps       | 2355200      |
| train/                   |              |
|    approx_kl             | 0.0063938396 |
|    clip_fraction         | 0.0563       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.04         |
|    cost_value_loss       | 12           |
|    cost_values           | 1.11         |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.96         |
|    n_updates             | 11490        |
|    policy_gradient_loss  | -0.00527     |
|    std                   | 0.402        |
|    value_loss            | 7.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.519        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.519        |
| reward                   | -0.26389697  |
| rollout/                 |              |
|    ep_len_mean           | 360          |
|    ep_rew_mean           | -170         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 533          |
|    total_timesteps       | 2357248      |
| train/                   |              |
|    approx_kl             | 0.0066965353 |
|    clip_fraction         | 0.0725       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 6.96         |
|    cost_values           | 1.43         |
|    entropy               | -1.01        |
|    entropy_loss          | -1.01        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.68         |
|    n_updates             | 11500        |
|    policy_gradient_loss  | -0.00452     |
|    std                   | 0.402        |
|    value_loss            | 5.27         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.773       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.773       |
| reward                   | -0.33556336 |
| rollout/                 |             |
|    ep_len_mean           | 348         |
|    ep_rew_mean           | -161        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 556         |
|    total_timesteps       | 2359296     |
| train/                   |             |
|    approx_kl             | 0.008980908 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 0.0948      |
|    cost_values           | 1.3         |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.88        |
|    n_updates             | 11510       |
|    policy_gradient_loss  | -0.00657    |
|    std                   | 0.401       |
|    value_loss            | 6.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.22        |
| reward                   | -0.3008714  |
| rollout/                 |             |
|    ep_len_mean           | 364         |
|    ep_rew_mean           | -170        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 578         |
|    total_timesteps       | 2361344     |
| train/                   |             |
|    approx_kl             | 0.005955576 |
|    clip_fraction         | 0.0438      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.612       |
|    cost_value_loss       | 0.0262      |
|    cost_values           | 0.738       |
|    entropy               | -1          |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0.774       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.78        |
|    n_updates             | 11520       |
|    policy_gradient_loss  | -0.0016     |
|    std                   | 0.4         |
|    value_loss            | 6.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.3284598  |
| rollout/                 |             |
|    ep_len_mean           | 363         |
|    ep_rew_mean           | -162        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 600         |
|    total_timesteps       | 2363392     |
| train/                   |             |
|    approx_kl             | 0.015415383 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.4         |
|    cost_value_loss       | 2.87        |
|    cost_values           | 1.24        |
|    entropy               | -0.997      |
|    entropy_loss          | -0.999      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.59        |
|    n_updates             | 11530       |
|    policy_gradient_loss  | -0.00854    |
|    std                   | 0.399       |
|    value_loss            | 3.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.426       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.426       |
| reward                   | -0.37798643 |
| rollout/                 |             |
|    ep_len_mean           | 355         |
|    ep_rew_mean           | -150        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 623         |
|    total_timesteps       | 2365440     |
| train/                   |             |
|    approx_kl             | 0.016051129 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.453       |
|    cost_value_loss       | 0.00771     |
|    cost_values           | 0.518       |
|    entropy               | -0.993      |
|    entropy_loss          | -0.995      |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.34        |
|    n_updates             | 11540       |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 0.398       |
|    value_loss            | 2.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.46        |
| reward                   | -0.7569607  |
| rollout/                 |             |
|    ep_len_mean           | 341         |
|    ep_rew_mean           | -141        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 645         |
|    total_timesteps       | 2367488     |
| train/                   |             |
|    approx_kl             | 0.013304215 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.421       |
|    cost_value_loss       | 0.0106      |
|    cost_values           | 0.486       |
|    entropy               | -0.983      |
|    entropy_loss          | -0.989      |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.838       |
|    n_updates             | 11550       |
|    policy_gradient_loss  | -0.00274    |
|    std                   | 0.396       |
|    value_loss            | 2.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.02        |
| reward                   | -1.0225831  |
| rollout/                 |             |
|    ep_len_mean           | 343         |
|    ep_rew_mean           | -142        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 668         |
|    total_timesteps       | 2369536     |
| train/                   |             |
|    approx_kl             | 0.008739252 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.546       |
|    cost_value_loss       | 0.0104      |
|    cost_values           | 0.619       |
|    entropy               | -0.981      |
|    entropy_loss          | -0.981      |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.72        |
|    n_updates             | 11560       |
|    policy_gradient_loss  | 0.00187     |
|    std                   | 0.396       |
|    value_loss            | 4.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.559       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.559       |
| reward                   | -0.3064481  |
| rollout/                 |             |
|    ep_len_mean           | 358         |
|    ep_rew_mean           | -153        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 690         |
|    total_timesteps       | 2371584     |
| train/                   |             |
|    approx_kl             | 0.007936674 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.718       |
|    cost_value_loss       | 0.039       |
|    cost_values           | 0.817       |
|    entropy               | -0.984      |
|    entropy_loss          | -0.982      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.54        |
|    n_updates             | 11570       |
|    policy_gradient_loss  | -0.00331    |
|    std                   | 0.397       |
|    value_loss            | 4.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.828       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.828       |
| reward                   | -0.26161575 |
| rollout/                 |             |
|    ep_len_mean           | 374         |
|    ep_rew_mean           | -159        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 32          |
|    time_elapsed          | 712         |
|    total_timesteps       | 2373632     |
| train/                   |             |
|    approx_kl             | 0.010027791 |
|    clip_fraction         | 0.0908      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.673       |
|    cost_value_loss       | 0.0756      |
|    cost_values           | 0.788       |
|    entropy               | -0.99       |
|    entropy_loss          | -0.987      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.8         |
|    n_updates             | 11580       |
|    policy_gradient_loss  | -0.0035     |
|    std                   | 0.398       |
|    value_loss            | 4           |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0539      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0539      |
| reward                   | -0.24372925 |
| rollout/                 |             |
|    ep_len_mean           | 360         |
|    ep_rew_mean           | -150        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 33          |
|    time_elapsed          | 734         |
|    total_timesteps       | 2375680     |
| train/                   |             |
|    approx_kl             | 0.006877692 |
|    clip_fraction         | 0.0662      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.388       |
|    cost_value_loss       | 0.0314      |
|    cost_values           | 0.467       |
|    entropy               | -0.984      |
|    entropy_loss          | -0.988      |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.652       |
|    n_updates             | 11590       |
|    policy_gradient_loss  | -0.00366    |
|    std                   | 0.396       |
|    value_loss            | 2.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.79         |
| reward                   | -0.39450088  |
| rollout/                 |              |
|    ep_len_mean           | 364          |
|    ep_rew_mean           | -154         |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 34           |
|    time_elapsed          | 756          |
|    total_timesteps       | 2377728      |
| train/                   |              |
|    approx_kl             | 0.0057120463 |
|    clip_fraction         | 0.0653       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0607       |
|    cost_value_loss       | 0.219        |
|    cost_values           | 0.00826      |
|    entropy               | -0.974       |
|    entropy_loss          | -0.978       |
|    explained_variance    | 0.92         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.82         |
|    n_updates             | 11600        |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.394        |
|    value_loss            | 4.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.368       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.368       |
| reward                   | -0.74521196 |
| rollout/                 |             |
|    ep_len_mean           | 361         |
|    ep_rew_mean           | -161        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 779         |
|    total_timesteps       | 2379776     |
| train/                   |             |
|    approx_kl             | 0.009472648 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.448       |
|    cost_value_loss       | 0.092       |
|    cost_values           | 0.509       |
|    entropy               | -0.967      |
|    entropy_loss          | -0.97       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.58        |
|    n_updates             | 11610       |
|    policy_gradient_loss  | -0.0042     |
|    std                   | 0.393       |
|    value_loss            | 5.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.36         |
| reward                   | -0.15835524  |
| rollout/                 |              |
|    ep_len_mean           | 353          |
|    ep_rew_mean           | -152         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 801          |
|    total_timesteps       | 2381824      |
| train/                   |              |
|    approx_kl             | 0.0073381793 |
|    clip_fraction         | 0.15         |
|    clip_range            | 0.2          |
|    cost_returns          | 5.38         |
|    cost_value_loss       | 57.1         |
|    cost_values           | 1.3          |
|    entropy               | -0.965       |
|    entropy_loss          | -0.966       |
|    explained_variance    | 0.946        |
|    lagrangian_multiplier | 0.0122       |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 11620        |
|    policy_gradient_loss  | -0.000689    |
|    std                   | 0.393        |
|    value_loss            | 119          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.22        |
| reward                   | -0.24911283 |
| rollout/                 |             |
|    ep_len_mean           | 346         |
|    ep_rew_mean           | -145        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 822         |
|    total_timesteps       | 2383872     |
| train/                   |             |
|    approx_kl             | 0.019130655 |
|    clip_fraction         | 0.096       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.437       |
|    cost_value_loss       | 0.0475      |
|    cost_values           | 0.536       |
|    entropy               | -0.968      |
|    entropy_loss          | -0.966      |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.4         |
|    n_updates             | 11630       |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.393       |
|    value_loss            | 3.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.07        |
| reward                   | -0.1806498  |
| rollout/                 |             |
|    ep_len_mean           | 341         |
|    ep_rew_mean           | -142        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 844         |
|    total_timesteps       | 2385920     |
| train/                   |             |
|    approx_kl             | 0.020394556 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.732       |
|    cost_value_loss       | 0.0477      |
|    cost_values           | 0.82        |
|    entropy               | -0.966      |
|    entropy_loss          | -0.967      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.42        |
|    n_updates             | 11640       |
|    policy_gradient_loss  | -0.00142    |
|    std                   | 0.393       |
|    value_loss            | 3.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.44        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.44        |
| reward                   | -0.18946625 |
| rollout/                 |             |
|    ep_len_mean           | 328         |
|    ep_rew_mean           | -134        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 866         |
|    total_timesteps       | 2387968     |
| train/                   |             |
|    approx_kl             | 0.008891546 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.126       |
|    cost_value_loss       | 0.00189     |
|    cost_values           | 0.147       |
|    entropy               | -0.965      |
|    entropy_loss          | -0.966      |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.09        |
|    n_updates             | 11650       |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.392       |
|    value_loss            | 3.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.42703155 |
| rollout/                 |             |
|    ep_len_mean           | 324         |
|    ep_rew_mean           | -133        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 888         |
|    total_timesteps       | 2390016     |
| train/                   |             |
|    approx_kl             | 0.008995286 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.117       |
|    cost_value_loss       | 0.00324     |
|    cost_values           | 0.138       |
|    entropy               | -0.957      |
|    entropy_loss          | -0.961      |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.887       |
|    n_updates             | 11660       |
|    policy_gradient_loss  | -0.00441    |
|    std                   | 0.391       |
|    value_loss            | 1.83        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.764      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.764      |
| reward                   | -0.2883168 |
| rollout/                 |            |
|    ep_len_mean           | 330        |
|    ep_rew_mean           | -137       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 41         |
|    time_elapsed          | 910        |
|    total_timesteps       | 2392064    |
| train/                   |            |
|    approx_kl             | 0.00464865 |
|    clip_fraction         | 0.137      |
|    clip_range            | 0.2        |
|    cost_returns          | 0.336      |
|    cost_value_loss       | 0.0284     |
|    cost_values           | 0.388      |
|    entropy               | -0.955     |
|    entropy_loss          | -0.956     |
|    explained_variance    | 0.995      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.801      |
|    n_updates             | 11670      |
|    policy_gradient_loss  | 0.000819   |
|    std                   | 0.391      |
|    value_loss            | 2.06       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.337       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.337       |
| reward                   | -0.24503553 |
| rollout/                 |             |
|    ep_len_mean           | 324         |
|    ep_rew_mean           | -134        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 932         |
|    total_timesteps       | 2394112     |
| train/                   |             |
|    approx_kl             | 0.008446891 |
|    clip_fraction         | 0.0945      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.262       |
|    cost_value_loss       | 0.0212      |
|    cost_values           | 0.315       |
|    entropy               | -0.96       |
|    entropy_loss          | -0.957      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.82        |
|    n_updates             | 11680       |
|    policy_gradient_loss  | -0.0039     |
|    std                   | 0.392       |
|    value_loss            | 2.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.4          |
| reward                   | -0.55109954  |
| rollout/                 |              |
|    ep_len_mean           | 321          |
|    ep_rew_mean           | -138         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 954          |
|    total_timesteps       | 2396160      |
| train/                   |              |
|    approx_kl             | 0.0051441407 |
|    clip_fraction         | 0.0732       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 15           |
|    cost_values           | 0.689        |
|    entropy               | -0.961       |
|    entropy_loss          | -0.961       |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.91         |
|    n_updates             | 11690        |
|    policy_gradient_loss  | -0.00553     |
|    std                   | 0.392        |
|    value_loss            | 10.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.364       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.364       |
| reward                   | -0.28548402 |
| rollout/                 |             |
|    ep_len_mean           | 317         |
|    ep_rew_mean           | -141        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 976         |
|    total_timesteps       | 2398208     |
| train/                   |             |
|    approx_kl             | 0.004891063 |
|    clip_fraction         | 0.0624      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.773       |
|    cost_value_loss       | 0.0938      |
|    cost_values           | 1.03        |
|    entropy               | -0.963      |
|    entropy_loss          | -0.962      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.6         |
|    n_updates             | 11700       |
|    policy_gradient_loss  | -0.004      |
|    std                   | 0.393       |
|    value_loss            | 3.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.35        |
| reward                   | -0.7897841  |
| rollout/                 |             |
|    ep_len_mean           | 299         |
|    ep_rew_mean           | -130        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 998         |
|    total_timesteps       | 2400256     |
| train/                   |             |
|    approx_kl             | 0.015222408 |
|    clip_fraction         | 0.0969      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.723       |
|    cost_value_loss       | 0.0411      |
|    cost_values           | 0.812       |
|    entropy               | -0.966      |
|    entropy_loss          | -0.964      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.51        |
|    n_updates             | 11710       |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.393       |
|    value_loss            | 3.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.51        |
| reward                   | -0.27816007 |
| rollout/                 |             |
|    ep_len_mean           | 298         |
|    ep_rew_mean           | -133        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1020        |
|    total_timesteps       | 2402304     |
| train/                   |             |
|    approx_kl             | 0.014026215 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.374       |
|    cost_value_loss       | 0.00787     |
|    cost_values           | 0.424       |
|    entropy               | -0.972      |
|    entropy_loss          | -0.968      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.782       |
|    n_updates             | 11720       |
|    policy_gradient_loss  | -0.00353    |
|    std                   | 0.394       |
|    value_loss            | 2.7         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.12         |
| reward                   | -1.0333104   |
| rollout/                 |              |
|    ep_len_mean           | 300          |
|    ep_rew_mean           | -134         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1042         |
|    total_timesteps       | 2404352      |
| train/                   |              |
|    approx_kl             | 0.0071933605 |
|    clip_fraction         | 0.0656       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.884        |
|    cost_value_loss       | 0.109        |
|    cost_values           | 1.07         |
|    entropy               | -0.972       |
|    entropy_loss          | -0.973       |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.42         |
|    n_updates             | 11730        |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.394        |
|    value_loss            | 5.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.644       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.644       |
| reward                   | -0.39935982 |
| rollout/                 |             |
|    ep_len_mean           | 312         |
|    ep_rew_mean           | -145        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1064        |
|    total_timesteps       | 2406400     |
| train/                   |             |
|    approx_kl             | 0.01038965  |
|    clip_fraction         | 0.0953      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.0924      |
|    cost_values           | 1.13        |
|    entropy               | -0.961      |
|    entropy_loss          | -0.967      |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.87        |
|    n_updates             | 11740       |
|    policy_gradient_loss  | -0.00309    |
|    std                   | 0.392       |
|    value_loss            | 4.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.222       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.222       |
| reward                   | -0.36601284 |
| rollout/                 |             |
|    ep_len_mean           | 308         |
|    ep_rew_mean           | -146        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1086        |
|    total_timesteps       | 2408448     |
| train/                   |             |
|    approx_kl             | 0.009569591 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.39        |
|    cost_value_loss       | 0.0473      |
|    cost_values           | 0.465       |
|    entropy               | -0.956      |
|    entropy_loss          | -0.958      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.47        |
|    n_updates             | 11750       |
|    policy_gradient_loss  | -0.00566    |
|    std                   | 0.391       |
|    value_loss            | 6.36        |
------------------------------------------
------------------------------------
| avg_speed          | 1.88        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 1.88        |
| reward             | -0.22058813 |
| rollout/           |             |
|    ep_len_mean     | 290         |
|    ep_rew_mean     | -126        |
| time/              |             |
|    fps             | 93          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 2410496     |
------------------------------------
------------------------------------------
| avg_speed                | 0.412       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.412       |
| reward                   | -0.27268642 |
| rollout/                 |             |
|    ep_len_mean           | 287         |
|    ep_rew_mean           | -128        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 2412544     |
| train/                   |             |
|    approx_kl             | 0.007978749 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.191      |
|    cost_value_loss       | 0.00684     |
|    cost_values           | -0.215      |
|    entropy               | -0.962      |
|    entropy_loss          | -0.961      |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.38        |
|    n_updates             | 11770       |
|    policy_gradient_loss  | -0.00569    |
|    std                   | 0.393       |
|    value_loss            | 2.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.19         |
| reward                   | -0.8046529   |
| rollout/                 |              |
|    ep_len_mean           | 287          |
|    ep_rew_mean           | -128         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 3            |
|    time_elapsed          | 66           |
|    total_timesteps       | 2414592      |
| train/                   |              |
|    approx_kl             | 0.0079011945 |
|    clip_fraction         | 0.0728       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 11           |
|    cost_values           | 0.572        |
|    entropy               | -0.964       |
|    entropy_loss          | -0.962       |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0.000402     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.65         |
|    n_updates             | 11780        |
|    policy_gradient_loss  | -0.00515     |
|    std                   | 0.393        |
|    value_loss            | 6.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.12         |
| reward                   | -0.4562544   |
| rollout/                 |              |
|    ep_len_mean           | 303          |
|    ep_rew_mean           | -145         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 2416640      |
| train/                   |              |
|    approx_kl             | 0.0055560665 |
|    clip_fraction         | 0.0797       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.521        |
|    cost_value_loss       | 0.235        |
|    cost_values           | 0.6          |
|    entropy               | -0.972       |
|    entropy_loss          | -0.968       |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.46         |
|    n_updates             | 11790        |
|    policy_gradient_loss  | -0.0037      |
|    std                   | 0.395        |
|    value_loss            | 4.07         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.74         |
| reward                   | -0.5474716   |
| rollout/                 |              |
|    ep_len_mean           | 311          |
|    ep_rew_mean           | -150         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 5            |
|    time_elapsed          | 110          |
|    total_timesteps       | 2418688      |
| train/                   |              |
|    approx_kl             | 0.0069899554 |
|    clip_fraction         | 0.0795       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.22         |
|    cost_value_loss       | 51.6         |
|    cost_values           | 1.25         |
|    entropy               | -0.976       |
|    entropy_loss          | -0.975       |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0.00769      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 11800        |
|    policy_gradient_loss  | -0.00554     |
|    std                   | 0.396        |
|    value_loss            | 74.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.68        |
| reward                   | -0.5509758  |
| rollout/                 |             |
|    ep_len_mean           | 321         |
|    ep_rew_mean           | -156        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 2420736     |
| train/                   |             |
|    approx_kl             | 0.008924206 |
|    clip_fraction         | 0.0772      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.722       |
|    cost_value_loss       | 0.204       |
|    cost_values           | 0.782       |
|    entropy               | -0.977      |
|    entropy_loss          | -0.976      |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.33        |
|    n_updates             | 11810       |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 0.396       |
|    value_loss            | 4.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.24        |
| reward                   | -0.45933783 |
| rollout/                 |             |
|    ep_len_mean           | 324         |
|    ep_rew_mean           | -158        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 2422784     |
| train/                   |             |
|    approx_kl             | 0.009123982 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.705       |
|    cost_value_loss       | 0.793       |
|    cost_values           | 0.692       |
|    entropy               | -0.984      |
|    entropy_loss          | -0.98       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.25        |
|    n_updates             | 11820       |
|    policy_gradient_loss  | -0.00642    |
|    std                   | 0.397       |
|    value_loss            | 6.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.22661039 |
| rollout/                 |             |
|    ep_len_mean           | 312         |
|    ep_rew_mean           | -152        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 176         |
|    total_timesteps       | 2424832     |
| train/                   |             |
|    approx_kl             | 0.009035297 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.425       |
|    cost_value_loss       | 0.0433      |
|    cost_values           | 0.491       |
|    entropy               | -0.983      |
|    entropy_loss          | -0.985      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.32        |
|    n_updates             | 11830       |
|    policy_gradient_loss  | -0.00502    |
|    std                   | 0.397       |
|    value_loss            | 4.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.488        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.488        |
| reward                   | -0.3518198   |
| rollout/                 |              |
|    ep_len_mean           | 310          |
|    ep_rew_mean           | -148         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 9            |
|    time_elapsed          | 198          |
|    total_timesteps       | 2426880      |
| train/                   |              |
|    approx_kl             | 0.0092807105 |
|    clip_fraction         | 0.08         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.397        |
|    cost_value_loss       | 0.0403       |
|    cost_values           | 0.442        |
|    entropy               | -0.975       |
|    entropy_loss          | -0.98        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.976        |
|    n_updates             | 11840        |
|    policy_gradient_loss  | -0.00067     |
|    std                   | 0.396        |
|    value_loss            | 2.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.415       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.415       |
| reward                   | -0.3869949  |
| rollout/                 |             |
|    ep_len_mean           | 302         |
|    ep_rew_mean           | -141        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 2428928     |
| train/                   |             |
|    approx_kl             | 0.007127969 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0511     |
|    cost_value_loss       | 0.00194     |
|    cost_values           | -0.0475     |
|    entropy               | -0.976      |
|    entropy_loss          | -0.974      |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.535       |
|    n_updates             | 11850       |
|    policy_gradient_loss  | -0.00304    |
|    std                   | 0.396       |
|    value_loss            | 1.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.622       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.622       |
| reward                   | -0.31859496 |
| rollout/                 |             |
|    ep_len_mean           | 303         |
|    ep_rew_mean           | -141        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 2430976     |
| train/                   |             |
|    approx_kl             | 0.007861802 |
|    clip_fraction         | 0.0941      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0462     |
|    cost_value_loss       | 0.00307     |
|    cost_values           | -0.0529     |
|    entropy               | -0.981      |
|    entropy_loss          | -0.979      |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.03        |
|    n_updates             | 11860       |
|    policy_gradient_loss  | -0.00382    |
|    std                   | 0.397       |
|    value_loss            | 3.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.48        |
| reward                   | -0.29328686 |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -117        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 2433024     |
| train/                   |             |
|    approx_kl             | 0.011736391 |
|    clip_fraction         | 0.0819      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.403       |
|    cost_value_loss       | 0.0409      |
|    cost_values           | 0.457       |
|    entropy               | -0.979      |
|    entropy_loss          | -0.981      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.14        |
|    n_updates             | 11870       |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.396       |
|    value_loss            | 3.1         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.3          |
| reward                   | -0.46373308  |
| rollout/                 |              |
|    ep_len_mean           | 267          |
|    ep_rew_mean           | -114         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 288          |
|    total_timesteps       | 2435072      |
| train/                   |              |
|    approx_kl             | 0.0057504936 |
|    clip_fraction         | 0.0933       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.116       |
|    cost_value_loss       | 0.00445      |
|    cost_values           | -0.128       |
|    entropy               | -0.968       |
|    entropy_loss          | -0.974       |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.07         |
|    n_updates             | 11880        |
|    policy_gradient_loss  | 4.44e-06     |
|    std                   | 0.394        |
|    value_loss            | 2.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.77        |
| reward                   | -0.25049824 |
| rollout/                 |             |
|    ep_len_mean           | 276         |
|    ep_rew_mean           | -120        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 2437120     |
| train/                   |             |
|    approx_kl             | 0.010645356 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.207       |
|    cost_value_loss       | 0.0257      |
|    cost_values           | 0.24        |
|    entropy               | -0.969      |
|    entropy_loss          | -0.966      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.918       |
|    n_updates             | 11890       |
|    policy_gradient_loss  | -0.00278    |
|    std                   | 0.394       |
|    value_loss            | 2.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.7         |
| reward                   | -0.47358102 |
| rollout/                 |             |
|    ep_len_mean           | 269         |
|    ep_rew_mean           | -112        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 332         |
|    total_timesteps       | 2439168     |
| train/                   |             |
|    approx_kl             | 0.009363389 |
|    clip_fraction         | 0.098       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.292       |
|    cost_value_loss       | 0.0348      |
|    cost_values           | 0.335       |
|    entropy               | -0.967      |
|    entropy_loss          | -0.969      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 11900       |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.394       |
|    value_loss            | 3.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.719       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.719       |
| reward                   | -0.38231683 |
| rollout/                 |             |
|    ep_len_mean           | 284         |
|    ep_rew_mean           | -125        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 354         |
|    total_timesteps       | 2441216     |
| train/                   |             |
|    approx_kl             | 0.005571621 |
|    clip_fraction         | 0.0633      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.15       |
|    cost_value_loss       | 0.00419     |
|    cost_values           | -0.17       |
|    entropy               | -0.972      |
|    entropy_loss          | -0.967      |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.986       |
|    n_updates             | 11910       |
|    policy_gradient_loss  | 0.000209    |
|    std                   | 0.395       |
|    value_loss            | 2.23        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.0334     |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.0334     |
| reward                   | -0.493673  |
| rollout/                 |            |
|    ep_len_mean           | 271        |
|    ep_rew_mean           | -108       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 17         |
|    time_elapsed          | 376        |
|    total_timesteps       | 2443264    |
| train/                   |            |
|    approx_kl             | 0.00875068 |
|    clip_fraction         | 0.113      |
|    clip_range            | 0.2        |
|    cost_returns          | 0.931      |
|    cost_value_loss       | 0.141      |
|    cost_values           | 1.05       |
|    entropy               | -0.979     |
|    entropy_loss          | -0.976     |
|    explained_variance    | 0.993      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.98       |
|    n_updates             | 11920      |
|    policy_gradient_loss  | -0.00491   |
|    std                   | 0.396      |
|    value_loss            | 6.25       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.23275717 |
| rollout/                 |             |
|    ep_len_mean           | 271         |
|    ep_rew_mean           | -108        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 399         |
|    total_timesteps       | 2445312     |
| train/                   |             |
|    approx_kl             | 0.009587594 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.139      |
|    cost_value_loss       | 0.00514     |
|    cost_values           | -0.172      |
|    entropy               | -0.977      |
|    entropy_loss          | -0.979      |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.17        |
|    n_updates             | 11930       |
|    policy_gradient_loss  | -0.00544    |
|    std                   | 0.396       |
|    value_loss            | 3.31        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.67         |
| reward                   | -0.7505135   |
| rollout/                 |              |
|    ep_len_mean           | 249          |
|    ep_rew_mean           | -95.2        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 421          |
|    total_timesteps       | 2447360      |
| train/                   |              |
|    approx_kl             | 0.0073029017 |
|    clip_fraction         | 0.0919       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.112        |
|    cost_value_loss       | 0.0174       |
|    cost_values           | 0.138        |
|    entropy               | -0.971       |
|    entropy_loss          | -0.974       |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.994        |
|    n_updates             | 11940        |
|    policy_gradient_loss  | -0.00499     |
|    std                   | 0.394        |
|    value_loss            | 2.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.28748852 |
| rollout/                 |             |
|    ep_len_mean           | 255         |
|    ep_rew_mean           | -96.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 443         |
|    total_timesteps       | 2449408     |
| train/                   |             |
|    approx_kl             | 0.005737138 |
|    clip_fraction         | 0.0717      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0175      |
|    cost_value_loss       | 0.00561     |
|    cost_values           | 0.0147      |
|    entropy               | -0.97       |
|    entropy_loss          | -0.97       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.56        |
|    n_updates             | 11950       |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.394       |
|    value_loss            | 3.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.905       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.905       |
| reward                   | -0.2895376  |
| rollout/                 |             |
|    ep_len_mean           | 250         |
|    ep_rew_mean           | -94.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 466         |
|    total_timesteps       | 2451456     |
| train/                   |             |
|    approx_kl             | 0.013626111 |
|    clip_fraction         | 0.086       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.127      |
|    cost_value_loss       | 0.00968     |
|    cost_values           | -0.135      |
|    entropy               | -0.963      |
|    entropy_loss          | -0.968      |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.607       |
|    n_updates             | 11960       |
|    policy_gradient_loss  | -0.00161    |
|    std                   | 0.393       |
|    value_loss            | 1.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.55        |
| reward                   | -0.2688246  |
| rollout/                 |             |
|    ep_len_mean           | 253         |
|    ep_rew_mean           | -95.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 488         |
|    total_timesteps       | 2453504     |
| train/                   |             |
|    approx_kl             | 0.012487003 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.125      |
|    cost_value_loss       | 0.00343     |
|    cost_values           | -0.132      |
|    entropy               | -0.936      |
|    entropy_loss          | -0.951      |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.669       |
|    n_updates             | 11970       |
|    policy_gradient_loss  | -0.00253    |
|    std                   | 0.387       |
|    value_loss            | 1.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.109       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.109       |
| reward                   | -0.2995618  |
| rollout/                 |             |
|    ep_len_mean           | 254         |
|    ep_rew_mean           | -95.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 510         |
|    total_timesteps       | 2455552     |
| train/                   |             |
|    approx_kl             | 0.011817792 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.085      |
|    cost_value_loss       | 0.00334     |
|    cost_values           | -0.094      |
|    entropy               | -0.937      |
|    entropy_loss          | -0.933      |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.723       |
|    n_updates             | 11980       |
|    policy_gradient_loss  | 0.000128    |
|    std                   | 0.387       |
|    value_loss            | 1.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.29        |
| reward                   | -0.28729784 |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -97.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 533         |
|    total_timesteps       | 2457600     |
| train/                   |             |
|    approx_kl             | 0.011099545 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.22        |
|    cost_value_loss       | 0.0204      |
|    cost_values           | 0.257       |
|    entropy               | -0.938      |
|    entropy_loss          | -0.939      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.12        |
|    n_updates             | 11990       |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.388       |
|    value_loss            | 2.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.559       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.559       |
| reward                   | -0.31048995 |
| rollout/                 |             |
|    ep_len_mean           | 262         |
|    ep_rew_mean           | -97.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 555         |
|    total_timesteps       | 2459648     |
| train/                   |             |
|    approx_kl             | 0.007368917 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.113      |
|    cost_value_loss       | 0.00233     |
|    cost_values           | -0.124      |
|    entropy               | -0.939      |
|    entropy_loss          | -0.938      |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.639       |
|    n_updates             | 12000       |
|    policy_gradient_loss  | -0.00242    |
|    std                   | 0.388       |
|    value_loss            | 1.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.50143605 |
| rollout/                 |             |
|    ep_len_mean           | 252         |
|    ep_rew_mean           | -90.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 578         |
|    total_timesteps       | 2461696     |
| train/                   |             |
|    approx_kl             | 0.008439224 |
|    clip_fraction         | 0.0736      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.113      |
|    cost_value_loss       | 0.00201     |
|    cost_values           | -0.123      |
|    entropy               | -0.928      |
|    entropy_loss          | -0.935      |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.648       |
|    n_updates             | 12010       |
|    policy_gradient_loss  | -0.00362    |
|    std                   | 0.385       |
|    value_loss            | 1.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.774       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.774       |
| reward                   | -0.23562108 |
| rollout/                 |             |
|    ep_len_mean           | 251         |
|    ep_rew_mean           | -91         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 27          |
|    time_elapsed          | 601         |
|    total_timesteps       | 2463744     |
| train/                   |             |
|    approx_kl             | 0.012657125 |
|    clip_fraction         | 0.155       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0278     |
|    cost_value_loss       | 0.00254     |
|    cost_values           | -0.027      |
|    entropy               | -0.906      |
|    entropy_loss          | -0.917      |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.401       |
|    n_updates             | 12020       |
|    policy_gradient_loss  | -0.00313    |
|    std                   | 0.381       |
|    value_loss            | 0.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.179       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.179       |
| reward                   | -0.28515077 |
| rollout/                 |             |
|    ep_len_mean           | 243         |
|    ep_rew_mean           | -80.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 623         |
|    total_timesteps       | 2465792     |
| train/                   |             |
|    approx_kl             | 0.008416832 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0786     |
|    cost_value_loss       | 0.00184     |
|    cost_values           | -0.0792     |
|    entropy               | -0.887      |
|    entropy_loss          | -0.896      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.302       |
|    n_updates             | 12030       |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 0.378       |
|    value_loss            | 0.716       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.974       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.974       |
| reward                   | -0.34406137 |
| rollout/                 |             |
|    ep_len_mean           | 246         |
|    ep_rew_mean           | -84.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 645         |
|    total_timesteps       | 2467840     |
| train/                   |             |
|    approx_kl             | 0.008338119 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0318     |
|    cost_value_loss       | 0.00197     |
|    cost_values           | -0.0318     |
|    entropy               | -0.877      |
|    entropy_loss          | -0.882      |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.639       |
|    n_updates             | 12040       |
|    policy_gradient_loss  | -0.00238    |
|    std                   | 0.376       |
|    value_loss            | 1.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.56        |
| reward                   | -0.28760734 |
| rollout/                 |             |
|    ep_len_mean           | 241         |
|    ep_rew_mean           | -80.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 667         |
|    total_timesteps       | 2469888     |
| train/                   |             |
|    approx_kl             | 0.013922539 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.193       |
|    cost_value_loss       | 0.021       |
|    cost_values           | 0.229       |
|    entropy               | -0.871      |
|    entropy_loss          | -0.874      |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.37        |
|    n_updates             | 12050       |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 0.375       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.19        |
| reward                   | -0.16872871 |
| rollout/                 |             |
|    ep_len_mean           | 234         |
|    ep_rew_mean           | -76.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 689         |
|    total_timesteps       | 2471936     |
| train/                   |             |
|    approx_kl             | 0.013057928 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0907     |
|    cost_value_loss       | 0.00187     |
|    cost_values           | -0.0986     |
|    entropy               | -0.868      |
|    entropy_loss          | -0.869      |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.493       |
|    n_updates             | 12060       |
|    policy_gradient_loss  | -0.00421    |
|    std                   | 0.374       |
|    value_loss            | 1.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.573       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.573       |
| reward                   | -0.21662474 |
| rollout/                 |             |
|    ep_len_mean           | 240         |
|    ep_rew_mean           | -80.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 711         |
|    total_timesteps       | 2473984     |
| train/                   |             |
|    approx_kl             | 0.010727115 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.046      |
|    cost_value_loss       | 0.00246     |
|    cost_values           | -0.0462     |
|    entropy               | -0.873      |
|    entropy_loss          | -0.87       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.535       |
|    n_updates             | 12070       |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.375       |
|    value_loss            | 1.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.699        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.699        |
| reward                   | -0.24947034  |
| rollout/                 |              |
|    ep_len_mean           | 250          |
|    ep_rew_mean           | -85.1        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 734          |
|    total_timesteps       | 2476032      |
| train/                   |              |
|    approx_kl             | 0.0073776497 |
|    clip_fraction         | 0.0564       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.366        |
|    cost_value_loss       | 0.0324       |
|    cost_values           | 0.417        |
|    entropy               | -0.873       |
|    entropy_loss          | -0.874       |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.887        |
|    n_updates             | 12080        |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 0.375        |
|    value_loss            | 2.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.18        |
| reward                   | -0.20312162 |
| rollout/                 |             |
|    ep_len_mean           | 256         |
|    ep_rew_mean           | -87.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 756         |
|    total_timesteps       | 2478080     |
| train/                   |             |
|    approx_kl             | 0.007230972 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0247      |
|    cost_value_loss       | 0.00771     |
|    cost_values           | 0.0383      |
|    entropy               | -0.866      |
|    entropy_loss          | -0.87       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.513       |
|    n_updates             | 12090       |
|    policy_gradient_loss  | -0.0041     |
|    std                   | 0.374       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.5         |
| reward                   | -0.26879424 |
| rollout/                 |             |
|    ep_len_mean           | 263         |
|    ep_rew_mean           | -91.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 778         |
|    total_timesteps       | 2480128     |
| train/                   |             |
|    approx_kl             | 0.006745427 |
|    clip_fraction         | 0.0882      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0834     |
|    cost_value_loss       | 0.0022      |
|    cost_values           | -0.0865     |
|    entropy               | -0.856      |
|    entropy_loss          | -0.861      |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.796       |
|    n_updates             | 12100       |
|    policy_gradient_loss  | -0.00331    |
|    std                   | 0.372       |
|    value_loss            | 1.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.137       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.137       |
| reward                   | -0.23080887 |
| rollout/                 |             |
|    ep_len_mean           | 251         |
|    ep_rew_mean           | -84.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 801         |
|    total_timesteps       | 2482176     |
| train/                   |             |
|    approx_kl             | 0.011994924 |
|    clip_fraction         | 0.0909      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00209    |
|    cost_value_loss       | 0.00389     |
|    cost_values           | 0.00296     |
|    entropy               | -0.849      |
|    entropy_loss          | -0.853      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.426       |
|    n_updates             | 12110       |
|    policy_gradient_loss  | -0.00333    |
|    std                   | 0.371       |
|    value_loss            | 1.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.768       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.768       |
| reward                   | -0.34910798 |
| rollout/                 |             |
|    ep_len_mean           | 257         |
|    ep_rew_mean           | -89.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 823         |
|    total_timesteps       | 2484224     |
| train/                   |             |
|    approx_kl             | 0.006781839 |
|    clip_fraction         | 0.0875      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0693     |
|    cost_value_loss       | 0.00222     |
|    cost_values           | -0.0703     |
|    entropy               | -0.848      |
|    entropy_loss          | -0.847      |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.381       |
|    n_updates             | 12120       |
|    policy_gradient_loss  | -0.00454    |
|    std                   | 0.371       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.782       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.782       |
| reward                   | -0.35008115 |
| rollout/                 |             |
|    ep_len_mean           | 262         |
|    ep_rew_mean           | -91.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 845         |
|    total_timesteps       | 2486272     |
| train/                   |             |
|    approx_kl             | 0.0098183   |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0601      |
|    cost_value_loss       | 0.00726     |
|    cost_values           | 0.0723      |
|    entropy               | -0.853      |
|    entropy_loss          | -0.85       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.346       |
|    n_updates             | 12130       |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.372       |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.841       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.841       |
| reward                   | -0.25320792 |
| rollout/                 |             |
|    ep_len_mean           | 260         |
|    ep_rew_mean           | -90.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 867         |
|    total_timesteps       | 2488320     |
| train/                   |             |
|    approx_kl             | 0.013951755 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0686     |
|    cost_value_loss       | 0.00169     |
|    cost_values           | -0.0714     |
|    entropy               | -0.844      |
|    entropy_loss          | -0.851      |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.418       |
|    n_updates             | 12140       |
|    policy_gradient_loss  | -0.00299    |
|    std                   | 0.37        |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.23        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.23        |
| reward                   | -0.16621175 |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -90.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 889         |
|    total_timesteps       | 2490368     |
| train/                   |             |
|    approx_kl             | 0.010768198 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0405     |
|    cost_value_loss       | 0.00212     |
|    cost_values           | -0.0411     |
|    entropy               | -0.844      |
|    entropy_loss          | -0.844      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.396       |
|    n_updates             | 12150       |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 0.371       |
|    value_loss            | 0.915       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.334        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.334        |
| reward                   | -0.22870912  |
| rollout/                 |              |
|    ep_len_mean           | 259          |
|    ep_rew_mean           | -89.9        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 911          |
|    total_timesteps       | 2492416      |
| train/                   |              |
|    approx_kl             | 0.0063463207 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.067       |
|    cost_value_loss       | 0.000683     |
|    cost_values           | -0.0682      |
|    entropy               | -0.841       |
|    entropy_loss          | -0.843       |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.219        |
|    n_updates             | 12160        |
|    policy_gradient_loss  | -0.00402     |
|    std                   | 0.37         |
|    value_loss            | 0.535        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.609       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.609       |
| reward                   | -0.34740323 |
| rollout/                 |             |
|    ep_len_mean           | 263         |
|    ep_rew_mean           | -90         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 934         |
|    total_timesteps       | 2494464     |
| train/                   |             |
|    approx_kl             | 0.009990796 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0376     |
|    cost_value_loss       | 0.00132     |
|    cost_values           | -0.0373     |
|    entropy               | -0.844      |
|    entropy_loss          | -0.842      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.382       |
|    n_updates             | 12170       |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.371       |
|    value_loss            | 0.865       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.797       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.797       |
| reward                   | -0.34189963 |
| rollout/                 |             |
|    ep_len_mean           | 266         |
|    ep_rew_mean           | -91.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 956         |
|    total_timesteps       | 2496512     |
| train/                   |             |
|    approx_kl             | 0.01090063  |
|    clip_fraction         | 0.095       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0144      |
|    cost_value_loss       | 0.00231     |
|    cost_values           | 0.0216      |
|    entropy               | -0.841      |
|    entropy_loss          | -0.844      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.396       |
|    n_updates             | 12180       |
|    policy_gradient_loss  | -0.00272    |
|    std                   | 0.37        |
|    value_loss            | 1.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.46254316 |
| rollout/                 |             |
|    ep_len_mean           | 274         |
|    ep_rew_mean           | -93.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 978         |
|    total_timesteps       | 2498560     |
| train/                   |             |
|    approx_kl             | 0.005660895 |
|    clip_fraction         | 0.0907      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0455     |
|    cost_value_loss       | 0.00052     |
|    cost_values           | -0.0477     |
|    entropy               | -0.834      |
|    entropy_loss          | -0.838      |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.331       |
|    n_updates             | 12190       |
|    policy_gradient_loss  | -0.00393    |
|    std                   | 0.369       |
|    value_loss            | 0.746       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0305       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0305       |
| reward                   | -0.25448325  |
| rollout/                 |              |
|    ep_len_mean           | 264          |
|    ep_rew_mean           | -88.2        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 1000         |
|    total_timesteps       | 2500608      |
| train/                   |              |
|    approx_kl             | 0.0055597182 |
|    clip_fraction         | 0.0974       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0397      |
|    cost_value_loss       | 0.00102      |
|    cost_values           | -0.0437      |
|    entropy               | -0.83        |
|    entropy_loss          | -0.832       |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.391        |
|    n_updates             | 12200        |
|    policy_gradient_loss  | -0.0011      |
|    std                   | 0.368        |
|    value_loss            | 1.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.12        |
| reward                   | -0.34385902 |
| rollout/                 |             |
|    ep_len_mean           | 251         |
|    ep_rew_mean           | -81.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1022        |
|    total_timesteps       | 2502656     |
| train/                   |             |
|    approx_kl             | 0.010087534 |
|    clip_fraction         | 0.0885      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0273     |
|    cost_value_loss       | 0.000839    |
|    cost_values           | -0.0277     |
|    entropy               | -0.834      |
|    entropy_loss          | -0.831      |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.394       |
|    n_updates             | 12210       |
|    policy_gradient_loss  | -0.00322    |
|    std                   | 0.369       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.37        |
| reward                   | -0.67077327 |
| rollout/                 |             |
|    ep_len_mean           | 245         |
|    ep_rew_mean           | -77.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1044        |
|    total_timesteps       | 2504704     |
| train/                   |             |
|    approx_kl             | 0.011373933 |
|    clip_fraction         | 0.0846      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0265     |
|    cost_value_loss       | 0.000377    |
|    cost_values           | -0.0282     |
|    entropy               | -0.827      |
|    entropy_loss          | -0.831      |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.389       |
|    n_updates             | 12220       |
|    policy_gradient_loss  | 0.000412    |
|    std                   | 0.367       |
|    value_loss            | 0.861       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.987       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.987       |
| reward                   | -0.47624776 |
| rollout/                 |             |
|    ep_len_mean           | 251         |
|    ep_rew_mean           | -81.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1066        |
|    total_timesteps       | 2506752     |
| train/                   |             |
|    approx_kl             | 0.006400456 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0198      |
|    cost_value_loss       | 0.000896    |
|    cost_values           | 0.024       |
|    entropy               | -0.82       |
|    entropy_loss          | -0.823      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.421       |
|    n_updates             | 12230       |
|    policy_gradient_loss  | -0.00276    |
|    std                   | 0.366       |
|    value_loss            | 1.42        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.639        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.639        |
| reward                   | -0.40572983  |
| rollout/                 |              |
|    ep_len_mean           | 262          |
|    ep_rew_mean           | -87.2        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 2508800      |
| train/                   |              |
|    approx_kl             | 0.0071480693 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0717       |
|    cost_value_loss       | 0.00707      |
|    cost_values           | 0.0853       |
|    entropy               | -0.82        |
|    entropy_loss          | -0.819       |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.461        |
|    n_updates             | 12240        |
|    policy_gradient_loss  | -0.0041      |
|    std                   | 0.366        |
|    value_loss            | 1.5          |
-------------------------------------------
------------------------------------
| avg_speed          | 0.213       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.213       |
| reward             | -0.21997663 |
| rollout/           |             |
|    ep_len_mean     | 263         |
|    ep_rew_mean     | -86.8       |
| time/              |             |
|    fps             | 93          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2510848     |
------------------------------------
-------------------------------------------
| avg_speed                | 0.307        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.307        |
| reward                   | -0.30090028  |
| rollout/                 |              |
|    ep_len_mean           | 272          |
|    ep_rew_mean           | -90.1        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 2            |
|    time_elapsed          | 44           |
|    total_timesteps       | 2512896      |
| train/                   |              |
|    approx_kl             | 0.0093872845 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0192       |
|    cost_value_loss       | 0.00319      |
|    cost_values           | 0.0234       |
|    entropy               | -0.811       |
|    entropy_loss          | -0.815       |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.425        |
|    n_updates             | 12260        |
|    policy_gradient_loss  | -0.000997    |
|    std                   | 0.365        |
|    value_loss            | 1.21         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.06        |
| reward                   | -0.24687639 |
| rollout/                 |             |
|    ep_len_mean           | 274         |
|    ep_rew_mean           | -90.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 3           |
|    time_elapsed          | 66          |
|    total_timesteps       | 2514944     |
| train/                   |             |
|    approx_kl             | 0.009203437 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.164       |
|    cost_value_loss       | 0.0178      |
|    cost_values           | 0.182       |
|    entropy               | -0.805      |
|    entropy_loss          | -0.808      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.376       |
|    n_updates             | 12270       |
|    policy_gradient_loss  | -0.00691    |
|    std                   | 0.363       |
|    value_loss            | 1.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.399       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.399       |
| reward                   | -0.29038557 |
| rollout/                 |             |
|    ep_len_mean           | 273         |
|    ep_rew_mean           | -90.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 4           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2516992     |
| train/                   |             |
|    approx_kl             | 0.00601476  |
|    clip_fraction         | 0.0707      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0798     |
|    cost_value_loss       | 0.000503    |
|    cost_values           | -0.0804     |
|    entropy               | -0.801      |
|    entropy_loss          | -0.803      |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.439       |
|    n_updates             | 12280       |
|    policy_gradient_loss  | -0.00318    |
|    std                   | 0.363       |
|    value_loss            | 0.917       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.273        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.273        |
| reward                   | -0.22497307  |
| rollout/                 |              |
|    ep_len_mean           | 275          |
|    ep_rew_mean           | -91.2        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 5            |
|    time_elapsed          | 111          |
|    total_timesteps       | 2519040      |
| train/                   |              |
|    approx_kl             | 0.0048517887 |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0414      |
|    cost_value_loss       | 0.000909     |
|    cost_values           | -0.0413      |
|    entropy               | -0.798       |
|    entropy_loss          | -0.799       |
|    explained_variance    | 0.987        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.472        |
|    n_updates             | 12290        |
|    policy_gradient_loss  | -0.00128     |
|    std                   | 0.362        |
|    value_loss            | 1.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.802       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.802       |
| reward                   | -0.17735326 |
| rollout/                 |             |
|    ep_len_mean           | 277         |
|    ep_rew_mean           | -92.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 6           |
|    time_elapsed          | 134         |
|    total_timesteps       | 2521088     |
| train/                   |             |
|    approx_kl             | 0.009158774 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0563     |
|    cost_value_loss       | 0.000514    |
|    cost_values           | -0.0572     |
|    entropy               | -0.78       |
|    entropy_loss          | -0.789      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.273       |
|    n_updates             | 12300       |
|    policy_gradient_loss  | -0.0033     |
|    std                   | 0.359       |
|    value_loss            | 0.631       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.44        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.44        |
| reward                   | -0.3476238  |
| rollout/                 |             |
|    ep_len_mean           | 274         |
|    ep_rew_mean           | -88.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 7           |
|    time_elapsed          | 156         |
|    total_timesteps       | 2523136     |
| train/                   |             |
|    approx_kl             | 0.008552472 |
|    clip_fraction         | 0.0875      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0207     |
|    cost_value_loss       | 0.000765    |
|    cost_values           | -0.0195     |
|    entropy               | -0.77       |
|    entropy_loss          | -0.775      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.3         |
|    n_updates             | 12310       |
|    policy_gradient_loss  | -0.00243    |
|    std                   | 0.358       |
|    value_loss            | 0.778       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.72         |
| reward                   | -0.18032373  |
| rollout/                 |              |
|    ep_len_mean           | 266          |
|    ep_rew_mean           | -86.3        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 8            |
|    time_elapsed          | 178          |
|    total_timesteps       | 2525184      |
| train/                   |              |
|    approx_kl             | 0.0068449937 |
|    clip_fraction         | 0.0811       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0448      |
|    cost_value_loss       | 0.000352     |
|    cost_values           | -0.0501      |
|    entropy               | -0.771       |
|    entropy_loss          | -0.769       |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.369        |
|    n_updates             | 12320        |
|    policy_gradient_loss  | -0.00348     |
|    std                   | 0.358        |
|    value_loss            | 1.06         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.163       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.163       |
| reward                   | -0.20180939 |
| rollout/                 |             |
|    ep_len_mean           | 266         |
|    ep_rew_mean           | -86.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 9           |
|    time_elapsed          | 201         |
|    total_timesteps       | 2527232     |
| train/                   |             |
|    approx_kl             | 0.007096221 |
|    clip_fraction         | 0.0745      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0134     |
|    cost_value_loss       | 0.000239    |
|    cost_values           | -0.0136     |
|    entropy               | -0.767      |
|    entropy_loss          | -0.769      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.247       |
|    n_updates             | 12330       |
|    policy_gradient_loss  | -0.00425    |
|    std                   | 0.357       |
|    value_loss            | 0.539       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.42        |
| reward                   | -0.13885863 |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -87.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 10          |
|    time_elapsed          | 223         |
|    total_timesteps       | 2529280     |
| train/                   |             |
|    approx_kl             | 0.011085249 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00436    |
|    cost_value_loss       | 0.00074     |
|    cost_values           | -0.00293    |
|    entropy               | -0.762      |
|    entropy_loss          | -0.764      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.257       |
|    n_updates             | 12340       |
|    policy_gradient_loss  | -0.00417    |
|    std                   | 0.356       |
|    value_loss            | 0.578       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.21         |
| reward                   | -0.41549283  |
| rollout/                 |              |
|    ep_len_mean           | 261          |
|    ep_rew_mean           | -84.3        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 11           |
|    time_elapsed          | 246          |
|    total_timesteps       | 2531328      |
| train/                   |              |
|    approx_kl             | 0.0062492415 |
|    clip_fraction         | 0.0881       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.019       |
|    cost_value_loss       | 0.000503     |
|    cost_values           | -0.0191      |
|    entropy               | -0.755       |
|    entropy_loss          | -0.759       |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.224        |
|    n_updates             | 12350        |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.355        |
|    value_loss            | 0.482        |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.678      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.678      |
| reward                   | -0.3064074 |
| rollout/                 |            |
|    ep_len_mean           | 261        |
|    ep_rew_mean           | -82.4      |
| time/                    |            |
|    fps                   | 91         |
|    iterations            | 12         |
|    time_elapsed          | 268        |
|    total_timesteps       | 2533376    |
| train/                   |            |
|    approx_kl             | 0.01002275 |
|    clip_fraction         | 0.118      |
|    clip_range            | 0.2        |
|    cost_returns          | 0.00285    |
|    cost_value_loss       | 0.000805   |
|    cost_values           | 0.0042     |
|    entropy               | -0.736     |
|    entropy_loss          | -0.746     |
|    explained_variance    | 0.996      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.172      |
|    n_updates             | 12360      |
|    policy_gradient_loss  | -0.0039    |
|    std                   | 0.351      |
|    value_loss            | 0.425      |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.48        |
| reward                   | -0.33225572 |
| rollout/                 |             |
|    ep_len_mean           | 244         |
|    ep_rew_mean           | -75.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 13          |
|    time_elapsed          | 291         |
|    total_timesteps       | 2535424     |
| train/                   |             |
|    approx_kl             | 0.007859868 |
|    clip_fraction         | 0.0855      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0251     |
|    cost_value_loss       | 0.000268    |
|    cost_values           | -0.027      |
|    entropy               | -0.73       |
|    entropy_loss          | -0.732      |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.358       |
|    n_updates             | 12370       |
|    policy_gradient_loss  | -0.00409    |
|    std                   | 0.35        |
|    value_loss            | 0.763       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.25        |
| reward                   | -0.49286506 |
| rollout/                 |             |
|    ep_len_mean           | 242         |
|    ep_rew_mean           | -75.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 14          |
|    time_elapsed          | 313         |
|    total_timesteps       | 2537472     |
| train/                   |             |
|    approx_kl             | 0.010507489 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0163     |
|    cost_value_loss       | 0.0003      |
|    cost_values           | -0.0165     |
|    entropy               | -0.734      |
|    entropy_loss          | -0.732      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.336       |
|    n_updates             | 12380       |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 0.351       |
|    value_loss            | 0.668       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.417       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.417       |
| reward                   | -0.2053305  |
| rollout/                 |             |
|    ep_len_mean           | 253         |
|    ep_rew_mean           | -80.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 15          |
|    time_elapsed          | 335         |
|    total_timesteps       | 2539520     |
| train/                   |             |
|    approx_kl             | 0.017202595 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0567      |
|    cost_value_loss       | 0.00297     |
|    cost_values           | 0.0657      |
|    entropy               | -0.732      |
|    entropy_loss          | -0.734      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.505       |
|    n_updates             | 12390       |
|    policy_gradient_loss  | -0.00469    |
|    std                   | 0.351       |
|    value_loss            | 1.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.733       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.733       |
| reward                   | -0.3620853  |
| rollout/                 |             |
|    ep_len_mean           | 262         |
|    ep_rew_mean           | -82.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 16          |
|    time_elapsed          | 357         |
|    total_timesteps       | 2541568     |
| train/                   |             |
|    approx_kl             | 0.007899382 |
|    clip_fraction         | 0.0892      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.223       |
|    cost_value_loss       | 0.0146      |
|    cost_values           | 0.243       |
|    entropy               | -0.728      |
|    entropy_loss          | -0.73       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.442       |
|    n_updates             | 12400       |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.35        |
|    value_loss            | 1.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.4          |
| reward                   | -0.4698409   |
| rollout/                 |              |
|    ep_len_mean           | 261          |
|    ep_rew_mean           | -82.2        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 17           |
|    time_elapsed          | 380          |
|    total_timesteps       | 2543616      |
| train/                   |              |
|    approx_kl             | 0.0075347405 |
|    clip_fraction         | 0.0563       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0969      |
|    cost_value_loss       | 0.000253     |
|    cost_values           | -0.102       |
|    entropy               | -0.722       |
|    entropy_loss          | -0.725       |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.466        |
|    n_updates             | 12410        |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 0.349        |
|    value_loss            | 1.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.813       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.813       |
| reward                   | -0.27478677 |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -82.4       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 18          |
|    time_elapsed          | 402         |
|    total_timesteps       | 2545664     |
| train/                   |             |
|    approx_kl             | 0.008734638 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | -0.002      |
|    cost_value_loss       | 0.000453    |
|    cost_values           | -0.00133    |
|    entropy               | -0.717      |
|    entropy_loss          | -0.719      |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.563       |
|    n_updates             | 12420       |
|    policy_gradient_loss  | -0.00563    |
|    std                   | 0.348       |
|    value_loss            | 1.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.899       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.899       |
| reward                   | -0.39037812 |
| rollout/                 |             |
|    ep_len_mean           | 249         |
|    ep_rew_mean           | -78.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 19          |
|    time_elapsed          | 425         |
|    total_timesteps       | 2547712     |
| train/                   |             |
|    approx_kl             | 0.009392661 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00535     |
|    cost_value_loss       | 0.000431    |
|    cost_values           | 0.00713     |
|    entropy               | -0.719      |
|    entropy_loss          | -0.717      |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.351       |
|    n_updates             | 12430       |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 0.348       |
|    value_loss            | 0.955       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.77        |
| reward                   | -0.3192622  |
| rollout/                 |             |
|    ep_len_mean           | 258         |
|    ep_rew_mean           | -83.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 20          |
|    time_elapsed          | 447         |
|    total_timesteps       | 2549760     |
| train/                   |             |
|    approx_kl             | 0.007281525 |
|    clip_fraction         | 0.0692      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0258     |
|    cost_value_loss       | 0.000371    |
|    cost_values           | -0.0281     |
|    entropy               | -0.715      |
|    entropy_loss          | -0.718      |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.775       |
|    n_updates             | 12440       |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.347       |
|    value_loss            | 1.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.07        |
| reward                   | -0.28134993 |
| rollout/                 |             |
|    ep_len_mean           | 259         |
|    ep_rew_mean           | -83.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 21          |
|    time_elapsed          | 469         |
|    total_timesteps       | 2551808     |
| train/                   |             |
|    approx_kl             | 0.012581793 |
|    clip_fraction         | 0.0841      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.133       |
|    cost_value_loss       | 0.0101      |
|    cost_values           | 0.145       |
|    entropy               | -0.71       |
|    entropy_loss          | -0.712      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.474       |
|    n_updates             | 12450       |
|    policy_gradient_loss  | -0.00233    |
|    std                   | 0.346       |
|    value_loss            | 1.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.08        |
| reward                   | -0.19938941 |
| rollout/                 |             |
|    ep_len_mean           | 259         |
|    ep_rew_mean           | -84.1       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 22          |
|    time_elapsed          | 492         |
|    total_timesteps       | 2553856     |
| train/                   |             |
|    approx_kl             | 0.008505734 |
|    clip_fraction         | 0.0801      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0131     |
|    cost_value_loss       | 0.000548    |
|    cost_values           | -0.0126     |
|    entropy               | -0.71       |
|    entropy_loss          | -0.71       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.561       |
|    n_updates             | 12460       |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.347       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.303       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.303       |
| reward                   | -0.30366397 |
| rollout/                 |             |
|    ep_len_mean           | 264         |
|    ep_rew_mean           | -86.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 23          |
|    time_elapsed          | 514         |
|    total_timesteps       | 2555904     |
| train/                   |             |
|    approx_kl             | 0.009272014 |
|    clip_fraction         | 0.091       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0454     |
|    cost_value_loss       | 0.0007      |
|    cost_values           | -0.0465     |
|    entropy               | -0.713      |
|    entropy_loss          | -0.712      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.222       |
|    n_updates             | 12470       |
|    policy_gradient_loss  | -0.00386    |
|    std                   | 0.347       |
|    value_loss            | 0.672       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.17        |
| reward                   | -0.35537663 |
| rollout/                 |             |
|    ep_len_mean           | 265         |
|    ep_rew_mean           | -87.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 24          |
|    time_elapsed          | 536         |
|    total_timesteps       | 2557952     |
| train/                   |             |
|    approx_kl             | 0.01015813  |
|    clip_fraction         | 0.0954      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000579   |
|    cost_value_loss       | 0.000401    |
|    cost_values           | -0.000547   |
|    entropy               | -0.724      |
|    entropy_loss          | -0.718      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.291       |
|    n_updates             | 12480       |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 0.349       |
|    value_loss            | 0.695       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.7         |
| reward                   | -0.16230005 |
| rollout/                 |             |
|    ep_len_mean           | 260         |
|    ep_rew_mean           | -86.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 25          |
|    time_elapsed          | 558         |
|    total_timesteps       | 2560000     |
| train/                   |             |
|    approx_kl             | 0.005421171 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0703      |
|    cost_value_loss       | 0.00402     |
|    cost_values           | 0.0799      |
|    entropy               | -0.717      |
|    entropy_loss          | -0.723      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.391       |
|    n_updates             | 12490       |
|    policy_gradient_loss  | -0.00159    |
|    std                   | 0.348       |
|    value_loss            | 1.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.517       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.517       |
| reward                   | -0.3055223  |
| rollout/                 |             |
|    ep_len_mean           | 260         |
|    ep_rew_mean           | -86.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 26          |
|    time_elapsed          | 580         |
|    total_timesteps       | 2562048     |
| train/                   |             |
|    approx_kl             | 0.004696317 |
|    clip_fraction         | 0.0731      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0218     |
|    cost_value_loss       | 0.000279    |
|    cost_values           | -0.0234     |
|    entropy               | -0.711      |
|    entropy_loss          | -0.712      |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.634       |
|    n_updates             | 12500       |
|    policy_gradient_loss  | -0.000354   |
|    std                   | 0.347       |
|    value_loss            | 1.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.39        |
| reward                   | -0.47107187 |
| rollout/                 |             |
|    ep_len_mean           | 241         |
|    ep_rew_mean           | -76.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 27          |
|    time_elapsed          | 603         |
|    total_timesteps       | 2564096     |
| train/                   |             |
|    approx_kl             | 0.009982044 |
|    clip_fraction         | 0.0915      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00735    |
|    cost_value_loss       | 0.000321    |
|    cost_values           | -0.00789    |
|    entropy               | -0.712      |
|    entropy_loss          | -0.711      |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.52        |
|    n_updates             | 12510       |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.347       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.64        |
| reward                   | -0.39026907 |
| rollout/                 |             |
|    ep_len_mean           | 246         |
|    ep_rew_mean           | -83.2       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 28          |
|    time_elapsed          | 624         |
|    total_timesteps       | 2566144     |
| train/                   |             |
|    approx_kl             | 0.007767845 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0136     |
|    cost_value_loss       | 0.000346    |
|    cost_values           | -0.0136     |
|    entropy               | -0.722      |
|    entropy_loss          | -0.716      |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.402       |
|    n_updates             | 12520       |
|    policy_gradient_loss  | -0.00372    |
|    std                   | 0.349       |
|    value_loss            | 1.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.023       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.023       |
| reward                   | -0.24231768 |
| rollout/                 |             |
|    ep_len_mean           | 245         |
|    ep_rew_mean           | -82.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 29          |
|    time_elapsed          | 647         |
|    total_timesteps       | 2568192     |
| train/                   |             |
|    approx_kl             | 0.006858593 |
|    clip_fraction         | 0.0809      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.307       |
|    cost_value_loss       | 0.0134      |
|    cost_values           | 0.333       |
|    entropy               | -0.721      |
|    entropy_loss          | -0.723      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.569       |
|    n_updates             | 12530       |
|    policy_gradient_loss  | -0.0025     |
|    std                   | 0.348       |
|    value_loss            | 2.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.7         |
| reward                   | -0.6548067  |
| rollout/                 |             |
|    ep_len_mean           | 244         |
|    ep_rew_mean           | -82.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 30          |
|    time_elapsed          | 668         |
|    total_timesteps       | 2570240     |
| train/                   |             |
|    approx_kl             | 0.006919129 |
|    clip_fraction         | 0.0873      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0486     |
|    cost_value_loss       | 0.000371    |
|    cost_values           | -0.047      |
|    entropy               | -0.722      |
|    entropy_loss          | -0.72       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.501       |
|    n_updates             | 12540       |
|    policy_gradient_loss  | -0.00416    |
|    std                   | 0.349       |
|    value_loss            | 1.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.35        |
| reward                   | -0.22991958 |
| rollout/                 |             |
|    ep_len_mean           | 260         |
|    ep_rew_mean           | -91.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 31          |
|    time_elapsed          | 690         |
|    total_timesteps       | 2572288     |
| train/                   |             |
|    approx_kl             | 0.008296908 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0201     |
|    cost_value_loss       | 0.000414    |
|    cost_values           | -0.0187     |
|    entropy               | -0.723      |
|    entropy_loss          | -0.723      |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.547       |
|    n_updates             | 12550       |
|    policy_gradient_loss  | -0.00306    |
|    std                   | 0.349       |
|    value_loss            | 1.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.48         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.48         |
| reward                   | -0.2823203   |
| rollout/                 |              |
|    ep_len_mean           | 258          |
|    ep_rew_mean           | -92.8        |
| time/                    |              |
|    fps                   | 91           |
|    iterations            | 32           |
|    time_elapsed          | 713          |
|    total_timesteps       | 2574336      |
| train/                   |              |
|    approx_kl             | 0.0097099235 |
|    clip_fraction         | 0.0784       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0316       |
|    cost_value_loss       | 0.00331      |
|    cost_values           | 0.036        |
|    entropy               | -0.731       |
|    entropy_loss          | -0.725       |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.301        |
|    n_updates             | 12560        |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 0.35         |
|    value_loss            | 1.12         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.56        |
| reward                   | -0.16485034 |
| rollout/                 |             |
|    ep_len_mean           | 257         |
|    ep_rew_mean           | -92.5       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 33          |
|    time_elapsed          | 735         |
|    total_timesteps       | 2576384     |
| train/                   |             |
|    approx_kl             | 0.00601333  |
|    clip_fraction         | 0.0527      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.228       |
|    cost_value_loss       | 0.00882     |
|    cost_values           | 0.244       |
|    entropy               | -0.727      |
|    entropy_loss          | -0.731      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.75        |
|    n_updates             | 12570       |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.349       |
|    value_loss            | 4.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.69        |
| reward                   | -0.5328625  |
| rollout/                 |             |
|    ep_len_mean           | 253         |
|    ep_rew_mean           | -91         |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 34          |
|    time_elapsed          | 757         |
|    total_timesteps       | 2578432     |
| train/                   |             |
|    approx_kl             | 0.007989992 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0197     |
|    cost_value_loss       | 0.000253    |
|    cost_values           | -0.019      |
|    entropy               | -0.72       |
|    entropy_loss          | -0.723      |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.507       |
|    n_updates             | 12580       |
|    policy_gradient_loss  | -0.00515    |
|    std                   | 0.348       |
|    value_loss            | 1.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.443       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.443       |
| reward                   | -0.31236482 |
| rollout/                 |             |
|    ep_len_mean           | 267         |
|    ep_rew_mean           | -96.9       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 35          |
|    time_elapsed          | 779         |
|    total_timesteps       | 2580480     |
| train/                   |             |
|    approx_kl             | 0.006076903 |
|    clip_fraction         | 0.0847      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0171     |
|    cost_value_loss       | 0.00043     |
|    cost_values           | -0.0191     |
|    entropy               | -0.721      |
|    entropy_loss          | -0.72       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.505       |
|    n_updates             | 12590       |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 0.348       |
|    value_loss            | 1.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.37        |
| reward                   | -0.17723675 |
| rollout/                 |             |
|    ep_len_mean           | 267         |
|    ep_rew_mean           | -96.8       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 36          |
|    time_elapsed          | 801         |
|    total_timesteps       | 2582528     |
| train/                   |             |
|    approx_kl             | 0.009403071 |
|    clip_fraction         | 0.065       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0884      |
|    cost_value_loss       | 0.00646     |
|    cost_values           | 0.0971      |
|    entropy               | -0.719      |
|    entropy_loss          | -0.721      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.623       |
|    n_updates             | 12600       |
|    policy_gradient_loss  | -0.0028     |
|    std                   | 0.348       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.47        |
| reward                   | -0.2737646  |
| rollout/                 |             |
|    ep_len_mean           | 260         |
|    ep_rew_mean           | -92.3       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 37          |
|    time_elapsed          | 823         |
|    total_timesteps       | 2584576     |
| train/                   |             |
|    approx_kl             | 0.008448765 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0299     |
|    cost_value_loss       | 0.00035     |
|    cost_values           | -0.0301     |
|    entropy               | -0.725      |
|    entropy_loss          | -0.72       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.39        |
|    n_updates             | 12610       |
|    policy_gradient_loss  | -0.00454    |
|    std                   | 0.349       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.53        |
| reward                   | -0.290369   |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -93.7       |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 38          |
|    time_elapsed          | 845         |
|    total_timesteps       | 2586624     |
| train/                   |             |
|    approx_kl             | 0.008580151 |
|    clip_fraction         | 0.0876      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0145     |
|    cost_value_loss       | 0.000214    |
|    cost_values           | -0.0153     |
|    entropy               | -0.733      |
|    entropy_loss          | -0.729      |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.428       |
|    n_updates             | 12620       |
|    policy_gradient_loss  | -0.00456    |
|    std                   | 0.35        |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.453       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.453       |
| reward                   | -0.2346457  |
| rollout/                 |             |
|    ep_len_mean           | 278         |
|    ep_rew_mean           | -101        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 867         |
|    total_timesteps       | 2588672     |
| train/                   |             |
|    approx_kl             | 0.004079179 |
|    clip_fraction         | 0.0629      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0311      |
|    cost_value_loss       | 0.0625      |
|    cost_values           | 0.0126      |
|    entropy               | -0.731      |
|    entropy_loss          | -0.733      |
|    explained_variance    | 0.932       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.683       |
|    n_updates             | 12630       |
|    policy_gradient_loss  | -0.00318    |
|    std                   | 0.35        |
|    value_loss            | 1.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0395      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0395      |
| reward                   | -0.32638675 |
| rollout/                 |             |
|    ep_len_mean           | 284         |
|    ep_rew_mean           | -102        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 889         |
|    total_timesteps       | 2590720     |
| train/                   |             |
|    approx_kl             | 0.004783109 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 6.25        |
|    cost_values           | 0.725       |
|    entropy               | -0.73       |
|    entropy_loss          | -0.73       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.55        |
|    n_updates             | 12640       |
|    policy_gradient_loss  | -0.00556    |
|    std                   | 0.35        |
|    value_loss            | 8.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.21         |
| reward                   | -0.5979102   |
| rollout/                 |              |
|    ep_len_mean           | 296          |
|    ep_rew_mean           | -108         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 911          |
|    total_timesteps       | 2592768      |
| train/                   |              |
|    approx_kl             | 0.0074729673 |
|    clip_fraction         | 0.0792       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.338        |
|    cost_value_loss       | 0.00737      |
|    cost_values           | 0.331        |
|    entropy               | -0.74        |
|    entropy_loss          | -0.734       |
|    explained_variance    | 0.964        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.717        |
|    n_updates             | 12650        |
|    policy_gradient_loss  | -0.00311     |
|    std                   | 0.351        |
|    value_loss            | 1.75         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.64         |
| reward                   | -0.3020266   |
| rollout/                 |              |
|    ep_len_mean           | 283          |
|    ep_rew_mean           | -102         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 933          |
|    total_timesteps       | 2594816      |
| train/                   |              |
|    approx_kl             | 0.0070188767 |
|    clip_fraction         | 0.0709       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.351        |
|    cost_value_loss       | 0.0059       |
|    cost_values           | 0.374        |
|    entropy               | -0.741       |
|    entropy_loss          | -0.742       |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.444        |
|    n_updates             | 12660        |
|    policy_gradient_loss  | -0.0035      |
|    std                   | 0.352        |
|    value_loss            | 2.24         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.192       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.192       |
| reward                   | -0.24910134 |
| rollout/                 |             |
|    ep_len_mean           | 281         |
|    ep_rew_mean           | -102        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 955         |
|    total_timesteps       | 2596864     |
| train/                   |             |
|    approx_kl             | 0.007080343 |
|    clip_fraction         | 0.0903      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.554       |
|    cost_value_loss       | 0.0379      |
|    cost_values           | 0.592       |
|    entropy               | -0.739      |
|    entropy_loss          | -0.74       |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.05        |
|    n_updates             | 12670       |
|    policy_gradient_loss  | -0.00338    |
|    std                   | 0.351       |
|    value_loss            | 2.62        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.84         |
| reward                   | -0.41090202  |
| rollout/                 |              |
|    ep_len_mean           | 296          |
|    ep_rew_mean           | -106         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 44           |
|    time_elapsed          | 977          |
|    total_timesteps       | 2598912      |
| train/                   |              |
|    approx_kl             | 0.0063833934 |
|    clip_fraction         | 0.0693       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.123        |
|    cost_value_loss       | 0.00155      |
|    cost_values           | 0.142        |
|    entropy               | -0.739       |
|    entropy_loss          | -0.738       |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.856        |
|    n_updates             | 12680        |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.351        |
|    value_loss            | 2.22         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.35         |
| reward                   | -0.2602906   |
| rollout/                 |              |
|    ep_len_mean           | 283          |
|    ep_rew_mean           | -98.7        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 999          |
|    total_timesteps       | 2600960      |
| train/                   |              |
|    approx_kl             | 0.0059308964 |
|    clip_fraction         | 0.096        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0937       |
|    cost_value_loss       | 0.00113      |
|    cost_values           | 0.103        |
|    entropy               | -0.737       |
|    entropy_loss          | -0.739       |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.632        |
|    n_updates             | 12690        |
|    policy_gradient_loss  | -0.0061      |
|    std                   | 0.351        |
|    value_loss            | 1.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.435       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.435       |
| reward                   | -0.51590556 |
| rollout/                 |             |
|    ep_len_mean           | 283         |
|    ep_rew_mean           | -97.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1022        |
|    total_timesteps       | 2603008     |
| train/                   |             |
|    approx_kl             | 0.012880044 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0953      |
|    cost_value_loss       | 0.000875    |
|    cost_values           | 0.0987      |
|    entropy               | -0.726      |
|    entropy_loss          | -0.732      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.342       |
|    n_updates             | 12700       |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.349       |
|    value_loss            | 0.729       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.22338772 |
| rollout/                 |             |
|    ep_len_mean           | 290         |
|    ep_rew_mean           | -101        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1044        |
|    total_timesteps       | 2605056     |
| train/                   |             |
|    approx_kl             | 0.00930148  |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0751      |
|    cost_value_loss       | 0.0017      |
|    cost_values           | 0.0828      |
|    entropy               | -0.722      |
|    entropy_loss          | -0.724      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.554       |
|    n_updates             | 12710       |
|    policy_gradient_loss  | -0.00115    |
|    std                   | 0.348       |
|    value_loss            | 1.52        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.495        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.495        |
| reward                   | -0.8577796   |
| rollout/                 |              |
|    ep_len_mean           | 291          |
|    ep_rew_mean           | -102         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 48           |
|    time_elapsed          | 1066         |
|    total_timesteps       | 2607104      |
| train/                   |              |
|    approx_kl             | 0.0045803976 |
|    clip_fraction         | 0.0886       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0603       |
|    cost_value_loss       | 0.00145      |
|    cost_values           | 0.0662       |
|    entropy               | -0.716       |
|    entropy_loss          | -0.72        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.16         |
|    n_updates             | 12720        |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.347        |
|    value_loss            | 2.39         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 1.16       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.16       |
| reward                   | -0.3343924 |
| rollout/                 |            |
|    ep_len_mean           | 298        |
|    ep_rew_mean           | -105       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 49         |
|    time_elapsed          | 1088       |
|    total_timesteps       | 2609152    |
| train/                   |            |
|    approx_kl             | 0.0072291  |
|    clip_fraction         | 0.0856     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.323      |
|    cost_value_loss       | 0.00833    |
|    cost_values           | 0.337      |
|    entropy               | -0.713     |
|    entropy_loss          | -0.714     |
|    explained_variance    | 0.992      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 1.11       |
|    n_updates             | 12730      |
|    policy_gradient_loss  | -0.0053    |
|    std                   | 0.347      |
|    value_loss            | 2.87       |
-----------------------------------------
Directory created: PPOL_New/models/seed-testing/tggzx3rw/model_epoch(25)
-----------------------------------
| avg_speed          | 0.0763     |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.0763     |
| reward             | -0.3332419 |
| rollout/           |            |
|    ep_len_mean     | 292        |
|    ep_rew_mean     | -102       |
| time/              |            |
|    fps             | 94         |
|    iterations      | 1          |
|    time_elapsed    | 21         |
|    total_timesteps | 2611200    |
-----------------------------------
-------------------------------------------
| avg_speed                | 1.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.47         |
| reward                   | -0.16961877  |
| rollout/                 |              |
|    ep_len_mean           | 297          |
|    ep_rew_mean           | -104         |
| time/                    |              |
|    fps                   | 94           |
|    iterations            | 2            |
|    time_elapsed          | 43           |
|    total_timesteps       | 2613248      |
| train/                   |              |
|    approx_kl             | 0.0052326396 |
|    clip_fraction         | 0.0833       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0117       |
|    cost_value_loss       | 0.000272     |
|    cost_values           | 0.0153       |
|    entropy               | -0.708       |
|    entropy_loss          | -0.706       |
|    explained_variance    | 0.952        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.13         |
|    n_updates             | 12750        |
|    policy_gradient_loss  | -0.0047      |
|    std                   | 0.346        |
|    value_loss            | 2.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.06        |
| reward                   | -0.38525498 |
| rollout/                 |             |
|    ep_len_mean           | 287         |
|    ep_rew_mean           | -103        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 2615296     |
| train/                   |             |
|    approx_kl             | 0.008430203 |
|    clip_fraction         | 0.0943      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0105     |
|    cost_value_loss       | 0.000277    |
|    cost_values           | -0.00996    |
|    entropy               | -0.703      |
|    entropy_loss          | -0.706      |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.398       |
|    n_updates             | 12760       |
|    policy_gradient_loss  | -0.00623    |
|    std                   | 0.345       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.33        |
| reward                   | -0.43318874 |
| rollout/                 |             |
|    ep_len_mean           | 270         |
|    ep_rew_mean           | -93         |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 2617344     |
| train/                   |             |
|    approx_kl             | 0.010374883 |
|    clip_fraction         | 0.0969      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0149     |
|    cost_value_loss       | 0.000133    |
|    cost_values           | -0.0153     |
|    entropy               | -0.694      |
|    entropy_loss          | -0.698      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.351       |
|    n_updates             | 12770       |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.343       |
|    value_loss            | 0.718       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.49        |
| reward                   | -0.38925433 |
| rollout/                 |             |
|    ep_len_mean           | 252         |
|    ep_rew_mean           | -82.8       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 2619392     |
| train/                   |             |
|    approx_kl             | 0.008981722 |
|    clip_fraction         | 0.144       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00553    |
|    cost_value_loss       | 0.00013     |
|    cost_values           | -0.0057     |
|    entropy               | -0.695      |
|    entropy_loss          | -0.694      |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.511       |
|    n_updates             | 12780       |
|    policy_gradient_loss  | 0.00134     |
|    std                   | 0.344       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.278       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.278       |
| reward                   | -0.40219933 |
| rollout/                 |             |
|    ep_len_mean           | 233         |
|    ep_rew_mean           | -75.8       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 2621440     |
| train/                   |             |
|    approx_kl             | 0.009420125 |
|    clip_fraction         | 0.0835      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00615    |
|    cost_value_loss       | 0.000145    |
|    cost_values           | -0.00633    |
|    entropy               | -0.703      |
|    entropy_loss          | -0.698      |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.248       |
|    n_updates             | 12790       |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.345       |
|    value_loss            | 0.672       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.05        |
| reward                   | -0.4131119  |
| rollout/                 |             |
|    ep_len_mean           | 230         |
|    ep_rew_mean           | -75.8       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 7           |
|    time_elapsed          | 153         |
|    total_timesteps       | 2623488     |
| train/                   |             |
|    approx_kl             | 0.012867345 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00293     |
|    cost_value_loss       | 0.000143    |
|    cost_values           | 0.00288     |
|    entropy               | -0.705      |
|    entropy_loss          | -0.705      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.309       |
|    n_updates             | 12800       |
|    policy_gradient_loss  | -0.00592    |
|    std                   | 0.345       |
|    value_loss            | 0.626       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.569        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.569        |
| reward                   | -0.2385267   |
| rollout/                 |              |
|    ep_len_mean           | 231          |
|    ep_rew_mean           | -77.1        |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 8            |
|    time_elapsed          | 175          |
|    total_timesteps       | 2625536      |
| train/                   |              |
|    approx_kl             | 0.0045643407 |
|    clip_fraction         | 0.0849       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.00883      |
|    cost_value_loss       | 0.000115     |
|    cost_values           | 0.00792      |
|    entropy               | -0.705       |
|    entropy_loss          | -0.705       |
|    explained_variance    | 0.967        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.729        |
|    n_updates             | 12810        |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.345        |
|    value_loss            | 1.94         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.98        |
| reward                   | -0.25646034 |
| rollout/                 |             |
|    ep_len_mean           | 223         |
|    ep_rew_mean           | -72.3       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 9           |
|    time_elapsed          | 197         |
|    total_timesteps       | 2627584     |
| train/                   |             |
|    approx_kl             | 0.00858946  |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.29        |
|    cost_value_loss       | 0.0139      |
|    cost_values           | 0.3         |
|    entropy               | -0.72       |
|    entropy_loss          | -0.711      |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.365       |
|    n_updates             | 12820       |
|    policy_gradient_loss  | -0.00554    |
|    std                   | 0.348       |
|    value_loss            | 0.997       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.541       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.541       |
| reward                   | -0.24272692 |
| rollout/                 |             |
|    ep_len_mean           | 206         |
|    ep_rew_mean           | -63.9       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 10          |
|    time_elapsed          | 219         |
|    total_timesteps       | 2629632     |
| train/                   |             |
|    approx_kl             | 0.008146992 |
|    clip_fraction         | 0.0849      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00208     |
|    cost_value_loss       | 0.000136    |
|    cost_values           | 0.00145     |
|    entropy               | -0.724      |
|    entropy_loss          | -0.724      |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.691       |
|    n_updates             | 12830       |
|    policy_gradient_loss  | -0.00358    |
|    std                   | 0.349       |
|    value_loss            | 1.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.47        |
| reward                   | -0.30856735 |
| rollout/                 |             |
|    ep_len_mean           | 198         |
|    ep_rew_mean           | -61.8       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 11          |
|    time_elapsed          | 242         |
|    total_timesteps       | 2631680     |
| train/                   |             |
|    approx_kl             | 0.008747468 |
|    clip_fraction         | 0.0854      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0113      |
|    cost_value_loss       | 0.000145    |
|    cost_values           | 0.0118      |
|    entropy               | -0.719      |
|    entropy_loss          | -0.722      |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.36        |
|    n_updates             | 12840       |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 0.348       |
|    value_loss            | 0.897       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.68        |
| reward                   | -0.373525   |
| rollout/                 |             |
|    ep_len_mean           | 208         |
|    ep_rew_mean           | -68.1       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 12          |
|    time_elapsed          | 264         |
|    total_timesteps       | 2633728     |
| train/                   |             |
|    approx_kl             | 0.010578213 |
|    clip_fraction         | 0.0783      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.00103    |
|    cost_value_loss       | 0.000146    |
|    cost_values           | -0.00104    |
|    entropy               | -0.705      |
|    entropy_loss          | -0.714      |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.322       |
|    n_updates             | 12850       |
|    policy_gradient_loss  | -0.00224    |
|    std                   | 0.345       |
|    value_loss            | 0.813       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.481      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.481      |
| reward                   | -0.3454245 |
| rollout/                 |            |
|    ep_len_mean           | 209        |
|    ep_rew_mean           | -71.2      |
| time/                    |            |
|    fps                   | 93         |
|    iterations            | 13         |
|    time_elapsed          | 286        |
|    total_timesteps       | 2635776    |
| train/                   |            |
|    approx_kl             | 0.00827631 |
|    clip_fraction         | 0.0936     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.308      |
|    cost_value_loss       | 0.012      |
|    cost_values           | 0.32       |
|    entropy               | -0.698     |
|    entropy_loss          | -0.701     |
|    explained_variance    | 0.994      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.841      |
|    n_updates             | 12860      |
|    policy_gradient_loss  | -0.00252   |
|    std                   | 0.344      |
|    value_loss            | 3.08       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.12        |
| reward                   | -0.2024516  |
| rollout/                 |             |
|    ep_len_mean           | 207         |
|    ep_rew_mean           | -70.6       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 14          |
|    time_elapsed          | 308         |
|    total_timesteps       | 2637824     |
| train/                   |             |
|    approx_kl             | 0.010706846 |
|    clip_fraction         | 0.0985      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.244       |
|    cost_value_loss       | 0.00786     |
|    cost_values           | 0.252       |
|    entropy               | -0.691      |
|    entropy_loss          | -0.695      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.77        |
|    n_updates             | 12870       |
|    policy_gradient_loss  | -0.00496    |
|    std                   | 0.343       |
|    value_loss            | 2.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.11        |
| reward                   | -0.6835742  |
| rollout/                 |             |
|    ep_len_mean           | 210         |
|    ep_rew_mean           | -71.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 330         |
|    total_timesteps       | 2639872     |
| train/                   |             |
|    approx_kl             | 0.008639304 |
|    clip_fraction         | 0.095       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0194      |
|    cost_value_loss       | 0.000237    |
|    cost_values           | 0.0195      |
|    entropy               | -0.688      |
|    entropy_loss          | -0.689      |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.896       |
|    n_updates             | 12880       |
|    policy_gradient_loss  | -0.00483    |
|    std                   | 0.342       |
|    value_loss            | 1.71        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.46         |
| reward                   | -0.21953174  |
| rollout/                 |              |
|    ep_len_mean           | 217          |
|    ep_rew_mean           | -77.1        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 16           |
|    time_elapsed          | 352          |
|    total_timesteps       | 2641920      |
| train/                   |              |
|    approx_kl             | 0.0081789205 |
|    clip_fraction         | 0.0832       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0243       |
|    cost_value_loss       | 0.000328     |
|    cost_values           | 0.025        |
|    entropy               | -0.69        |
|    entropy_loss          | -0.688       |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.815        |
|    n_updates             | 12890        |
|    policy_gradient_loss  | -0.00431     |
|    std                   | 0.343        |
|    value_loss            | 2.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.767       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.767       |
| reward                   | -0.6969897  |
| rollout/                 |             |
|    ep_len_mean           | 221         |
|    ep_rew_mean           | -78.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 375         |
|    total_timesteps       | 2643968     |
| train/                   |             |
|    approx_kl             | 0.007480519 |
|    clip_fraction         | 0.0712      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.114       |
|    cost_value_loss       | 0.00553     |
|    cost_values           | 0.123       |
|    entropy               | -0.688      |
|    entropy_loss          | -0.69       |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.324       |
|    n_updates             | 12900       |
|    policy_gradient_loss  | -0.00143    |
|    std                   | 0.343       |
|    value_loss            | 0.909       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.32        |
| reward                   | -0.3888205  |
| rollout/                 |             |
|    ep_len_mean           | 233         |
|    ep_rew_mean           | -82.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 397         |
|    total_timesteps       | 2646016     |
| train/                   |             |
|    approx_kl             | 0.009065615 |
|    clip_fraction         | 0.0802      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0882      |
|    cost_value_loss       | 0.000707    |
|    cost_values           | 0.0898      |
|    entropy               | -0.688      |
|    entropy_loss          | -0.687      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.13        |
|    n_updates             | 12910       |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 0.343       |
|    value_loss            | 2.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.377       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.377       |
| reward                   | -0.21582174 |
| rollout/                 |             |
|    ep_len_mean           | 227         |
|    ep_rew_mean           | -78.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 419         |
|    total_timesteps       | 2648064     |
| train/                   |             |
|    approx_kl             | 0.00793208  |
|    clip_fraction         | 0.073       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0969      |
|    cost_value_loss       | 0.006       |
|    cost_values           | 0.105       |
|    entropy               | -0.69       |
|    entropy_loss          | -0.689      |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.449       |
|    n_updates             | 12920       |
|    policy_gradient_loss  | -0.00336    |
|    std                   | 0.343       |
|    value_loss            | 1.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.79         |
| reward                   | -0.37517866  |
| rollout/                 |              |
|    ep_len_mean           | 224          |
|    ep_rew_mean           | -77.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 20           |
|    time_elapsed          | 441          |
|    total_timesteps       | 2650112      |
| train/                   |              |
|    approx_kl             | 0.0077385483 |
|    clip_fraction         | 0.0785       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0136      |
|    cost_value_loss       | 0.000288     |
|    cost_values           | -0.0143      |
|    entropy               | -0.684       |
|    entropy_loss          | -0.689       |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.538        |
|    n_updates             | 12930        |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 0.342        |
|    value_loss            | 1.54         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.698      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.698      |
| reward                   | -0.2979393 |
| rollout/                 |            |
|    ep_len_mean           | 235        |
|    ep_rew_mean           | -84.9      |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 21         |
|    time_elapsed          | 463        |
|    total_timesteps       | 2652160    |
| train/                   |            |
|    approx_kl             | 0.00784002 |
|    clip_fraction         | 0.0852     |
|    clip_range            | 0.2        |
|    cost_returns          | -0.00188   |
|    cost_value_loss       | 0.000203   |
|    cost_values           | -0.00249   |
|    entropy               | -0.684     |
|    entropy_loss          | -0.683     |
|    explained_variance    | 0.973      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.803      |
|    n_updates             | 12940      |
|    policy_gradient_loss  | -0.00449   |
|    std                   | 0.342      |
|    value_loss            | 2.02       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.641        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.641        |
| reward                   | -0.39206737  |
| rollout/                 |              |
|    ep_len_mean           | 252          |
|    ep_rew_mean           | -94.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 22           |
|    time_elapsed          | 485          |
|    total_timesteps       | 2654208      |
| train/                   |              |
|    approx_kl             | 0.0063592703 |
|    clip_fraction         | 0.0923       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.207        |
|    cost_value_loss       | 0.00526      |
|    cost_values           | 0.212        |
|    entropy               | -0.685       |
|    entropy_loss          | -0.685       |
|    explained_variance    | 0.997        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.364        |
|    n_updates             | 12950        |
|    policy_gradient_loss  | -0.00486     |
|    std                   | 0.342        |
|    value_loss            | 1.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.37        |
| reward                   | -1.6406235  |
| rollout/                 |             |
|    ep_len_mean           | 253         |
|    ep_rew_mean           | -94.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 508         |
|    total_timesteps       | 2656256     |
| train/                   |             |
|    approx_kl             | 0.009300683 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.149       |
|    cost_value_loss       | 0.00663     |
|    cost_values           | 0.163       |
|    entropy               | -0.681      |
|    entropy_loss          | -0.685      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.522       |
|    n_updates             | 12960       |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.341       |
|    value_loss            | 2.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.72         |
| reward                   | -0.46314815  |
| rollout/                 |              |
|    ep_len_mean           | 248          |
|    ep_rew_mean           | -95.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 530          |
|    total_timesteps       | 2658304      |
| train/                   |              |
|    approx_kl             | 0.0052582617 |
|    clip_fraction         | 0.0537       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.73         |
|    cost_value_loss       | 23.1         |
|    cost_values           | 1.28         |
|    entropy               | -0.679       |
|    entropy_loss          | -0.679       |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0.00226      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.97         |
|    n_updates             | 12970        |
|    policy_gradient_loss  | -0.00582     |
|    std                   | 0.341        |
|    value_loss            | 18.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.264       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.264       |
| reward                   | -0.8440306  |
| rollout/                 |             |
|    ep_len_mean           | 252         |
|    ep_rew_mean           | -97.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 553         |
|    total_timesteps       | 2660352     |
| train/                   |             |
|    approx_kl             | 0.005054673 |
|    clip_fraction         | 0.0525      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.22        |
|    cost_value_loss       | 5.1         |
|    cost_values           | 0.805       |
|    entropy               | -0.682      |
|    entropy_loss          | -0.68       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.62        |
|    n_updates             | 12980       |
|    policy_gradient_loss  | -0.0079     |
|    std                   | 0.341       |
|    value_loss            | 5.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0354       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0354       |
| reward                   | -0.23205249  |
| rollout/                 |              |
|    ep_len_mean           | 255          |
|    ep_rew_mean           | -97.9        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 575          |
|    total_timesteps       | 2662400      |
| train/                   |              |
|    approx_kl             | 0.0105635505 |
|    clip_fraction         | 0.0663       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.407        |
|    cost_value_loss       | 0.0272       |
|    cost_values           | 0.505        |
|    entropy               | -0.683       |
|    entropy_loss          | -0.683       |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.488        |
|    n_updates             | 12990        |
|    policy_gradient_loss  | -0.00477     |
|    std                   | 0.342        |
|    value_loss            | 1.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.32        |
| reward                   | -0.2278802  |
| rollout/                 |             |
|    ep_len_mean           | 265         |
|    ep_rew_mean           | -107        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 597         |
|    total_timesteps       | 2664448     |
| train/                   |             |
|    approx_kl             | 0.014461805 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.547       |
|    cost_value_loss       | 0.0218      |
|    cost_values           | 0.64        |
|    entropy               | -0.677      |
|    entropy_loss          | -0.682      |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.17        |
|    n_updates             | 13000       |
|    policy_gradient_loss  | -0.00166    |
|    std                   | 0.34        |
|    value_loss            | 3.46        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.1          |
| reward                   | -0.8854599   |
| rollout/                 |              |
|    ep_len_mean           | 270          |
|    ep_rew_mean           | -111         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 619          |
|    total_timesteps       | 2666496      |
| train/                   |              |
|    approx_kl             | 0.0051392126 |
|    clip_fraction         | 0.133        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.9          |
|    cost_value_loss       | 33.7         |
|    cost_values           | 1.22         |
|    entropy               | -0.675       |
|    entropy_loss          | -0.675       |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0.00719      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.91         |
|    n_updates             | 13010        |
|    policy_gradient_loss  | -0.00218     |
|    std                   | 0.34         |
|    value_loss            | 19.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.96        |
| reward                   | -0.1958907  |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -110        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 641         |
|    total_timesteps       | 2668544     |
| train/                   |             |
|    approx_kl             | 0.008928549 |
|    clip_fraction         | 0.0686      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.167       |
|    cost_value_loss       | 0.00843     |
|    cost_values           | 0.204       |
|    entropy               | -0.672      |
|    entropy_loss          | -0.674      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.502       |
|    n_updates             | 13020       |
|    policy_gradient_loss  | -0.0046     |
|    std                   | 0.34        |
|    value_loss            | 2.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.843       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.843       |
| reward                   | -0.76233107 |
| rollout/                 |             |
|    ep_len_mean           | 273         |
|    ep_rew_mean           | -114        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 663         |
|    total_timesteps       | 2670592     |
| train/                   |             |
|    approx_kl             | 0.009526151 |
|    clip_fraction         | 0.0857      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.336       |
|    cost_value_loss       | 0.0114      |
|    cost_values           | 0.39        |
|    entropy               | -0.662      |
|    entropy_loss          | -0.668      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.969       |
|    n_updates             | 13030       |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.338       |
|    value_loss            | 2.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.597       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.597       |
| reward                   | -0.26996467 |
| rollout/                 |             |
|    ep_len_mean           | 282         |
|    ep_rew_mean           | -121        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 684         |
|    total_timesteps       | 2672640     |
| train/                   |             |
|    approx_kl             | 0.012611078 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.37        |
|    cost_value_loss       | 0.0149      |
|    cost_values           | 0.416       |
|    entropy               | -0.659      |
|    entropy_loss          | -0.659      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.689       |
|    n_updates             | 13040       |
|    policy_gradient_loss  | -0.00463    |
|    std                   | 0.337       |
|    value_loss            | 2.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.804       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.804       |
| reward                   | -0.24651682 |
| rollout/                 |             |
|    ep_len_mean           | 283         |
|    ep_rew_mean           | -126        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 706         |
|    total_timesteps       | 2674688     |
| train/                   |             |
|    approx_kl             | 0.010151302 |
|    clip_fraction         | 0.0894      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.292       |
|    cost_value_loss       | 0.0465      |
|    cost_values           | 0.349       |
|    entropy               | -0.653      |
|    entropy_loss          | -0.656      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.26        |
|    n_updates             | 13050       |
|    policy_gradient_loss  | -0.00181    |
|    std                   | 0.336       |
|    value_loss            | 2.86        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.01         |
| reward                   | -0.6924578   |
| rollout/                 |              |
|    ep_len_mean           | 282          |
|    ep_rew_mean           | -126         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 33           |
|    time_elapsed          | 728          |
|    total_timesteps       | 2676736      |
| train/                   |              |
|    approx_kl             | 0.0065295957 |
|    clip_fraction         | 0.0886       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.112        |
|    cost_value_loss       | 0.00426      |
|    cost_values           | 0.131        |
|    entropy               | -0.654       |
|    entropy_loss          | -0.653       |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.44         |
|    n_updates             | 13060        |
|    policy_gradient_loss  | -0.00589     |
|    std                   | 0.337        |
|    value_loss            | 5.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.259       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.259       |
| reward                   | -0.42398947 |
| rollout/                 |             |
|    ep_len_mean           | 287         |
|    ep_rew_mean           | -132        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 751         |
|    total_timesteps       | 2678784     |
| train/                   |             |
|    approx_kl             | 0.008967098 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.232       |
|    cost_value_loss       | 0.00657     |
|    cost_values           | 0.254       |
|    entropy               | -0.652      |
|    entropy_loss          | -0.653      |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.06        |
|    n_updates             | 13070       |
|    policy_gradient_loss  | -0.00593    |
|    std                   | 0.336       |
|    value_loss            | 3.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.702       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.702       |
| reward                   | -0.19707504 |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -120        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 773         |
|    total_timesteps       | 2680832     |
| train/                   |             |
|    approx_kl             | 0.008780448 |
|    clip_fraction         | 0.0997      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.92        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 0.644       |
|    entropy               | -0.65       |
|    entropy_loss          | -0.65       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.00414     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.65        |
|    n_updates             | 13080       |
|    policy_gradient_loss  | -0.0107     |
|    std                   | 0.336       |
|    value_loss            | 11.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.93         |
| reward                   | -0.81574243  |
| rollout/                 |              |
|    ep_len_mean           | 269          |
|    ep_rew_mean           | -120         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 36           |
|    time_elapsed          | 794          |
|    total_timesteps       | 2682880      |
| train/                   |              |
|    approx_kl             | 0.0090831015 |
|    clip_fraction         | 0.0792       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.00665     |
|    cost_value_loss       | 0.00453      |
|    cost_values           | -0.0479      |
|    entropy               | -0.651       |
|    entropy_loss          | -0.651       |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.94         |
|    n_updates             | 13090        |
|    policy_gradient_loss  | -0.00401     |
|    std                   | 0.336        |
|    value_loss            | 2.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.881        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.881        |
| reward                   | -0.40058428  |
| rollout/                 |              |
|    ep_len_mean           | 278          |
|    ep_rew_mean           | -123         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 37           |
|    time_elapsed          | 817          |
|    total_timesteps       | 2684928      |
| train/                   |              |
|    approx_kl             | 0.0072084805 |
|    clip_fraction         | 0.0714       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.377        |
|    cost_value_loss       | 0.157        |
|    cost_values           | 0.379        |
|    entropy               | -0.649       |
|    entropy_loss          | -0.65        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.75         |
|    n_updates             | 13100        |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 0.336        |
|    value_loss            | 2.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.34        |
| reward                   | -0.7240957  |
| rollout/                 |             |
|    ep_len_mean           | 283         |
|    ep_rew_mean           | -125        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 839         |
|    total_timesteps       | 2686976     |
| train/                   |             |
|    approx_kl             | 0.007648858 |
|    clip_fraction         | 0.0788      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.18        |
|    cost_value_loss       | 21.3        |
|    cost_values           | 0.489       |
|    entropy               | -0.651      |
|    entropy_loss          | -0.649      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0.00627     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 13110       |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 0.336       |
|    value_loss            | 7.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.812       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.812       |
| reward                   | -0.26941088 |
| rollout/                 |             |
|    ep_len_mean           | 282         |
|    ep_rew_mean           | -126        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 861         |
|    total_timesteps       | 2689024     |
| train/                   |             |
|    approx_kl             | 0.009928855 |
|    clip_fraction         | 0.0824      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.117       |
|    cost_value_loss       | 0.00527     |
|    cost_values           | 0.159       |
|    entropy               | -0.649      |
|    entropy_loss          | -0.651      |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.81        |
|    n_updates             | 13120       |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 0.336       |
|    value_loss            | 4.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.29        |
| reward                   | -0.29400578 |
| rollout/                 |             |
|    ep_len_mean           | 287         |
|    ep_rew_mean           | -128        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 884         |
|    total_timesteps       | 2691072     |
| train/                   |             |
|    approx_kl             | 0.009641334 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0436      |
|    cost_value_loss       | 0.00218     |
|    cost_values           | 0.0473      |
|    entropy               | -0.638      |
|    entropy_loss          | -0.644      |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.455       |
|    n_updates             | 13130       |
|    policy_gradient_loss  | -0.0052     |
|    std                   | 0.334       |
|    value_loss            | 1.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.29618865 |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -109        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 906         |
|    total_timesteps       | 2693120     |
| train/                   |             |
|    approx_kl             | 0.012442961 |
|    clip_fraction         | 0.0947      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.398       |
|    cost_value_loss       | 0.0409      |
|    cost_values           | 0.459       |
|    entropy               | -0.639      |
|    entropy_loss          | -0.637      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.703       |
|    n_updates             | 13140       |
|    policy_gradient_loss  | -0.002      |
|    std                   | 0.334       |
|    value_loss            | 2.14        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.7        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.7        |
| reward                   | -0.693988  |
| rollout/                 |            |
|    ep_len_mean           | 263        |
|    ep_rew_mean           | -110       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 42         |
|    time_elapsed          | 929        |
|    total_timesteps       | 2695168    |
| train/                   |            |
|    approx_kl             | 0.00825324 |
|    clip_fraction         | 0.107      |
|    clip_range            | 0.2        |
|    cost_returns          | -0.0498    |
|    cost_value_loss       | 0.00142    |
|    cost_values           | -0.0584    |
|    entropy               | -0.644     |
|    entropy_loss          | -0.642     |
|    explained_variance    | 0.981      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.451      |
|    n_updates             | 13150      |
|    policy_gradient_loss  | -0.000596  |
|    std                   | 0.335      |
|    value_loss            | 1.41       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 1.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.14         |
| reward                   | -0.30918407  |
| rollout/                 |              |
|    ep_len_mean           | 275          |
|    ep_rew_mean           | -117         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 43           |
|    time_elapsed          | 951          |
|    total_timesteps       | 2697216      |
| train/                   |              |
|    approx_kl             | 0.0057840324 |
|    clip_fraction         | 0.0991       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0116      |
|    cost_value_loss       | 0.00171      |
|    cost_values           | -0.00561     |
|    entropy               | -0.639       |
|    entropy_loss          | -0.642       |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.11         |
|    n_updates             | 13160        |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 0.334        |
|    value_loss            | 3.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.5135277  |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -116        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 973         |
|    total_timesteps       | 2699264     |
| train/                   |             |
|    approx_kl             | 0.012118736 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.572       |
|    cost_value_loss       | 0.05        |
|    cost_values           | 0.651       |
|    entropy               | -0.633      |
|    entropy_loss          | -0.636      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.956       |
|    n_updates             | 13170       |
|    policy_gradient_loss  | -0.00569    |
|    std                   | 0.333       |
|    value_loss            | 2.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.574        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.574        |
| reward                   | -0.22480775  |
| rollout/                 |              |
|    ep_len_mean           | 278          |
|    ep_rew_mean           | -122         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 995          |
|    total_timesteps       | 2701312      |
| train/                   |              |
|    approx_kl             | 0.0072169364 |
|    clip_fraction         | 0.0526       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.12         |
|    cost_value_loss       | 54.5         |
|    cost_values           | 0.978        |
|    entropy               | -0.631       |
|    entropy_loss          | -0.631       |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0.00174      |
|    learning_rate         | 0.0003       |
|    loss                  | 19.3         |
|    n_updates             | 13180        |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.333        |
|    value_loss            | 17.5         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 1.46       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.46       |
| reward                   | -0.8621392 |
| rollout/                 |            |
|    ep_len_mean           | 277        |
|    ep_rew_mean           | -120       |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 46         |
|    time_elapsed          | 1017       |
|    total_timesteps       | 2703360    |
| train/                   |            |
|    approx_kl             | 0.00744598 |
|    clip_fraction         | 0.0424     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.907      |
|    cost_value_loss       | 0.0619     |
|    cost_values           | 1.01       |
|    entropy               | -0.63      |
|    entropy_loss          | -0.63      |
|    explained_variance    | 0.995      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.935      |
|    n_updates             | 13190      |
|    policy_gradient_loss  | -0.0029    |
|    std                   | 0.333      |
|    value_loss            | 3.02       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.609        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.609        |
| reward                   | -0.27229416  |
| rollout/                 |              |
|    ep_len_mean           | 294          |
|    ep_rew_mean           | -129         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1039         |
|    total_timesteps       | 2705408      |
| train/                   |              |
|    approx_kl             | 0.0090490645 |
|    clip_fraction         | 0.0898       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.621        |
|    cost_value_loss       | 0.0481       |
|    cost_values           | 0.705        |
|    entropy               | -0.63        |
|    entropy_loss          | -0.629       |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.733        |
|    n_updates             | 13200        |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 0.333        |
|    value_loss            | 1.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.174       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.174       |
| reward                   | -0.81538266 |
| rollout/                 |             |
|    ep_len_mean           | 289         |
|    ep_rew_mean           | -123        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1061        |
|    total_timesteps       | 2707456     |
| train/                   |             |
|    approx_kl             | 0.013441168 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.395       |
|    cost_value_loss       | 0.0289      |
|    cost_values           | 0.431       |
|    entropy               | -0.623      |
|    entropy_loss          | -0.627      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.752       |
|    n_updates             | 13210       |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.332       |
|    value_loss            | 1.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.16        |
| reward                   | -0.35126486 |
| rollout/                 |             |
|    ep_len_mean           | 298         |
|    ep_rew_mean           | -128        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1083        |
|    total_timesteps       | 2709504     |
| train/                   |             |
|    approx_kl             | 0.008764212 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00288     |
|    cost_value_loss       | 0.000978    |
|    cost_values           | 0.00901     |
|    entropy               | -0.619      |
|    entropy_loss          | -0.621      |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.92        |
|    n_updates             | 13220       |
|    policy_gradient_loss  | -0.00468    |
|    std                   | 0.331       |
|    value_loss            | 3.9         |
------------------------------------------
------------------------------------
| avg_speed          | 0.161       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.161       |
| reward             | -0.58138424 |
| rollout/           |             |
|    ep_len_mean     | 302         |
|    ep_rew_mean     | -130        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2711552     |
------------------------------------
------------------------------------------
| avg_speed                | 1.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.73        |
| reward                   | -0.2538013  |
| rollout/                 |             |
|    ep_len_mean           | 312         |
|    ep_rew_mean           | -136        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 2713600     |
| train/                   |             |
|    approx_kl             | 0.013573443 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0178     |
|    cost_value_loss       | 0.000811    |
|    cost_values           | -0.0185     |
|    entropy               | -0.617      |
|    entropy_loss          | -0.618      |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.22        |
|    n_updates             | 13240       |
|    policy_gradient_loss  | -0.0042     |
|    std                   | 0.331       |
|    value_loss            | 3.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.81        |
| reward                   | -0.17377776 |
| rollout/                 |             |
|    ep_len_mean           | 291         |
|    ep_rew_mean           | -123        |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 2715648     |
| train/                   |             |
|    approx_kl             | 0.008448034 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0164     |
|    cost_value_loss       | 0.00165     |
|    cost_values           | -0.0184     |
|    entropy               | -0.615      |
|    entropy_loss          | -0.615      |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.288       |
|    n_updates             | 13250       |
|    policy_gradient_loss  | -0.00582    |
|    std                   | 0.33        |
|    value_loss            | 0.871       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.02        |
| reward                   | -0.3177608  |
| rollout/                 |             |
|    ep_len_mean           | 286         |
|    ep_rew_mean           | -118        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 4           |
|    time_elapsed          | 87          |
|    total_timesteps       | 2717696     |
| train/                   |             |
|    approx_kl             | 0.008289125 |
|    clip_fraction         | 0.0929      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0371      |
|    cost_value_loss       | 0.000824    |
|    cost_values           | 0.0516      |
|    entropy               | -0.609      |
|    entropy_loss          | -0.613      |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.763       |
|    n_updates             | 13260       |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.329       |
|    value_loss            | 2.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.81230885 |
| rollout/                 |             |
|    ep_len_mean           | 287         |
|    ep_rew_mean           | -119        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 5           |
|    time_elapsed          | 109         |
|    total_timesteps       | 2719744     |
| train/                   |             |
|    approx_kl             | 0.008076586 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00255     |
|    cost_value_loss       | 0.000775    |
|    cost_values           | 0.0028      |
|    entropy               | -0.614      |
|    entropy_loss          | -0.609      |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.48        |
|    n_updates             | 13270       |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 0.33        |
|    value_loss            | 2.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.65        |
| reward                   | -0.43236396 |
| rollout/                 |             |
|    ep_len_mean           | 306         |
|    ep_rew_mean           | -129        |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 6           |
|    time_elapsed          | 131         |
|    total_timesteps       | 2721792     |
| train/                   |             |
|    approx_kl             | 0.010750559 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0201     |
|    cost_value_loss       | 0.00157     |
|    cost_values           | -0.0186     |
|    entropy               | -0.619      |
|    entropy_loss          | -0.617      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.56        |
|    n_updates             | 13280       |
|    policy_gradient_loss  | -0.00219    |
|    std                   | 0.331       |
|    value_loss            | 2.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.54        |
| reward                   | -0.15543671 |
| rollout/                 |             |
|    ep_len_mean           | 304         |
|    ep_rew_mean           | -128        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 2723840     |
| train/                   |             |
|    approx_kl             | 0.02118016  |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.26        |
|    cost_value_loss       | 0.0237      |
|    cost_values           | 0.294       |
|    entropy               | -0.621      |
|    entropy_loss          | -0.62       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.631       |
|    n_updates             | 13290       |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.331       |
|    value_loss            | 1.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.3030891  |
| rollout/                 |             |
|    ep_len_mean           | 316         |
|    ep_rew_mean           | -135        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 176         |
|    total_timesteps       | 2725888     |
| train/                   |             |
|    approx_kl             | 0.013238632 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0271     |
|    cost_value_loss       | 0.000861    |
|    cost_values           | -0.0288     |
|    entropy               | -0.622      |
|    entropy_loss          | -0.622      |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.31        |
|    n_updates             | 13300       |
|    policy_gradient_loss  | -0.0017     |
|    std                   | 0.331       |
|    value_loss            | 2.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.643       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.643       |
| reward                   | -0.36790505 |
| rollout/                 |             |
|    ep_len_mean           | 306         |
|    ep_rew_mean           | -128        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 198         |
|    total_timesteps       | 2727936     |
| train/                   |             |
|    approx_kl             | 0.009983163 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0137     |
|    cost_value_loss       | 0.00184     |
|    cost_values           | -0.0131     |
|    entropy               | -0.616      |
|    entropy_loss          | -0.62       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.862       |
|    n_updates             | 13310       |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.33        |
|    value_loss            | 2.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.58        |
| reward                   | -0.28445885 |
| rollout/                 |             |
|    ep_len_mean           | 308         |
|    ep_rew_mean           | -125        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 2729984     |
| train/                   |             |
|    approx_kl             | 0.015441461 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0183     |
|    cost_value_loss       | 0.00147     |
|    cost_values           | -0.0187     |
|    entropy               | -0.616      |
|    entropy_loss          | -0.615      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.575       |
|    n_updates             | 13320       |
|    policy_gradient_loss  | -0.00421    |
|    std                   | 0.33        |
|    value_loss            | 1.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.881       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.881       |
| reward                   | -0.34032032 |
| rollout/                 |             |
|    ep_len_mean           | 274         |
|    ep_rew_mean           | -103        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 2732032     |
| train/                   |             |
|    approx_kl             | 0.013796944 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.313       |
|    cost_value_loss       | 0.0276      |
|    cost_values           | 0.352       |
|    entropy               | -0.608      |
|    entropy_loss          | -0.613      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.568       |
|    n_updates             | 13330       |
|    policy_gradient_loss  | -0.00473    |
|    std                   | 0.329       |
|    value_loss            | 1.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.553       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.553       |
| reward                   | -0.17532866 |
| rollout/                 |             |
|    ep_len_mean           | 282         |
|    ep_rew_mean           | -108        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 2734080     |
| train/                   |             |
|    approx_kl             | 0.008957906 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0706     |
|    cost_value_loss       | 0.000651    |
|    cost_values           | -0.0776     |
|    entropy               | -0.598      |
|    entropy_loss          | -0.603      |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.643       |
|    n_updates             | 13340       |
|    policy_gradient_loss  | -0.00247    |
|    std                   | 0.327       |
|    value_loss            | 1.67        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.628        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.628        |
| reward                   | -0.22259271  |
| rollout/                 |              |
|    ep_len_mean           | 268          |
|    ep_rew_mean           | -99.7        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 287          |
|    total_timesteps       | 2736128      |
| train/                   |              |
|    approx_kl             | 0.0072875284 |
|    clip_fraction         | 0.085        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0379      |
|    cost_value_loss       | 0.000996     |
|    cost_values           | -0.0402      |
|    entropy               | -0.595       |
|    entropy_loss          | -0.596       |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.552        |
|    n_updates             | 13350        |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 0.327        |
|    value_loss            | 1.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.51         |
| reward                   | -0.31967103  |
| rollout/                 |              |
|    ep_len_mean           | 255          |
|    ep_rew_mean           | -92.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 14           |
|    time_elapsed          | 310          |
|    total_timesteps       | 2738176      |
| train/                   |              |
|    approx_kl             | 0.0067328154 |
|    clip_fraction         | 0.103        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0357      |
|    cost_value_loss       | 0.000453     |
|    cost_values           | -0.0404      |
|    entropy               | -0.592       |
|    entropy_loss          | -0.593       |
|    explained_variance    | 0.96         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.11         |
|    n_updates             | 13360        |
|    policy_gradient_loss  | -0.00118     |
|    std                   | 0.326        |
|    value_loss            | 2.69         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.01        |
| reward                   | -0.2177108  |
| rollout/                 |             |
|    ep_len_mean           | 257         |
|    ep_rew_mean           | -94.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 332         |
|    total_timesteps       | 2740224     |
| train/                   |             |
|    approx_kl             | 0.010005527 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0232     |
|    cost_value_loss       | 0.000348    |
|    cost_values           | -0.0261     |
|    entropy               | -0.596      |
|    entropy_loss          | -0.594      |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.48        |
|    n_updates             | 13370       |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.327       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.14        |
| reward                   | -0.41366252 |
| rollout/                 |             |
|    ep_len_mean           | 265         |
|    ep_rew_mean           | -98.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 355         |
|    total_timesteps       | 2742272     |
| train/                   |             |
|    approx_kl             | 0.01011056  |
|    clip_fraction         | 0.0838      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0281     |
|    cost_value_loss       | 0.000368    |
|    cost_values           | -0.0309     |
|    entropy               | -0.598      |
|    entropy_loss          | -0.597      |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.406       |
|    n_updates             | 13380       |
|    policy_gradient_loss  | -0.000756   |
|    std                   | 0.327       |
|    value_loss            | 1.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.62         |
| reward                   | -0.46060193  |
| rollout/                 |              |
|    ep_len_mean           | 279          |
|    ep_rew_mean           | -112         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 17           |
|    time_elapsed          | 377          |
|    total_timesteps       | 2744320      |
| train/                   |              |
|    approx_kl             | 0.0077990433 |
|    clip_fraction         | 0.13         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0113       |
|    cost_value_loss       | 0.0015       |
|    cost_values           | 0.0138       |
|    entropy               | -0.595       |
|    entropy_loss          | -0.597       |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.671        |
|    n_updates             | 13390        |
|    policy_gradient_loss  | 0.00278      |
|    std                   | 0.327        |
|    value_loss            | 2.62         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.36         |
| reward                   | -0.37475383  |
| rollout/                 |              |
|    ep_len_mean           | 262          |
|    ep_rew_mean           | -102         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 399          |
|    total_timesteps       | 2746368      |
| train/                   |              |
|    approx_kl             | 0.0075534573 |
|    clip_fraction         | 0.0777       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.38         |
|    cost_value_loss       | 55.1         |
|    cost_values           | 1.47         |
|    entropy               | -0.594       |
|    entropy_loss          | -0.593       |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0.00768      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.84         |
|    n_updates             | 13400        |
|    policy_gradient_loss  | -0.00692     |
|    std                   | 0.327        |
|    value_loss            | 21.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.49        |
| reward                   | -0.9459268  |
| rollout/                 |             |
|    ep_len_mean           | 255         |
|    ep_rew_mean           | -98.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 421         |
|    total_timesteps       | 2748416     |
| train/                   |             |
|    approx_kl             | 0.010779716 |
|    clip_fraction         | 0.0735      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.67        |
|    cost_value_loss       | 0.0331      |
|    cost_values           | 0.771       |
|    entropy               | -0.59       |
|    entropy_loss          | -0.593      |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.624       |
|    n_updates             | 13410       |
|    policy_gradient_loss  | -0.00319    |
|    std                   | 0.326       |
|    value_loss            | 2.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.413       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.413       |
| reward                   | -1.9124188  |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -103        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 444         |
|    total_timesteps       | 2750464     |
| train/                   |             |
|    approx_kl             | 0.012754999 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 0.0228      |
|    cost_values           | 1.04        |
|    entropy               | -0.585      |
|    entropy_loss          | -0.587      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.429       |
|    n_updates             | 13420       |
|    policy_gradient_loss  | -0.00218    |
|    std                   | 0.325       |
|    value_loss            | 1.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.977       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.977       |
| reward                   | -0.7532313  |
| rollout/                 |             |
|    ep_len_mean           | 258         |
|    ep_rew_mean           | -107        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 466         |
|    total_timesteps       | 2752512     |
| train/                   |             |
|    approx_kl             | 0.007002498 |
|    clip_fraction         | 0.0696      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.08        |
|    cost_value_loss       | 50          |
|    cost_values           | 1.49        |
|    entropy               | -0.583      |
|    entropy_loss          | -0.583      |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.00576     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 13430       |
|    policy_gradient_loss  | -0.00861    |
|    std                   | 0.325       |
|    value_loss            | 16.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.49        |
| reward                   | -0.25717932 |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -113        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 487         |
|    total_timesteps       | 2754560     |
| train/                   |             |
|    approx_kl             | 0.009672393 |
|    clip_fraction         | 0.0585      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 7.88        |
|    cost_values           | 0.612       |
|    entropy               | -0.583      |
|    entropy_loss          | -0.583      |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.00155     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.24        |
|    n_updates             | 13440       |
|    policy_gradient_loss  | -0.00646    |
|    std                   | 0.325       |
|    value_loss            | 9.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.51        |
| reward                   | -0.18475977 |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -108        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 510         |
|    total_timesteps       | 2756608     |
| train/                   |             |
|    approx_kl             | 0.009078747 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.386       |
|    cost_value_loss       | 0.0175      |
|    cost_values           | 0.474       |
|    entropy               | -0.579      |
|    entropy_loss          | -0.582      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.48        |
|    n_updates             | 13450       |
|    policy_gradient_loss  | -0.00443    |
|    std                   | 0.324       |
|    value_loss            | 3.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.29        |
| reward                   | -0.4365363  |
| rollout/                 |             |
|    ep_len_mean           | 278         |
|    ep_rew_mean           | -123        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 532         |
|    total_timesteps       | 2758656     |
| train/                   |             |
|    approx_kl             | 0.013018684 |
|    clip_fraction         | 0.0918      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.471       |
|    cost_value_loss       | 0.0149      |
|    cost_values           | 0.556       |
|    entropy               | -0.562      |
|    entropy_loss          | -0.573      |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.01        |
|    n_updates             | 13460       |
|    policy_gradient_loss  | -0.00338    |
|    std                   | 0.321       |
|    value_loss            | 2.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.94         |
| reward                   | -0.71974605  |
| rollout/                 |              |
|    ep_len_mean           | 287          |
|    ep_rew_mean           | -129         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 554          |
|    total_timesteps       | 2760704      |
| train/                   |              |
|    approx_kl             | 0.0052322163 |
|    clip_fraction         | 0.064        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.79         |
|    cost_value_loss       | 22.9         |
|    cost_values           | 1.95         |
|    entropy               | -0.552       |
|    entropy_loss          | -0.556       |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0.00337      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.56         |
|    n_updates             | 13470        |
|    policy_gradient_loss  | -0.00369     |
|    std                   | 0.32         |
|    value_loss            | 13           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.311       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.311       |
| reward                   | -0.4129706  |
| rollout/                 |             |
|    ep_len_mean           | 284         |
|    ep_rew_mean           | -129        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 26          |
|    time_elapsed          | 576         |
|    total_timesteps       | 2762752     |
| train/                   |             |
|    approx_kl             | 0.009924207 |
|    clip_fraction         | 0.0993      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 0.546       |
|    cost_values           | 0.947       |
|    entropy               | -0.546      |
|    entropy_loss          | -0.55       |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.933       |
|    n_updates             | 13480       |
|    policy_gradient_loss  | -0.00676    |
|    std                   | 0.319       |
|    value_loss            | 2.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.6          |
| reward                   | -0.403464    |
| rollout/                 |              |
|    ep_len_mean           | 296          |
|    ep_rew_mean           | -135         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 27           |
|    time_elapsed          | 598          |
|    total_timesteps       | 2764800      |
| train/                   |              |
|    approx_kl             | 0.0058063823 |
|    clip_fraction         | 0.103        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.31         |
|    cost_value_loss       | 0.0152       |
|    cost_values           | 0.415        |
|    entropy               | -0.546       |
|    entropy_loss          | -0.546       |
|    explained_variance    | 0.974        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.48         |
|    n_updates             | 13490        |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 0.319        |
|    value_loss            | 5.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.39        |
| reward                   | -0.25883234 |
| rollout/                 |             |
|    ep_len_mean           | 297         |
|    ep_rew_mean           | -134        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 620         |
|    total_timesteps       | 2766848     |
| train/                   |             |
|    approx_kl             | 0.009567745 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.155       |
|    cost_value_loss       | 0.00314     |
|    cost_values           | 0.164       |
|    entropy               | -0.534      |
|    entropy_loss          | -0.542      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.27        |
|    n_updates             | 13500       |
|    policy_gradient_loss  | -0.00247    |
|    std                   | 0.317       |
|    value_loss            | 1.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.51        |
| reward                   | -0.57470316 |
| rollout/                 |             |
|    ep_len_mean           | 304         |
|    ep_rew_mean           | -139        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 642         |
|    total_timesteps       | 2768896     |
| train/                   |             |
|    approx_kl             | 0.015096279 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.21        |
|    cost_value_loss       | 0.00317     |
|    cost_values           | 0.245       |
|    entropy               | -0.529      |
|    entropy_loss          | -0.531      |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.539       |
|    n_updates             | 13510       |
|    policy_gradient_loss  | 3.89e-05    |
|    std                   | 0.316       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.21        |
| reward                   | -0.15211271 |
| rollout/                 |             |
|    ep_len_mean           | 314         |
|    ep_rew_mean           | -143        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 664         |
|    total_timesteps       | 2770944     |
| train/                   |             |
|    approx_kl             | 0.01704751  |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.47        |
|    cost_value_loss       | 0.0416      |
|    cost_values           | 0.548       |
|    entropy               | -0.529      |
|    entropy_loss          | -0.529      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.732       |
|    n_updates             | 13520       |
|    policy_gradient_loss  | -0.00571    |
|    std                   | 0.316       |
|    value_loss            | 2.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.986       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.986       |
| reward                   | -0.23112288 |
| rollout/                 |             |
|    ep_len_mean           | 298         |
|    ep_rew_mean           | -134        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 687         |
|    total_timesteps       | 2772992     |
| train/                   |             |
|    approx_kl             | 0.009155399 |
|    clip_fraction         | 0.0949      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0678      |
|    cost_value_loss       | 0.00123     |
|    cost_values           | 0.0768      |
|    entropy               | -0.528      |
|    entropy_loss          | -0.529      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.952       |
|    n_updates             | 13530       |
|    policy_gradient_loss  | -0.00343    |
|    std                   | 0.316       |
|    value_loss            | 2.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.53        |
| reward                   | -0.4064638  |
| rollout/                 |             |
|    ep_len_mean           | 294         |
|    ep_rew_mean           | -130        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 709         |
|    total_timesteps       | 2775040     |
| train/                   |             |
|    approx_kl             | 0.007911763 |
|    clip_fraction         | 0.0805      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0263      |
|    cost_value_loss       | 0.00443     |
|    cost_values           | 0.0233      |
|    entropy               | -0.522      |
|    entropy_loss          | -0.526      |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.868       |
|    n_updates             | 13540       |
|    policy_gradient_loss  | -0.00338    |
|    std                   | 0.315       |
|    value_loss            | 2.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.532       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.532       |
| reward                   | -0.393949   |
| rollout/                 |             |
|    ep_len_mean           | 282         |
|    ep_rew_mean           | -123        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 731         |
|    total_timesteps       | 2777088     |
| train/                   |             |
|    approx_kl             | 0.011987362 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.09        |
|    cost_value_loss       | 14.5        |
|    cost_values           | 0.935       |
|    entropy               | -0.522      |
|    entropy_loss          | -0.52       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0.000836    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.71        |
|    n_updates             | 13550       |
|    policy_gradient_loss  | -0.00854    |
|    std                   | 0.315       |
|    value_loss            | 8.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.26        |
| reward                   | -0.40107864 |
| rollout/                 |             |
|    ep_len_mean           | 276         |
|    ep_rew_mean           | -114        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 754         |
|    total_timesteps       | 2779136     |
| train/                   |             |
|    approx_kl             | 0.00814123  |
|    clip_fraction         | 0.0756      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.137       |
|    cost_value_loss       | 0.00186     |
|    cost_values           | 0.135       |
|    entropy               | -0.522      |
|    entropy_loss          | -0.523      |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.466       |
|    n_updates             | 13560       |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.315       |
|    value_loss            | 1.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.427       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.427       |
| reward                   | -0.26884532 |
| rollout/                 |             |
|    ep_len_mean           | 260         |
|    ep_rew_mean           | -105        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 776         |
|    total_timesteps       | 2781184     |
| train/                   |             |
|    approx_kl             | 0.013159105 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.183       |
|    cost_value_loss       | 0.00246     |
|    cost_values           | 0.207       |
|    entropy               | -0.517      |
|    entropy_loss          | -0.52       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.499       |
|    n_updates             | 13570       |
|    policy_gradient_loss  | -0.00492    |
|    std                   | 0.314       |
|    value_loss            | 1.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.23        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.23        |
| reward                   | -0.26861346 |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -109        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 798         |
|    total_timesteps       | 2783232     |
| train/                   |             |
|    approx_kl             | 0.008128206 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0844      |
|    cost_value_loss       | 0.00182     |
|    cost_values           | 0.0978      |
|    entropy               | -0.509      |
|    entropy_loss          | -0.513      |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.608       |
|    n_updates             | 13580       |
|    policy_gradient_loss  | -0.00427    |
|    std                   | 0.313       |
|    value_loss            | 1.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.45        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.45        |
| reward                   | -0.35008413 |
| rollout/                 |             |
|    ep_len_mean           | 252         |
|    ep_rew_mean           | -93.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 820         |
|    total_timesteps       | 2785280     |
| train/                   |             |
|    approx_kl             | 0.015081213 |
|    clip_fraction         | 0.0939      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0258      |
|    cost_value_loss       | 0.00168     |
|    cost_values           | 0.0353      |
|    entropy               | -0.505      |
|    entropy_loss          | -0.506      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.448       |
|    n_updates             | 13590       |
|    policy_gradient_loss  | -5.35e-05   |
|    std                   | 0.313       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.48        |
| reward                   | -0.30124956 |
| rollout/                 |             |
|    ep_len_mean           | 253         |
|    ep_rew_mean           | -99.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 842         |
|    total_timesteps       | 2787328     |
| train/                   |             |
|    approx_kl             | 0.00853407  |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.44        |
|    cost_value_loss       | 0.0442      |
|    cost_values           | 0.506       |
|    entropy               | -0.496      |
|    entropy_loss          | -0.502      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.455       |
|    n_updates             | 13600       |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 0.311       |
|    value_loss            | 1.88        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.742        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.742        |
| reward                   | -0.256876    |
| rollout/                 |              |
|    ep_len_mean           | 246          |
|    ep_rew_mean           | -94.9        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 39           |
|    time_elapsed          | 865          |
|    total_timesteps       | 2789376      |
| train/                   |              |
|    approx_kl             | 0.0069571817 |
|    clip_fraction         | 0.0659       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.46         |
|    cost_value_loss       | 58           |
|    cost_values           | 1.1          |
|    entropy               | -0.496       |
|    entropy_loss          | -0.495       |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0.00734      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 13610        |
|    policy_gradient_loss  | -0.00673     |
|    std                   | 0.311        |
|    value_loss            | 36.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.849       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.849       |
| reward                   | -0.30590904 |
| rollout/                 |             |
|    ep_len_mean           | 243         |
|    ep_rew_mean           | -93.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 887         |
|    total_timesteps       | 2791424     |
| train/                   |             |
|    approx_kl             | 0.013351792 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.241       |
|    cost_value_loss       | 0.00841     |
|    cost_values           | 0.31        |
|    entropy               | -0.497      |
|    entropy_loss          | -0.497      |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.545       |
|    n_updates             | 13620       |
|    policy_gradient_loss  | -0.00418    |
|    std                   | 0.311       |
|    value_loss            | 1.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.76        |
| reward                   | -0.24773246 |
| rollout/                 |             |
|    ep_len_mean           | 234         |
|    ep_rew_mean           | -88.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 909         |
|    total_timesteps       | 2793472     |
| train/                   |             |
|    approx_kl             | 0.011045225 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.162       |
|    cost_value_loss       | 0.00218     |
|    cost_values           | 0.174       |
|    entropy               | -0.499      |
|    entropy_loss          | -0.498      |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.475       |
|    n_updates             | 13630       |
|    policy_gradient_loss  | -0.00333    |
|    std                   | 0.312       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.353       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.353       |
| reward                   | -0.3245599  |
| rollout/                 |             |
|    ep_len_mean           | 245         |
|    ep_rew_mean           | -94.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 931         |
|    total_timesteps       | 2795520     |
| train/                   |             |
|    approx_kl             | 0.020412235 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0118      |
|    cost_value_loss       | 0.00141     |
|    cost_values           | 0.0156      |
|    entropy               | -0.498      |
|    entropy_loss          | -0.499      |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.65        |
|    n_updates             | 13640       |
|    policy_gradient_loss  | 0.000585    |
|    std                   | 0.311       |
|    value_loss            | 2.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.596       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.596       |
| reward                   | -0.9233333  |
| rollout/                 |             |
|    ep_len_mean           | 248         |
|    ep_rew_mean           | -94.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 954         |
|    total_timesteps       | 2797568     |
| train/                   |             |
|    approx_kl             | 0.009707075 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.583       |
|    cost_value_loss       | 0.0527      |
|    cost_values           | 0.673       |
|    entropy               | -0.504      |
|    entropy_loss          | -0.499      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.481       |
|    n_updates             | 13650       |
|    policy_gradient_loss  | 0.00233     |
|    std                   | 0.313       |
|    value_loss            | 1.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.48        |
| reward                   | -0.3164933  |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -101        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 976         |
|    total_timesteps       | 2799616     |
| train/                   |             |
|    approx_kl             | 0.011055811 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.557       |
|    cost_value_loss       | 0.0153      |
|    cost_values           | 0.602       |
|    entropy               | -0.514      |
|    entropy_loss          | -0.51       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.634       |
|    n_updates             | 13660       |
|    policy_gradient_loss  | -0.00341    |
|    std                   | 0.314       |
|    value_loss            | 2.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.71         |
| reward                   | -0.3572282   |
| rollout/                 |              |
|    ep_len_mean           | 256          |
|    ep_rew_mean           | -94.7        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 998          |
|    total_timesteps       | 2801664      |
| train/                   |              |
|    approx_kl             | 0.0088778995 |
|    clip_fraction         | 0.108        |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0027      |
|    cost_value_loss       | 0.0294       |
|    cost_values           | 0.0081       |
|    entropy               | -0.517       |
|    entropy_loss          | -0.516       |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.339        |
|    n_updates             | 13670        |
|    policy_gradient_loss  | -0.000294    |
|    std                   | 0.315        |
|    value_loss            | 1.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.16        |
| reward                   | -0.67599124 |
| rollout/                 |             |
|    ep_len_mean           | 260         |
|    ep_rew_mean           | -95.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 46          |
|    time_elapsed          | 1020        |
|    total_timesteps       | 2803712     |
| train/                   |             |
|    approx_kl             | 0.010843983 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0393     |
|    cost_value_loss       | 0.000544    |
|    cost_values           | -0.0416     |
|    entropy               | -0.516      |
|    entropy_loss          | -0.516      |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.455       |
|    n_updates             | 13680       |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.314       |
|    value_loss            | 0.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.04         |
| reward                   | -0.6057681   |
| rollout/                 |              |
|    ep_len_mean           | 268          |
|    ep_rew_mean           | -101         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 47           |
|    time_elapsed          | 1042         |
|    total_timesteps       | 2805760      |
| train/                   |              |
|    approx_kl             | 0.0075899204 |
|    clip_fraction         | 0.0682       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.141        |
|    cost_value_loss       | 0.00334      |
|    cost_values           | 0.155        |
|    entropy               | -0.514       |
|    entropy_loss          | -0.515       |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.504        |
|    n_updates             | 13690        |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.314        |
|    value_loss            | 1.85         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.31        |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 1.31        |
| reward                   | -0.11016089 |
| rollout/                 |             |
|    ep_len_mean           | 278         |
|    ep_rew_mean           | -107        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1064        |
|    total_timesteps       | 2807808     |
| train/                   |             |
|    approx_kl             | 0.008961684 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.531       |
|    cost_value_loss       | 0.0458      |
|    cost_values           | 0.591       |
|    entropy               | -0.514      |
|    entropy_loss          | -0.514      |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.466       |
|    n_updates             | 13700       |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 0.314       |
|    value_loss            | 1.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.73        |
| reward                   | -0.2349897  |
| rollout/                 |             |
|    ep_len_mean           | 282         |
|    ep_rew_mean           | -108        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1086        |
|    total_timesteps       | 2809856     |
| train/                   |             |
|    approx_kl             | 0.009127682 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.264       |
|    cost_value_loss       | 0.0298      |
|    cost_values           | 0.3         |
|    entropy               | -0.516      |
|    entropy_loss          | -0.515      |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.342       |
|    n_updates             | 13710       |
|    policy_gradient_loss  | 0.000452    |
|    std                   | 0.315       |
|    value_loss            | 1.15        |
------------------------------------------
------------------------------------
| avg_speed          | 0.229       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.229       |
| reward             | -0.25741068 |
| rollout/           |             |
|    ep_len_mean     | 274         |
|    ep_rew_mean     | -109        |
| time/              |             |
|    fps             | 95          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2811904     |
------------------------------------
------------------------------------------
| avg_speed                | 2.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.12        |
| reward                   | -0.4595392  |
| rollout/                 |             |
|    ep_len_mean           | 259         |
|    ep_rew_mean           | -96.8       |
| time/                    |             |
|    fps                   | 94          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 2813952     |
| train/                   |             |
|    approx_kl             | 0.007122316 |
|    clip_fraction         | 0.0747      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.5         |
|    cost_value_loss       | 60.5        |
|    cost_values           | 1.04        |
|    entropy               | -0.51       |
|    entropy_loss          | -0.51       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00236     |
|    learning_rate         | 0.0003      |
|    loss                  | 23.5        |
|    n_updates             | 13730       |
|    policy_gradient_loss  | -0.00572    |
|    std                   | 0.313       |
|    value_loss            | 36.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.136       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.136       |
| reward                   | -0.2629273  |
| rollout/                 |             |
|    ep_len_mean           | 260         |
|    ep_rew_mean           | -97.3       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 3           |
|    time_elapsed          | 65          |
|    total_timesteps       | 2816000     |
| train/                   |             |
|    approx_kl             | 0.006105954 |
|    clip_fraction         | 0.0704      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.267       |
|    cost_value_loss       | 0.00795     |
|    cost_values           | 0.318       |
|    entropy               | -0.506      |
|    entropy_loss          | -0.508      |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.524       |
|    n_updates             | 13740       |
|    policy_gradient_loss  | -0.00377    |
|    std                   | 0.313       |
|    value_loss            | 1.51        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.17         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.17         |
| reward                   | -0.974004    |
| rollout/                 |              |
|    ep_len_mean           | 262          |
|    ep_rew_mean           | -98.5        |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 4            |
|    time_elapsed          | 88           |
|    total_timesteps       | 2818048      |
| train/                   |              |
|    approx_kl             | 0.0060482486 |
|    clip_fraction         | 0.103        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.23         |
|    cost_value_loss       | 0.0029       |
|    cost_values           | 0.25         |
|    entropy               | -0.503       |
|    entropy_loss          | -0.504       |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.422        |
|    n_updates             | 13750        |
|    policy_gradient_loss  | 0.000911     |
|    std                   | 0.312        |
|    value_loss            | 1.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.26        |
| reward                   | -0.31746307 |
| rollout/                 |             |
|    ep_len_mean           | 252         |
|    ep_rew_mean           | -96.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 2820096     |
| train/                   |             |
|    approx_kl             | 0.004458769 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.61        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 0.568       |
|    entropy               | -0.5        |
|    entropy_loss          | -0.501      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.000517    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.33        |
|    n_updates             | 13760       |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 0.312       |
|    value_loss            | 3.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.25         |
| reward                   | -0.46451926  |
| rollout/                 |              |
|    ep_len_mean           | 260          |
|    ep_rew_mean           | -101         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 6            |
|    time_elapsed          | 132          |
|    total_timesteps       | 2822144      |
| train/                   |              |
|    approx_kl             | 0.0059432676 |
|    clip_fraction         | 0.0527       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.67         |
|    cost_value_loss       | 26.8         |
|    cost_values           | 0.808        |
|    entropy               | -0.498       |
|    entropy_loss          | -0.499       |
|    explained_variance    | 0.994        |
|    lagrangian_multiplier | 0.00212      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.09         |
|    n_updates             | 13770        |
|    policy_gradient_loss  | -0.00721     |
|    std                   | 0.311        |
|    value_loss            | 5.74         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.57        |
| reward                   | -0.48557958 |
| rollout/                 |             |
|    ep_len_mean           | 250         |
|    ep_rew_mean           | -95.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 7           |
|    time_elapsed          | 154         |
|    total_timesteps       | 2824192     |
| train/                   |             |
|    approx_kl             | 0.007906199 |
|    clip_fraction         | 0.0626      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.205       |
|    cost_value_loss       | 0.00637     |
|    cost_values           | 0.256       |
|    entropy               | -0.498      |
|    entropy_loss          | -0.498      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.797       |
|    n_updates             | 13780       |
|    policy_gradient_loss  | -0.000943   |
|    std                   | 0.311       |
|    value_loss            | 2.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.4          |
| reward                   | -0.21723044  |
| rollout/                 |              |
|    ep_len_mean           | 256          |
|    ep_rew_mean           | -100         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 8            |
|    time_elapsed          | 176          |
|    total_timesteps       | 2826240      |
| train/                   |              |
|    approx_kl             | 0.0067831026 |
|    clip_fraction         | 0.0779       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.314        |
|    cost_value_loss       | 0.00544      |
|    cost_values           | 0.358        |
|    entropy               | -0.5         |
|    entropy_loss          | -0.498       |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.797        |
|    n_updates             | 13790        |
|    policy_gradient_loss  | -0.00405     |
|    std                   | 0.312        |
|    value_loss            | 2.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.704       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.704       |
| reward                   | -0.23873709 |
| rollout/                 |             |
|    ep_len_mean           | 250         |
|    ep_rew_mean           | -99.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 198         |
|    total_timesteps       | 2828288     |
| train/                   |             |
|    approx_kl             | 0.015459226 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.65        |
|    cost_value_loss       | 0.0463      |
|    cost_values           | 0.683       |
|    entropy               | -0.496      |
|    entropy_loss          | -0.499      |
|    explained_variance    | 0.999       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.219       |
|    n_updates             | 13800       |
|    policy_gradient_loss  | -0.00155    |
|    std                   | 0.311       |
|    value_loss            | 0.745       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.251       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.251       |
| reward                   | -0.19428733 |
| rollout/                 |             |
|    ep_len_mean           | 235         |
|    ep_rew_mean           | -88.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 2830336     |
| train/                   |             |
|    approx_kl             | 0.009232471 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0911      |
|    cost_value_loss       | 0.00152     |
|    cost_values           | 0.119       |
|    entropy               | -0.489      |
|    entropy_loss          | -0.493      |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.615       |
|    n_updates             | 13810       |
|    policy_gradient_loss  | -0.000911   |
|    std                   | 0.31        |
|    value_loss            | 1.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.6          |
| reward                   | -0.49916297  |
| rollout/                 |              |
|    ep_len_mean           | 238          |
|    ep_rew_mean           | -91.2        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 11           |
|    time_elapsed          | 243          |
|    total_timesteps       | 2832384      |
| train/                   |              |
|    approx_kl             | 0.0081105195 |
|    clip_fraction         | 0.101        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0881       |
|    cost_value_loss       | 0.000683     |
|    cost_values           | 0.0971       |
|    entropy               | -0.488       |
|    entropy_loss          | -0.488       |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.345        |
|    n_updates             | 13820        |
|    policy_gradient_loss  | -3.01e-05    |
|    std                   | 0.31         |
|    value_loss            | 0.791        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.711       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.711       |
| reward                   | -0.37282267 |
| rollout/                 |             |
|    ep_len_mean           | 232         |
|    ep_rew_mean           | -81.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 265         |
|    total_timesteps       | 2834432     |
| train/                   |             |
|    approx_kl             | 0.01852336  |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.376       |
|    cost_value_loss       | 0.0322      |
|    cost_values           | 0.432       |
|    entropy               | -0.485      |
|    entropy_loss          | -0.487      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.483       |
|    n_updates             | 13830       |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 0.309       |
|    value_loss            | 1.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.602        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.602        |
| reward                   | -0.29660207  |
| rollout/                 |              |
|    ep_len_mean           | 238          |
|    ep_rew_mean           | -85.2        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 13           |
|    time_elapsed          | 288          |
|    total_timesteps       | 2836480      |
| train/                   |              |
|    approx_kl             | 0.0054852907 |
|    clip_fraction         | 0.0627       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0116       |
|    cost_value_loss       | 0.000328     |
|    cost_values           | 0.0111       |
|    entropy               | -0.464       |
|    entropy_loss          | -0.477       |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.432        |
|    n_updates             | 13840        |
|    policy_gradient_loss  | -0.000949    |
|    std                   | 0.306        |
|    value_loss            | 1.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.81        |
| reward                   | -0.45764893 |
| rollout/                 |             |
|    ep_len_mean           | 250         |
|    ep_rew_mean           | -90.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 2838528     |
| train/                   |             |
|    approx_kl             | 0.01142689  |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0105     |
|    cost_value_loss       | 0.000609    |
|    cost_values           | -0.00603    |
|    entropy               | -0.46       |
|    entropy_loss          | -0.459      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.519       |
|    n_updates             | 13850       |
|    policy_gradient_loss  | -0.00784    |
|    std                   | 0.306       |
|    value_loss            | 1.59        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.42703155  |
| rollout/                 |              |
|    ep_len_mean           | 256          |
|    ep_rew_mean           | -97.5        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 15           |
|    time_elapsed          | 333          |
|    total_timesteps       | 2840576      |
| train/                   |              |
|    approx_kl             | 0.0045204647 |
|    clip_fraction         | 0.0885       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0259      |
|    cost_value_loss       | 0.000643     |
|    cost_values           | -0.0314      |
|    entropy               | -0.462       |
|    entropy_loss          | -0.461       |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.79         |
|    n_updates             | 13860        |
|    policy_gradient_loss  | -0.00387     |
|    std                   | 0.306        |
|    value_loss            | 2.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.33        |
| reward                   | -0.41659734 |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -105        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 355         |
|    total_timesteps       | 2842624     |
| train/                   |             |
|    approx_kl             | 0.006008173 |
|    clip_fraction         | 0.0569      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.09        |
|    cost_value_loss       | 71          |
|    cost_values           | 1.03        |
|    entropy               | -0.462      |
|    entropy_loss          | -0.462      |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00743     |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 13870       |
|    policy_gradient_loss  | -0.00254    |
|    std                   | 0.306       |
|    value_loss            | 16.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.433       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.433       |
| reward                   | -0.31645042 |
| rollout/                 |             |
|    ep_len_mean           | 276         |
|    ep_rew_mean           | -120        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 377         |
|    total_timesteps       | 2844672     |
| train/                   |             |
|    approx_kl             | 0.006840223 |
|    clip_fraction         | 0.0533      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.98        |
|    cost_value_loss       | 63.2        |
|    cost_values           | 1.43        |
|    entropy               | -0.463      |
|    entropy_loss          | -0.462      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0.00687     |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 13880       |
|    policy_gradient_loss  | -0.00631    |
|    std                   | 0.306       |
|    value_loss            | 12          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.926        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.926        |
| reward                   | -0.7644732   |
| rollout/                 |              |
|    ep_len_mean           | 268          |
|    ep_rew_mean           | -113         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 18           |
|    time_elapsed          | 399          |
|    total_timesteps       | 2846720      |
| train/                   |              |
|    approx_kl             | 0.0054367264 |
|    clip_fraction         | 0.0544       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.23         |
|    cost_value_loss       | 62.2         |
|    cost_values           | 2.42         |
|    entropy               | -0.462       |
|    entropy_loss          | -0.463       |
|    explained_variance    | 0.988        |
|    lagrangian_multiplier | 0.00661      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.97         |
|    n_updates             | 13890        |
|    policy_gradient_loss  | -0.00613     |
|    std                   | 0.306        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1            |
| reward                   | -0.4605558   |
| rollout/                 |              |
|    ep_len_mean           | 264          |
|    ep_rew_mean           | -112         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 19           |
|    time_elapsed          | 422          |
|    total_timesteps       | 2848768      |
| train/                   |              |
|    approx_kl             | 0.0046614436 |
|    clip_fraction         | 0.0471       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.606        |
|    cost_value_loss       | 0.0401       |
|    cost_values           | 0.758        |
|    entropy               | -0.459       |
|    entropy_loss          | -0.461       |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.23         |
|    n_updates             | 13900        |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.305        |
|    value_loss            | 3.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.908       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.908       |
| reward                   | -0.31985357 |
| rollout/                 |             |
|    ep_len_mean           | 257         |
|    ep_rew_mean           | -108        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 444         |
|    total_timesteps       | 2850816     |
| train/                   |             |
|    approx_kl             | 0.007005134 |
|    clip_fraction         | 0.0704      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.53        |
|    cost_value_loss       | 0.024       |
|    cost_values           | 0.618       |
|    entropy               | -0.452      |
|    entropy_loss          | -0.456      |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.491       |
|    n_updates             | 13910       |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.304       |
|    value_loss            | 1.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.97        |
| reward                   | -0.20663346 |
| rollout/                 |             |
|    ep_len_mean           | 260         |
|    ep_rew_mean           | -109        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 466         |
|    total_timesteps       | 2852864     |
| train/                   |             |
|    approx_kl             | 0.011239316 |
|    clip_fraction         | 0.0812      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.467       |
|    cost_value_loss       | 0.0125      |
|    cost_values           | 0.528       |
|    entropy               | -0.446      |
|    entropy_loss          | -0.449      |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.48        |
|    n_updates             | 13920       |
|    policy_gradient_loss  | -0.00466    |
|    std                   | 0.304       |
|    value_loss            | 1.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.59        |
| reward                   | -0.67222476 |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -109        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 488         |
|    total_timesteps       | 2854912     |
| train/                   |             |
|    approx_kl             | 0.010723628 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.371       |
|    cost_value_loss       | 0.00766     |
|    cost_values           | 0.425       |
|    entropy               | -0.438      |
|    entropy_loss          | -0.442      |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.703       |
|    n_updates             | 13930       |
|    policy_gradient_loss  | -0.00351    |
|    std                   | 0.302       |
|    value_loss            | 1.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.32        |
| reward                   | -0.5387988  |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -113        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 23          |
|    time_elapsed          | 510         |
|    total_timesteps       | 2856960     |
| train/                   |             |
|    approx_kl             | 0.012541426 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.491       |
|    cost_value_loss       | 0.0135      |
|    cost_values           | 0.558       |
|    entropy               | -0.434      |
|    entropy_loss          | -0.436      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.637       |
|    n_updates             | 13940       |
|    policy_gradient_loss  | -0.00442    |
|    std                   | 0.302       |
|    value_loss            | 2.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.839       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.839       |
| reward                   | -0.19588466 |
| rollout/                 |             |
|    ep_len_mean           | 269         |
|    ep_rew_mean           | -115        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 24          |
|    time_elapsed          | 532         |
|    total_timesteps       | 2859008     |
| train/                   |             |
|    approx_kl             | 0.007148212 |
|    clip_fraction         | 0.0646      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.367       |
|    cost_value_loss       | 0.0469      |
|    cost_values           | 0.414       |
|    entropy               | -0.432      |
|    entropy_loss          | -0.433      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.765       |
|    n_updates             | 13950       |
|    policy_gradient_loss  | -0.0053     |
|    std                   | 0.301       |
|    value_loss            | 2.72        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.34         |
| reward                   | -0.2144154   |
| rollout/                 |              |
|    ep_len_mean           | 262          |
|    ep_rew_mean           | -112         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 25           |
|    time_elapsed          | 554          |
|    total_timesteps       | 2861056      |
| train/                   |              |
|    approx_kl             | 0.0096275285 |
|    clip_fraction         | 0.0815       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.118        |
|    cost_value_loss       | 0.00236      |
|    cost_values           | 0.145        |
|    entropy               | -0.424       |
|    entropy_loss          | -0.43        |
|    explained_variance    | 0.996        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.458        |
|    n_updates             | 13960        |
|    policy_gradient_loss  | -0.000886    |
|    std                   | 0.3          |
|    value_loss            | 1.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.711        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.711        |
| reward                   | -0.24203771  |
| rollout/                 |              |
|    ep_len_mean           | 250          |
|    ep_rew_mean           | -105         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 576          |
|    total_timesteps       | 2863104      |
| train/                   |              |
|    approx_kl             | 0.0072643617 |
|    clip_fraction         | 0.0704       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0525       |
|    cost_value_loss       | 0.000805     |
|    cost_values           | 0.06         |
|    entropy               | -0.422       |
|    entropy_loss          | -0.422       |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.304        |
|    n_updates             | 13970        |
|    policy_gradient_loss  | 0.000255     |
|    std                   | 0.3          |
|    value_loss            | 0.824        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.56        |
| reward                   | -0.4117762  |
| rollout/                 |             |
|    ep_len_mean           | 248         |
|    ep_rew_mean           | -98.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 598         |
|    total_timesteps       | 2865152     |
| train/                   |             |
|    approx_kl             | 0.010321863 |
|    clip_fraction         | 0.0944      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00388     |
|    cost_value_loss       | 0.000611    |
|    cost_values           | 0.00503     |
|    entropy               | -0.419      |
|    entropy_loss          | -0.421      |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.639       |
|    n_updates             | 13980       |
|    policy_gradient_loss  | -0.000962   |
|    std                   | 0.299       |
|    value_loss            | 1.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.98         |
| reward                   | -0.39557266  |
| rollout/                 |              |
|    ep_len_mean           | 258          |
|    ep_rew_mean           | -103         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 28           |
|    time_elapsed          | 620          |
|    total_timesteps       | 2867200      |
| train/                   |              |
|    approx_kl             | 0.0067582885 |
|    clip_fraction         | 0.0735       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0486       |
|    cost_value_loss       | 0.00149      |
|    cost_values           | 0.0644       |
|    entropy               | -0.413       |
|    entropy_loss          | -0.416       |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.651        |
|    n_updates             | 13990        |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.299        |
|    value_loss            | 1.35         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.03        |
| reward                   | -0.33553448 |
| rollout/                 |             |
|    ep_len_mean           | 243         |
|    ep_rew_mean           | -86.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 642         |
|    total_timesteps       | 2869248     |
| train/                   |             |
|    approx_kl             | 0.015451817 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0509      |
|    cost_value_loss       | 0.13        |
|    cost_values           | 0.0122      |
|    entropy               | -0.418      |
|    entropy_loss          | -0.414      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.431       |
|    n_updates             | 14000       |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 0.3         |
|    value_loss            | 1.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.35         |
| reward                   | -0.40039417  |
| rollout/                 |              |
|    ep_len_mean           | 232          |
|    ep_rew_mean           | -81.4        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 30           |
|    time_elapsed          | 665          |
|    total_timesteps       | 2871296      |
| train/                   |              |
|    approx_kl             | 0.0083524175 |
|    clip_fraction         | 0.0954       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.58         |
|    cost_value_loss       | 18.5         |
|    cost_values           | 0.966        |
|    entropy               | -0.421       |
|    entropy_loss          | -0.42        |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0.00274      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.22         |
|    n_updates             | 14010        |
|    policy_gradient_loss  | -0.00526     |
|    std                   | 0.3          |
|    value_loss            | 2.8          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00174     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00174     |
| reward                   | -0.3221066  |
| rollout/                 |             |
|    ep_len_mean           | 245         |
|    ep_rew_mean           | -86.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 687         |
|    total_timesteps       | 2873344     |
| train/                   |             |
|    approx_kl             | 0.013894764 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.216       |
|    cost_value_loss       | 0.00413     |
|    cost_values           | 0.244       |
|    entropy               | -0.416      |
|    entropy_loss          | -0.419      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.257       |
|    n_updates             | 14020       |
|    policy_gradient_loss  | -0.00214    |
|    std                   | 0.299       |
|    value_loss            | 0.608       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.811       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.811       |
| reward                   | -0.4238785  |
| rollout/                 |             |
|    ep_len_mean           | 244         |
|    ep_rew_mean           | -85.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 32          |
|    time_elapsed          | 709         |
|    total_timesteps       | 2875392     |
| train/                   |             |
|    approx_kl             | 0.012220483 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0946      |
|    cost_value_loss       | 0.00142     |
|    cost_values           | 0.117       |
|    entropy               | -0.409      |
|    entropy_loss          | -0.413      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.361       |
|    n_updates             | 14030       |
|    policy_gradient_loss  | -0.00202    |
|    std                   | 0.298       |
|    value_loss            | 1.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.768       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.768       |
| reward                   | -0.23574787 |
| rollout/                 |             |
|    ep_len_mean           | 252         |
|    ep_rew_mean           | -88.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 731         |
|    total_timesteps       | 2877440     |
| train/                   |             |
|    approx_kl             | 0.007882794 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.104       |
|    cost_value_loss       | 0.00124     |
|    cost_values           | 0.114       |
|    entropy               | -0.421      |
|    entropy_loss          | -0.414      |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.405       |
|    n_updates             | 14040       |
|    policy_gradient_loss  | -0.00109    |
|    std                   | 0.3         |
|    value_loss            | 0.873       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.569       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.569       |
| reward                   | -0.437024   |
| rollout/                 |             |
|    ep_len_mean           | 253         |
|    ep_rew_mean           | -88.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 34          |
|    time_elapsed          | 753         |
|    total_timesteps       | 2879488     |
| train/                   |             |
|    approx_kl             | 0.010935292 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0694      |
|    cost_value_loss       | 0.000889    |
|    cost_values           | 0.0795      |
|    entropy               | -0.425      |
|    entropy_loss          | -0.424      |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.38        |
|    n_updates             | 14050       |
|    policy_gradient_loss  | -0.00328    |
|    std                   | 0.301       |
|    value_loss            | 0.934       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.31         |
| reward                   | -0.7372024   |
| rollout/                 |              |
|    ep_len_mean           | 248          |
|    ep_rew_mean           | -84.8        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 35           |
|    time_elapsed          | 775          |
|    total_timesteps       | 2881536      |
| train/                   |              |
|    approx_kl             | 0.0076029086 |
|    clip_fraction         | 0.122        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.0681       |
|    cost_value_loss       | 0.00113      |
|    cost_values           | 0.0772       |
|    entropy               | -0.418       |
|    entropy_loss          | -0.422       |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.31         |
|    n_updates             | 14060        |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 0.3          |
|    value_loss            | 0.705        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.113       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.113       |
| reward                   | -0.37153792 |
| rollout/                 |             |
|    ep_len_mean           | 252         |
|    ep_rew_mean           | -86.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 797         |
|    total_timesteps       | 2883584     |
| train/                   |             |
|    approx_kl             | 0.009113194 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.036       |
|    cost_value_loss       | 0.00157     |
|    cost_values           | 0.0458      |
|    entropy               | -0.404      |
|    entropy_loss          | -0.412      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.302       |
|    n_updates             | 14070       |
|    policy_gradient_loss  | -0.000534   |
|    std                   | 0.298       |
|    value_loss            | 0.907       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.32        |
| reward                   | -0.2018549  |
| rollout/                 |             |
|    ep_len_mean           | 259         |
|    ep_rew_mean           | -90.5       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 819         |
|    total_timesteps       | 2885632     |
| train/                   |             |
|    approx_kl             | 0.008121253 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.000631   |
|    cost_value_loss       | 0.00106     |
|    cost_values           | 0.00413     |
|    entropy               | -0.401      |
|    entropy_loss          | -0.401      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.08        |
|    n_updates             | 14080       |
|    policy_gradient_loss  | 0.000719    |
|    std                   | 0.297       |
|    value_loss            | 2.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.38        |
| reward                   | -0.3506026  |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -95.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 841         |
|    total_timesteps       | 2887680     |
| train/                   |             |
|    approx_kl             | 0.007991123 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0215     |
|    cost_value_loss       | 0.00101     |
|    cost_values           | -0.0203     |
|    entropy               | -0.398      |
|    entropy_loss          | -0.4        |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.43        |
|    n_updates             | 14090       |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.297       |
|    value_loss            | 1.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.62        |
| reward                   | -0.35164022 |
| rollout/                 |             |
|    ep_len_mean           | 273         |
|    ep_rew_mean           | -100        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 863         |
|    total_timesteps       | 2889728     |
| train/                   |             |
|    approx_kl             | 0.019786604 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.588       |
|    cost_value_loss       | 0.0576      |
|    cost_values           | 0.665       |
|    entropy               | -0.396      |
|    entropy_loss          | -0.396      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.623       |
|    n_updates             | 14100       |
|    policy_gradient_loss  | -0.00407    |
|    std                   | 0.296       |
|    value_loss            | 1.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0332      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0332      |
| reward                   | -0.29569405 |
| rollout/                 |             |
|    ep_len_mean           | 273         |
|    ep_rew_mean           | -101        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 886         |
|    total_timesteps       | 2891776     |
| train/                   |             |
|    approx_kl             | 0.012659293 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.533       |
|    cost_value_loss       | 0.0498      |
|    cost_values           | 0.605       |
|    entropy               | -0.392      |
|    entropy_loss          | -0.395      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.55        |
|    n_updates             | 14110       |
|    policy_gradient_loss  | -0.000838   |
|    std                   | 0.296       |
|    value_loss            | 3.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.19        |
| reward                   | -0.1839896  |
| rollout/                 |             |
|    ep_len_mean           | 266         |
|    ep_rew_mean           | -96.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 41          |
|    time_elapsed          | 908         |
|    total_timesteps       | 2893824     |
| train/                   |             |
|    approx_kl             | 0.010357181 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.059      |
|    cost_value_loss       | 0.00228     |
|    cost_values           | -0.0698     |
|    entropy               | -0.389      |
|    entropy_loss          | -0.39       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.583       |
|    n_updates             | 14120       |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.295       |
|    value_loss            | 2.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.34        |
| reward                   | -0.22179061 |
| rollout/                 |             |
|    ep_len_mean           | 266         |
|    ep_rew_mean           | -96         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 42          |
|    time_elapsed          | 930         |
|    total_timesteps       | 2895872     |
| train/                   |             |
|    approx_kl             | 0.013491111 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0703     |
|    cost_value_loss       | 0.00188     |
|    cost_values           | -0.0743     |
|    entropy               | -0.388      |
|    entropy_loss          | -0.389      |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.338       |
|    n_updates             | 14130       |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.295       |
|    value_loss            | 0.853       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.576       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.576       |
| reward                   | -0.4251359  |
| rollout/                 |             |
|    ep_len_mean           | 273         |
|    ep_rew_mean           | -98.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 952         |
|    total_timesteps       | 2897920     |
| train/                   |             |
|    approx_kl             | 0.009191664 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.474       |
|    cost_value_loss       | 0.0411      |
|    cost_values           | 0.532       |
|    entropy               | -0.386      |
|    entropy_loss          | -0.387      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.01        |
|    n_updates             | 14140       |
|    policy_gradient_loss  | -0.001      |
|    std                   | 0.295       |
|    value_loss            | 2.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.38        |
| reward                   | -0.36541745 |
| rollout/                 |             |
|    ep_len_mean           | 270         |
|    ep_rew_mean           | -97.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 974         |
|    total_timesteps       | 2899968     |
| train/                   |             |
|    approx_kl             | 0.010271948 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0802     |
|    cost_value_loss       | 0.00275     |
|    cost_values           | -0.0856     |
|    entropy               | -0.383      |
|    entropy_loss          | -0.385      |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.285       |
|    n_updates             | 14150       |
|    policy_gradient_loss  | -0.00382    |
|    std                   | 0.295       |
|    value_loss            | 0.748       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.51063734 |
| rollout/                 |             |
|    ep_len_mean           | 270         |
|    ep_rew_mean           | -98.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 45          |
|    time_elapsed          | 996         |
|    total_timesteps       | 2902016     |
| train/                   |             |
|    approx_kl             | 0.012400982 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.239       |
|    cost_value_loss       | 0.0266      |
|    cost_values           | 0.277       |
|    entropy               | -0.381      |
|    entropy_loss          | -0.382      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.383       |
|    n_updates             | 14160       |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.294       |
|    value_loss            | 1.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.549327    |
| rollout/                 |              |
|    ep_len_mean           | 261          |
|    ep_rew_mean           | -95.9        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1019         |
|    total_timesteps       | 2904064      |
| train/                   |              |
|    approx_kl             | 0.0076857926 |
|    clip_fraction         | 0.0795       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0854      |
|    cost_value_loss       | 0.00285      |
|    cost_values           | -0.0963      |
|    entropy               | -0.374       |
|    entropy_loss          | -0.378       |
|    explained_variance    | 0.985        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.382        |
|    n_updates             | 14170        |
|    policy_gradient_loss  | -0.00365     |
|    std                   | 0.293        |
|    value_loss            | 1.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0912      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0912      |
| reward                   | -0.21326394 |
| rollout/                 |             |
|    ep_len_mean           | 270         |
|    ep_rew_mean           | -101        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1041        |
|    total_timesteps       | 2906112     |
| train/                   |             |
|    approx_kl             | 0.012844198 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0928     |
|    cost_value_loss       | 0.00256     |
|    cost_values           | -0.0984     |
|    entropy               | -0.374      |
|    entropy_loss          | -0.373      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.361       |
|    n_updates             | 14180       |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 0.293       |
|    value_loss            | 0.857       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.55        |
| reward                   | -0.41022724 |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -97.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 2908160     |
| train/                   |             |
|    approx_kl             | 0.008726199 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.259       |
|    cost_value_loss       | 0.0241      |
|    cost_values           | 0.299       |
|    entropy               | -0.369      |
|    entropy_loss          | -0.373      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.526       |
|    n_updates             | 14190       |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.292       |
|    value_loss            | 1.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.14        |
| reward                   | -0.34311    |
| rollout/                 |             |
|    ep_len_mean           | 255         |
|    ep_rew_mean           | -94.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 49          |
|    time_elapsed          | 1084        |
|    total_timesteps       | 2910208     |
| train/                   |             |
|    approx_kl             | 0.007466265 |
|    clip_fraction         | 0.0989      |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0872     |
|    cost_value_loss       | 0.00258     |
|    cost_values           | -0.0992     |
|    entropy               | -0.351      |
|    entropy_loss          | -0.362      |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.253       |
|    n_updates             | 14200       |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.29        |
|    value_loss            | 0.92        |
------------------------------------------
------------------------------------
| avg_speed          | 0.245       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.245       |
| reward             | -0.24225737 |
| rollout/           |             |
|    ep_len_mean     | 237         |
|    ep_rew_mean     | -83.9       |
| time/              |             |
|    fps             | 94          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2912256     |
------------------------------------
------------------------------------------
| avg_speed                | 1.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.42        |
| reward                   | -0.18871163 |
| rollout/                 |             |
|    ep_len_mean           | 227         |
|    ep_rew_mean           | -77.3       |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 2914304     |
| train/                   |             |
|    approx_kl             | 0.012277215 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | -0.0706     |
|    cost_value_loss       | 0.00186     |
|    cost_values           | -0.0771     |
|    entropy               | -0.33       |
|    entropy_loss          | -0.334      |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.413       |
|    n_updates             | 14220       |
|    policy_gradient_loss  | -0.000622   |
|    std                   | 0.287       |
|    value_loss            | 1.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.35         |
| reward                   | -0.5602321   |
| rollout/                 |              |
|    ep_len_mean           | 219          |
|    ep_rew_mean           | -75          |
| time/                    |              |
|    fps                   | 93           |
|    iterations            | 3            |
|    time_elapsed          | 66           |
|    total_timesteps       | 2916352      |
| train/                   |              |
|    approx_kl             | 0.0071446626 |
|    clip_fraction         | 0.0853       |
|    clip_range            | 0.2          |
|    cost_returns          | -0.0503      |
|    cost_value_loss       | 0.00115      |
|    cost_values           | -0.0529      |
|    entropy               | -0.32        |
|    entropy_loss          | -0.326       |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.402        |
|    n_updates             | 14230        |
|    policy_gradient_loss  | -0.00259     |
|    std                   | 0.285        |
|    value_loss            | 1.04         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 2.63       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.63       |
| reward                   | -1.8522527 |
| rollout/                 |            |
|    ep_len_mean           | 218        |
|    ep_rew_mean           | -73.8      |
| time/                    |            |
|    fps                   | 92         |
|    iterations            | 4          |
|    time_elapsed          | 88         |
|    total_timesteps       | 2918400    |
| train/                   |            |
|    approx_kl             | 0.00865061 |
|    clip_fraction         | 0.105      |
|    clip_range            | 0.2        |
|    cost_returns          | -0.0178    |
|    cost_value_loss       | 0.00125    |
|    cost_values           | -0.0199    |
|    entropy               | -0.317     |
|    entropy_loss          | -0.317     |
|    explained_variance    | 0.987      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 0.589      |
|    n_updates             | 14240      |
|    policy_gradient_loss  | -0.00321   |
|    std                   | 0.285      |
|    value_loss            | 1.63       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.28        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.28        |
| reward                   | -0.34520262 |
| rollout/                 |             |
|    ep_len_mean           | 228         |
|    ep_rew_mean           | -83.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 5           |
|    time_elapsed          | 110         |
|    total_timesteps       | 2920448     |
| train/                   |             |
|    approx_kl             | 0.007653973 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 2.31        |
|    cost_value_loss       | 18.5        |
|    cost_values           | 0.827       |
|    entropy               | -0.317      |
|    entropy_loss          | -0.317      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.5        |
|    n_updates             | 14250       |
|    policy_gradient_loss  | -0.00448    |
|    std                   | 0.285       |
|    value_loss            | 6.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.33        |
| reward                   | -0.26931292 |
| rollout/                 |             |
|    ep_len_mean           | 221         |
|    ep_rew_mean           | -79         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 6           |
|    time_elapsed          | 132         |
|    total_timesteps       | 2922496     |
| train/                   |             |
|    approx_kl             | 0.012230165 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.476       |
|    cost_value_loss       | 3.16        |
|    cost_values           | 0.244       |
|    entropy               | -0.317      |
|    entropy_loss          | -0.317      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.36        |
|    n_updates             | 14260       |
|    policy_gradient_loss  | -0.00871    |
|    std                   | 0.285       |
|    value_loss            | 4.3         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.2          |
| reward                   | -0.49733713  |
| rollout/                 |              |
|    ep_len_mean           | 220          |
|    ep_rew_mean           | -77.8        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 7            |
|    time_elapsed          | 155          |
|    total_timesteps       | 2924544      |
| train/                   |              |
|    approx_kl             | 0.0083666025 |
|    clip_fraction         | 0.0973       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.164        |
|    cost_value_loss       | 0.00233      |
|    cost_values           | 0.187        |
|    entropy               | -0.309       |
|    entropy_loss          | -0.315       |
|    explained_variance    | 0.983        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.378        |
|    n_updates             | 14270        |
|    policy_gradient_loss  | -0.00406     |
|    std                   | 0.284        |
|    value_loss            | 0.917        |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.54        |
| reward                   | -1.8021103  |
| rollout/                 |             |
|    ep_len_mean           | 228         |
|    ep_rew_mean           | -82.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 8           |
|    time_elapsed          | 177         |
|    total_timesteps       | 2926592     |
| train/                   |             |
|    approx_kl             | 0.008073939 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.121       |
|    cost_value_loss       | 0.00157     |
|    cost_values           | 0.144       |
|    entropy               | -0.305      |
|    entropy_loss          | -0.306      |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.984       |
|    n_updates             | 14280       |
|    policy_gradient_loss  | -0.00401    |
|    std                   | 0.283       |
|    value_loss            | 2.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.89        |
| reward                   | -0.56971043 |
| rollout/                 |             |
|    ep_len_mean           | 222         |
|    ep_rew_mean           | -85         |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 9           |
|    time_elapsed          | 199         |
|    total_timesteps       | 2928640     |
| train/                   |             |
|    approx_kl             | 0.00834899  |
|    clip_fraction         | 0.097       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 30.4        |
|    cost_values           | 0.729       |
|    entropy               | -0.304      |
|    entropy_loss          | -0.304      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0.0055      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.25        |
|    n_updates             | 14290       |
|    policy_gradient_loss  | -0.00459    |
|    std                   | 0.283       |
|    value_loss            | 6.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.78        |
| reward                   | -0.16583295 |
| rollout/                 |             |
|    ep_len_mean           | 230         |
|    ep_rew_mean           | -91.7       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 10          |
|    time_elapsed          | 221         |
|    total_timesteps       | 2930688     |
| train/                   |             |
|    approx_kl             | 0.009240297 |
|    clip_fraction         | 0.0603      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.35        |
|    cost_value_loss       | 24.8        |
|    cost_values           | 0.767       |
|    entropy               | -0.304      |
|    entropy_loss          | -0.304      |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0.00348     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.8         |
|    n_updates             | 14300       |
|    policy_gradient_loss  | -0.0091     |
|    std                   | 0.283       |
|    value_loss            | 10.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.54        |
| reward                   | -0.3439208  |
| rollout/                 |             |
|    ep_len_mean           | 228         |
|    ep_rew_mean           | -90.6       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 11          |
|    time_elapsed          | 243         |
|    total_timesteps       | 2932736     |
| train/                   |             |
|    approx_kl             | 0.007993272 |
|    clip_fraction         | 0.0594      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.65        |
|    cost_value_loss       | 34.1        |
|    cost_values           | 1.02        |
|    entropy               | -0.305      |
|    entropy_loss          | -0.304      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0.00372     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.43        |
|    n_updates             | 14310       |
|    policy_gradient_loss  | -0.00615    |
|    std                   | 0.283       |
|    value_loss            | 4.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.48        |
| reward                   | -0.19156957 |
| rollout/                 |             |
|    ep_len_mean           | 229         |
|    ep_rew_mean           | -91.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 12          |
|    time_elapsed          | 266         |
|    total_timesteps       | 2934784     |
| train/                   |             |
|    approx_kl             | 0.008109007 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.326       |
|    cost_value_loss       | 0.0086      |
|    cost_values           | 0.377       |
|    entropy               | -0.292      |
|    entropy_loss          | -0.3        |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.328       |
|    n_updates             | 14320       |
|    policy_gradient_loss  | -0.0018     |
|    std                   | 0.281       |
|    value_loss            | 0.911       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.767       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.767       |
| reward                   | -0.27123052 |
| rollout/                 |             |
|    ep_len_mean           | 227         |
|    ep_rew_mean           | -91.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 13          |
|    time_elapsed          | 288         |
|    total_timesteps       | 2936832     |
| train/                   |             |
|    approx_kl             | 0.008395567 |
|    clip_fraction         | 0.0947      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.234       |
|    cost_value_loss       | 0.00354     |
|    cost_values           | 0.262       |
|    entropy               | -0.299      |
|    entropy_loss          | -0.293      |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.405       |
|    n_updates             | 14330       |
|    policy_gradient_loss  | -0.00163    |
|    std                   | 0.282       |
|    value_loss            | 0.868       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.61        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.61        |
| reward                   | -0.40653566 |
| rollout/                 |             |
|    ep_len_mean           | 232         |
|    ep_rew_mean           | -92.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 14          |
|    time_elapsed          | 310         |
|    total_timesteps       | 2938880     |
| train/                   |             |
|    approx_kl             | 0.016348973 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.171       |
|    cost_value_loss       | 0.00212     |
|    cost_values           | 0.188       |
|    entropy               | -0.303      |
|    entropy_loss          | -0.302      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.273       |
|    n_updates             | 14340       |
|    policy_gradient_loss  | -0.00186    |
|    std                   | 0.283       |
|    value_loss            | 0.629       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.81        |
| reward                   | -0.2573559  |
| rollout/                 |             |
|    ep_len_mean           | 216         |
|    ep_rew_mean           | -80.4       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 15          |
|    time_elapsed          | 332         |
|    total_timesteps       | 2940928     |
| train/                   |             |
|    approx_kl             | 0.005513002 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0721      |
|    cost_value_loss       | 0.00131     |
|    cost_values           | 0.0829      |
|    entropy               | -0.304      |
|    entropy_loss          | -0.304      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.288       |
|    n_updates             | 14350       |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.283       |
|    value_loss            | 0.637       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.45        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.45        |
| reward                   | -0.2527715  |
| rollout/                 |             |
|    ep_len_mean           | 211         |
|    ep_rew_mean           | -78.1       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 16          |
|    time_elapsed          | 354         |
|    total_timesteps       | 2942976     |
| train/                   |             |
|    approx_kl             | 0.006570111 |
|    clip_fraction         | 0.0974      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0665      |
|    cost_value_loss       | 0.00132     |
|    cost_values           | 0.0722      |
|    entropy               | -0.296      |
|    entropy_loss          | -0.301      |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.27        |
|    n_updates             | 14360       |
|    policy_gradient_loss  | -0.00435    |
|    std                   | 0.282       |
|    value_loss            | 0.596       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.76        |
| reward                   | -0.39159843 |
| rollout/                 |             |
|    ep_len_mean           | 210         |
|    ep_rew_mean           | -78.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 17          |
|    time_elapsed          | 376         |
|    total_timesteps       | 2945024     |
| train/                   |             |
|    approx_kl             | 0.012840893 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0838      |
|    cost_value_loss       | 0.0024      |
|    cost_values           | 0.0938      |
|    entropy               | -0.285      |
|    entropy_loss          | -0.29       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.229       |
|    n_updates             | 14370       |
|    policy_gradient_loss  | -0.0026     |
|    std                   | 0.28        |
|    value_loss            | 0.663       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.62        |
| reward                   | -0.26553765 |
| rollout/                 |             |
|    ep_len_mean           | 197         |
|    ep_rew_mean           | -67.3       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 18          |
|    time_elapsed          | 398         |
|    total_timesteps       | 2947072     |
| train/                   |             |
|    approx_kl             | 0.014693476 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0272      |
|    cost_value_loss       | 0.0015      |
|    cost_values           | 0.0353      |
|    entropy               | -0.287      |
|    entropy_loss          | -0.285      |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.508       |
|    n_updates             | 14380       |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 0.281       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.5         |
| reward                   | -0.41934383 |
| rollout/                 |             |
|    ep_len_mean           | 209         |
|    ep_rew_mean           | -78.9       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 19          |
|    time_elapsed          | 419         |
|    total_timesteps       | 2949120     |
| train/                   |             |
|    approx_kl             | 0.008301787 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.00758     |
|    cost_value_loss       | 0.00202     |
|    cost_values           | 0.0129      |
|    entropy               | -0.283      |
|    entropy_loss          | -0.286      |
|    explained_variance    | 0.997       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.374       |
|    n_updates             | 14390       |
|    policy_gradient_loss  | -0.00395    |
|    std                   | 0.28        |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.963       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.963       |
| reward                   | -0.38295028 |
| rollout/                 |             |
|    ep_len_mean           | 209         |
|    ep_rew_mean           | -76.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 20          |
|    time_elapsed          | 442         |
|    total_timesteps       | 2951168     |
| train/                   |             |
|    approx_kl             | 0.007127947 |
|    clip_fraction         | 0.086       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.56        |
|    cost_value_loss       | 61.9        |
|    cost_values           | 1.04        |
|    entropy               | -0.281      |
|    entropy_loss          | -0.281      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0.00747     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.7         |
|    n_updates             | 14400       |
|    policy_gradient_loss  | -0.00836    |
|    std                   | 0.28        |
|    value_loss            | 21.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.52        |
| reward                   | -0.30949897 |
| rollout/                 |             |
|    ep_len_mean           | 216         |
|    ep_rew_mean           | -80.8       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 21          |
|    time_elapsed          | 463         |
|    total_timesteps       | 2953216     |
| train/                   |             |
|    approx_kl             | 0.009892883 |
|    clip_fraction         | 0.0932      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.134       |
|    cost_value_loss       | 0.00624     |
|    cost_values           | 0.187       |
|    entropy               | -0.288      |
|    entropy_loss          | -0.284      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.48        |
|    n_updates             | 14410       |
|    policy_gradient_loss  | -0.00301    |
|    std                   | 0.281       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.72        |
| reward                   | -0.24083197 |
| rollout/                 |             |
|    ep_len_mean           | 225         |
|    ep_rew_mean           | -91.2       |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 22          |
|    time_elapsed          | 486         |
|    total_timesteps       | 2955264     |
| train/                   |             |
|    approx_kl             | 0.007862734 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0775      |
|    cost_value_loss       | 0.00206     |
|    cost_values           | 0.0898      |
|    entropy               | -0.293      |
|    entropy_loss          | -0.291      |
|    explained_variance    | 0.995       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.561       |
|    n_updates             | 14420       |
|    policy_gradient_loss  | -0.00443    |
|    std                   | 0.282       |
|    value_loss            | 1.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.51         |
| reward                   | -0.25685254  |
| rollout/                 |              |
|    ep_len_mean           | 224          |
|    ep_rew_mean           | -90.9        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 23           |
|    time_elapsed          | 508          |
|    total_timesteps       | 2957312      |
| train/                   |              |
|    approx_kl             | 0.0065742712 |
|    clip_fraction         | 0.064        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.4          |
|    cost_value_loss       | 70.2         |
|    cost_values           | 1.2          |
|    entropy               | -0.293       |
|    entropy_loss          | -0.293       |
|    explained_variance    | 0.99         |
|    lagrangian_multiplier | 0.00648      |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 14430        |
|    policy_gradient_loss  | -0.00649     |
|    std                   | 0.282        |
|    value_loss            | 20.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.39         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.39         |
| reward                   | -1.5289412   |
| rollout/                 |              |
|    ep_len_mean           | 232          |
|    ep_rew_mean           | -98.7        |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 24           |
|    time_elapsed          | 530          |
|    total_timesteps       | 2959360      |
| train/                   |              |
|    approx_kl             | 0.0101174945 |
|    clip_fraction         | 0.0808       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.23         |
|    cost_value_loss       | 0.0139       |
|    cost_values           | 0.33         |
|    entropy               | -0.291       |
|    entropy_loss          | -0.292       |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.679        |
|    n_updates             | 14440        |
|    policy_gradient_loss  | -0.00398     |
|    std                   | 0.281        |
|    value_loss            | 1.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.822       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.822       |
| reward                   | -0.20425665 |
| rollout/                 |             |
|    ep_len_mean           | 239         |
|    ep_rew_mean           | -105        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 25          |
|    time_elapsed          | 552         |
|    total_timesteps       | 2961408     |
| train/                   |             |
|    approx_kl             | 0.006406317 |
|    clip_fraction         | 0.081       |
|    clip_range            | 0.2         |
|    cost_returns          | 9.39        |
|    cost_value_loss       | 97.5        |
|    cost_values           | 2.01        |
|    entropy               | -0.289      |
|    entropy_loss          | -0.29       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.017       |
|    learning_rate         | 0.0003      |
|    loss                  | 8.06        |
|    n_updates             | 14450       |
|    policy_gradient_loss  | -0.00142    |
|    std                   | 0.281       |
|    value_loss            | 7.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.59         |
| reward                   | -0.16266763  |
| rollout/                 |              |
|    ep_len_mean           | 234          |
|    ep_rew_mean           | -103         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 26           |
|    time_elapsed          | 575          |
|    total_timesteps       | 2963456      |
| train/                   |              |
|    approx_kl             | 0.0046301186 |
|    clip_fraction         | 0.0587       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.626        |
|    cost_value_loss       | 2.51         |
|    cost_values           | 0.386        |
|    entropy               | -0.297       |
|    entropy_loss          | -0.292       |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.19         |
|    n_updates             | 14460        |
|    policy_gradient_loss  | -0.00584     |
|    std                   | 0.282        |
|    value_loss            | 3.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.41        |
| reward                   | -0.7358233  |
| rollout/                 |             |
|    ep_len_mean           | 233         |
|    ep_rew_mean           | -103        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 27          |
|    time_elapsed          | 597         |
|    total_timesteps       | 2965504     |
| train/                   |             |
|    approx_kl             | 0.012485413 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.206       |
|    cost_value_loss       | 0.00648     |
|    cost_values           | 0.265       |
|    entropy               | -0.294      |
|    entropy_loss          | -0.298      |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.932       |
|    n_updates             | 14470       |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 0.282       |
|    value_loss            | 2.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.84        |
| reward                   | -0.25337332 |
| rollout/                 |             |
|    ep_len_mean           | 238         |
|    ep_rew_mean           | -107        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 28          |
|    time_elapsed          | 619         |
|    total_timesteps       | 2967552     |
| train/                   |             |
|    approx_kl             | 0.006734265 |
|    clip_fraction         | 0.0624      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.481       |
|    cost_value_loss       | 0.0172      |
|    cost_values           | 0.547       |
|    entropy               | -0.293      |
|    entropy_loss          | -0.293      |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.942       |
|    n_updates             | 14480       |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.281       |
|    value_loss            | 3.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.61        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.61        |
| reward                   | -0.47518152 |
| rollout/                 |             |
|    ep_len_mean           | 232         |
|    ep_rew_mean           | -103        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 29          |
|    time_elapsed          | 642         |
|    total_timesteps       | 2969600     |
| train/                   |             |
|    approx_kl             | 0.01154165  |
|    clip_fraction         | 0.0898      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.588       |
|    cost_value_loss       | 0.247       |
|    cost_values           | 0.604       |
|    entropy               | -0.296      |
|    entropy_loss          | -0.294      |
|    explained_variance    | 0.998       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.541       |
|    n_updates             | 14490       |
|    policy_gradient_loss  | -0.00084    |
|    std                   | 0.282       |
|    value_loss            | 1.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.18        |
| reward                   | -0.8217185  |
| rollout/                 |             |
|    ep_len_mean           | 243         |
|    ep_rew_mean           | -114        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 30          |
|    time_elapsed          | 664         |
|    total_timesteps       | 2971648     |
| train/                   |             |
|    approx_kl             | 0.008484406 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.583       |
|    cost_value_loss       | 2.94        |
|    cost_values           | 0.289       |
|    entropy               | -0.299      |
|    entropy_loss          | -0.297      |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3           |
|    n_updates             | 14500       |
|    policy_gradient_loss  | 0.00168     |
|    std                   | 0.282       |
|    value_loss            | 4.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.253       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.253       |
| reward                   | -0.3935094  |
| rollout/                 |             |
|    ep_len_mean           | 247         |
|    ep_rew_mean           | -116        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 31          |
|    time_elapsed          | 686         |
|    total_timesteps       | 2973696     |
| train/                   |             |
|    approx_kl             | 0.007588669 |
|    clip_fraction         | 0.0509      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.19        |
|    cost_value_loss       | 68.2        |
|    cost_values           | 1.3         |
|    entropy               | -0.299      |
|    entropy_loss          | -0.299      |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0.00325     |
|    learning_rate         | 0.0003      |
|    loss                  | 17.8        |
|    n_updates             | 14510       |
|    policy_gradient_loss  | -0.00475    |
|    std                   | 0.282       |
|    value_loss            | 21.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.05         |
| reward                   | -0.44371194  |
| rollout/                 |              |
|    ep_len_mean           | 240          |
|    ep_rew_mean           | -112         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 32           |
|    time_elapsed          | 708          |
|    total_timesteps       | 2975744      |
| train/                   |              |
|    approx_kl             | 0.0038271295 |
|    clip_fraction         | 0.00669      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.65         |
|    cost_value_loss       | 72.3         |
|    cost_values           | 0.771        |
|    entropy               | -0.299       |
|    entropy_loss          | -0.299       |
|    explained_variance    | 0.881        |
|    lagrangian_multiplier | 0.0238       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.93         |
|    n_updates             | 14520        |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 0.282        |
|    value_loss            | 43.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.935       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.935       |
| reward                   | -0.38055924 |
| rollout/                 |             |
|    ep_len_mean           | 238         |
|    ep_rew_mean           | -118        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 33          |
|    time_elapsed          | 730         |
|    total_timesteps       | 2977792     |
| train/                   |             |
|    approx_kl             | 0.009807283 |
|    clip_fraction         | 0.0811      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.265       |
|    cost_value_loss       | 0.0114      |
|    cost_values           | 0.313       |
|    entropy               | -0.296      |
|    entropy_loss          | -0.298      |
|    explained_variance    | 0.857       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.13        |
|    n_updates             | 14530       |
|    policy_gradient_loss  | -0.00626    |
|    std                   | 0.282       |
|    value_loss            | 7.32        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0996       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0996       |
| reward                   | -0.2849604   |
| rollout/                 |              |
|    ep_len_mean           | 247          |
|    ep_rew_mean           | -120         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 34           |
|    time_elapsed          | 752          |
|    total_timesteps       | 2979840      |
| train/                   |              |
|    approx_kl             | 0.0021523198 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.93         |
|    cost_value_loss       | 54.9         |
|    cost_values           | -0.0596      |
|    entropy               | -0.295       |
|    entropy_loss          | -0.295       |
|    explained_variance    | 0.725        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 51.4         |
|    n_updates             | 14540        |
|    policy_gradient_loss  | 0.000762     |
|    std                   | 0.282        |
|    value_loss            | 247          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.877       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.877       |
| reward                   | -0.8981101  |
| rollout/                 |             |
|    ep_len_mean           | 249         |
|    ep_rew_mean           | -122        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 35          |
|    time_elapsed          | 774         |
|    total_timesteps       | 2981888     |
| train/                   |             |
|    approx_kl             | 0.013298618 |
|    clip_fraction         | 0.0645      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 43.6        |
|    cost_values           | 1.22        |
|    entropy               | -0.294      |
|    entropy_loss          | -0.294      |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0.00215     |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 14550       |
|    policy_gradient_loss  | -0.00655    |
|    std                   | 0.281       |
|    value_loss            | 4.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.30944225 |
| rollout/                 |             |
|    ep_len_mean           | 267         |
|    ep_rew_mean           | -132        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 36          |
|    time_elapsed          | 797         |
|    total_timesteps       | 2983936     |
| train/                   |             |
|    approx_kl             | 0.008680034 |
|    clip_fraction         | 0.0919      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.846       |
|    cost_value_loss       | 0.0261      |
|    cost_values           | 0.927       |
|    entropy               | -0.29       |
|    entropy_loss          | -0.292      |
|    explained_variance    | 0.994       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.663       |
|    n_updates             | 14560       |
|    policy_gradient_loss  | -0.00396    |
|    std                   | 0.281       |
|    value_loss            | 2.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.88880724 |
| rollout/                 |             |
|    ep_len_mean           | 258         |
|    ep_rew_mean           | -125        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 37          |
|    time_elapsed          | 819         |
|    total_timesteps       | 2985984     |
| train/                   |             |
|    approx_kl             | 0.008386913 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.469       |
|    cost_value_loss       | 0.357       |
|    cost_values           | 0.431       |
|    entropy               | -0.292      |
|    entropy_loss          | -0.291      |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.26        |
|    n_updates             | 14570       |
|    policy_gradient_loss  | -0.00336    |
|    std                   | 0.281       |
|    value_loss            | 3.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.94        |
| reward                   | -1.2965196  |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -134        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 38          |
|    time_elapsed          | 841         |
|    total_timesteps       | 2988032     |
| train/                   |             |
|    approx_kl             | 0.012899491 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 10.9        |
|    cost_value_loss       | 125         |
|    cost_values           | 1.81        |
|    entropy               | -0.294      |
|    entropy_loss          | -0.293      |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 66.2        |
|    n_updates             | 14580       |
|    policy_gradient_loss  | 0.00717     |
|    std                   | 0.282       |
|    value_loss            | 27.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.15        |
| reward                   | -0.37529474 |
| rollout/                 |             |
|    ep_len_mean           | 272         |
|    ep_rew_mean           | -146        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 39          |
|    time_elapsed          | 863         |
|    total_timesteps       | 2990080     |
| train/                   |             |
|    approx_kl             | 0.006734869 |
|    clip_fraction         | 0.0452      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 28.7        |
|    cost_values           | 0.913       |
|    entropy               | -0.291      |
|    entropy_loss          | -0.293      |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19          |
|    n_updates             | 14590       |
|    policy_gradient_loss  | -0.0052     |
|    std                   | 0.281       |
|    value_loss            | 9.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.935       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.935       |
| reward                   | -0.2910346  |
| rollout/                 |             |
|    ep_len_mean           | 282         |
|    ep_rew_mean           | -153        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 40          |
|    time_elapsed          | 885         |
|    total_timesteps       | 2992128     |
| train/                   |             |
|    approx_kl             | 0.004314952 |
|    clip_fraction         | 0.037       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.52        |
|    cost_value_loss       | 44.5        |
|    cost_values           | 0.484       |
|    entropy               | -0.289      |
|    entropy_loss          | -0.289      |
|    explained_variance    | 0.187       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.8        |
|    n_updates             | 14600       |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.281       |
|    value_loss            | 127         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0087       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0087       |
| reward                   | -0.32298028  |
| rollout/                 |              |
|    ep_len_mean           | 281          |
|    ep_rew_mean           | -155         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 41           |
|    time_elapsed          | 907          |
|    total_timesteps       | 2994176      |
| train/                   |              |
|    approx_kl             | 0.0038805467 |
|    clip_fraction         | 0.0565       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 0.177        |
|    cost_values           | 1.43         |
|    entropy               | -0.287       |
|    entropy_loss          | -0.288       |
|    explained_variance    | 0.995        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.19         |
|    n_updates             | 14610        |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 0.281        |
|    value_loss            | 3.58         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.47         |
| reward                   | -0.41325635  |
| rollout/                 |              |
|    ep_len_mean           | 283          |
|    ep_rew_mean           | -165         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 42           |
|    time_elapsed          | 930          |
|    total_timesteps       | 2996224      |
| train/                   |              |
|    approx_kl             | 0.0049659763 |
|    clip_fraction         | 0.0719       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.72         |
|    cost_value_loss       | 75.1         |
|    cost_values           | 1.48         |
|    entropy               | -0.285       |
|    entropy_loss          | -0.286       |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45           |
|    n_updates             | 14620        |
|    policy_gradient_loss  | -0.003       |
|    std                   | 0.28         |
|    value_loss            | 13.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0183      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0183      |
| reward                   | -0.61006457 |
| rollout/                 |             |
|    ep_len_mean           | 284         |
|    ep_rew_mean           | -166        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 43          |
|    time_elapsed          | 952         |
|    total_timesteps       | 2998272     |
| train/                   |             |
|    approx_kl             | 0.004631116 |
|    clip_fraction         | 0.0157      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 57.1        |
|    cost_values           | 0.91        |
|    entropy               | -0.285      |
|    entropy_loss          | -0.285      |
|    explained_variance    | 0.338       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.1        |
|    n_updates             | 14630       |
|    policy_gradient_loss  | -0.00501    |
|    std                   | 0.28        |
|    value_loss            | 85.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.47        |
| reward                   | -0.25217852 |
| rollout/                 |             |
|    ep_len_mean           | 291         |
|    ep_rew_mean           | -169        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 44          |
|    time_elapsed          | 974         |
|    total_timesteps       | 3000320     |
| train/                   |             |
|    approx_kl             | 0.007767372 |
|    clip_fraction         | 0.0602      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.88        |
|    cost_value_loss       | 0.069       |
|    cost_values           | 1.09        |
|    entropy               | -0.284      |
|    entropy_loss          | -0.285      |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.86        |
|    n_updates             | 14640       |
|    policy_gradient_loss  | -0.00343    |
|    std                   | 0.28        |
|    value_loss            | 4           |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.433        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.433        |
| reward                   | -0.40503848  |
| rollout/                 |              |
|    ep_len_mean           | 287          |
|    ep_rew_mean           | -166         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 45           |
|    time_elapsed          | 996          |
|    total_timesteps       | 3002368      |
| train/                   |              |
|    approx_kl             | 0.0053295903 |
|    clip_fraction         | 0.0741       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.96         |
|    cost_value_loss       | 79.2         |
|    cost_values           | 1.47         |
|    entropy               | -0.282       |
|    entropy_loss          | -0.283       |
|    explained_variance    | 0.929        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 45.4         |
|    n_updates             | 14650        |
|    policy_gradient_loss  | -0.00345     |
|    std                   | 0.28         |
|    value_loss            | 27.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.4          |
| reward                   | -0.37516728  |
| rollout/                 |              |
|    ep_len_mean           | 297          |
|    ep_rew_mean           | -176         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 46           |
|    time_elapsed          | 1018         |
|    total_timesteps       | 3004416      |
| train/                   |              |
|    approx_kl             | 0.0066547636 |
|    clip_fraction         | 0.0464       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.17         |
|    cost_value_loss       | 77.3         |
|    cost_values           | 1.88         |
|    entropy               | -0.282       |
|    entropy_loss          | -0.282       |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.6         |
|    n_updates             | 14660        |
|    policy_gradient_loss  | -0.00603     |
|    std                   | 0.28         |
|    value_loss            | 10.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.21        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.21        |
| reward                   | -0.7191644  |
| rollout/                 |             |
|    ep_len_mean           | 303         |
|    ep_rew_mean           | -185        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 47          |
|    time_elapsed          | 1040        |
|    total_timesteps       | 3006464     |
| train/                   |             |
|    approx_kl             | 0.005065614 |
|    clip_fraction         | 0.0427      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.59        |
|    cost_value_loss       | 64.2        |
|    cost_values           | 2.18        |
|    entropy               | -0.283      |
|    entropy_loss          | -0.283      |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.0012      |
|    learning_rate         | 0.0003      |
|    loss                  | 21.8        |
|    n_updates             | 14670       |
|    policy_gradient_loss  | -0.00461    |
|    std                   | 0.28        |
|    value_loss            | 12.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.316       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.316       |
| reward                   | -0.36455056 |
| rollout/                 |             |
|    ep_len_mean           | 285         |
|    ep_rew_mean           | -169        |
| time/                    |             |
|    fps                   | 92          |
|    iterations            | 48          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 3008512     |
| train/                   |             |
|    approx_kl             | 0.006983785 |
|    clip_fraction         | 0.0403      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.78        |
|    cost_value_loss       | 81.1        |
|    cost_values           | 2.73        |
|    entropy               | -0.284      |
|    entropy_loss          | -0.284      |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.00807     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 14680       |
|    policy_gradient_loss  | -0.0048     |
|    std                   | 0.28        |
|    value_loss            | 24.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.03         |
| reward                   | -0.76912713  |
| rollout/                 |              |
|    ep_len_mean           | 273          |
|    ep_rew_mean           | -162         |
| time/                    |              |
|    fps                   | 92           |
|    iterations            | 49           |
|    time_elapsed          | 1085         |
|    total_timesteps       | 3010560      |
| train/                   |              |
|    approx_kl             | 0.0046375417 |
|    clip_fraction         | 0.0473       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.85         |
|    cost_value_loss       | 43.5         |
|    cost_values           | 2.06         |
|    entropy               | -0.282       |
|    entropy_loss          | -0.284       |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0.00483      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 14690        |
|    policy_gradient_loss  | -0.00329     |
|    std                   | 0.28         |
|    value_loss            | 10.4         |
-------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.37651047110557556
Final reward: -0.37516728043556213
Final reward: -0.37252670526504517
Final reward: -0.3698276877403259
Final reward: -0.3660314381122589
Final reward: -0.3609960377216339
Final reward: -0.3679567873477936
Final reward: -0.3523809015750885
Final reward: -0.3598529100418091
Final reward: -0.34183621406555176
Final reward: -0.3498102128505707
Final reward: -0.3304970860481262
Final reward: -0.3388168215751648
Final reward: -0.3282565176486969
Final reward: -0.34742867946624756
Final reward: -0.34219875931739807
Final reward: -0.35679730772972107
Final reward: -0.35190752148628235
Final reward: -0.3541989326477051
Final reward: -0.3557644486427307
Final reward: -0.35618576407432556
Final reward: -0.35624346137046814
Final reward: -0.35622233152389526
Final reward: -0.35603880882263184
Final reward: -0.3552972078323364
Final reward: -0.35954907536506653
Final reward: -0.3565811514854431
Final reward: -0.3417671322822571
Final reward: -0.3484306335449219
Final reward: -0.32841870188713074
Final reward: -0.3362788259983063
Final reward: -0.32449281215667725
Final reward: -0.3463555574417114
Final reward: -0.3352682292461395
Final reward: -0.35429397225379944
Final reward: -0.3449113070964813
Final reward: -0.36071932315826416
Final reward: -0.3525157570838928
Final reward: -0.3640565574169159
Final reward: -0.3590708076953888
Final reward: -0.3660808801651001
Final reward: -0.3699275255203247
Final reward: -0.370753675699234
Final reward: -0.3694112300872803
Final reward: -0.36540746688842773
Final reward: -0.35828784108161926
Final reward: -0.35390228033065796
Final reward: -0.35342031717300415
Final reward: -0.3448566198348999
Final reward: -0.34477028250694275
Final reward: -0.33203741908073425
Final reward: -0.33188149333000183
Final reward: -0.3163926303386688
Final reward: -0.31556832790374756
Final reward: -0.30473536252975464
Final reward: -0.31624335050582886
Final reward: -0.31506529450416565
Final reward: -0.3225261867046356
Final reward: -0.3223241865634918
Final reward: -0.3257983326911926
Final reward: -0.32668882608413696
Final reward: -0.32702091336250305
Final reward: -0.3270663619041443
Final reward: -0.32703179121017456
Final reward: -0.3267812728881836
Final reward: -0.32616961002349854
Final reward: -0.3313594460487366
Final reward: -0.3189678490161896
Final reward: -0.326465368270874
Final reward: -0.30296021699905396
Final reward: -0.31307452917099
Final reward: -0.29140540957450867
Final reward: -0.31750956177711487
Final reward: -0.3004230856895447
Final reward: -0.3265668451786041
Final reward: -0.30902421474456787
Final reward: -0.3322906196117401
Final reward: -0.3172513544559479
Final reward: -0.3360413610935211
Final reward: -0.32492613792419434
Final reward: -0.3380228877067566
Final reward: -0.330985426902771
Final reward: -0.335819810628891
Final reward: -0.33728909492492676
Final reward: -0.3383522927761078
Final reward: -0.33660879731178284
Final reward: -0.3318655788898468
Final reward: -0.3245542049407959
Final reward: -0.3200443387031555
Final reward: -0.3176245391368866
Final reward: -0.3092171251773834
Final reward: -0.30785977840423584
Final reward: -0.2941310703754425
Final reward: -0.29277142882347107
Final reward: -0.2746308743953705
Final reward: -0.27173808217048645
Final reward: -0.25336936116218567
Final reward: -0.2532140612602234
Final reward: -0.2523370385169983
Final reward: -0.26167982816696167
Final reward: -0.26210296154022217
Final reward: -0.2667475938796997
Final reward: -0.26910385489463806
Final reward: -0.27119678258895874
Final reward: -0.27162373065948486
Final reward: -0.27168649435043335
Final reward: -0.2716425955295563
Final reward: -0.27133697271347046
Final reward: -0.2706179618835449
Final reward: -0.27681517601013184
Final reward: -0.26718640327453613
Final reward: -0.25770431756973267
Final reward: -0.25217708945274353
Final reward: -0.22969014942646027
Final reward: -0.25006479024887085
Final reward: -0.24267496168613434
Final reward: -0.2634885311126709
Final reward: -0.25773075222969055
Final reward: -0.2771812081336975
Final reward: -0.2716025710105896
Final reward: -0.285771906375885
Final reward: -0.294147253036499
Final reward: -0.2856358587741852
Final reward: -0.2956966459751129
Final reward: -0.2979312539100647
Final reward: -0.30047607421875
Final reward: -0.3001130223274231
Final reward: -0.2965523898601532
Final reward: -0.28934791684150696
Final reward: -0.2824445962905884
Final reward: -0.27900537848472595
Final reward: -0.27085548639297485
Final reward: -0.2679399251937866
Final reward: -0.25403931736946106
Final reward: -0.2501726448535919
Final reward: -0.23392382264137268
Final reward: -0.2294100672006607
Final reward: -0.2131963074207306
Final reward: -0.2183980494737625
Final reward: -0.2188248485326767
Final reward: -0.22743293642997742
Final reward: -0.2286452203989029
Final reward: -0.23331795632839203
Final reward: -0.2351292073726654
Final reward: -0.23655501008033752
Final reward: -0.23672451078891754
Final reward: -0.2367253303527832
Final reward: -0.2366006076335907
Final reward: -0.23592142760753632
Final reward: -0.23885713517665863
Final reward: -0.2458411008119583
Final reward: -0.22065980732440948
Final reward: -0.23217569291591644
Final reward: -0.19454842805862427
Final reward: -0.21985122561454773
Final reward: -0.195203498005867
Final reward: -0.23054902255535126
Final reward: -0.20651739835739136
Final reward: -0.2391871213912964
Final reward: -0.21895824372768402
Final reward: -0.24365676939487457
Final reward: -0.22941114008426666
Final reward: -0.24498140811920166
Final reward: -0.23660391569137573
Final reward: -0.2453480213880539
Final reward: -0.24555720388889313
Final reward: -0.24599161744117737
Final reward: -0.24287189543247223
Final reward: -0.23547649383544922
Final reward: -0.22496503591537476
Final reward: -0.2181510627269745
Final reward: -0.21745893359184265
Final reward: -0.20229409635066986
Final reward: -0.20215551555156708
Final reward: -0.17948344349861145
Final reward: -0.17838871479034424
Final reward: -0.15035668015480042
Final reward: -0.14714336395263672
Final reward: -0.13944163918495178
Final reward: -0.16080884635448456
Final reward: -0.1593172252178192
Final reward: -0.17349375784397125
Final reward: -0.17328904569149017
Final reward: -0.17959468066692352
Final reward: -0.18139033019542694
Final reward: -0.1822761446237564
Final reward: -0.18238434195518494
Final reward: -0.18232938647270203
Final reward: -0.18191631138324738
Final reward: -0.18033424019813538
Final reward: -0.18939583003520966
Final reward: -0.17174279689788818
Final reward: -0.18416383862495422
Final reward: -0.13658681511878967
Final reward: -0.15745320916175842
Final reward: -0.07946347445249557
Final reward: -0.47091415524482727
Final reward: -0.4698409140110016
Final reward: -0.4677351117134094
Final reward: -0.4642217755317688
Final reward: -0.46055203676223755
Final reward: -0.45492470264434814
Final reward: -0.4493684470653534
Final reward: -0.44162464141845703
Final reward: -0.43384912610054016
Final reward: -0.4237916171550751
Final reward: -0.4136911630630493
Final reward: -0.4017709791660309
Final reward: -0.3928869962692261
Final reward: -0.393873929977417
Final reward: -0.3978099822998047
Final reward: -0.39881962537765503
Final reward: -0.40239429473876953
Final reward: -0.4030279815196991
Final reward: -0.40619704127311707
Final reward: -0.4064832925796509
Final reward: -0.40919169783592224
Final reward: -0.40937572717666626
Final reward: -0.41177403926849365
Final reward: -0.41339948773384094
Final reward: -0.41632896661758423
Final reward: -0.41734451055526733
Final reward: -0.41782087087631226
Final reward: -0.4179207980632782
Final reward: -0.41775357723236084
Final reward: -0.4177819788455963
Final reward: -0.4180024266242981
Final reward: -0.4181447923183441
Final reward: -0.4176744222640991
Final reward: -0.4210161864757538
Final reward: -0.4109309911727905
Final reward: -0.4153061509132385
Final reward: -0.40122243762016296
Final reward: -0.40681639313697815
Final reward: -0.3883775472640991
Final reward: -0.39541587233543396
Final reward: -0.3721943795681
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.3807714283466339
Final reward: -0.35285210609436035
Final reward: -0.36233994364738464
Final reward: -0.33235517144203186
Final reward: -0.3496303856372833
Final reward: -0.3392651379108429
Final reward: -0.3646765351295471
Final reward: -0.3548971116542816
Final reward: -0.37510621547698975
Final reward: -0.36735835671424866
Final reward: -0.38290858268737793
Final reward: -0.37691253423690796
Final reward: -0.3881992697715759
Final reward: -0.38373062014579773
Final reward: -0.39104121923446655
Final reward: -0.39264976978302
Final reward: -0.3959369361400604
Final reward: -0.39724692702293396
Final reward: -0.3961324691772461
Final reward: -0.3924870789051056
Final reward: -0.3865970969200134
Final reward: -0.3830105662345886
Final reward: -0.3772134780883789
Final reward: -0.3717021346092224
Final reward: -0.363544225692749
Final reward: -0.3554549813270569
Final reward: -0.3444342613220215
Final reward: -0.33354324102401733
Final reward: -0.319118469953537
Final reward: -0.3065270185470581
Final reward: -0.2877415120601654
Final reward: -0.28659331798553467
Final reward: -0.28730887174606323
Final reward: -0.2940365672111511
Final reward: -0.29490354657173157
Final reward: -0.3000301420688629
Final reward: -0.3012915551662445
Final reward: -0.3057202100753784
Final reward: -0.3064318895339966
Final reward: -0.310260534286499
Final reward: -0.31221044063568115
Final reward: -0.3167445957660675
Final reward: -0.3182397186756134
Final reward: -0.3215693533420563
Final reward: -0.3224007785320282
Final reward: -0.3229602873325348
Final reward: -0.3225831985473633
Final reward: -0.32222121953964233
Final reward: -0.322265625
Final reward: -0.32271867990493774
Final reward: -0.3232381045818329
Final reward: -0.32313913106918335
Final reward: -0.32493138313293457
Final reward: -0.3157235383987427
Final reward: -0.3191726505756378
Final reward: -0.30496278405189514
Final reward: -0.31034547090530396
Final reward: -0.29054316878318787
Final reward: -0.29823023080825806
Final reward: -0.27195024490356445
Final reward: -0.28246453404426575
Final reward: -0.24840548634529114
Final reward: -0.26222699880599976
Final reward: -0.21900908648967743
Final reward: -0.24184775352478027
Final reward: -0.22815941274166107
Final reward: -0.27342960238456726
Final reward: -0.2622368633747101
Final reward: -0.30018848180770874
Final reward: -0.29100728034973145
Final reward: -0.32240620255470276
Final reward: -0.3157424330711365
Final reward: -0.3402669429779053
Final reward: -0.33565253019332886
Final reward: -0.35417813062667847
Final reward: -0.3512330949306488
Final reward: -0.3645313084125519
Final reward: -0.3629780113697052
Final reward: -0.3715687394142151
Final reward: -0.3728872537612915
Final reward: -0.38195016980171204
Final reward: -0.37798094749450684
Final reward: -0.38155099749565125
Final reward: -0.3824111521244049
Final reward: -0.380685031414032
Final reward: -0.3762018382549286
Final reward: -0.37203219532966614
Final reward: -0.36767876148223877
Final reward: -0.36281949281692505
Final reward: -0.3554897606372833
Final reward: -0.3482692241668701
Final reward: -0.33807605504989624
Final reward: -0.3278500437736511
Final reward: -0.3143719434738159
Final reward: -0.302387535572052
Final reward: -0.282772034406662
Final reward: -0.2685013711452484
Final reward: -0.24040769040584564
Final reward: -0.22210846841335297
Final reward: -0.18097248673439026
Final reward: -0.15362630784511566
Final reward: -0.11861154437065125
Final reward: -0.5498690009117126
Final reward: -0.5510995388031006
Final reward: -0.5529778003692627
Final reward: -0.5492880940437317
Final reward: -0.5435175895690918
Final reward: -0.5475938320159912
Final reward: -0.5337450504302979
Final reward: -0.539604127407074
Final reward: -0.5220215320587158
Final reward: -0.5285100936889648
Final reward: -0.5098475813865662
Final reward: -0.5162233114242554
Final reward: -0.4985937178134918
Final reward: -0.5051496624946594
Final reward: -0.494900107383728
Final reward: -0.506047785282135
Final reward: -0.49885979294776917
Final reward: -0.5072454810142517
Final reward: -0.502504825592041
Final reward: -0.5075511336326599
Final reward: -0.5102318525314331
Final reward: -0.5112704634666443
Final reward: -0.5106372237205505
Final reward: -0.5082674026489258
Final reward: -0.5038787722587585
Final reward: -0.49745267629623413
Final reward: -0.493936687707901
Final reward: -0.4882870614528656
Final reward: -0.4823305904865265
Final reward: -0.4764619469642639
Final reward: -0.478528767824173
Final reward: -0.47791945934295654
Final reward: -0.47994863986968994
Final reward: -0.4794045090675354
Final reward: -0.4812053442001343
Final reward: -0.48050808906555176
Final reward: -0.4820966124534607
Final reward: -0.48401907086372375
Final reward: -0.48930615186691284
Final reward: -0.4892333149909973
Final reward: -0.48901984095573425
Final reward: -0.489429771900177
Final reward: -0.4889388382434845
Final reward: -0.48849329352378845
Final reward: -0.48839622735977173
Final reward: -0.4887213110923767
Final reward: -0.4893161654472351
Final reward: -0.48980194330215454
Final reward: -0.4895731806755066
Final reward: -0.49253541231155396
Final reward: -0.48314169049263
Final reward: -0.48703092336654663
Final reward: -0.4743652641773224
Final reward: -0.47891858220100403
Final reward: -0.4640732705593109
Final reward: -0.4690021276473999
Final reward: -0.4531204104423523
Final reward: -0.45825713872909546
Final reward: -0.44228601455688477
Final reward: -0.44739171862602234
Final reward: -0.44190719723701477
Final reward: -0.45309513807296753
Final reward: -0.44851791858673096
Final reward: -0.4562881886959076
Final reward: -0.4583205580711365
Final reward: -0.46323099732398987
Final reward: -0.465327650308609
Final reward: -0.4659975469112396
Final reward: -0.4648059606552124
Final reward: -0.46161720156669617
Final reward: -0.4560598134994507
Final reward: -0.4503672420978546
Final reward: -0.4457492530345917
Final reward: -0.4399726688861847
Final reward: -0.4321959316730499
Final reward: -0.42696380615234375
Final reward: -0.42618200182914734
Final reward: -0.4286987781524658
Final reward: -0.42826274037361145
Final reward: -0.4305219054222107
Final reward: -0.4298691153526306
Final reward: -0.4318596422672272
Final reward: -0.4316389262676239
Final reward: -0.43380066752433777
Final reward: -0.43359071016311646
Final reward: -0.4352966547012329
Final reward: -0.43503645062446594
Final reward: -0.43555280566215515
Final reward: -0.43497493863105774
Final reward: -0.43440157175064087
Final reward: -0.43421226739883423
Final reward: -0.4345279037952423
Final reward: -0.435215026140213
Final reward: -0.4358861446380615
Final reward: -0.43589890003204346
Final reward: -0.43789398670196533
Final reward: -0.4298047125339508
Final reward: -0.4365807771682739
Final reward: -0.4168958067893982
Final reward: -0.4246336817741394
Final reward: -0.40198713541030884
Final reward: -0.41002947092056274
Final reward: -0.38651686906814575
Final reward: -0.39494800567626953
Final reward: -0.3703783452510834
Final reward: -0.3791366219520569
Final reward: -0.35725313425064087
Final reward: -0.37583792209625244
Final reward: -0.3646504580974579
Final reward: -0.3775075674057007
Final reward: -0.3703533113002777
Final reward: -0.37773996591567993
Final reward: -0.37836989760398865
Final reward: -0.38034749031066895
Final reward: -0.37997400760650635
Final reward: -0.3771814703941345
Final reward: -0.37163659930229187
Final reward: -0.36434540152549744
Final reward: -0.35954999923706055
Final reward: -0.35184526443481445
Final reward: -0.3437831997871399
Final reward: -0.333479642868042
Final reward: -0.3362189531326294
Final reward: -0.33531394600868225
Final reward: -0.33828073740005493
Final reward: -0.33749741315841675
Final reward: -0.3400619924068451
Final reward: -0.33909252285957336
Final reward: -0.34145286679267883
Final reward: -0.34309712052345276
Final reward: -0.34715360403060913
Final reward: -0.3485596477985382
Final reward: -0.349711537361145
Final reward: -0.3489963412284851
Final reward: -0.3477708399295807
Final reward: -0.3467859625816345
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.3465065658092499
Final reward: -0.34706780314445496
Final reward: -0.3482881188392639
Final reward: -0.3496706783771515
Final reward: -0.35040220618247986
Final reward: -0.3501415252685547
Final reward: -0.35734254121780396
Final reward: -0.3361896574497223
Final reward: -0.3452737331390381
Final reward: -0.3182803690433502
Final reward: -0.32825207710266113
Final reward: -0.29769167304039
Final reward: -0.30803361535072327
Final reward: -0.2769361436367035
Final reward: -0.28782883286476135
Final reward: -0.2573128640651703
Final reward: -0.282777339220047
Final reward: -0.2667514979839325
Final reward: -0.28771746158599854
Final reward: -0.2759377062320709
Final reward: -0.2892666459083557
Final reward: -0.2826269865036011
Final reward: -0.2887710630893707
Final reward: -0.291293740272522
Final reward: -0.29058030247688293
Final reward: -0.2865656316280365
Final reward: -0.27872928977012634
Final reward: -0.2714841365814209
Final reward: -0.2644003629684448
Final reward: -0.25413978099823
Final reward: -0.24669964611530304
Final reward: -0.2335393726825714
Final reward: -0.23865996301174164
Final reward: -0.2393912523984909
Final reward: -0.2502802610397339
Final reward: -0.25103288888931274
Final reward: -0.2607705593109131
Final reward: -0.26173657178878784
Final reward: -0.2674780786037445
Final reward: -0.26967114210128784
Final reward: -0.2727352976799011
Final reward: -0.2728930413722992
Final reward: -0.27235305309295654
Final reward: -0.27130523324012756
Final reward: -0.2707294821739197
Final reward: -0.2709640860557556
Final reward: -0.2719351053237915
Final reward: -0.2731610834598541
Final reward: -0.2737584114074707
Final reward: -0.27316486835479736
Final reward: -0.2818880081176758
Final reward: -0.2568305432796478
Final reward: -0.26772886514663696
Final reward: -0.235622376203537
Final reward: -0.24792742729187012
Final reward: -0.21017876267433167
Final reward: -0.22355598211288452
Final reward: -0.18352332711219788
Final reward: -0.19853101670742035
Final reward: -0.17630024254322052
Final reward: -0.20727230608463287
Final reward: -0.19030620157718658
Final reward: -0.21030175685882568
Final reward: -0.20037607848644257
Final reward: -0.2102905958890915
Final reward: -0.21489660441875458
Final reward: -0.21503779292106628
Final reward: -0.21078693866729736
Final reward: -0.20145514607429504
Final reward: -0.1892865002155304
Final reward: -0.1802557110786438
Final reward: -0.16504257917404175
Final reward: -0.14733976125717163
Final reward: -0.12494704872369766
Final reward: -0.13675209879875183
Final reward: -0.1403314471244812
Final reward: -0.15163922309875488
Final reward: -0.16055215895175934
Final reward: -0.16488945484161377
Final reward: -0.19750450551509857
Final reward: -0.18589551746845245
Final reward: -0.2215663492679596
Final reward: -0.21382683515548706
Final reward: -0.23607264459133148
Final reward: -0.2449510246515274
Final reward: -0.2560080885887146
Final reward: -0.26241710782051086
Final reward: -0.26393431425094604
Final reward: -0.2605811357498169
Final reward: -0.2522404193878174
Final reward: -0.23868219554424286
Final reward: -0.21965838968753815
Final reward: -0.20449642837047577
Final reward: -0.21087701618671417
Final reward: -0.18712320923805237
Final reward: -0.1966424137353897
Final reward: -0.16178089380264282
Final reward: -0.17416097223758698
Final reward: -0.13049986958503723
Final reward: -0.14535614848136902
Final reward: -0.0896427258849144
Final reward: -0.5122069120407104
Final reward: -0.5135276913642883
Final reward: -0.5155428647994995
Final reward: -0.5088821053504944
Final reward: -0.5110500454902649
Final reward: -0.49994009733200073
Final reward: -0.5050340890884399
Final reward: -0.49053627252578735
Final reward: -0.4962035119533539
Final reward: -0.4790549874305725
Final reward: -0.48508647084236145
Final reward: -0.4670557677745819
Final reward: -0.47316962480545044
Final reward: -0.4561544954776764
Final reward: -0.470215380191803
Final reward: -0.4615766704082489
Final reward: -0.47363370656967163
Final reward: -0.46691781282424927
Final reward: -0.4749704599380493
Final reward: -0.47101151943206787
Final reward: -0.4749065637588501
Final reward: -0.4765792787075043
Final reward: -0.4762363135814667
Final reward: -0.4738594591617584
Final reward: -0.4692075252532959
Final reward: -0.46553903818130493
Final reward: -0.46141383051872253
Final reward: -0.4574171006679535
Final reward: -0.4513384997844696
Final reward: -0.445545494556427
Final reward: -0.44268810749053955
Final reward: -0.44693613052368164
Final reward: -0.4480474591255188
Final reward: -0.4514171779155731
Final reward: -0.4524992108345032
Final reward: -0.4554153084754944
Final reward: -0.4561821222305298
Final reward: -0.45862430334091187
Final reward: -0.45914021134376526
Final reward: -0.4608260691165924
Final reward: -0.4610283076763153
Final reward: -0.46075916290283203
Final reward: -0.4605134427547455
Final reward: -0.46053940057754517
Final reward: -0.4608418941497803
Final reward: -0.46118462085723877
Final reward: -0.46109071373939514
Final reward: -0.46244555711746216
Final reward: -0.46056434512138367
Final reward: -0.45081737637519836
Final reward: -0.4546166956424713
Final reward: -0.4417182207107544
Final reward: -0.44611626863479614
Final reward: -0.43188658356666565
Final reward: -0.4357306957244873
Final reward: -0.4231373071670532
Final reward: -0.426456093788147
Final reward: -0.4229671359062195
Final reward: -0.4324358403682709
Final reward: -0.4295251965522766
Final reward: -0.43569836020469666
Final reward: -0.442282110452652
Final reward: -0.4412693679332733
Final reward: -0.4432726502418518
Final reward: -0.44312891364097595
Final reward: -0.44084399938583374
Final reward: -0.43617478013038635
Final reward: -0.43127381801605225
Final reward: -0.4271398186683655
Final reward: -0.42180192470550537
Final reward: -0.4144374430179596
Final reward: -0.41079437732696533
Final reward: -0.4102681875228882
Final reward: -0.4126247465610504
Final reward: -0.4120778739452362
Final reward: -0.4142606258392334
Final reward: -0.4146113991737366
Final reward: -0.4173530340194702
Final reward: -0.41767263412475586
Final reward: -0.41990625858306885
Final reward: -0.42000964283943176
Final reward: -0.42161160707473755
Final reward: -0.4215913712978363
Final reward: -0.42112433910369873
Final reward: -0.4207606911659241
Final reward: -0.42078065872192383
Final reward: -0.42119860649108887
Final reward: -0.4217657744884491
Final reward: -0.4219704270362854
Final reward: -0.4218420088291168
Final reward: -0.42724061012268066
Final reward: -0.4114328920841217
Final reward: -0.41838616132736206
Final reward: -0.39865440130233765
Final reward: -0.4059540331363678
Final reward: -0.3843414783477783
Final reward: -0.39212092757225037
Final reward: -0.36934182047843933
Final reward: -0.37699419260025024
Final reward: -0.36376476287841797
Final reward: -0.379803329706192
Final reward: -0.3706505596637726
Final reward: -0.38155144453048706
Final reward: -0.37616950273513794
Final reward: -0.38159310817718506
Final reward: -0.38419100642204285
Final reward: -0.38430342078208923
Final reward: -0.38197121024131775
Final reward: -0.3769327700138092
Final reward: -0.3706210255622864
Final reward: -0.36610618233680725
Final reward: -0.359266459941864
Final reward: -0.353632390499115
Final reward: -0.3475658893585205
Final reward: -0.3527016341686249
Final reward: -0.35422319173812866
Final reward: -0.358533650636673
Final reward: -0.3601353168487549
Final reward: -0.36422523856163025
Final reward: -0.3657081127166748
Final reward: -0.3690297603607178
Final reward: -0.37004610896110535
Final reward: -0.3719114363193512
Final reward: -0.37200605869293213
Final reward: -0.3715824484825134
Final reward: -0.37124502658843994
Final reward: -0.37129276990890503
Final reward: -0.3717231750488281
Final reward: -0.37223485112190247
Final reward: -0.372228741645813
Final reward: -0.3734305500984192
Final reward: -0.37366753816604614
Final reward: -0.3594454526901245
Final reward: -0.36526912450790405
Final reward: -0.346744567155838
Final reward: -0.3534904420375824
Final reward: -0.3322509527206421
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.339124470949173
Final reward: -0.3230735957622528
Final reward: -0.34051042795181274
Final reward: -0.3323575556278229
Final reward: -0.34517213702201843
Final reward: -0.3388690948486328
Final reward: -0.34731534123420715
Final reward: -0.35250455141067505
Final reward: -0.35533347725868225
Final reward: -0.3555299937725067
Final reward: -0.35314980149269104
Final reward: -0.34790781140327454
Final reward: -0.33970460295677185
Final reward: -0.3350566029548645
Final reward: -0.327495813369751
Final reward: -0.31954121589660645
Final reward: -0.3086067736148834
Final reward: -0.3040567934513092
Final reward: -0.3036971688270569
Final reward: -0.3073132634162903
Final reward: -0.3069521188735962
Final reward: -0.31019166111946106
Final reward: -0.3122471272945404
Final reward: -0.3174205422401428
Final reward: -0.3193780779838562
Final reward: -0.32334956526756287
Final reward: -0.32458221912384033
Final reward: -0.325671523809433
Final reward: -0.3250747621059418
Final reward: -0.3241700232028961
Final reward: -0.32362279295921326
Final reward: -0.3237498104572296
Final reward: -0.3245239555835724
Final reward: -0.3255772590637207
Final reward: -0.3262025713920593
Final reward: -0.3253559172153473
Final reward: -0.3323286175727844
Final reward: -0.3132745027542114
Final reward: -0.3213983178138733
Final reward: -0.29700013995170593
Final reward: -0.30622005462646484
Final reward: -0.2782951593399048
Final reward: -0.2878163456916809
Final reward: -0.2595110535621643
Final reward: -0.2692381739616394
Final reward: -0.2411651313304901
Final reward: -0.2647351026535034
Final reward: -0.25052860379219055
Final reward: -0.26861727237701416
Final reward: -0.25946328043937683
Final reward: -0.2705475091934204
Final reward: -0.2712663412094116
Final reward: -0.274568110704422
Final reward: -0.2743651270866394
Final reward: -0.2706655263900757
Final reward: -0.2629806399345398
Final reward: -0.25523343682289124
Final reward: -0.2481277585029602
Final reward: -0.23828966915607452
Final reward: -0.226608008146286
Final reward: -0.22281746566295624
Final reward: -0.2400902807712555
Final reward: -0.23804102838039398
Final reward: -0.2555868923664093
Final reward: -0.25307998061180115
Final reward: -0.25829097628593445
Final reward: -0.2588708698749542
Final reward: -0.26238083839416504
Final reward: -0.26272696256637573
Final reward: -0.2637908160686493
Final reward: -0.2631518542766571
Final reward: -0.2624819576740265
Final reward: -0.2623406946659088
Final reward: -0.26285967230796814
Final reward: -0.26374608278274536
Final reward: -0.2642880380153656
Final reward: -0.2633581757545471
Final reward: -0.2707560360431671
Final reward: -0.24991531670093536
Final reward: -0.25908973813056946
Final reward: -0.23108452558517456
Final reward: -0.24062083661556244
Final reward: -0.21076369285583496
Final reward: -0.2211420089006424
Final reward: -0.18920515477657318
Final reward: -0.21038317680358887
Final reward: -0.19566398859024048
Final reward: -0.21815143525600433
Final reward: -0.20659248530864716
Final reward: -0.22230826318264008
Final reward: -0.2281065732240677
Final reward: -0.231255903840065
Final reward: -0.233379527926445
Final reward: -0.23154009878635406
Final reward: -0.22548149526119232
Final reward: -0.2142527997493744
Final reward: -0.20527420938014984
Final reward: -0.19487068057060242
Final reward: -0.1842203289270401
Final reward: -0.1674392819404602
Final reward: -0.16364260017871857
Final reward: -0.1661677360534668
Final reward: -0.17475922405719757
Final reward: -0.17712099850177765
Final reward: -0.1851987987756729
Final reward: -0.18745091557502747
Final reward: -0.1941741406917572
Final reward: -0.1956399828195572
Final reward: -0.2007570117712021
Final reward: -0.20405665040016174
Final reward: -0.20440277457237244
Final reward: -0.21653617918491364
Final reward: -0.22545307874679565
Final reward: -0.22876082360744476
Final reward: -0.22655458748340607
Final reward: -0.2187204658985138
Final reward: -0.2049502432346344
Final reward: -0.2041839212179184
Final reward: -0.21086031198501587
Final reward: -0.1893453150987625
Final reward: -0.19853803515434265
Final reward: -0.16708944737911224
Final reward: -0.1796434372663498
Final reward: -0.13680770993232727
Final reward: -0.15069285035133362
Final reward: -0.10291418433189392
Final reward: -0.47154632210731506
Final reward: -0.47298067808151245
Final reward: -0.47516781091690063
Final reward: -0.47604134678840637
Final reward: -0.46506279706954956
Final reward: -0.46947187185287476
Final reward: -0.45301902294158936
Final reward: -0.4594191312789917
Final reward: -0.4370400011539459
Final reward: -0.4456351399421692
Final reward: -0.4188612401485443
Final reward: -0.4281634986400604
Final reward: -0.3989991843700409
Final reward: -0.4200420081615448
Final reward: -0.40136319398880005
Final reward: -0.42553848028182983
Final reward: -0.4068320691585541
Final reward: -0.4303435981273651
Final reward: -0.4125051498413086
Final reward: -0.4335055947303772
Final reward: -0.41777440905570984
Final reward: -0.4352039098739624
Final reward: -0.42261990904808044
Final reward: -0.43036019802093506
Final reward: -0.4226458668708801
Final reward: -0.4319568872451782
Final reward: -0.43283215165138245
Final reward: -0.4349970817565918
Final reward: -0.4368606209754944
Final reward: -0.4366604685783386
Final reward: -0.434394508600235
Final reward: -0.42979860305786133
Final reward: -0.4227822721004486
Final reward: -0.41887345910072327
Final reward: -0.41680240631103516
Final reward: -0.4097023010253906
Final reward: -0.40777623653411865
Final reward: -0.39694082736968994
Final reward: -0.39502790570259094
Final reward: -0.38020646572113037
Final reward: -0.37793636322021484
Final reward: -0.36021560430526733
Final reward: -0.3571215271949768
Final reward: -0.33900126814842224
Final reward: -0.3418792188167572
Final reward: -0.34044578671455383
Final reward: -0.351948618888855
Final reward: -0.3511139154434204
Final reward: -0.3597201108932495
Final reward: -0.359701931476593
Final reward: -0.3651045560836792
Final reward: -0.3661002814769745
Final reward: -0.36927980184555054
Final reward: -0.3703867197036743
Final reward: -0.37178730964660645
Final reward: -0.371980220079422
Final reward: -0.37198275327682495
Final reward: -0.3719920814037323
Final reward: -0.3719039559364319
Final reward: -0.3713153302669525
Final reward: -0.37463706731796265
Final reward: -0.3790907859802246
Final reward: -0.36145663261413574
Final reward: -0.36833423376083374
Final reward: -0.3431260585784912
Final reward: -0.35277003049850464
Final reward: -0.32025620341300964
Final reward: -0.3322819173336029
Final reward: -0.2951456308364868
Final reward: -0.309926837682724
Final reward: -0.28557348251342773
Final reward: -0.3172360360622406
Final reward: -0.2937069237232208
Final reward: -0.32209715247154236
Final reward: -0.30143240094184875
Final reward: -0.32422924041748047
Final reward: -0.30790382623672485
Final reward: -0.32335418462753296
Final reward: -0.3118211030960083
Final reward: -0.32387346029281616
Final reward: -0.3171331286430359
Final reward: -0.3230344355106354
Final reward: -0.325756698846817
Final reward: -0.3257148861885071
Final reward: -0.32293564081192017
Final reward: -0.3170557916164398
Final reward: -0.3073230981826782
Final reward: -0.3015695810317993
Final reward: -0.30036461353302
Final reward: -0.2895655333995819
Final reward: -0.28872811794281006
Final reward: -0.27240437269210815
Final reward: -0.27177751064300537
Final reward: -0.24945084750652313
Final reward: -0.24785825610160828
Final reward: -0.2219848483800888
Final reward: -0.23788361251354218
Final reward: -0.23546701669692993
Final reward: -0.2517794370651245
Final reward: -0.2503560483455658
Final reward: -0.26193955540657043
Final reward: -0.26164916157722473
Final reward: -0.26849910616874695
Final reward: -0.2695334255695343
Final reward: -0.2725673019886017
Final reward: -0.27328628301620483
Final reward: -0.27329498529434204
Final reward: -0.2732318341732025
Final reward: -0.27332183718681335
Final reward: -0.27338024973869324
Final reward: -0.27281567454338074
Final reward: -0.2760007977485657
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.2825181484222412
Final reward: -0.2581293284893036
Final reward: -0.2683594822883606
Final reward: -0.23256315290927887
Final reward: -0.24689476191997528
Final reward: -0.2047014832496643
Final reward: -0.22176837921142578
Final reward: -0.16635483503341675
Final reward: -0.20440204441547394
Final reward: -0.17150744795799255
Final reward: -0.21107862889766693
Final reward: -0.18523874878883362
Final reward: -0.21521800756454468
Final reward: -0.19564500451087952
Final reward: -0.21688693761825562
Final reward: -0.20454682409763336
Final reward: -0.2161264717578888
Final reward: -0.21755842864513397
Final reward: -0.21981564164161682
Final reward: -0.21806037425994873
Final reward: -0.21202808618545532
Final reward: -0.20067936182022095
Final reward: -0.18671754002571106
Final reward: -0.17707008123397827
Final reward: -0.17903469502925873
Final reward: -0.1558268815279007
Final reward: -0.15908603370189667
Final reward: -0.12294042110443115
Final reward: -0.12529204785823822
Final reward: -0.10723195970058441
Final reward: -0.3197210133075714
Final reward: -0.3183057904243469
Final reward: -0.31550198793411255
Final reward: -0.31238147616386414
Final reward: -0.30828627943992615
Final reward: -0.31310752034187317
Final reward: -0.2963699698448181
Final reward: -0.3030317723751068
Final reward: -0.281085342168808
Final reward: -0.28913140296936035
Final reward: -0.26326295733451843
Final reward: -0.27193406224250793
Final reward: -0.2440483123064041
Final reward: -0.2555354833602905
Final reward: -0.24544371664524078
Final reward: -0.26486510038375854
Final reward: -0.25660449266433716
Final reward: -0.2698085904121399
Final reward: -0.2637670338153839
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: \ 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: | 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: / 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                   avg_speed ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÅ‚ñÇ
wandb:                        cost ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ
wandb:                  is_success ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   max_speed ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÅ‚ñÇ
wandb:                      reward ‚ñÅ‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñÖ‚ñÑ‚ñá‚ñá
wandb:             train/approx_kl ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÑ‚ñá‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÑ‚ñÉ
wandb:         train/clip_fraction ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÇ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñá‚ñá‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñá‚ñÑ
wandb:            train/clip_range ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/cost_returns ‚ñÜ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ
wandb:       train/cost_value_loss ‚ñá‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ
wandb:           train/cost_values ‚ñÉ‚ñÖ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ
wandb:               train/entropy ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:          train/entropy_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:    train/explained_variance ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñÑ‚ñÜ‚ñÇ‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train/lagrangian_multiplier ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÅ‚ñÖ
wandb:         train/learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  train/loss ‚ñà‚ñÜ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:             train/n_updates ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  train/policy_gradient_loss ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñá‚ñá‚ñÖ‚ñÑ‚ñá‚ñÇ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÖ
wandb:                   train/std ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            train/value_loss ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                   avg_speed 1.03124
wandb:                        cost 0
wandb:                  is_success 0
wandb:                   max_speed 1.03124
wandb:                      reward -0.76913
wandb:             train/approx_kl 0.00464
wandb:         train/clip_fraction 0.04731
wandb:            train/clip_range 0.2
wandb:          train/cost_returns 4.85387
wandb:       train/cost_value_loss 43.48832
wandb:           train/cost_values 2.06105
wandb:               train/entropy -0.28249
wandb:          train/entropy_loss -0.28382
wandb:    train/explained_variance 0.99113
wandb: train/lagrangian_multiplier 0.00483
wandb:         train/learning_rate 0.0003
wandb:                  train/loss 10.14646
wandb:             train/n_updates 14690
wandb:  train/policy_gradient_loss -0.00329
wandb:                   train/std 0.27998
wandb:            train/value_loss 10.36404
wandb: 
wandb: üöÄ View run solar-frost-48 at: https://wandb.ai/ecrl/seed-testing/runs/tggzx3rw
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240123_021837-tggzx3rw/logs
